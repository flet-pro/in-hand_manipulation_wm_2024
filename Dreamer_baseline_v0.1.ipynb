{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ba316b01-928d-46bc-aaae-21f55459fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium-robotics in /root/venv/work/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: mujoco<3.2.0,>=2.2.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium-robotics) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium-robotics) (1.26.4)\n",
      "Requirement already satisfied: gymnasium>=1.0.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium-robotics) (1.0.0)\n",
      "Requirement already satisfied: PettingZoo>=1.23.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium-robotics) (1.24.3)\n",
      "Requirement already satisfied: Jinja2>=3.0.3 in /root/venv/work/lib/python3.10/site-packages (from gymnasium-robotics) (3.1.4)\n",
      "Requirement already satisfied: imageio in /root/venv/work/lib/python3.10/site-packages (from gymnasium-robotics) (2.36.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium>=1.0.0->gymnasium-robotics) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium>=1.0.0->gymnasium-robotics) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /root/venv/work/lib/python3.10/site-packages (from gymnasium>=1.0.0->gymnasium-robotics) (0.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/venv/work/lib/python3.10/site-packages (from Jinja2>=3.0.3->gymnasium-robotics) (3.0.1)\n",
      "Requirement already satisfied: absl-py in /root/venv/work/lib/python3.10/site-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (2.1.0)\n",
      "Requirement already satisfied: etils[epath] in /root/venv/work/lib/python3.10/site-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.11.0)\n",
      "Requirement already satisfied: glfw in /root/venv/work/lib/python3.10/site-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (2.8.0)\n",
      "Requirement already satisfied: pyopengl in /root/venv/work/lib/python3.10/site-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.1.7)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /root/venv/work/lib/python3.10/site-packages (from imageio->gymnasium-robotics) (11.0.0)\n",
      "Requirement already satisfied: fsspec in /root/venv/work/lib/python3.10/site-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in /root/venv/work/lib/python3.10/site-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (6.4.5)\n",
      "Requirement already satisfied: zipp in /root/venv/work/lib/python3.10/site-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.21.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /root/venv/work/lib/python3.10/site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/venv/work/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /root/venv/work/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy<2.0 in /root/venv/work/lib/python3.10/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: stable_baselines3 in /root/venv/work/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /root/venv/work/lib/python3.10/site-packages (from stable_baselines3) (1.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.20 in /root/venv/work/lib/python3.10/site-packages (from stable_baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /root/venv/work/lib/python3.10/site-packages (from stable_baselines3) (2.0.0+cu118)\n",
      "Requirement already satisfied: cloudpickle in /root/venv/work/lib/python3.10/site-packages (from stable_baselines3) (3.1.0)\n",
      "Requirement already satisfied: pandas in /root/venv/work/lib/python3.10/site-packages (from stable_baselines3) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /root/venv/work/lib/python3.10/site-packages (from stable_baselines3) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /root/venv/work/lib/python3.10/site-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /root/venv/work/lib/python3.10/site-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /root/venv/work/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3) (3.16.1)\n",
      "Requirement already satisfied: sympy in /root/venv/work/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3) (1.13.3)\n",
      "Requirement already satisfied: networkx in /root/venv/work/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /root/venv/work/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/venv/work/lib/python3.10/site-packages (from torch>=1.13->stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: cmake in /root/venv/work/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13->stable_baselines3) (3.30.4)\n",
      "Requirement already satisfied: lit in /root/venv/work/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13->stable_baselines3) (18.1.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/venv/work/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/venv/work/lib/python3.10/site-packages (from pandas->stable_baselines3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/venv/work/lib/python3.10/site-packages (from pandas->stable_baselines3) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/venv/work/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/venv/work/lib/python3.10/site-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/venv/work/lib/python3.10/site-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /root/venv/work/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /root/venv/work/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /root/venv/work/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (5.29.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /root/venv/work/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /root/venv/work/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: einops in /root/venv/work/lib/python3.10/site-packages (0.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium-robotics\n",
    "!pip install matplotlib\n",
    "!pip install 'numpy<2.0'\n",
    "!pip install stable_baselines3\n",
    "!pip install opencv-python\n",
    "!pip install tensorboard\n",
    "!pip install einops\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d243ab82-ae6e-461d-80d2-7091f72ca387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MUJOCO_GL=egl\n"
     ]
    }
   ],
   "source": [
    "%env MUJOCO_GL=egl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff30a50-e0f8-4793-acbf-2117232cf5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch.deviceを定義．この変数は後々モデルやデータをGPUに転送する時にも使います\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2992bbc0-6953-4457-a119-7a25dfd12828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  5 23:53:38 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.72                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "|  0%   32C    P8              3W /  450W |     792MiB /  24564MiB |     21%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        24      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "01b3edd1-36c9-4f76-b245-4eb17e00c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from typing import Any, List, Tuple\n",
    "\n",
    "# import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import pybullet_envs  # PyBulletの環境をgymに登録する\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from einops import rearrange\n",
    "\n",
    "# 可視化のためにTensorBoardを用いるので，Colab上でTensorBoardを表示するための宣言を行う\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cb36a4ac-8ee8-4817-bfa8-9e91e2c4e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "\n",
    "# gym.register_envs(gymnasium_robotics)\n",
    "\n",
    "env = gym.make('HandManipulateEgg_BooleanTouchSensors-v1', render_mode=\"rgb_array\")\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(2):\n",
    "    action = env.action_space.sample()  # User-defined policy function\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    print(terminated)\n",
    "\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b4149-0f5b-47d7-bf1f-14a33d0f7b08",
   "metadata": {},
   "source": [
    " この環境のアクションは、手の各関節の目標角度を指定する連続値のベクトルで構成されています。各要素は対応する関節の目標角度を表し、一般的に-1から1の範囲で正規化されています。これらの値は、実際の関節角度にマッピングされ、手の動作を制御します。(ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3738c24-5674-400c-8342-af1ba0364020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9997618 , -0.54609793,  0.9564068 , -0.8345315 , -0.08502209,\n",
       "        0.6398142 , -0.00447307,  0.44555607, -0.7514431 ,  0.84015286,\n",
       "       -0.20886995, -0.5462471 ,  0.23273464, -0.8776227 ,  0.3450948 ,\n",
       "        0.32649797, -0.04635695,  0.48766968, -0.47548178,  0.0259785 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bb085-500f-45d5-84fb-b0de1e9b19b8",
   "metadata": {},
   "source": [
    "観測（オブザベーション）: 観測は、手の状態、物体の状態、目標状態、そしてタッチセンサーの情報を含むベクトルです。具体的には、以下の情報が含まれます：\n",
    "\n",
    "- 手の関節角度と速度: 各関節の現在の角度とその変化率。\n",
    "- 物体の位置と回転: 操作対象である卵の現在の位置と回転状態。\n",
    "- 目標位置と回転: 卵が達成すべき目標の位置と回転状態。\n",
    "- タッチセンサーの状態: 各センサーが接触を検出しているかどうかを示すブール値。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98b6bb1d-59d2-4089-a3e7-134176156aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation': array([-2.82567281e-01, -1.74904921e-01,  1.17510004e-01,  7.81172159e-01,\n",
       "         6.03863308e-01,  6.11211321e-01,  8.72080307e-03,  6.56297466e-01,\n",
       "         8.12277325e-01,  7.66396317e-01, -8.76329401e-02,  7.70069878e-01,\n",
       "         6.31787695e-01,  5.98114266e-01,  3.62178064e-01, -4.99004818e-03,\n",
       "         6.52629220e-01,  8.34686449e-01,  7.91648002e-01,  3.56604224e-01,\n",
       "         6.23719778e-01,  4.40748760e-02, -9.52741992e-02, -6.62793515e-01,\n",
       "        -2.01411464e+00, -2.58924615e+00,  2.38445541e+00, -6.69088374e+00,\n",
       "         1.23125413e+00,  1.36650744e-02,  2.27350296e+00,  1.23947712e+00,\n",
       "         1.46918292e+00,  1.73378969e+00, -1.50253018e+00,  3.90400020e+00,\n",
       "        -2.59594297e+00, -1.22947423e+00, -1.21709038e+00,  7.17711332e-01,\n",
       "        -3.36240419e+00,  1.65161528e+00,  1.91221718e+00, -2.54212935e-02,\n",
       "        -4.61004348e-01,  6.53949428e-01, -1.63404656e+00, -9.86592057e-01,\n",
       "         3.67922416e-01,  7.27251511e-02, -1.73829690e-01, -1.33922987e+00,\n",
       "         3.04193384e-01, -2.40899872e-01,  1.02355577e+00,  8.80822181e-01,\n",
       "         1.72102925e-01,  5.86599683e-01, -1.62120699e-01,  7.39976019e-01,\n",
       "         2.86449264e-01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]),\n",
       " 'achieved_goal': array([ 1.02355577,  0.88082218,  0.17210292,  0.58659968, -0.1621207 ,\n",
       "         0.73997602,  0.28644926]),\n",
       " 'desired_goal': array([ 1.03101157,  0.81904434,  0.1901187 ,  0.91874742, -0.30412118,\n",
       "        -0.10252113, -0.23000632])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31fc487e-605f-44a5-aa06-efab97b94c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 480, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "878b6ddd-8225-40f7-8fc4-e8ccdcf21ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        ...,\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145]],\n",
       "\n",
       "       [[114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        ...,\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145]],\n",
       "\n",
       "       [[114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        ...,\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145],\n",
       "        [114, 219, 145]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        ...,\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146]],\n",
       "\n",
       "       [[116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        ...,\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146]],\n",
       "\n",
       "       [[116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        ...,\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146],\n",
       "        [116, 220, 146]]], dtype=uint8)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 例として、リサイズ後のサイズを (240, 240) に設定\n",
    "new_size = (240, 240)\n",
    "\n",
    "# 画像をリサイズ\n",
    "resized_img = cv2.resize(img, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd49a5-caa3-4f41-82b3-a6026e907fca",
   "metadata": {},
   "source": [
    "### 環境Wrapperを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0c91c1c7-2736-4115-960d-bc02a7a68102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymWrapper(object):\n",
    "    \"\"\"\n",
    "    PyBullet環境のためのラッパー\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"]}\n",
    "    reward_range = (-np.inf, np.inf)\n",
    "\n",
    "    # 　同時に画像の大きさも変更できるようにします\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        render_width: int = 64,\n",
    "        render_height: int = 64,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        env : gym.Env\n",
    "            gymで提供されている環境のインスタンス．\n",
    "        render_width : int\n",
    "            観測画像の幅．\n",
    "        render_height : int\n",
    "            観測画像の高さ．\n",
    "        \"\"\"\n",
    "        self._env = env\n",
    "\n",
    "        self._render_width = render_width\n",
    "        self._render_height = render_height\n",
    "\n",
    "    def __getattr(self, name: str) -> Any:\n",
    "        \"\"\"\n",
    "        環境が保持している属性値を取得するメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            取得したい属性値の名前．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _env.name : Any\n",
    "            環境が保持している属性値．\n",
    "        \"\"\"\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    @property\n",
    "    def observation_space(self) -> gym.spaces.Box:\n",
    "        \"\"\"\n",
    "        観測空間に関する情報を取得するメソッド．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        space : gym.spaces.Box\n",
    "            観測空間に関する情報（各画素値の最小値，各画素値の最大値，観測データの形状， データの型）．\n",
    "        \"\"\"\n",
    "        width = self._render_width\n",
    "        height = self._render_height\n",
    "        return gym.spaces.Box(0, 255, (height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    @property\n",
    "    def action_space(self) -> gym.spaces.Box:\n",
    "        \"\"\"\n",
    "        行動空間に関する情報を取得するメソッド．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        space : gym.spaces.Box\n",
    "            行動空間に関する情報（各行動の最小値，各行動の最大値，行動空間の次元， データの型） ．\n",
    "        \"\"\"\n",
    "        return self._env.action_space\n",
    "\n",
    "    # 　元の観測（低次元の状態）は今回は捨てて，env.render()で取得した画像を観測とします.\n",
    "    #  画像，報酬，終了シグナルが得られます.\n",
    "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):\n",
    "        \"\"\"\n",
    "        環境に行動を与え次の観測，報酬，終了フラグを取得するメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : np.dnarray (action_dim, )\n",
    "            与える行動．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs : np.ndarray (height, width, 3)\n",
    "            行動を与えたときの次の観測．\n",
    "        reward : float\n",
    "            行動を与えたときに得られる報酬．\n",
    "        done : bool\n",
    "            エピソードが終了したかどうか表すフラグ．\n",
    "        info : dict\n",
    "            その他の環境に関する情報．\n",
    "        \"\"\"\n",
    "        _, reward, terminated, truncated, info = self._env.step(action)\n",
    "        obs = self._env.render()\n",
    "        obs = cv2.resize(img, (self._render_height, self._render_width), interpolation=cv2.INTER_LINEAR)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        環境をリセットするためのメソッド．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs : np.ndarray (height, width, 3)\n",
    "            環境をリセットしたときの初期の観測．\n",
    "        \"\"\"\n",
    "        self._env.reset()\n",
    "        obs = self._env.render()\n",
    "        return obs\n",
    "\n",
    "    def render(self, **kwargs) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        観測をレンダリングするためのメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        obs : np.ndarray (height, width, 3)\n",
    "            観測をレンダリングした結果．\n",
    "        \"\"\"\n",
    "        return self._env.render(**kwargs)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"\n",
    "        環境を閉じるためのメソッド．\n",
    "        \"\"\"\n",
    "        self._env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "7e0c7ad6-c9de-4d0f-9cc4-9368d08b785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatAction(GymWrapper):\n",
    "    \"\"\"\n",
    "    同じ行動を指定され\n",
    "    た回数自動的に繰り返すラッパー．観測は最後の行動に対応するものになる\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: GymWrapper, skip: int = 4) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        skip : int\n",
    "            同じ行動を繰り返す回数．\n",
    "        \"\"\"\n",
    "        # gym.Wrapper.__init__(self, env)\n",
    "        super().__init__(env, render_width=env._render_width, render_height=env._render_height)\n",
    "        self._skip = skip\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        環境をリセットするためのメソッド．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs : np.ndarray (width, height, 3)\n",
    "            環境をリセットしたときの初期の観測．\n",
    "        \"\"\"\n",
    "        obs = self._env.reset()\n",
    "        obs = cv2.resize(img, (self._render_height, self._render_width), interpolation=cv2.INTER_LINEAR)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):\n",
    "        \"\"\"\n",
    "        環境に行動を与え次の観測，報酬，終了フラグを取得するメソッド．\n",
    "        与えられた行動をskipの回数だけ繰り返した結果を返す．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : np.ndarray (action_dim, )\n",
    "            与える行動．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs : np.ndarray (width, height, 3)\n",
    "            行動をskipの回数だけ繰り返したあとの観測．\n",
    "        total_reawrd : float\n",
    "            行動をskipの回数だけ繰り返したときの報酬和．\n",
    "        done : bool\n",
    "            エピソードが終了したかどうか表すフラグ．\n",
    "        info : dict\n",
    "            その他の環境に関する情報．\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, terminated, truncated, info = self._env.step(action)\n",
    "            obs = cv2.resize(img, (self._render_height, self._render_width), interpolation=cv2.INTER_LINEAR)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "5b512f79-0e87-414f-a8ed-a32726c7caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env() -> RepeatAction:\n",
    "    \"\"\"\n",
    "    作成たラッパーをまとめて適用して環境を作成する関数．\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    env : RepeatAction\n",
    "        ラッパーを適用した環境．\n",
    "    \"\"\"\n",
    "    env = gym.make('HandManipulateEgg_BooleanTouchSensors-v1', render_mode=\"rgb_array\", max_episode_steps=1000)\n",
    "    # Dreamerでは観測は64x64のRGB画像\n",
    "    env = GymWrapper(\n",
    "        env, render_width=64, render_height=64\n",
    "    )\n",
    "    env = RepeatAction(env, skip=2)  # DreamerではActionRepeatは2\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d3a59844-a796-4c5a-9d86-e075312375e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6b7a67a1-7a80-404d-9758-115fd8a87edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (64, 64, 3), uint8)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a5ea9a8c-377e-43b4-be43-0252998ca754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._render_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "dc694a1c-eb71-4b26-8195-4566f2058f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org = env.reset()\n",
    "org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2009724f-d3ab-4193-8017-8d6b9e093f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5d0e9b57-0be2-4536-a897-655b7e9965e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "502ceb29-6262-459f-bfd4-16022c7698f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de74f5-f7b0-49eb-b474-1b96906e4f22",
   "metadata": {},
   "source": [
    "### classの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "899d33b5-90bc-4571-882c-641ab422ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    状態遷移を担うクラス．このクラスは複数の要素を含んでいます．\n",
    "    決定的状態遷移 （RNN) : h_t+1 = f(h_t, s_t, a_t)\n",
    "    確率的状態遷移による1ステップ予測として定義される \"prior\" : p(s_t+1 | h_t+1)\n",
    "    観測の情報を取り込んで定義される \"posterior\": q(s_t+1 | h_t+1, e_t+1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        action_dim: int,\n",
    "        rnn_hidden_dim: int,\n",
    "        hidden_dim: int = 200,\n",
    "        min_stddev: float = 0.1,\n",
    "        act: \"function\" = F.elu,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_dim : int\n",
    "            確率的状態sの次元数．\n",
    "        action_dim : int\n",
    "            行動空間の次元数．\n",
    "        rnn_hidden_dim : int\n",
    "            決定的状態遷移を計算するRNNの隠れ層の次元数．\n",
    "        hidden_dim : int\n",
    "            決定的状態hの次元数．\n",
    "        min_stddev : float\n",
    "            確率状態遷移の標準偏差の最小値．\n",
    "        act : function\n",
    "            活性化関数．\n",
    "        \"\"\"\n",
    "        super(TransitionModel, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.rnn_hidden_dim = rnn_hidden_dim\n",
    "        self.fc_state_action = nn.Linear(state_dim + action_dim, hidden_dim)\n",
    "\n",
    "        self.fc_rnn_hidden = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
    "        self.fc_state_mean_prior = nn.Linear(hidden_dim, state_dim)\n",
    "        self.fc_state_stddev_prior = nn.Linear(hidden_dim, state_dim)\n",
    "        self.fc_rnn_hidden_embedded_obs = nn.Linear(rnn_hidden_dim + 1024, hidden_dim)\n",
    "        self.fc_state_mean_posterior = nn.Linear(hidden_dim, state_dim)\n",
    "        self.fc_state_stddev_posterior = nn.Linear(hidden_dim, state_dim)\n",
    "\n",
    "        # next hidden stateを計算\n",
    "        self.rnn = nn.GRUCell(hidden_dim, rnn_hidden_dim)\n",
    "        self._min_stddev = min_stddev\n",
    "        self.act = act\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        state: torch.Tensor,\n",
    "        action: torch.Tensor,\n",
    "        rnn_hidden: torch.Tensor,\n",
    "        embedded_next_obs: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        prior p(s_t+1 | h_t+1) と posterior q(s_t+1 | h_t+1, e_t+1) を返すメソッド．\n",
    "        この2つが近づくように学習する．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            時刻tの状態(s_t)．\n",
    "        action : torch.Tensor (batch size, action dim)\n",
    "            時刻tの行動(a_t)．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持している決定的状態(h_t)．\n",
    "        embedded_next_obs : torch.Tensor (batch size, 1024)\n",
    "            時刻t+1の観測をエンコードしたもの(e_t+1)．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next_state_prior : torch.Tensor (batch size, state dim)\n",
    "            prior(p(s_t+1 | h_t+1))による次の時刻の状態の予測．\n",
    "        next_state_posterior : torch.Tensor (batch size, state dim)\n",
    "            posterior(q(s_t+1 | h_t+1, e_t+1))による次の時刻の状態の予測．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持する次の決定的状態(h_t+1)．\n",
    "        \"\"\"\n",
    "        next_state_prior, rnn_hidden = self.prior(\n",
    "            self.recurrent(state, action, rnn_hidden)\n",
    "        )\n",
    "        next_state_posterior = self.posterior(rnn_hidden, embedded_next_obs)\n",
    "        return next_state_prior, next_state_posterior, rnn_hidden\n",
    "\n",
    "    def recurrent(\n",
    "        self, state: torch.Tensor, action: torch.Tensor, rnn_hidden: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        決定的状態 h_t+1 = f(h_t, s_t, a_t)を計算するメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            時刻tの状態(s_t)．\n",
    "        action : torch.Tensor (batch size, action dim)\n",
    "            時刻tの行動(a_t)．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持している決定的状態(h_t)．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持する次の決定的状態(h_t+1)．\n",
    "        \"\"\"\n",
    "        hidden = self.act(self.fc_state_action(torch.cat([state, action], dim=1)))\n",
    "        # h_t+1を求める\n",
    "        rnn_hidden = self.rnn(hidden, rnn_hidden)\n",
    "        return rnn_hidden\n",
    "\n",
    "    def prior(self, rnn_hidden: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        prior p(s_t+1 | h_t+1) を計算するメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持している決定的状態(h_t+1)．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            決定的状態を用いてサンプリングされた確率的な状態(s_t+1)．\n",
    "            ここでは決定的状態h_t+1からガウス分布の平均，標準偏差を推定してサンプリングしています．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持する決定的状態(h_t+1)．\n",
    "            入力からのものをそのまま返しています．\n",
    "        \"\"\"\n",
    "        #h_t+1を求める（ヒント: self.act, self.fc_rnn_hiddenを使用）\n",
    "        hidden = self.act(self.fc_rnn_hidden(rnn_hidden)) # WRITE ME\n",
    "\n",
    "        mean = self.fc_state_mean_prior(hidden)\n",
    "        stddev = F.softplus(self.fc_state_stddev_prior(hidden)) + self._min_stddev\n",
    "        return Normal(mean, stddev), rnn_hidden\n",
    "\n",
    "    def posterior(\n",
    "        self, rnn_hidden: torch.Tensor, embedded_obs: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        posterior q(s_t+1 | h_t+1, e_t+1)  を計算するメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
    "            RNNが保持している決定的状態(h_t+1)．\n",
    "        embedded_obs : torch.Tensor (batch size, 1024)\n",
    "            時刻t+1の観測をエンコードしたもの．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            決定的状態とエンコードした観測を用いてサンプリングされた確率的な状態(s_t+1)．\n",
    "            ここでは決定的状態h_t+1とエンコードした観測e_t+1からガウス分布の平均，標準偏差を推定してサンプリングしています．\n",
    "        \"\"\"\n",
    "        # h_t+1，o_t+1を結合し，q(s_t+1 | h_t+1, e_t+1) を計算する\n",
    "        hidden = self.act(self.fc_rnn_hidden_embedded_obs(torch.cat([rnn_hidden, embedded_obs], dim=1))) # WRITE ME\n",
    "        mean = self.fc_state_mean_posterior(hidden)\n",
    "        stddev = F.softplus(self.fc_state_stddev_posterior(hidden)) + self._min_stddev\n",
    "        return Normal(mean, stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "08aeabac-b300-4ea5-bb26-472844aed2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    p(o_t | s_t, h_t)\n",
    "    低次元の状態表現から画像を再構成するデコーダ (3, 64, 64)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_dim: int, rnn_hidden_dim: int) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_dim : int\n",
    "            確率的状態sの次元数．\n",
    "        rnn_hidden_dim : int\n",
    "            決定的状態hの次元数．\n",
    "        \"\"\"\n",
    "        super(ObservationModel, self).__init__()\n",
    "        self.fc = nn.Linear(state_dim + rnn_hidden_dim, 1024)\n",
    "        self.dc1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=2)\n",
    "        self.dc2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
    "        self.dc3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
    "        self.dc4 = nn.ConvTranspose2d(32, 3, kernel_size=6, stride=2)\n",
    "\n",
    "    def forward(self, state: torch.Tensor, rnn_hidden: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        順伝播を行うメソッド．確率的状態sと決定的状態hから観測を再構成する．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            確率的状態s．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
    "            決定的状態h．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        obs : torch.Tensor (batch size, 3, 64, 64)\n",
    "            再構成された観測o．\n",
    "        \"\"\"\n",
    "        hidden = self.fc(torch.cat([state, rnn_hidden], dim=1))\n",
    "        hidden = hidden.view(hidden.size(0), 1024, 1, 1)\n",
    "        hidden = F.relu(self.dc1(hidden))\n",
    "        hidden = F.relu(self.dc2(hidden))\n",
    "        hidden = F.relu(self.dc3(hidden))\n",
    "        obs = self.dc4(hidden)\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "caa3f5b5-6cdb-4bcc-929d-46e001bd608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModel(nn.Module):\n",
    "    \"\"\"\n",
    "    p(r_t | s_t, h_t)\n",
    "    低次元の状態表現から報酬を予測する．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        rnn_hidden_dim: int,\n",
    "        hidden_dim: int = 400,\n",
    "        act: \"function\" = F.elu,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_dim : int\n",
    "            確率的状態sの次元数．\n",
    "        rnn_hidden_dim : int\n",
    "            決定的状態hの次元数．\n",
    "        hidden_dim : int\n",
    "            報酬モデルの隠れ層の次元数． (default=400)\n",
    "        act : function\n",
    "            報酬モデルに利用される活性化関数． (default=torch.nn.functional.elu)\n",
    "        \"\"\"\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + rnn_hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, state: torch.Tensor, rnn_hidden: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        順伝播を行うメソッド．確率的状態sと決定的状態hから報酬rを推定する．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            確率的状態s．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
    "            決定的状態h．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reward : torch.Tensor (batch size, 1)\n",
    "            確率的状態s，決定的状態hに対する報酬r．\n",
    "        \"\"\"\n",
    "        hidden = self.act(self.fc1(torch.cat([state, rnn_hidden], dim=1)))\n",
    "        hidden = self.act(self.fc2(hidden))\n",
    "        hidden = self.act(self.fc3(hidden))\n",
    "        reward = self.fc4(hidden)\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ff69841a-08ef-476d-958c-db09951b2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSSM:\n",
    "    \"\"\"\n",
    "    TransitionModel, ObservationModel, RewardModelの3つをまとめたRSSMクラス．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        action_dim: int,\n",
    "        rnn_hidden_dim: int,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_dim : int\n",
    "            確率的状態sの次元数．\n",
    "        action_dim : int\n",
    "            行動空間の次元数．\n",
    "        rnn_hidden_dim : int\n",
    "            決定的状態hの次元数．\n",
    "        \"\"\"\n",
    "        self.transition = TransitionModel(state_dim, action_dim, rnn_hidden_dim).to(\n",
    "            device\n",
    "        )\n",
    "        self.observation = ObservationModel(\n",
    "            state_dim,\n",
    "            rnn_hidden_dim,\n",
    "        ).to(device)\n",
    "        self.reward = RewardModel(\n",
    "            state_dim,\n",
    "            rnn_hidden_dim,\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7965c2f0-ddda-493c-8bf5-1118ce91f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# こちらはDQNのReplayBufferの定義\n",
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    これまでの経験をためておくリプレイバッファ．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, memory_size: int) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        memory_size : int\n",
    "            リプレイバッファに貯められるデータの上限．\n",
    "        \"\"\"\n",
    "        self.memory_size = memory_size\n",
    "        # 収集する経験は上限を決め古いものから削除する．\n",
    "        self.memory = deque([], maxlen=memory_size)\n",
    "\n",
    "    def append(self, transition: dict) -> None:\n",
    "        \"\"\"\n",
    "        環境から得た経験（状態，行動，次の状態，報酬，終了フラグ）をキューに追加するメソッド．\n",
    "        dequeを用いているため上限(memory_size)に達すると古いものが削除される．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trainsition : dict\n",
    "            状態(state)，次の状態(next_state)，報酬(reward)，行動(action)，終了フラグ(done)を格納した辞書．\n",
    "        \"\"\"\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size: int) -> dict:  # 貯めた経験の中からランダムにミニバッチ単位で経験を取り出す．\n",
    "        \"\"\"\n",
    "        バッファに貯めた経験の中からランダムにミニバッチ単位で経験を取り出すメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            バッチサイズ．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sample : dict\n",
    "            状態(states)，次の状態(next_states)，報酬(rewards)，行動(actions)，終了フラグ(dones)をバッチサイズ分だけ格納した辞書．\n",
    "        \"\"\"\n",
    "        batch_indexes = np.random.randint(0, len(self.memory), size=batch_size)\n",
    "        states = np.array([self.memory[index][\"state\"] for index in batch_indexes])\n",
    "        next_states = np.array(\n",
    "            [self.memory[index][\"next_state\"] for index in batch_indexes]\n",
    "        )\n",
    "        rewards = np.array([self.memory[index][\"reward\"] for index in batch_indexes])\n",
    "        actions = np.array([self.memory[index][\"action\"] for index in batch_indexes])\n",
    "        dones = np.array([self.memory[index][\"terminated\"] for index in batch_indexes])\n",
    "        return {\n",
    "            \"states\": states,\n",
    "            \"next_states\": next_states,\n",
    "            \"rewards\": rewards,\n",
    "            \"actions\": actions,\n",
    "            \"dones\": terminated,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f3b06195-d4e0-42fd-85dd-6b5e1a47e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 　今回のReplayBuffer\n",
    "class ReplayBuffer(object):\n",
    "    \"\"\"\n",
    "    RNNを用いて訓練するのに適したリプレイバッファ．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, capacity: int, observation_shape: List[int], action_dim: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        capacity : int\n",
    "            リプレイバッファにためておくことができる経験の上限．\n",
    "        observation_shape : List[int]\n",
    "            環境から与えられる観測の形状．\n",
    "        action_dim : int\n",
    "            行動空間の次元数．\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "\n",
    "        self.observations = np.zeros((capacity, *observation_shape), dtype=np.uint8)\n",
    "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
    "        self.rewards = np.zeros((capacity, 1), dtype=np.float32)\n",
    "        self.done = np.zeros((capacity, 1), dtype=bool)\n",
    "        # self.done = np.zeros((capacity, 1), dtype=np.bool)\n",
    "\n",
    "        self.index = 0\n",
    "        self.is_filled = False\n",
    "\n",
    "    def push(\n",
    "        self, observation: np.ndarray, action: np.ndarray, reward: float, done: bool\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        リプレイバッファに経験を追加するメソッド．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : np.ndarray (64, 64, 3)\n",
    "            環境から得られた観測．\n",
    "        action : np.ndarray (action_dim, )\n",
    "            エージェントがとった（もしくは経験を貯める際のランダムな）行動．\n",
    "        reward : float\n",
    "            観測に対して行動をとったときに得られる報酬．\n",
    "        done : bool\n",
    "            エピソードが終了するかどうかのフラグ．\n",
    "        \"\"\"\n",
    "        self.observations[self.index] = observation\n",
    "        self.actions[self.index] = action\n",
    "        self.rewards[self.index] = reward\n",
    "        self.done[self.index] = done\n",
    "\n",
    "        # indexは巡回し，最も古い経験を上書きする\n",
    "        if self.index == self.capacity - 1:\n",
    "            self.is_filled = True\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size: int, chunk_length: int) -> Tuple[np.ndarray]:\n",
    "        \"\"\"\n",
    "        経験をリプレイバッファからサンプルします．（ほぼ）一様なサンプルです．\n",
    "        結果として返ってくるのは観測（画像），行動，報酬，終了シグナルについての(batch_size, chunk_length, 各要素の次元)の配列です．\n",
    "        各バッチは連続した経験になっています．\n",
    "        注意: chunk_lengthをあまり大きな値にすると問題が発生する場合があります．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            バッチサイズ．\n",
    "        chunk_length : int\n",
    "            バッチあたりの系列長．\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sampled_observations : np.ndarray (batch size, chunk length, 3, 64, 64)\n",
    "            バッファからサンプリングされた観測．\n",
    "        sampled_actions : np.ndarray (batch size, chunk length, action dim)\n",
    "            バッファからサンプリングされた行動．\n",
    "        sampled_rewards : np.ndarray (batch size, chunk length, 1)\n",
    "            バッファからサンプリングされた報酬．\n",
    "        sampled_rewards : np.ndarray (batch size, chunk length, 1)\n",
    "            バッファからサンプリングされたエピソードの終了フラグ．\n",
    "        \"\"\"\n",
    "        episode_borders = np.where(self.done)[0]\n",
    "        sampled_indexes = []\n",
    "        for _ in range(batch_size):\n",
    "            cross_border = True\n",
    "            while cross_border:\n",
    "                initial_index = np.random.randint(len(self) - chunk_length + 1)\n",
    "                final_index = initial_index + chunk_length - 1\n",
    "                cross_border = np.logical_and(\n",
    "                    initial_index <= episode_borders, episode_borders < final_index\n",
    "                ).any()  # 論理積\n",
    "            sampled_indexes += list(range(initial_index, final_index + 1))\n",
    "\n",
    "        sampled_observations = self.observations[sampled_indexes].reshape(\n",
    "            batch_size, chunk_length, *self.observations.shape[1:]\n",
    "        )\n",
    "        sampled_actions = self.actions[sampled_indexes].reshape(\n",
    "            batch_size, chunk_length, self.actions.shape[1]\n",
    "        )\n",
    "        sampled_rewards = self.rewards[sampled_indexes].reshape(\n",
    "            batch_size, chunk_length, 1\n",
    "        )\n",
    "        sampled_done = self.done[sampled_indexes].reshape(batch_size, chunk_length, 1)\n",
    "        return sampled_observations, sampled_actions, sampled_rewards, sampled_done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        バッファに貯められている経験の数を返すメソッド．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        length : int\n",
    "            バッファに貯められている経験の数．\n",
    "        \"\"\"\n",
    "        return self.capacity if self.is_filled else self.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a9140-21f5-4bf6-ad04-13a9bfdfcc53",
   "metadata": {},
   "source": [
    "次に観測の前処理を行う関数を実装します．ちなみに，これもラッパーとして最初から適用してしまわないのは，リプレイバッファにはより容量の小さなnp．uint8の形式で保存しておきたいためです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "5ca7a2a0-1e02-41b6-bd8c-42bee8a66cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_obs(obs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    画像を正規化する．[0, 255] -> [-0.5, 0.5]．\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : np.ndarray (64, 64, 3) or (chank length, batch size, 64, 64, 3)\n",
    "        環境から得られた観測．画素値は[0, 255]．\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    normalized_obs : np.ndarray (64, 64, 3) or (chank length, batch size, 64, 64, 3)\n",
    "        画素値を[-0.5, 0.5]で正規化した観測．\n",
    "    \"\"\"\n",
    "    obs = obs.astype(np.float32)\n",
    "    normalized_obs = obs / 255.0 - 0.5\n",
    "    return normalized_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939deef-0738-430a-910c-f0f2fa545e93",
   "metadata": {},
   "source": [
    "Dreamerでは価値関数の学習を行いますが，このために通常のTD誤差ではなく，**TD(λ)をベースにしたλ-return**としてターゲット価値を計算し，それと現在の予測価値の誤差を用います．そのためにλ-returnを計算する関数をここで実装しておきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f02a4e4b-d361-4fc8-b7af-973929475ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_target(\n",
    "    rewards: torch.Tensor, values: torch.Tensor, gamma: float, lambda_: float\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    価値関数の学習のためのλ-returnを計算する関数．\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rewards : torch.Tensor (imagination_horizon, batch size * (chank length - 1))\n",
    "        報酬モデルによる報酬の推定値．\n",
    "    values : torch.Tensor (imagination_horizon, batch size * (chank length - 1))\n",
    "        価値関数を近似するValueモデルによる状態価値観数の推定値．\n",
    "    gamma : float\n",
    "        割引率．\n",
    "    lambda_ : float\n",
    "        λ-returnのパラメータλ．\n",
    "\n",
    "    V_lambda : torch.Tensor (imagination_horizon, batch size * (chank length - 1))\n",
    "        各状態に対するλ-returnの値．\n",
    "    \"\"\"\n",
    "    V_lambda = torch.zeros_like(rewards, device=rewards.device)\n",
    "\n",
    "    H = rewards.shape[0] - 1\n",
    "    V_n = torch.zeros_like(rewards, device=rewards.device)\n",
    "    V_n[H] = values[H]\n",
    "    for n in range(1, H + 1):\n",
    "        # まずn-step returnを計算します\n",
    "        # 注意: 系列が途中で終わってしまったら，可能な中で最大のnを用いたn-stepを使います\n",
    "        V_n[:-n] = (gamma**n) * values[n:]\n",
    "        for k in range(1, n + 1):\n",
    "            if k == n:\n",
    "                V_n[:-n] += (gamma ** (n - 1)) * rewards[k:]\n",
    "            else:\n",
    "                V_n[:-n] += (gamma ** (k - 1)) * rewards[k : -n + k]\n",
    "\n",
    "        # lambda_でn-step returnを重みづけてλ-returnを計算します\n",
    "        if n == H:\n",
    "            V_lambda += (lambda_ ** (H - 1)) * V_n\n",
    "        else:\n",
    "            V_lambda += (1 - lambda_) * (lambda_ ** (n - 1)) * V_n\n",
    "\n",
    "    return V_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e9001897-c792-4c17-abef-d3ab00332827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    (3, 64, 64)の画像を(1024,)のベクトルに変換するエンコーダクラス．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "        層の定義のみを行う．\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2)\n",
    "        self.cv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.cv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
    "        self.cv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        順伝播を行うメソッド．観測画像をベクトルに埋め込む．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : torch.Tensor (batch size, 3, 64, 64)\n",
    "            環境から得られた観測画像．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        embedded_obs : torch.Tensor (batch size, 1024)\n",
    "            観測を1024次元のベクトルに埋め込んだもの．\n",
    "        \"\"\"\n",
    "        hidden = F.relu(self.cv1(obs))\n",
    "        hidden = F.relu(self.cv2(hidden))\n",
    "        hidden = F.relu(self.cv3(hidden))\n",
    "        embedded_obs = F.relu(self.cv4(hidden)).reshape(hidden.size(0), -1)\n",
    "        return embedded_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c06dbb42-81f3-432a-985a-40fa5843d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueModel(nn.Module):\n",
    "    \"\"\"\n",
    "    低次元の状態表現(state_dim + rnn_hidden_dim)から状態価値を出力するクラス．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        rnn_hidden_dim: int,\n",
    "        hidden_dim: int = 400,\n",
    "        act: \"function\" = F.elu,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_dim : int\n",
    "            確率的状態sの次元数．\n",
    "        rnn_hidden_dim : int\n",
    "            決定的状態hの次元数．\n",
    "        hidden_dim : int\n",
    "            モデルの隠れ層の次元数． (default=400)\n",
    "        act : function\n",
    "            モデルの活性化関数． (default=torch.nn.functional.elu)\n",
    "        \"\"\"\n",
    "        super(ValueModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + rnn_hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, state: torch.Tensor, rnn_hidden: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        順伝播を行うメソッド．低次元の状態表現から状態価値を推定する．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : torch.Tensor (batch size, state dim)\n",
    "            確率的状態s．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
    "            決定的状態h．\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        state_value : torch.Tensor (batch size, 1)\n",
    "            入力された状態に対する状態価値の推定値．\n",
    "        \"\"\"\n",
    "        hidden = self.act(self.fc1(torch.cat([state, rnn_hidden], dim=1)))\n",
    "        hidden = self.act(self.fc2(hidden))\n",
    "        hidden = self.act(self.fc3(hidden))\n",
    "        state_value = self.fc4(hidden)\n",
    "        return state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "337e7871-83e1-46d5-b90c-5662dfc9ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    低次元の状態表現(state_dim + rnn_hidden_dim)から行動を計算するクラス．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        rnn_hidden_dim: int,\n",
    "        action_dim: int,\n",
    "        hidden_dim: int = 400,\n",
    "        act: \"function\" = F.elu,\n",
    "        min_stddev: float = 1e-4,\n",
    "        init_stddev: float = 5.0,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_dim : int\n",
    "            確率的状態sの次元数．\n",
    "        rnn_hidden_dim : int\n",
    "            決定的状態hの次元数．\n",
    "        action_dim : int\n",
    "            行動空間の次元数．\n",
    "        hidden_dim : int\n",
    "            モデルの隠れ層の次元数． (default=400)\n",
    "        act : function\n",
    "            モデルの活性化関数． (default=torch.nn.functional.elu)\n",
    "        min_stddev : float\n",
    "            行動をサンプリングする分布の標準偏差の最小値． (default=1e-4)\n",
    "        init_stddev : float\n",
    "            行動をサンプリングする分布の標準偏差の初期値． (default=5.0)\n",
    "        \"\"\"\n",
    "        super(ActionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + rnn_hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mean = nn.Linear(hidden_dim, action_dim)\n",
    "        self.fc_stddev = nn.Linear(hidden_dim, action_dim)\n",
    "        self.act = act\n",
    "        self.min_stddev = min_stddev\n",
    "        self.init_stddev = np.log(np.exp(init_stddev) - 1)\n",
    "\n",
    "    def forward(\n",
    "        self, state: torch.Tensor, rnn_hidden: torch.Tensor, training: bool = True\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        順伝播を行うメソッド．入力された状態に対する行動を出力する．\n",
    "        training=Trueなら，NNのパラメータに関して微分可能な形の行動のサンプル（Reparametrizationによる）を返す．\n",
    "        training=Falseなら，行動の確率分布の平均値を返す．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        staet : torch.Tensor (batch size, state dim)\n",
    "            確率的状態s．\n",
    "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
    "            決定的状態h．\n",
    "        training : bool\n",
    "            訓練か推論かを示すフラグ． (default=True)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : torch.Tensor (batch size, action dim)\n",
    "            入力された状態に対する行動．\n",
    "            training=Trueでは微分可能な形の行動をサンプリングした値，\n",
    "            training=Falseでは行動の確率分布の平均値を返す．\n",
    "        \"\"\"\n",
    "        hidden = self.act(self.fc1(torch.cat([state, rnn_hidden], dim=1)))\n",
    "        hidden = self.act(self.fc2(hidden))\n",
    "        hidden = self.act(self.fc3(hidden))\n",
    "        hidden = self.act(self.fc4(hidden))\n",
    "\n",
    "        # Dreamerの実装に合わせて少し平均と分散に対する簡単な変換が入っています\n",
    "        mean = self.fc_mean(hidden)\n",
    "        mean = 5.0 * torch.tanh(mean / 5.0)\n",
    "        stddev = self.fc_stddev(hidden)\n",
    "        stddev = F.softplus(stddev + self.init_stddev) + self.min_stddev\n",
    "\n",
    "        if training:\n",
    "            action = torch.tanh(Normal(mean, stddev).rsample())  # 微分可能にするためrsample()\n",
    "        else:\n",
    "            action = torch.tanh(mean)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "93a4efc7-9752-4ae2-8a56-eaf86af4492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    ActionModelに基づき行動を決定する．そのためにRSSMを用いて状態表現をリアルタイムで推論して維持するクラス．\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Encoder, rssm: RSSM, action_model: ActionModel) -> None:\n",
    "        \"\"\"\n",
    "        コンストラクタ．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoder : Encoder\n",
    "            上で定義したEncoderクラスのインスタンス．\n",
    "            観測画像を1024次元のベクトルに埋め込む ．\n",
    "        rssm : RSSM\n",
    "            上で定義したRSSMクラスのインスタンス．\n",
    "            遷移モデル，1024次元のベクトルを観測画像にするデコーダ，報酬を予測するモデルを持つ．\n",
    "        action_model : ActionModel\n",
    "            上で定義したActionModelのインスタンス．\n",
    "            低次元の状態表現から行動を予測する．\n",
    "        \"\"\"\n",
    "        self.encoder = encoder\n",
    "        self.rssm = rssm\n",
    "        self.action_model = action_model\n",
    "\n",
    "        self.device = next(self.action_model.parameters()).device\n",
    "        self.rnn_hidden = torch.zeros(1, rssm.rnn_hidden_dim, device=self.device)\n",
    "\n",
    "    def __call__(self, obs: np.ndarray, training=True) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        特殊メソッド．\n",
    "        インスタンスに直接引数を渡すことで実行される．\n",
    "        （例）agent = Agent(*args)\n",
    "             action = agent(obs)  # このときに__call__メソッドが呼び出される．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : np.ndarray (batch size, 3, 64, 64)\n",
    "            環境から得られた観測画像．\n",
    "        training : bool\n",
    "            訓練か推論かを示すフラグ． (default=True)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : np.ndarray (batch size, action dim)\n",
    "            入力された観測に対する行動の予測．\n",
    "        \"\"\"\n",
    "        # preprocessを適用，PyTorchのためにChannel-Firstに変換\n",
    "        obs = preprocess_obs(obs)\n",
    "        obs = torch.as_tensor(obs, device=self.device)\n",
    "        obs = obs.transpose(1, 2).transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 観測を低次元の表現に変換し，posteriorからのサンプルをActionModelに入力して行動を決定する\n",
    "            embedded_obs = self.encoder(obs)\n",
    "            state_posterior = self.rssm.posterior(self.rnn_hidden, embedded_obs)\n",
    "            state = state_posterior.sample()\n",
    "            action = self.action_model(state, self.rnn_hidden, training=training)\n",
    "\n",
    "            # 次のステップのためにRNNの隠れ状態を更新しておく\n",
    "            _, self.rnn_hidden = self.rssm.prior(\n",
    "                self.rssm.recurrent(state, action, self.rnn_hidden)\n",
    "            )\n",
    "\n",
    "        return action.squeeze().cpu().numpy()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        RNNの隠れ状態（=決定的状態）をリセットする．\n",
    "        \"\"\"\n",
    "        self.rnn_hidden = torch.zeros(1, self.rssm.rnn_hidden_dim, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ba69edd6-3b95-4e2b-9ec3-04c6c733e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リプレイバッファの宣言\n",
    "buffer_capacity = 200000  # Colabのメモリの都合上，元の実装より小さめにとっています\n",
    "replay_buffer = ReplayBuffer(\n",
    "    capacity=buffer_capacity,\n",
    "    observation_shape=env.observation_space.shape,\n",
    "    action_dim=env.action_space.shape[0],\n",
    ")\n",
    "\n",
    "# モデルの宣言\n",
    "state_dim = 30  # 確率的状態の次元\n",
    "rnn_hidden_dim = 200  # 決定的状態（RNNの隠れ状態）の次元\n",
    "# 確率的状態の次元と決定的状態（RNNの隠れ状態）の次元は一致しなくて良い\n",
    "encoder = Encoder().to(device)\n",
    "rssm = RSSM(\n",
    "    state_dim,\n",
    "    env.action_space.shape[0],\n",
    "    rnn_hidden_dim,\n",
    ")\n",
    "value_model = ValueModel(state_dim, rnn_hidden_dim).to(device)\n",
    "action_model = ActionModel(state_dim, rnn_hidden_dim, env.action_space.shape[0]).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "# オプティマイザの宣言\n",
    "model_lr = 6e-4  # encoder, rssm, obs_model, reward_modelの学習率\n",
    "value_lr = 8e-5\n",
    "action_lr = 8e-5\n",
    "eps = 1e-4\n",
    "model_params = (\n",
    "    list(encoder.parameters())\n",
    "    + list(rssm.transition.parameters())\n",
    "    + list(rssm.observation.parameters())\n",
    "    + list(rssm.reward.parameters())\n",
    ")\n",
    "model_optimizer = torch.optim.Adam(model_params, lr=model_lr, eps=eps)\n",
    "value_optimizer = torch.optim.Adam(value_model.parameters(), lr=value_lr, eps=eps)\n",
    "action_optimizer = torch.optim.Adam(action_model.parameters(), lr=action_lr, eps=eps)\n",
    "\n",
    "# その他ハイパーパラメータ\n",
    "seed_episodes = 5  # 最初にランダム行動で探索するエピソード数\n",
    "all_episodes = 100  # 学習全体のエピソード数（300ほどで，ある程度収束します）\n",
    "test_interval = 10  # 何エピソードごとに探索ノイズなしのテストを行うか\n",
    "model_save_interval = 20  # NNの重みを何エピソードごとに保存するか\n",
    "collect_interval = 100  # 何回のNNの更新ごとに経験を集めるか（＝1エピソード経験を集めるごとに何回更新するか）\n",
    "\n",
    "action_noise_var = 0.3  # 探索ノイズの強さ\n",
    "\n",
    "batch_size = 50\n",
    "chunk_length = 50  # 1回の更新で用いる系列の長さ\n",
    "imagination_horizon = 15  # Actor-Criticの更新のために，Dreamerで何ステップ先までの想像上の軌道を生成するか\n",
    "\n",
    "\n",
    "gamma = 0.9  # 割引率\n",
    "lambda_ = 0.95  # λ-returnのパラメータ\n",
    "clip_grad_norm = 100  # gradient clippingの値\n",
    "free_nats = 3  # KL誤差（RSSMのTransitionModelにおけるpriorとposteriorの間の誤差）がこの値以下の場合，無視する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "56dc7989-c277-41b2-b47a-77cf86f05d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0623e2590444338d3a71aea91e1b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "env = make_env()\n",
    "for episode in tqdm(range(seed_episodes)):\n",
    "    obs = env.reset()\n",
    "    terminated = False\n",
    "    # while not terminated:\n",
    "    action = env.action_space.sample()\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    replay_buffer.push(obs, action, reward, terminated)\n",
    "    obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "872920f6-0dce-430f-89c6-f43b8d419553",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3569d-cfa0-4d89-a25e-d5d4b480b790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode [   6/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.36s\n",
      "update_step:   1 model loss: 1244.56726, kl_loss: 1244.48767, obs_loss: 0.07956, reward_loss: 0.00001, value_loss: 0.10734 action_loss: 18.47068\n",
      "update_step:   2 model loss: 625.70697, kl_loss: 624.16376, obs_loss: 1.54302, reward_loss: 0.00019, value_loss: 0.44376 action_loss: 17.30429\n",
      "update_step:   3 model loss: 94.20093, kl_loss: 89.80300, obs_loss: 4.39365, reward_loss: 0.00428, value_loss: 1.69046 action_loss: 15.93995\n",
      "update_step:   4 model loss: 12.38095, kl_loss: 4.96706, obs_loss: 7.39966, reward_loss: 0.01422, value_loss: 5.84914 action_loss: 16.16188\n",
      "update_step:   5 model loss: 11.57397, kl_loss: 3.03567, obs_loss: 8.53123, reward_loss: 0.00707, value_loss: 10.40611 action_loss: 16.10630\n",
      "update_step:   6 model loss: 10.44078, kl_loss: 3.36822, obs_loss: 7.04674, reward_loss: 0.02582, value_loss: 8.14044 action_loss: 14.74537\n",
      "update_step:   7 model loss: 12.13269, kl_loss: 3.52908, obs_loss: 8.59597, reward_loss: 0.00764, value_loss: 6.68783 action_loss: 14.27775\n",
      "update_step:   8 model loss: 12.34676, kl_loss: 3.35654, obs_loss: 8.97579, reward_loss: 0.01443, value_loss: 7.03833 action_loss: 14.26246\n",
      "update_step:   9 model loss: 9.93077, kl_loss: 3.11732, obs_loss: 6.80354, reward_loss: 0.00992, value_loss: 10.87583 action_loss: 15.35940\n",
      "update_step:  10 model loss: 9.12037, kl_loss: 3.03362, obs_loss: 6.07350, reward_loss: 0.01325, value_loss: 10.64800 action_loss: 15.83430\n",
      "update_step:  11 model loss: 10.39625, kl_loss: 3.20005, obs_loss: 7.17479, reward_loss: 0.02141, value_loss: 6.56402 action_loss: 14.36810\n",
      "update_step:  12 model loss: 14.11134, kl_loss: 3.05853, obs_loss: 11.02744, reward_loss: 0.02537, value_loss: 4.63684 action_loss: 14.16002\n",
      "update_step:  13 model loss: 14.89588, kl_loss: 3.01935, obs_loss: 11.80779, reward_loss: 0.06875, value_loss: 4.54188 action_loss: 15.51367\n",
      "update_step:  14 model loss: 11.55398, kl_loss: 3.00811, obs_loss: 8.51820, reward_loss: 0.02767, value_loss: 4.88625 action_loss: 16.92984\n",
      "update_step:  15 model loss: 13.69185, kl_loss: 3.00702, obs_loss: 10.67955, reward_loss: 0.00528, value_loss: 5.39826 action_loss: 17.62041\n",
      "update_step:  16 model loss: 9.21203, kl_loss: 3.00753, obs_loss: 6.18687, reward_loss: 0.01763, value_loss: 4.35355 action_loss: 17.27849\n",
      "update_step:  17 model loss: 11.09443, kl_loss: 3.00514, obs_loss: 8.08614, reward_loss: 0.00316, value_loss: 3.67366 action_loss: 17.29277\n",
      "update_step:  18 model loss: 9.05359, kl_loss: 3.00248, obs_loss: 6.04757, reward_loss: 0.00354, value_loss: 3.16458 action_loss: 18.11520\n",
      "update_step:  19 model loss: 13.40658, kl_loss: 3.00927, obs_loss: 10.39515, reward_loss: 0.00216, value_loss: 3.07149 action_loss: 18.57123\n",
      "update_step:  20 model loss: 14.10561, kl_loss: 3.00741, obs_loss: 11.09614, reward_loss: 0.00206, value_loss: 3.32799 action_loss: 18.62670\n",
      "update_step:  21 model loss: 7.57354, kl_loss: 3.00809, obs_loss: 4.56275, reward_loss: 0.00270, value_loss: 3.63866 action_loss: 18.84219\n",
      "update_step:  22 model loss: 13.50595, kl_loss: 3.00868, obs_loss: 10.49551, reward_loss: 0.00176, value_loss: 3.47429 action_loss: 19.34315\n",
      "update_step:  23 model loss: 15.11380, kl_loss: 3.01158, obs_loss: 12.09848, reward_loss: 0.00373, value_loss: 2.99696 action_loss: 20.03484\n",
      "update_step:  24 model loss: 10.87615, kl_loss: 3.01337, obs_loss: 7.85492, reward_loss: 0.00785, value_loss: 2.39206 action_loss: 20.64387\n",
      "update_step:  25 model loss: 10.03392, kl_loss: 3.01409, obs_loss: 7.01246, reward_loss: 0.00737, value_loss: 2.56032 action_loss: 20.23375\n",
      "update_step:  26 model loss: 9.79208, kl_loss: 3.01758, obs_loss: 6.77267, reward_loss: 0.00184, value_loss: 3.05624 action_loss: 19.55585\n",
      "update_step:  27 model loss: 9.06453, kl_loss: 3.01782, obs_loss: 6.03527, reward_loss: 0.01145, value_loss: 2.62712 action_loss: 19.81615\n",
      "update_step:  28 model loss: 8.77641, kl_loss: 3.01135, obs_loss: 5.76042, reward_loss: 0.00464, value_loss: 1.94928 action_loss: 20.80995\n",
      "update_step:  29 model loss: 7.86644, kl_loss: 3.00947, obs_loss: 4.85288, reward_loss: 0.00409, value_loss: 1.81406 action_loss: 21.00356\n",
      "update_step:  30 model loss: 9.12316, kl_loss: 3.00243, obs_loss: 6.11215, reward_loss: 0.00859, value_loss: 1.99311 action_loss: 20.22620\n",
      "update_step:  31 model loss: 8.23267, kl_loss: 3.00316, obs_loss: 5.22868, reward_loss: 0.00083, value_loss: 2.16765 action_loss: 19.70475\n",
      "update_step:  32 model loss: 8.28962, kl_loss: 3.00202, obs_loss: 5.28304, reward_loss: 0.00455, value_loss: 1.97412 action_loss: 19.78647\n",
      "update_step:  33 model loss: 8.34394, kl_loss: 3.00115, obs_loss: 5.33914, reward_loss: 0.00364, value_loss: 1.55512 action_loss: 19.82827\n",
      "update_step:  34 model loss: 7.70640, kl_loss: 3.00154, obs_loss: 4.70414, reward_loss: 0.00072, value_loss: 1.33920 action_loss: 19.73728\n",
      "update_step:  35 model loss: 7.70800, kl_loss: 3.00093, obs_loss: 4.70503, reward_loss: 0.00204, value_loss: 1.18220 action_loss: 19.68340\n",
      "update_step:  36 model loss: 8.53045, kl_loss: 3.00128, obs_loss: 5.52639, reward_loss: 0.00278, value_loss: 1.15069 action_loss: 19.38766\n",
      "update_step:  37 model loss: 8.97852, kl_loss: 3.00076, obs_loss: 5.97719, reward_loss: 0.00057, value_loss: 1.22850 action_loss: 18.81489\n",
      "update_step:  38 model loss: 8.12809, kl_loss: 3.00018, obs_loss: 5.12561, reward_loss: 0.00229, value_loss: 1.19027 action_loss: 18.56441\n",
      "update_step:  39 model loss: 7.34647, kl_loss: 3.00023, obs_loss: 4.34345, reward_loss: 0.00279, value_loss: 1.03831 action_loss: 18.96318\n",
      "update_step:  40 model loss: 7.64733, kl_loss: 3.00000, obs_loss: 4.64686, reward_loss: 0.00046, value_loss: 0.97135 action_loss: 19.40973\n",
      "update_step:  41 model loss: 8.00484, kl_loss: 3.00030, obs_loss: 5.00191, reward_loss: 0.00262, value_loss: 0.89521 action_loss: 19.34483\n",
      "update_step:  42 model loss: 7.30369, kl_loss: 3.00013, obs_loss: 4.30199, reward_loss: 0.00157, value_loss: 0.77179 action_loss: 19.14371\n",
      "update_step:  43 model loss: 8.08764, kl_loss: 3.00002, obs_loss: 5.08714, reward_loss: 0.00047, value_loss: 0.67587 action_loss: 19.14017\n",
      "update_step:  44 model loss: 7.64557, kl_loss: 3.00000, obs_loss: 4.64386, reward_loss: 0.00171, value_loss: 0.56749 action_loss: 19.40206\n",
      "update_step:  45 model loss: 8.16976, kl_loss: 3.00050, obs_loss: 5.16833, reward_loss: 0.00093, value_loss: 0.49536 action_loss: 19.64832\n",
      "update_step:  46 model loss: 7.67662, kl_loss: 3.00121, obs_loss: 4.67505, reward_loss: 0.00036, value_loss: 0.44534 action_loss: 19.81576\n",
      "update_step:  47 model loss: 7.79086, kl_loss: 3.00022, obs_loss: 4.78949, reward_loss: 0.00115, value_loss: 0.39999 action_loss: 19.87576\n",
      "update_step:  48 model loss: 8.30993, kl_loss: 3.00000, obs_loss: 5.30914, reward_loss: 0.00079, value_loss: 0.39100 action_loss: 19.79007\n",
      "update_step:  49 model loss: 8.14037, kl_loss: 3.00045, obs_loss: 5.13963, reward_loss: 0.00029, value_loss: 0.43510 action_loss: 19.63287\n",
      "update_step:  50 model loss: 6.89967, kl_loss: 3.00089, obs_loss: 3.89770, reward_loss: 0.00109, value_loss: 0.39051 action_loss: 19.64507\n",
      "update_step:  51 model loss: 7.29832, kl_loss: 3.00134, obs_loss: 4.29621, reward_loss: 0.00076, value_loss: 0.32466 action_loss: 19.84454\n",
      "update_step:  52 model loss: 7.15905, kl_loss: 3.00176, obs_loss: 4.15701, reward_loss: 0.00028, value_loss: 0.30383 action_loss: 20.00721\n",
      "update_step:  53 model loss: 7.50365, kl_loss: 3.00164, obs_loss: 4.50094, reward_loss: 0.00107, value_loss: 0.30025 action_loss: 19.90300\n",
      "update_step:  54 model loss: 6.74852, kl_loss: 3.00130, obs_loss: 3.74674, reward_loss: 0.00049, value_loss: 0.31105 action_loss: 19.71917\n",
      "update_step:  55 model loss: 8.44996, kl_loss: 3.00183, obs_loss: 5.44781, reward_loss: 0.00032, value_loss: 0.31243 action_loss: 19.65585\n",
      "update_step:  56 model loss: 8.26708, kl_loss: 3.00216, obs_loss: 5.26413, reward_loss: 0.00080, value_loss: 0.26692 action_loss: 19.74010\n",
      "update_step:  57 model loss: 7.77819, kl_loss: 3.00184, obs_loss: 4.77600, reward_loss: 0.00035, value_loss: 0.22899 action_loss: 19.85215\n",
      "update_step:  58 model loss: 7.04214, kl_loss: 3.00250, obs_loss: 4.03938, reward_loss: 0.00026, value_loss: 0.21358 action_loss: 19.91051\n",
      "update_step:  59 model loss: 6.50934, kl_loss: 3.00139, obs_loss: 3.50737, reward_loss: 0.00059, value_loss: 0.19827 action_loss: 19.89300\n",
      "update_step:  60 model loss: 7.66076, kl_loss: 3.00147, obs_loss: 4.65896, reward_loss: 0.00034, value_loss: 0.20052 action_loss: 19.80499\n",
      "update_step:  61 model loss: 7.06427, kl_loss: 3.00002, obs_loss: 4.06406, reward_loss: 0.00020, value_loss: 0.19629 action_loss: 19.70180\n",
      "update_step:  62 model loss: 7.70895, kl_loss: 3.00062, obs_loss: 4.70783, reward_loss: 0.00050, value_loss: 0.18059 action_loss: 19.66857\n",
      "update_step:  63 model loss: 7.37172, kl_loss: 3.00019, obs_loss: 4.37121, reward_loss: 0.00032, value_loss: 0.16966 action_loss: 19.71889\n",
      "update_step:  64 model loss: 7.34227, kl_loss: 3.00024, obs_loss: 4.34185, reward_loss: 0.00018, value_loss: 0.16969 action_loss: 19.73883\n",
      "update_step:  65 model loss: 7.53810, kl_loss: 3.00350, obs_loss: 4.53416, reward_loss: 0.00044, value_loss: 0.16694 action_loss: 19.63743\n",
      "update_step:  66 model loss: 6.71930, kl_loss: 3.00087, obs_loss: 3.71819, reward_loss: 0.00024, value_loss: 0.16067 action_loss: 19.47239\n",
      "update_step:  67 model loss: 7.30893, kl_loss: 3.00163, obs_loss: 4.30712, reward_loss: 0.00018, value_loss: 0.15233 action_loss: 19.42259\n",
      "update_step:  68 model loss: 8.01645, kl_loss: 3.00013, obs_loss: 5.01597, reward_loss: 0.00035, value_loss: 0.14582 action_loss: 19.46792\n",
      "update_step:  69 model loss: 6.83958, kl_loss: 3.00079, obs_loss: 3.83860, reward_loss: 0.00019, value_loss: 0.14669 action_loss: 19.57034\n",
      "update_step:  70 model loss: 7.32713, kl_loss: 3.00132, obs_loss: 4.32564, reward_loss: 0.00016, value_loss: 0.14050 action_loss: 19.65730\n",
      "update_step:  71 model loss: 8.13341, kl_loss: 3.00024, obs_loss: 5.13289, reward_loss: 0.00028, value_loss: 0.13036 action_loss: 19.68351\n",
      "update_step:  72 model loss: 8.35612, kl_loss: 3.00088, obs_loss: 5.35507, reward_loss: 0.00016, value_loss: 0.12450 action_loss: 19.69609\n",
      "update_step:  73 model loss: 7.31217, kl_loss: 3.00042, obs_loss: 4.31161, reward_loss: 0.00015, value_loss: 0.12391 action_loss: 19.71066\n",
      "update_step:  74 model loss: 7.30200, kl_loss: 3.00051, obs_loss: 4.30124, reward_loss: 0.00025, value_loss: 0.12116 action_loss: 19.79191\n",
      "update_step:  75 model loss: 7.60058, kl_loss: 3.00000, obs_loss: 4.60044, reward_loss: 0.00014, value_loss: 0.11741 action_loss: 19.89068\n",
      "update_step:  76 model loss: 8.08520, kl_loss: 3.00054, obs_loss: 5.08452, reward_loss: 0.00014, value_loss: 0.11793 action_loss: 19.94052\n",
      "update_step:  77 model loss: 7.34836, kl_loss: 3.00048, obs_loss: 4.34764, reward_loss: 0.00023, value_loss: 0.11378 action_loss: 19.92667\n",
      "update_step:  78 model loss: 7.26832, kl_loss: 3.00019, obs_loss: 4.26799, reward_loss: 0.00014, value_loss: 0.11857 action_loss: 19.85798\n",
      "update_step:  79 model loss: 7.09411, kl_loss: 3.00055, obs_loss: 4.09342, reward_loss: 0.00013, value_loss: 0.12170 action_loss: 19.80699\n",
      "update_step:  80 model loss: 7.17875, kl_loss: 3.00112, obs_loss: 4.17742, reward_loss: 0.00020, value_loss: 0.11473 action_loss: 19.80362\n",
      "update_step:  81 model loss: 7.88650, kl_loss: 3.00031, obs_loss: 4.88606, reward_loss: 0.00013, value_loss: 0.10949 action_loss: 19.79228\n",
      "update_step:  82 model loss: 7.16630, kl_loss: 3.00014, obs_loss: 4.16602, reward_loss: 0.00014, value_loss: 0.10922 action_loss: 19.74752\n",
      "update_step:  83 model loss: 6.86816, kl_loss: 3.00076, obs_loss: 3.86724, reward_loss: 0.00017, value_loss: 0.10716 action_loss: 19.70746\n",
      "update_step:  84 model loss: 7.18527, kl_loss: 3.00120, obs_loss: 4.18395, reward_loss: 0.00012, value_loss: 0.10566 action_loss: 19.64539\n",
      "update_step:  85 model loss: 7.96258, kl_loss: 3.00044, obs_loss: 4.96201, reward_loss: 0.00013, value_loss: 0.10414 action_loss: 19.59658\n",
      "update_step:  86 model loss: 6.42664, kl_loss: 3.00023, obs_loss: 3.42627, reward_loss: 0.00015, value_loss: 0.10267 action_loss: 19.63084\n",
      "update_step:  87 model loss: 6.71178, kl_loss: 3.00074, obs_loss: 3.71094, reward_loss: 0.00010, value_loss: 0.09997 action_loss: 19.65715\n",
      "update_step:  88 model loss: 6.71717, kl_loss: 3.00085, obs_loss: 3.71620, reward_loss: 0.00012, value_loss: 0.10000 action_loss: 19.66016\n",
      "update_step:  89 model loss: 7.22634, kl_loss: 3.00093, obs_loss: 4.22529, reward_loss: 0.00012, value_loss: 0.09594 action_loss: 19.63257\n",
      "update_step:  90 model loss: 7.57221, kl_loss: 3.00260, obs_loss: 4.56951, reward_loss: 0.00010, value_loss: 0.09361 action_loss: 19.60994\n",
      "update_step:  91 model loss: 6.31248, kl_loss: 3.00099, obs_loss: 3.31138, reward_loss: 0.00011, value_loss: 0.09325 action_loss: 19.60202\n",
      "update_step:  92 model loss: 7.11952, kl_loss: 3.00171, obs_loss: 4.11771, reward_loss: 0.00010, value_loss: 0.09123 action_loss: 19.58379\n",
      "update_step:  93 model loss: 8.26155, kl_loss: 3.00077, obs_loss: 5.26068, reward_loss: 0.00010, value_loss: 0.08973 action_loss: 19.57870\n",
      "update_step:  94 model loss: 8.66119, kl_loss: 3.00038, obs_loss: 5.66072, reward_loss: 0.00010, value_loss: 0.09280 action_loss: 19.54884\n",
      "update_step:  95 model loss: 7.32638, kl_loss: 3.00071, obs_loss: 4.32557, reward_loss: 0.00011, value_loss: 0.09166 action_loss: 19.53129\n",
      "update_step:  96 model loss: 7.91956, kl_loss: 3.00034, obs_loss: 4.91912, reward_loss: 0.00010, value_loss: 0.09196 action_loss: 19.51038\n",
      "update_step:  97 model loss: 7.69029, kl_loss: 3.00013, obs_loss: 4.69007, reward_loss: 0.00009, value_loss: 0.09109 action_loss: 19.51593\n",
      "update_step:  98 model loss: 7.09862, kl_loss: 3.00034, obs_loss: 4.09818, reward_loss: 0.00011, value_loss: 0.08822 action_loss: 19.56763\n",
      "update_step:  99 model loss: 7.86354, kl_loss: 3.00014, obs_loss: 4.86331, reward_loss: 0.00009, value_loss: 0.08835 action_loss: 19.62101\n",
      "update_step: 100 model loss: 6.95539, kl_loss: 3.00015, obs_loss: 3.95513, reward_loss: 0.00010, value_loss: 0.08603 action_loss: 19.66808\n",
      "elasped time for update: 20.36s\n",
      "episode [   7/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 7.40789, kl_loss: 3.00008, obs_loss: 4.40771, reward_loss: 0.00010, value_loss: 0.08500 action_loss: 19.70658\n",
      "update_step:   2 model loss: 7.60602, kl_loss: 3.00000, obs_loss: 4.60592, reward_loss: 0.00009, value_loss: 0.08764 action_loss: 19.72522\n",
      "update_step:   3 model loss: 6.83955, kl_loss: 3.00025, obs_loss: 3.83919, reward_loss: 0.00010, value_loss: 0.08621 action_loss: 19.73551\n",
      "update_step:   4 model loss: 7.65925, kl_loss: 3.00015, obs_loss: 4.65901, reward_loss: 0.00009, value_loss: 0.08719 action_loss: 19.70897\n",
      "update_step:   5 model loss: 7.57024, kl_loss: 3.00000, obs_loss: 4.57016, reward_loss: 0.00009, value_loss: 0.08749 action_loss: 19.68232\n",
      "update_step:   6 model loss: 6.40337, kl_loss: 3.00109, obs_loss: 3.40218, reward_loss: 0.00009, value_loss: 0.08624 action_loss: 19.70641\n",
      "update_step:   7 model loss: 6.50526, kl_loss: 3.00000, obs_loss: 3.50517, reward_loss: 0.00009, value_loss: 0.08461 action_loss: 19.68188\n",
      "update_step:   8 model loss: 6.89376, kl_loss: 3.00002, obs_loss: 3.89365, reward_loss: 0.00009, value_loss: 0.08492 action_loss: 19.62969\n",
      "update_step:   9 model loss: 7.04013, kl_loss: 3.00039, obs_loss: 4.03964, reward_loss: 0.00009, value_loss: 0.08311 action_loss: 19.56129\n",
      "update_step:  10 model loss: 7.60492, kl_loss: 3.00103, obs_loss: 4.60381, reward_loss: 0.00009, value_loss: 0.08266 action_loss: 19.49595\n",
      "update_step:  11 model loss: 7.25013, kl_loss: 3.00125, obs_loss: 4.24879, reward_loss: 0.00009, value_loss: 0.08451 action_loss: 19.42337\n",
      "update_step:  12 model loss: 6.54746, kl_loss: 3.00013, obs_loss: 3.54724, reward_loss: 0.00009, value_loss: 0.08715 action_loss: 19.37535\n",
      "update_step:  13 model loss: 6.55884, kl_loss: 3.00083, obs_loss: 3.55792, reward_loss: 0.00009, value_loss: 0.08756 action_loss: 19.33760\n",
      "update_step:  14 model loss: 7.06291, kl_loss: 3.00056, obs_loss: 4.06227, reward_loss: 0.00009, value_loss: 0.08746 action_loss: 19.31877\n",
      "update_step:  15 model loss: 7.09899, kl_loss: 3.00065, obs_loss: 4.09826, reward_loss: 0.00009, value_loss: 0.08822 action_loss: 19.34304\n",
      "update_step:  16 model loss: 6.36162, kl_loss: 3.00091, obs_loss: 3.36063, reward_loss: 0.00009, value_loss: 0.08547 action_loss: 19.35735\n",
      "update_step:  17 model loss: 7.02626, kl_loss: 3.00073, obs_loss: 4.02544, reward_loss: 0.00009, value_loss: 0.08307 action_loss: 19.41545\n",
      "update_step:  18 model loss: 6.41297, kl_loss: 3.00231, obs_loss: 3.41057, reward_loss: 0.00009, value_loss: 0.08477 action_loss: 19.46989\n",
      "update_step:  19 model loss: 7.66258, kl_loss: 3.00374, obs_loss: 4.65874, reward_loss: 0.00009, value_loss: 0.08561 action_loss: 19.49549\n",
      "update_step:  20 model loss: 7.04314, kl_loss: 3.00778, obs_loss: 4.03526, reward_loss: 0.00010, value_loss: 0.08794 action_loss: 19.49520\n",
      "update_step:  21 model loss: 6.63286, kl_loss: 3.02092, obs_loss: 3.61182, reward_loss: 0.00013, value_loss: 0.09153 action_loss: 19.43538\n",
      "update_step:  22 model loss: 7.07411, kl_loss: 3.02548, obs_loss: 4.04847, reward_loss: 0.00016, value_loss: 0.08773 action_loss: 19.29343\n",
      "update_step:  23 model loss: 6.79656, kl_loss: 3.00056, obs_loss: 3.79587, reward_loss: 0.00013, value_loss: 0.08818 action_loss: 19.19318\n",
      "update_step:  24 model loss: 6.70019, kl_loss: 3.00154, obs_loss: 3.69849, reward_loss: 0.00016, value_loss: 0.09010 action_loss: 19.09415\n",
      "update_step:  25 model loss: 6.41790, kl_loss: 3.00944, obs_loss: 3.40827, reward_loss: 0.00019, value_loss: 0.11932 action_loss: 18.87251\n",
      "update_step:  26 model loss: 6.19400, kl_loss: 3.00028, obs_loss: 3.19352, reward_loss: 0.00020, value_loss: 0.11195 action_loss: 18.99322\n",
      "update_step:  27 model loss: 5.91216, kl_loss: 3.00000, obs_loss: 2.91189, reward_loss: 0.00027, value_loss: 0.09164 action_loss: 18.92103\n",
      "update_step:  28 model loss: 6.22105, kl_loss: 3.00000, obs_loss: 3.22086, reward_loss: 0.00020, value_loss: 0.11134 action_loss: 18.65655\n",
      "update_step:  29 model loss: 6.69668, kl_loss: 3.00000, obs_loss: 3.69642, reward_loss: 0.00026, value_loss: 0.09940 action_loss: 18.78194\n",
      "update_step:  30 model loss: 6.16463, kl_loss: 3.00000, obs_loss: 3.16444, reward_loss: 0.00018, value_loss: 0.08543 action_loss: 19.03722\n",
      "update_step:  31 model loss: 6.69308, kl_loss: 3.00000, obs_loss: 3.69276, reward_loss: 0.00032, value_loss: 0.10623 action_loss: 18.75007\n",
      "update_step:  32 model loss: 5.99145, kl_loss: 3.00000, obs_loss: 2.99115, reward_loss: 0.00031, value_loss: 0.11944 action_loss: 18.84122\n",
      "update_step:  33 model loss: 7.02507, kl_loss: 3.00000, obs_loss: 4.02481, reward_loss: 0.00026, value_loss: 0.16473 action_loss: 18.75832\n",
      "update_step:  34 model loss: 6.88764, kl_loss: 3.00000, obs_loss: 3.88732, reward_loss: 0.00032, value_loss: 0.16973 action_loss: 18.47597\n",
      "update_step:  35 model loss: 6.43197, kl_loss: 3.00000, obs_loss: 3.43169, reward_loss: 0.00028, value_loss: 0.12566 action_loss: 18.30303\n",
      "update_step:  36 model loss: 6.47213, kl_loss: 3.00000, obs_loss: 3.47184, reward_loss: 0.00029, value_loss: 0.12835 action_loss: 18.30879\n",
      "update_step:  37 model loss: 6.59749, kl_loss: 3.00000, obs_loss: 3.59721, reward_loss: 0.00029, value_loss: 0.16694 action_loss: 18.29030\n",
      "update_step:  38 model loss: 5.93155, kl_loss: 3.00000, obs_loss: 2.93124, reward_loss: 0.00030, value_loss: 0.16545 action_loss: 18.10265\n",
      "update_step:  39 model loss: 6.15307, kl_loss: 3.00000, obs_loss: 3.15280, reward_loss: 0.00028, value_loss: 0.11119 action_loss: 18.13433\n",
      "update_step:  40 model loss: 6.79470, kl_loss: 3.00000, obs_loss: 3.79443, reward_loss: 0.00027, value_loss: 0.10627 action_loss: 18.31518\n",
      "update_step:  41 model loss: 5.88926, kl_loss: 3.00017, obs_loss: 2.88877, reward_loss: 0.00031, value_loss: 0.09979 action_loss: 18.55363\n",
      "update_step:  42 model loss: 5.87708, kl_loss: 3.00033, obs_loss: 2.87655, reward_loss: 0.00019, value_loss: 0.09256 action_loss: 18.94496\n",
      "update_step:  43 model loss: 6.44026, kl_loss: 3.00054, obs_loss: 3.43942, reward_loss: 0.00030, value_loss: 0.10360 action_loss: 19.04534\n",
      "update_step:  44 model loss: 5.48443, kl_loss: 3.00006, obs_loss: 2.48420, reward_loss: 0.00017, value_loss: 0.10306 action_loss: 19.03265\n",
      "update_step:  45 model loss: 6.63942, kl_loss: 3.00036, obs_loss: 3.63882, reward_loss: 0.00025, value_loss: 0.07958 action_loss: 19.01617\n",
      "update_step:  46 model loss: 5.86956, kl_loss: 3.00002, obs_loss: 2.86941, reward_loss: 0.00014, value_loss: 0.07018 action_loss: 19.42728\n",
      "update_step:  47 model loss: 7.19936, kl_loss: 3.00000, obs_loss: 4.19910, reward_loss: 0.00026, value_loss: 0.07294 action_loss: 19.30852\n",
      "update_step:  48 model loss: 6.38536, kl_loss: 3.00016, obs_loss: 3.38490, reward_loss: 0.00031, value_loss: 0.08585 action_loss: 19.07321\n",
      "update_step:  49 model loss: 7.04525, kl_loss: 3.00041, obs_loss: 4.04472, reward_loss: 0.00012, value_loss: 0.10669 action_loss: 18.96053\n",
      "update_step:  50 model loss: 6.42658, kl_loss: 3.00086, obs_loss: 3.42550, reward_loss: 0.00022, value_loss: 0.11105 action_loss: 18.97790\n",
      "update_step:  51 model loss: 5.77959, kl_loss: 3.00008, obs_loss: 2.77928, reward_loss: 0.00023, value_loss: 0.08261 action_loss: 18.99554\n",
      "update_step:  52 model loss: 6.78925, kl_loss: 3.00000, obs_loss: 3.78909, reward_loss: 0.00016, value_loss: 0.09876 action_loss: 18.85000\n",
      "update_step:  53 model loss: 5.35567, kl_loss: 3.00003, obs_loss: 2.35552, reward_loss: 0.00013, value_loss: 0.15681 action_loss: 18.76312\n",
      "update_step:  54 model loss: 6.62411, kl_loss: 3.00016, obs_loss: 3.62377, reward_loss: 0.00018, value_loss: 0.13653 action_loss: 19.02888\n",
      "update_step:  55 model loss: 5.19272, kl_loss: 3.00000, obs_loss: 2.19250, reward_loss: 0.00022, value_loss: 0.11333 action_loss: 19.11754\n",
      "update_step:  56 model loss: 6.21782, kl_loss: 3.00053, obs_loss: 3.21713, reward_loss: 0.00016, value_loss: 0.14334 action_loss: 19.12207\n",
      "update_step:  57 model loss: 6.02399, kl_loss: 3.00035, obs_loss: 3.02330, reward_loss: 0.00034, value_loss: 0.15920 action_loss: 19.44410\n",
      "update_step:  58 model loss: 5.36867, kl_loss: 3.00150, obs_loss: 2.36702, reward_loss: 0.00016, value_loss: 0.17388 action_loss: 19.73427\n",
      "update_step:  59 model loss: 5.88686, kl_loss: 3.00148, obs_loss: 2.88513, reward_loss: 0.00025, value_loss: 0.11967 action_loss: 19.65316\n",
      "update_step:  60 model loss: 6.30512, kl_loss: 3.00038, obs_loss: 3.30456, reward_loss: 0.00018, value_loss: 0.12041 action_loss: 19.63490\n",
      "update_step:  61 model loss: 5.56182, kl_loss: 3.00356, obs_loss: 2.55809, reward_loss: 0.00017, value_loss: 0.17994 action_loss: 19.62929\n",
      "update_step:  62 model loss: 6.39726, kl_loss: 3.00152, obs_loss: 3.39558, reward_loss: 0.00016, value_loss: 0.20477 action_loss: 19.52839\n",
      "update_step:  63 model loss: 5.57557, kl_loss: 3.00183, obs_loss: 2.57354, reward_loss: 0.00020, value_loss: 0.13973 action_loss: 19.48814\n",
      "update_step:  64 model loss: 6.05588, kl_loss: 3.00026, obs_loss: 3.05549, reward_loss: 0.00013, value_loss: 0.13294 action_loss: 19.52206\n",
      "update_step:  65 model loss: 5.22933, kl_loss: 3.00116, obs_loss: 2.22797, reward_loss: 0.00020, value_loss: 0.10478 action_loss: 19.38512\n",
      "update_step:  66 model loss: 6.20227, kl_loss: 3.00109, obs_loss: 3.20105, reward_loss: 0.00014, value_loss: 0.10355 action_loss: 19.19281\n",
      "update_step:  67 model loss: 5.12520, kl_loss: 3.00196, obs_loss: 2.12305, reward_loss: 0.00018, value_loss: 0.10868 action_loss: 19.29306\n",
      "update_step:  68 model loss: 5.92880, kl_loss: 3.00352, obs_loss: 2.92515, reward_loss: 0.00013, value_loss: 0.10857 action_loss: 19.37504\n",
      "update_step:  69 model loss: 5.18539, kl_loss: 3.00198, obs_loss: 2.18327, reward_loss: 0.00013, value_loss: 0.10708 action_loss: 19.23098\n",
      "update_step:  70 model loss: 4.82016, kl_loss: 3.00294, obs_loss: 1.81710, reward_loss: 0.00012, value_loss: 0.10546 action_loss: 19.25154\n",
      "update_step:  71 model loss: 4.87942, kl_loss: 3.00640, obs_loss: 1.87290, reward_loss: 0.00012, value_loss: 0.10727 action_loss: 19.23082\n",
      "update_step:  72 model loss: 5.44806, kl_loss: 3.00719, obs_loss: 2.44075, reward_loss: 0.00012, value_loss: 0.10784 action_loss: 19.20906\n",
      "update_step:  73 model loss: 4.98055, kl_loss: 3.01117, obs_loss: 1.96925, reward_loss: 0.00013, value_loss: 0.10438 action_loss: 19.38439\n",
      "update_step:  74 model loss: 4.94644, kl_loss: 3.01481, obs_loss: 1.93148, reward_loss: 0.00015, value_loss: 0.12385 action_loss: 19.08149\n",
      "update_step:  75 model loss: 4.90984, kl_loss: 3.00903, obs_loss: 1.90067, reward_loss: 0.00014, value_loss: 0.12207 action_loss: 19.27793\n",
      "update_step:  76 model loss: 5.62080, kl_loss: 3.00386, obs_loss: 2.61682, reward_loss: 0.00012, value_loss: 0.16843 action_loss: 19.38895\n",
      "update_step:  77 model loss: 5.43858, kl_loss: 3.00233, obs_loss: 2.43612, reward_loss: 0.00013, value_loss: 0.14552 action_loss: 19.13708\n",
      "update_step:  78 model loss: 5.15520, kl_loss: 3.00204, obs_loss: 2.15303, reward_loss: 0.00013, value_loss: 0.14155 action_loss: 19.25776\n",
      "update_step:  79 model loss: 5.57310, kl_loss: 3.00017, obs_loss: 2.57281, reward_loss: 0.00012, value_loss: 0.12183 action_loss: 19.32098\n",
      "update_step:  80 model loss: 4.58254, kl_loss: 3.00030, obs_loss: 1.58210, reward_loss: 0.00014, value_loss: 0.13392 action_loss: 19.07210\n",
      "update_step:  81 model loss: 5.81793, kl_loss: 3.00092, obs_loss: 2.81687, reward_loss: 0.00015, value_loss: 0.11963 action_loss: 19.23157\n",
      "update_step:  82 model loss: 5.00962, kl_loss: 3.00158, obs_loss: 2.00793, reward_loss: 0.00012, value_loss: 0.12544 action_loss: 19.37226\n",
      "update_step:  83 model loss: 5.56869, kl_loss: 3.00043, obs_loss: 2.56811, reward_loss: 0.00014, value_loss: 0.14510 action_loss: 19.35564\n",
      "update_step:  84 model loss: 4.91681, kl_loss: 3.00231, obs_loss: 1.91435, reward_loss: 0.00015, value_loss: 0.15160 action_loss: 19.37148\n",
      "update_step:  85 model loss: 4.97761, kl_loss: 3.00182, obs_loss: 1.97567, reward_loss: 0.00012, value_loss: 0.13158 action_loss: 19.44171\n",
      "update_step:  86 model loss: 4.65487, kl_loss: 3.00051, obs_loss: 1.65422, reward_loss: 0.00014, value_loss: 0.13878 action_loss: 19.43669\n",
      "update_step:  87 model loss: 5.25733, kl_loss: 3.00022, obs_loss: 2.25699, reward_loss: 0.00012, value_loss: 0.12412 action_loss: 19.39305\n",
      "update_step:  88 model loss: 4.43835, kl_loss: 3.00113, obs_loss: 1.43709, reward_loss: 0.00013, value_loss: 0.12183 action_loss: 19.49933\n",
      "update_step:  89 model loss: 4.33222, kl_loss: 3.00318, obs_loss: 1.32889, reward_loss: 0.00014, value_loss: 0.13614 action_loss: 19.30802\n",
      "update_step:  90 model loss: 4.32301, kl_loss: 3.00607, obs_loss: 1.31681, reward_loss: 0.00013, value_loss: 0.13751 action_loss: 19.38310\n",
      "update_step:  91 model loss: 4.40024, kl_loss: 3.03588, obs_loss: 1.36424, reward_loss: 0.00012, value_loss: 0.17380 action_loss: 19.49278\n",
      "update_step:  92 model loss: 4.92148, kl_loss: 3.01178, obs_loss: 1.90958, reward_loss: 0.00013, value_loss: 0.18916 action_loss: 19.47540\n",
      "update_step:  93 model loss: 4.26435, kl_loss: 3.00139, obs_loss: 1.26283, reward_loss: 0.00013, value_loss: 0.18872 action_loss: 19.54389\n",
      "update_step:  94 model loss: 3.94413, kl_loss: 3.00089, obs_loss: 0.94311, reward_loss: 0.00014, value_loss: 0.19166 action_loss: 19.57349\n",
      "update_step:  95 model loss: 4.20548, kl_loss: 3.00015, obs_loss: 1.20520, reward_loss: 0.00014, value_loss: 0.17497 action_loss: 19.61983\n",
      "update_step:  96 model loss: 4.17691, kl_loss: 3.00216, obs_loss: 1.17461, reward_loss: 0.00015, value_loss: 0.17087 action_loss: 19.65549\n",
      "update_step:  97 model loss: 4.00469, kl_loss: 3.00315, obs_loss: 1.00139, reward_loss: 0.00014, value_loss: 0.18893 action_loss: 19.54938\n",
      "update_step:  98 model loss: 4.03322, kl_loss: 3.01714, obs_loss: 1.01592, reward_loss: 0.00016, value_loss: 0.21293 action_loss: 19.65434\n",
      "update_step:  99 model loss: 3.77370, kl_loss: 3.02131, obs_loss: 0.75224, reward_loss: 0.00015, value_loss: 0.19923 action_loss: 19.53971\n",
      "update_step: 100 model loss: 3.57864, kl_loss: 3.00603, obs_loss: 0.57246, reward_loss: 0.00015, value_loss: 0.17607 action_loss: 19.61354\n",
      "elasped time for update: 20.07s\n",
      "episode [   8/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.48258, kl_loss: 3.00452, obs_loss: 0.47790, reward_loss: 0.00016, value_loss: 0.17719 action_loss: 19.47265\n",
      "update_step:   2 model loss: 3.49017, kl_loss: 3.01123, obs_loss: 0.47879, reward_loss: 0.00015, value_loss: 0.19007 action_loss: 19.49118\n",
      "update_step:   3 model loss: 3.51512, kl_loss: 3.00877, obs_loss: 0.50617, reward_loss: 0.00018, value_loss: 0.20028 action_loss: 19.34725\n",
      "update_step:   4 model loss: 3.61058, kl_loss: 3.01538, obs_loss: 0.59500, reward_loss: 0.00020, value_loss: 0.25052 action_loss: 19.68792\n",
      "update_step:   5 model loss: 4.30500, kl_loss: 3.03089, obs_loss: 1.27372, reward_loss: 0.00039, value_loss: 0.26742 action_loss: 18.94373\n",
      "update_step:   6 model loss: 6.03609, kl_loss: 3.01299, obs_loss: 3.02198, reward_loss: 0.00113, value_loss: 0.32265 action_loss: 19.94513\n",
      "update_step:   7 model loss: 4.24603, kl_loss: 3.00119, obs_loss: 1.24380, reward_loss: 0.00104, value_loss: 0.28274 action_loss: 19.94916\n",
      "update_step:   8 model loss: 4.87071, kl_loss: 3.00085, obs_loss: 1.86928, reward_loss: 0.00057, value_loss: 0.31491 action_loss: 19.59727\n",
      "update_step:   9 model loss: 4.18979, kl_loss: 3.00108, obs_loss: 1.18848, reward_loss: 0.00023, value_loss: 0.37331 action_loss: 19.34178\n",
      "update_step:  10 model loss: 4.27246, kl_loss: 3.00089, obs_loss: 1.27119, reward_loss: 0.00038, value_loss: 0.40512 action_loss: 19.28933\n",
      "update_step:  11 model loss: 4.16728, kl_loss: 3.00005, obs_loss: 1.16662, reward_loss: 0.00061, value_loss: 0.39500 action_loss: 19.50098\n",
      "update_step:  12 model loss: 3.96835, kl_loss: 3.00330, obs_loss: 0.96447, reward_loss: 0.00058, value_loss: 0.36229 action_loss: 19.92655\n",
      "update_step:  13 model loss: 3.49765, kl_loss: 3.02035, obs_loss: 0.47715, reward_loss: 0.00015, value_loss: 0.36427 action_loss: 20.33991\n",
      "update_step:  14 model loss: 3.53549, kl_loss: 3.06525, obs_loss: 0.46974, reward_loss: 0.00051, value_loss: 0.35817 action_loss: 20.44402\n",
      "update_step:  15 model loss: 3.72266, kl_loss: 3.07845, obs_loss: 0.64349, reward_loss: 0.00072, value_loss: 0.31887 action_loss: 20.14652\n",
      "update_step:  16 model loss: 3.59341, kl_loss: 3.06154, obs_loss: 0.53159, reward_loss: 0.00027, value_loss: 0.28644 action_loss: 19.66204\n",
      "update_step:  17 model loss: 3.36810, kl_loss: 3.02807, obs_loss: 0.33964, reward_loss: 0.00040, value_loss: 0.26203 action_loss: 19.21502\n",
      "update_step:  18 model loss: 3.53998, kl_loss: 3.02115, obs_loss: 0.51818, reward_loss: 0.00066, value_loss: 0.25439 action_loss: 18.96195\n",
      "update_step:  19 model loss: 3.43053, kl_loss: 3.00656, obs_loss: 0.42354, reward_loss: 0.00042, value_loss: 0.25540 action_loss: 18.95451\n",
      "update_step:  20 model loss: 3.34982, kl_loss: 3.01118, obs_loss: 0.33844, reward_loss: 0.00021, value_loss: 0.27855 action_loss: 19.09530\n",
      "update_step:  21 model loss: 3.39779, kl_loss: 3.00923, obs_loss: 0.38820, reward_loss: 0.00036, value_loss: 0.26741 action_loss: 19.23055\n",
      "update_step:  22 model loss: 3.45878, kl_loss: 3.01370, obs_loss: 0.44455, reward_loss: 0.00054, value_loss: 0.21337 action_loss: 19.29305\n",
      "update_step:  23 model loss: 3.37925, kl_loss: 3.01073, obs_loss: 0.36813, reward_loss: 0.00040, value_loss: 0.17216 action_loss: 19.40006\n",
      "update_step:  24 model loss: 3.30255, kl_loss: 3.01257, obs_loss: 0.28982, reward_loss: 0.00016, value_loss: 0.17249 action_loss: 19.56311\n",
      "update_step:  25 model loss: 3.32272, kl_loss: 3.01983, obs_loss: 0.30263, reward_loss: 0.00025, value_loss: 0.18739 action_loss: 19.77474\n",
      "update_step:  26 model loss: 3.25245, kl_loss: 3.01930, obs_loss: 0.23279, reward_loss: 0.00035, value_loss: 0.18741 action_loss: 19.99844\n",
      "update_step:  27 model loss: 3.26353, kl_loss: 3.01663, obs_loss: 0.24658, reward_loss: 0.00033, value_loss: 0.16647 action_loss: 20.19669\n",
      "update_step:  28 model loss: 3.23870, kl_loss: 3.02236, obs_loss: 0.21618, reward_loss: 0.00016, value_loss: 0.14241 action_loss: 20.28802\n",
      "update_step:  29 model loss: 3.27360, kl_loss: 3.01865, obs_loss: 0.25477, reward_loss: 0.00018, value_loss: 0.11885 action_loss: 20.26135\n",
      "update_step:  30 model loss: 3.25237, kl_loss: 3.02115, obs_loss: 0.23093, reward_loss: 0.00029, value_loss: 0.11330 action_loss: 20.11817\n",
      "update_step:  31 model loss: 3.16261, kl_loss: 3.01666, obs_loss: 0.14570, reward_loss: 0.00025, value_loss: 0.10584 action_loss: 19.90277\n",
      "update_step:  32 model loss: 3.19284, kl_loss: 3.02399, obs_loss: 0.16872, reward_loss: 0.00013, value_loss: 0.10684 action_loss: 19.68392\n",
      "update_step:  33 model loss: 3.17538, kl_loss: 3.02070, obs_loss: 0.15456, reward_loss: 0.00012, value_loss: 0.10639 action_loss: 19.49638\n",
      "update_step:  34 model loss: 3.16657, kl_loss: 3.02576, obs_loss: 0.14061, reward_loss: 0.00020, value_loss: 0.10260 action_loss: 19.40995\n",
      "update_step:  35 model loss: 3.15953, kl_loss: 3.01851, obs_loss: 0.14084, reward_loss: 0.00018, value_loss: 0.09820 action_loss: 19.38016\n",
      "update_step:  36 model loss: 3.14570, kl_loss: 3.02002, obs_loss: 0.12555, reward_loss: 0.00013, value_loss: 0.10351 action_loss: 19.36757\n",
      "update_step:  37 model loss: 3.16458, kl_loss: 3.01757, obs_loss: 0.14690, reward_loss: 0.00011, value_loss: 0.10705 action_loss: 19.36014\n",
      "update_step:  38 model loss: 3.20385, kl_loss: 3.02948, obs_loss: 0.17426, reward_loss: 0.00010, value_loss: 0.10436 action_loss: 19.39079\n",
      "update_step:  39 model loss: 3.15618, kl_loss: 3.01599, obs_loss: 0.14005, reward_loss: 0.00014, value_loss: 0.09886 action_loss: 19.48029\n",
      "update_step:  40 model loss: 3.17713, kl_loss: 3.02457, obs_loss: 0.15243, reward_loss: 0.00012, value_loss: 0.09925 action_loss: 19.58630\n",
      "update_step:  41 model loss: 3.13647, kl_loss: 3.01687, obs_loss: 0.11949, reward_loss: 0.00011, value_loss: 0.09369 action_loss: 19.69449\n",
      "update_step:  42 model loss: 3.13312, kl_loss: 3.01574, obs_loss: 0.11726, reward_loss: 0.00012, value_loss: 0.09103 action_loss: 19.76035\n",
      "update_step:  43 model loss: 3.12401, kl_loss: 3.01449, obs_loss: 0.10942, reward_loss: 0.00009, value_loss: 0.09597 action_loss: 19.79720\n",
      "update_step:  44 model loss: 3.15142, kl_loss: 3.02666, obs_loss: 0.12463, reward_loss: 0.00012, value_loss: 0.09856 action_loss: 19.81273\n",
      "update_step:  45 model loss: 3.15651, kl_loss: 3.02088, obs_loss: 0.13551, reward_loss: 0.00011, value_loss: 0.09845 action_loss: 19.81981\n",
      "update_step:  46 model loss: 3.14939, kl_loss: 3.02035, obs_loss: 0.12894, reward_loss: 0.00010, value_loss: 0.09217 action_loss: 19.81237\n",
      "update_step:  47 model loss: 3.12855, kl_loss: 3.01440, obs_loss: 0.11405, reward_loss: 0.00010, value_loss: 0.08861 action_loss: 19.78596\n",
      "update_step:  48 model loss: 3.12127, kl_loss: 3.00791, obs_loss: 0.11327, reward_loss: 0.00009, value_loss: 0.08501 action_loss: 19.76894\n",
      "update_step:  49 model loss: 3.10567, kl_loss: 3.00734, obs_loss: 0.09823, reward_loss: 0.00010, value_loss: 0.08206 action_loss: 19.75471\n",
      "update_step:  50 model loss: 3.13755, kl_loss: 3.01462, obs_loss: 0.12282, reward_loss: 0.00011, value_loss: 0.08229 action_loss: 19.73322\n",
      "update_step:  51 model loss: 3.11073, kl_loss: 3.01161, obs_loss: 0.09904, reward_loss: 0.00008, value_loss: 0.08030 action_loss: 19.71566\n",
      "update_step:  52 model loss: 3.13071, kl_loss: 3.01816, obs_loss: 0.11247, reward_loss: 0.00008, value_loss: 0.07871 action_loss: 19.68692\n",
      "update_step:  53 model loss: 3.09710, kl_loss: 3.01097, obs_loss: 0.08605, reward_loss: 0.00009, value_loss: 0.07625 action_loss: 19.65291\n",
      "update_step:  54 model loss: 3.11473, kl_loss: 3.01741, obs_loss: 0.09723, reward_loss: 0.00009, value_loss: 0.07704 action_loss: 19.62076\n",
      "update_step:  55 model loss: 3.13159, kl_loss: 3.03036, obs_loss: 0.10115, reward_loss: 0.00009, value_loss: 0.07680 action_loss: 19.60955\n",
      "update_step:  56 model loss: 3.09629, kl_loss: 3.01162, obs_loss: 0.08460, reward_loss: 0.00007, value_loss: 0.07572 action_loss: 19.62209\n",
      "update_step:  57 model loss: 3.09859, kl_loss: 3.01050, obs_loss: 0.08801, reward_loss: 0.00008, value_loss: 0.07554 action_loss: 19.62582\n",
      "update_step:  58 model loss: 3.11674, kl_loss: 3.02213, obs_loss: 0.09452, reward_loss: 0.00009, value_loss: 0.07538 action_loss: 19.62644\n",
      "update_step:  59 model loss: 3.10062, kl_loss: 3.01569, obs_loss: 0.08484, reward_loss: 0.00008, value_loss: 0.07324 action_loss: 19.62602\n",
      "update_step:  60 model loss: 3.08261, kl_loss: 3.00739, obs_loss: 0.07515, reward_loss: 0.00008, value_loss: 0.07114 action_loss: 19.62378\n",
      "update_step:  61 model loss: 3.09764, kl_loss: 3.00864, obs_loss: 0.08893, reward_loss: 0.00007, value_loss: 0.07067 action_loss: 19.62693\n",
      "update_step:  62 model loss: 3.09787, kl_loss: 3.00856, obs_loss: 0.08923, reward_loss: 0.00008, value_loss: 0.07205 action_loss: 19.64573\n",
      "update_step:  63 model loss: 3.09450, kl_loss: 3.00921, obs_loss: 0.08522, reward_loss: 0.00007, value_loss: 0.07092 action_loss: 19.66212\n",
      "update_step:  64 model loss: 3.08392, kl_loss: 3.01125, obs_loss: 0.07260, reward_loss: 0.00007, value_loss: 0.07051 action_loss: 19.66679\n",
      "update_step:  65 model loss: 3.10680, kl_loss: 3.01611, obs_loss: 0.09062, reward_loss: 0.00007, value_loss: 0.07106 action_loss: 19.66455\n",
      "update_step:  66 model loss: 3.11076, kl_loss: 3.01535, obs_loss: 0.09533, reward_loss: 0.00007, value_loss: 0.07044 action_loss: 19.67241\n",
      "update_step:  67 model loss: 3.08766, kl_loss: 3.00838, obs_loss: 0.07922, reward_loss: 0.00007, value_loss: 0.06721 action_loss: 19.67996\n",
      "update_step:  68 model loss: 3.09655, kl_loss: 3.01052, obs_loss: 0.08596, reward_loss: 0.00007, value_loss: 0.06850 action_loss: 19.67985\n",
      "update_step:  69 model loss: 3.09420, kl_loss: 3.01677, obs_loss: 0.07737, reward_loss: 0.00007, value_loss: 0.06742 action_loss: 19.66174\n",
      "update_step:  70 model loss: 3.08684, kl_loss: 3.01132, obs_loss: 0.07546, reward_loss: 0.00007, value_loss: 0.06599 action_loss: 19.65613\n",
      "update_step:  71 model loss: 3.08406, kl_loss: 3.00803, obs_loss: 0.07596, reward_loss: 0.00007, value_loss: 0.06628 action_loss: 19.66996\n",
      "update_step:  72 model loss: 3.08059, kl_loss: 3.01065, obs_loss: 0.06989, reward_loss: 0.00006, value_loss: 0.06512 action_loss: 19.68385\n",
      "update_step:  73 model loss: 3.08955, kl_loss: 3.01475, obs_loss: 0.07474, reward_loss: 0.00006, value_loss: 0.06577 action_loss: 19.70057\n",
      "update_step:  74 model loss: 3.08609, kl_loss: 3.01087, obs_loss: 0.07516, reward_loss: 0.00006, value_loss: 0.06538 action_loss: 19.70876\n",
      "update_step:  75 model loss: 3.09861, kl_loss: 3.01518, obs_loss: 0.08337, reward_loss: 0.00007, value_loss: 0.06477 action_loss: 19.70009\n",
      "update_step:  76 model loss: 3.09259, kl_loss: 3.01052, obs_loss: 0.08200, reward_loss: 0.00007, value_loss: 0.06543 action_loss: 19.69828\n",
      "update_step:  77 model loss: 3.09187, kl_loss: 3.01122, obs_loss: 0.08058, reward_loss: 0.00006, value_loss: 0.06435 action_loss: 19.69761\n",
      "update_step:  78 model loss: 3.07143, kl_loss: 3.00514, obs_loss: 0.06623, reward_loss: 0.00006, value_loss: 0.06269 action_loss: 19.68691\n",
      "update_step:  79 model loss: 3.09350, kl_loss: 3.01244, obs_loss: 0.08099, reward_loss: 0.00007, value_loss: 0.06330 action_loss: 19.67799\n",
      "update_step:  80 model loss: 3.08130, kl_loss: 3.00797, obs_loss: 0.07326, reward_loss: 0.00006, value_loss: 0.06228 action_loss: 19.67492\n",
      "update_step:  81 model loss: 3.06462, kl_loss: 3.00361, obs_loss: 0.06094, reward_loss: 0.00006, value_loss: 0.06083 action_loss: 19.68064\n",
      "update_step:  82 model loss: 3.07813, kl_loss: 3.00710, obs_loss: 0.07096, reward_loss: 0.00006, value_loss: 0.06151 action_loss: 19.66981\n",
      "update_step:  83 model loss: 3.07675, kl_loss: 3.00690, obs_loss: 0.06979, reward_loss: 0.00006, value_loss: 0.06268 action_loss: 19.65527\n",
      "update_step:  84 model loss: 3.07232, kl_loss: 3.00975, obs_loss: 0.06251, reward_loss: 0.00006, value_loss: 0.06069 action_loss: 19.64495\n",
      "update_step:  85 model loss: 3.06829, kl_loss: 3.00833, obs_loss: 0.05990, reward_loss: 0.00006, value_loss: 0.06025 action_loss: 19.63976\n",
      "update_step:  86 model loss: 3.08943, kl_loss: 3.00924, obs_loss: 0.08013, reward_loss: 0.00006, value_loss: 0.06122 action_loss: 19.64732\n",
      "update_step:  87 model loss: 3.08452, kl_loss: 3.01106, obs_loss: 0.07339, reward_loss: 0.00006, value_loss: 0.05989 action_loss: 19.63776\n",
      "update_step:  88 model loss: 3.06599, kl_loss: 3.00551, obs_loss: 0.06042, reward_loss: 0.00006, value_loss: 0.05935 action_loss: 19.63099\n",
      "update_step:  89 model loss: 3.08876, kl_loss: 3.00978, obs_loss: 0.07892, reward_loss: 0.00006, value_loss: 0.05972 action_loss: 19.61631\n",
      "update_step:  90 model loss: 3.06177, kl_loss: 3.00753, obs_loss: 0.05417, reward_loss: 0.00006, value_loss: 0.05740 action_loss: 19.61120\n",
      "update_step:  91 model loss: 3.07341, kl_loss: 3.00526, obs_loss: 0.06809, reward_loss: 0.00006, value_loss: 0.05792 action_loss: 19.62027\n",
      "update_step:  92 model loss: 3.08525, kl_loss: 3.00764, obs_loss: 0.07755, reward_loss: 0.00006, value_loss: 0.05858 action_loss: 19.62227\n",
      "update_step:  93 model loss: 3.07401, kl_loss: 3.00507, obs_loss: 0.06888, reward_loss: 0.00006, value_loss: 0.05878 action_loss: 19.62651\n",
      "update_step:  94 model loss: 3.07778, kl_loss: 3.00559, obs_loss: 0.07213, reward_loss: 0.00006, value_loss: 0.05765 action_loss: 19.63995\n",
      "update_step:  95 model loss: 3.08352, kl_loss: 3.01259, obs_loss: 0.07087, reward_loss: 0.00006, value_loss: 0.05705 action_loss: 19.65708\n",
      "update_step:  96 model loss: 3.07265, kl_loss: 3.00780, obs_loss: 0.06480, reward_loss: 0.00006, value_loss: 0.05732 action_loss: 19.67177\n",
      "update_step:  97 model loss: 3.08149, kl_loss: 3.01483, obs_loss: 0.06660, reward_loss: 0.00006, value_loss: 0.05572 action_loss: 19.67573\n",
      "update_step:  98 model loss: 3.07204, kl_loss: 3.00792, obs_loss: 0.06406, reward_loss: 0.00006, value_loss: 0.05784 action_loss: 19.67789\n",
      "update_step:  99 model loss: 3.08481, kl_loss: 3.00950, obs_loss: 0.07526, reward_loss: 0.00006, value_loss: 0.05611 action_loss: 19.66921\n",
      "update_step: 100 model loss: 3.07613, kl_loss: 3.01002, obs_loss: 0.06606, reward_loss: 0.00006, value_loss: 0.05549 action_loss: 19.66737\n",
      "elasped time for update: 20.16s\n",
      "episode [   9/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.08091, kl_loss: 3.00986, obs_loss: 0.07100, reward_loss: 0.00006, value_loss: 0.05664 action_loss: 19.66876\n",
      "update_step:   2 model loss: 3.06391, kl_loss: 3.00683, obs_loss: 0.05702, reward_loss: 0.00006, value_loss: 0.05648 action_loss: 19.68604\n",
      "update_step:   3 model loss: 3.06708, kl_loss: 3.00916, obs_loss: 0.05787, reward_loss: 0.00006, value_loss: 0.05396 action_loss: 19.69112\n",
      "update_step:   4 model loss: 3.07745, kl_loss: 3.01067, obs_loss: 0.06673, reward_loss: 0.00006, value_loss: 0.05415 action_loss: 19.67419\n",
      "update_step:   5 model loss: 3.06968, kl_loss: 3.00632, obs_loss: 0.06331, reward_loss: 0.00005, value_loss: 0.05515 action_loss: 19.66695\n",
      "update_step:   6 model loss: 3.07024, kl_loss: 3.00491, obs_loss: 0.06528, reward_loss: 0.00006, value_loss: 0.05459 action_loss: 19.66321\n",
      "update_step:   7 model loss: 3.08588, kl_loss: 3.00707, obs_loss: 0.07876, reward_loss: 0.00005, value_loss: 0.05563 action_loss: 19.65999\n",
      "update_step:   8 model loss: 3.07980, kl_loss: 3.01079, obs_loss: 0.06895, reward_loss: 0.00006, value_loss: 0.05430 action_loss: 19.65795\n",
      "update_step:   9 model loss: 3.06862, kl_loss: 3.00639, obs_loss: 0.06218, reward_loss: 0.00005, value_loss: 0.05413 action_loss: 19.65968\n",
      "update_step:  10 model loss: 3.06276, kl_loss: 3.00450, obs_loss: 0.05821, reward_loss: 0.00005, value_loss: 0.05317 action_loss: 19.65783\n",
      "update_step:  11 model loss: 3.07317, kl_loss: 3.00890, obs_loss: 0.06421, reward_loss: 0.00006, value_loss: 0.05331 action_loss: 19.65077\n",
      "update_step:  12 model loss: 3.08473, kl_loss: 3.01269, obs_loss: 0.07199, reward_loss: 0.00005, value_loss: 0.05322 action_loss: 19.65874\n",
      "update_step:  13 model loss: 3.06373, kl_loss: 3.00567, obs_loss: 0.05801, reward_loss: 0.00005, value_loss: 0.05356 action_loss: 19.66039\n",
      "update_step:  14 model loss: 3.06077, kl_loss: 3.00554, obs_loss: 0.05517, reward_loss: 0.00005, value_loss: 0.05162 action_loss: 19.65633\n",
      "update_step:  15 model loss: 3.06687, kl_loss: 3.00585, obs_loss: 0.06096, reward_loss: 0.00005, value_loss: 0.05215 action_loss: 19.66234\n",
      "update_step:  16 model loss: 3.05116, kl_loss: 3.00104, obs_loss: 0.05007, reward_loss: 0.00005, value_loss: 0.05041 action_loss: 19.66770\n",
      "update_step:  17 model loss: 3.07574, kl_loss: 3.01032, obs_loss: 0.06537, reward_loss: 0.00005, value_loss: 0.05234 action_loss: 19.66109\n",
      "update_step:  18 model loss: 3.06075, kl_loss: 3.00485, obs_loss: 0.05585, reward_loss: 0.00005, value_loss: 0.05196 action_loss: 19.66698\n",
      "update_step:  19 model loss: 3.07625, kl_loss: 3.00981, obs_loss: 0.06640, reward_loss: 0.00005, value_loss: 0.05097 action_loss: 19.66128\n",
      "update_step:  20 model loss: 3.08009, kl_loss: 3.00852, obs_loss: 0.07153, reward_loss: 0.00005, value_loss: 0.05186 action_loss: 19.65412\n",
      "update_step:  21 model loss: 3.05735, kl_loss: 3.00688, obs_loss: 0.05043, reward_loss: 0.00005, value_loss: 0.05039 action_loss: 19.64037\n",
      "update_step:  22 model loss: 3.06258, kl_loss: 3.00456, obs_loss: 0.05797, reward_loss: 0.00005, value_loss: 0.04945 action_loss: 19.64411\n",
      "update_step:  23 model loss: 3.06811, kl_loss: 3.00921, obs_loss: 0.05885, reward_loss: 0.00005, value_loss: 0.04985 action_loss: 19.64009\n",
      "update_step:  24 model loss: 3.06120, kl_loss: 3.00886, obs_loss: 0.05229, reward_loss: 0.00005, value_loss: 0.04948 action_loss: 19.62431\n",
      "update_step:  25 model loss: 3.06029, kl_loss: 3.00589, obs_loss: 0.05435, reward_loss: 0.00005, value_loss: 0.04873 action_loss: 19.63070\n",
      "update_step:  26 model loss: 3.05507, kl_loss: 3.00427, obs_loss: 0.05075, reward_loss: 0.00005, value_loss: 0.04912 action_loss: 19.64095\n",
      "update_step:  27 model loss: 3.07308, kl_loss: 3.00715, obs_loss: 0.06588, reward_loss: 0.00005, value_loss: 0.04937 action_loss: 19.65340\n",
      "update_step:  28 model loss: 3.05469, kl_loss: 3.00508, obs_loss: 0.04955, reward_loss: 0.00005, value_loss: 0.04945 action_loss: 19.65807\n",
      "update_step:  29 model loss: 3.05864, kl_loss: 3.00348, obs_loss: 0.05511, reward_loss: 0.00005, value_loss: 0.04995 action_loss: 19.67634\n",
      "update_step:  30 model loss: 3.05392, kl_loss: 3.00730, obs_loss: 0.04657, reward_loss: 0.00005, value_loss: 0.04838 action_loss: 19.69278\n",
      "update_step:  31 model loss: 3.04768, kl_loss: 3.00257, obs_loss: 0.04506, reward_loss: 0.00005, value_loss: 0.04914 action_loss: 19.71044\n",
      "update_step:  32 model loss: 3.05955, kl_loss: 3.00582, obs_loss: 0.05367, reward_loss: 0.00005, value_loss: 0.04809 action_loss: 19.72390\n",
      "update_step:  33 model loss: 3.06049, kl_loss: 3.00727, obs_loss: 0.05317, reward_loss: 0.00005, value_loss: 0.04855 action_loss: 19.73276\n",
      "update_step:  34 model loss: 3.07195, kl_loss: 3.01243, obs_loss: 0.05947, reward_loss: 0.00005, value_loss: 0.04910 action_loss: 19.73512\n",
      "update_step:  35 model loss: 3.07534, kl_loss: 3.01117, obs_loss: 0.06411, reward_loss: 0.00005, value_loss: 0.04995 action_loss: 19.73083\n",
      "update_step:  36 model loss: 3.07677, kl_loss: 3.00846, obs_loss: 0.06826, reward_loss: 0.00005, value_loss: 0.04916 action_loss: 19.71766\n",
      "update_step:  37 model loss: 3.06125, kl_loss: 3.00805, obs_loss: 0.05315, reward_loss: 0.00005, value_loss: 0.04834 action_loss: 19.69016\n",
      "update_step:  38 model loss: 3.07778, kl_loss: 3.01134, obs_loss: 0.06639, reward_loss: 0.00005, value_loss: 0.04763 action_loss: 19.66446\n",
      "update_step:  39 model loss: 3.05803, kl_loss: 3.00389, obs_loss: 0.05409, reward_loss: 0.00005, value_loss: 0.04656 action_loss: 19.64635\n",
      "update_step:  40 model loss: 3.06300, kl_loss: 3.00572, obs_loss: 0.05724, reward_loss: 0.00005, value_loss: 0.04584 action_loss: 19.63402\n",
      "update_step:  41 model loss: 3.05569, kl_loss: 3.00472, obs_loss: 0.05093, reward_loss: 0.00005, value_loss: 0.04663 action_loss: 19.63241\n",
      "update_step:  42 model loss: 3.06550, kl_loss: 3.00713, obs_loss: 0.05832, reward_loss: 0.00005, value_loss: 0.04575 action_loss: 19.63180\n",
      "update_step:  43 model loss: 3.05842, kl_loss: 3.00581, obs_loss: 0.05256, reward_loss: 0.00005, value_loss: 0.04613 action_loss: 19.63451\n",
      "update_step:  44 model loss: 3.04566, kl_loss: 3.00365, obs_loss: 0.04196, reward_loss: 0.00005, value_loss: 0.04573 action_loss: 19.64820\n",
      "update_step:  45 model loss: 3.05172, kl_loss: 3.00333, obs_loss: 0.04834, reward_loss: 0.00005, value_loss: 0.04652 action_loss: 19.65598\n",
      "update_step:  46 model loss: 3.05214, kl_loss: 3.00340, obs_loss: 0.04869, reward_loss: 0.00005, value_loss: 0.04545 action_loss: 19.65744\n",
      "update_step:  47 model loss: 3.05108, kl_loss: 3.00619, obs_loss: 0.04484, reward_loss: 0.00005, value_loss: 0.04569 action_loss: 19.65965\n",
      "update_step:  48 model loss: 3.05797, kl_loss: 3.00456, obs_loss: 0.05336, reward_loss: 0.00005, value_loss: 0.04630 action_loss: 19.66139\n",
      "update_step:  49 model loss: 3.05116, kl_loss: 3.00619, obs_loss: 0.04492, reward_loss: 0.00005, value_loss: 0.04560 action_loss: 19.66558\n",
      "update_step:  50 model loss: 3.05451, kl_loss: 3.00708, obs_loss: 0.04739, reward_loss: 0.00005, value_loss: 0.04580 action_loss: 19.66981\n",
      "update_step:  51 model loss: 3.06483, kl_loss: 3.00536, obs_loss: 0.05943, reward_loss: 0.00005, value_loss: 0.04501 action_loss: 19.67285\n",
      "update_step:  52 model loss: 3.05201, kl_loss: 3.00298, obs_loss: 0.04899, reward_loss: 0.00005, value_loss: 0.04597 action_loss: 19.66733\n",
      "update_step:  53 model loss: 3.05312, kl_loss: 3.00406, obs_loss: 0.04902, reward_loss: 0.00005, value_loss: 0.04558 action_loss: 19.67236\n",
      "update_step:  54 model loss: 3.04744, kl_loss: 3.00360, obs_loss: 0.04379, reward_loss: 0.00005, value_loss: 0.04472 action_loss: 19.68158\n",
      "update_step:  55 model loss: 3.06305, kl_loss: 3.00544, obs_loss: 0.05757, reward_loss: 0.00005, value_loss: 0.04606 action_loss: 19.68182\n",
      "update_step:  56 model loss: 3.05617, kl_loss: 3.00514, obs_loss: 0.05098, reward_loss: 0.00004, value_loss: 0.04530 action_loss: 19.69435\n",
      "update_step:  57 model loss: 3.04879, kl_loss: 3.00302, obs_loss: 0.04573, reward_loss: 0.00004, value_loss: 0.04479 action_loss: 19.69503\n",
      "update_step:  58 model loss: 3.05954, kl_loss: 3.00742, obs_loss: 0.05208, reward_loss: 0.00004, value_loss: 0.04488 action_loss: 19.69625\n",
      "update_step:  59 model loss: 3.05846, kl_loss: 3.00626, obs_loss: 0.05215, reward_loss: 0.00004, value_loss: 0.04535 action_loss: 19.70260\n",
      "update_step:  60 model loss: 3.05288, kl_loss: 3.00299, obs_loss: 0.04985, reward_loss: 0.00004, value_loss: 0.04351 action_loss: 19.70095\n",
      "update_step:  61 model loss: 3.05708, kl_loss: 3.00762, obs_loss: 0.04942, reward_loss: 0.00004, value_loss: 0.04318 action_loss: 19.68794\n",
      "update_step:  62 model loss: 3.06565, kl_loss: 3.00682, obs_loss: 0.05879, reward_loss: 0.00004, value_loss: 0.04390 action_loss: 19.68228\n",
      "update_step:  63 model loss: 3.05457, kl_loss: 3.00373, obs_loss: 0.05079, reward_loss: 0.00005, value_loss: 0.04337 action_loss: 19.67722\n",
      "update_step:  64 model loss: 3.05395, kl_loss: 3.00456, obs_loss: 0.04935, reward_loss: 0.00004, value_loss: 0.04319 action_loss: 19.67953\n",
      "update_step:  65 model loss: 3.05137, kl_loss: 3.00407, obs_loss: 0.04725, reward_loss: 0.00004, value_loss: 0.04190 action_loss: 19.67115\n",
      "update_step:  66 model loss: 3.05685, kl_loss: 3.00675, obs_loss: 0.05006, reward_loss: 0.00004, value_loss: 0.04274 action_loss: 19.65971\n",
      "update_step:  67 model loss: 3.06635, kl_loss: 3.00483, obs_loss: 0.06147, reward_loss: 0.00004, value_loss: 0.04242 action_loss: 19.65693\n",
      "update_step:  68 model loss: 3.04152, kl_loss: 3.00263, obs_loss: 0.03885, reward_loss: 0.00004, value_loss: 0.04162 action_loss: 19.65863\n",
      "update_step:  69 model loss: 3.05672, kl_loss: 3.00616, obs_loss: 0.05052, reward_loss: 0.00004, value_loss: 0.04241 action_loss: 19.67028\n",
      "update_step:  70 model loss: 3.05574, kl_loss: 3.00371, obs_loss: 0.05199, reward_loss: 0.00004, value_loss: 0.04310 action_loss: 19.66195\n",
      "update_step:  71 model loss: 3.04903, kl_loss: 3.00424, obs_loss: 0.04474, reward_loss: 0.00004, value_loss: 0.04204 action_loss: 19.66367\n",
      "update_step:  72 model loss: 3.04161, kl_loss: 3.00221, obs_loss: 0.03935, reward_loss: 0.00004, value_loss: 0.04077 action_loss: 19.66897\n",
      "update_step:  73 model loss: 3.04495, kl_loss: 3.00365, obs_loss: 0.04126, reward_loss: 0.00004, value_loss: 0.04092 action_loss: 19.67418\n",
      "update_step:  74 model loss: 3.04618, kl_loss: 3.00340, obs_loss: 0.04274, reward_loss: 0.00004, value_loss: 0.04064 action_loss: 19.67143\n",
      "update_step:  75 model loss: 3.04805, kl_loss: 3.00418, obs_loss: 0.04383, reward_loss: 0.00004, value_loss: 0.04210 action_loss: 19.68767\n",
      "update_step:  76 model loss: 3.04586, kl_loss: 3.00605, obs_loss: 0.03977, reward_loss: 0.00004, value_loss: 0.04133 action_loss: 19.68254\n",
      "update_step:  77 model loss: 3.04950, kl_loss: 3.00323, obs_loss: 0.04623, reward_loss: 0.00004, value_loss: 0.04109 action_loss: 19.69076\n",
      "update_step:  78 model loss: 3.06022, kl_loss: 3.00884, obs_loss: 0.05133, reward_loss: 0.00004, value_loss: 0.04081 action_loss: 19.69665\n",
      "update_step:  79 model loss: 3.05956, kl_loss: 3.00892, obs_loss: 0.05060, reward_loss: 0.00004, value_loss: 0.04176 action_loss: 19.69906\n",
      "update_step:  80 model loss: 3.05138, kl_loss: 3.00421, obs_loss: 0.04713, reward_loss: 0.00004, value_loss: 0.04073 action_loss: 19.69851\n",
      "update_step:  81 model loss: 3.04735, kl_loss: 3.00363, obs_loss: 0.04369, reward_loss: 0.00004, value_loss: 0.04047 action_loss: 19.69409\n",
      "update_step:  82 model loss: 3.05991, kl_loss: 3.00982, obs_loss: 0.05005, reward_loss: 0.00004, value_loss: 0.04093 action_loss: 19.69001\n",
      "update_step:  83 model loss: 3.05261, kl_loss: 3.00509, obs_loss: 0.04748, reward_loss: 0.00004, value_loss: 0.04040 action_loss: 19.68223\n",
      "update_step:  84 model loss: 3.04012, kl_loss: 3.00258, obs_loss: 0.03749, reward_loss: 0.00004, value_loss: 0.04066 action_loss: 19.67442\n",
      "update_step:  85 model loss: 3.05473, kl_loss: 3.00222, obs_loss: 0.05247, reward_loss: 0.00004, value_loss: 0.04103 action_loss: 19.67169\n",
      "update_step:  86 model loss: 3.04428, kl_loss: 3.00487, obs_loss: 0.03937, reward_loss: 0.00004, value_loss: 0.03919 action_loss: 19.67160\n",
      "update_step:  87 model loss: 3.04629, kl_loss: 3.00350, obs_loss: 0.04275, reward_loss: 0.00004, value_loss: 0.04059 action_loss: 19.67177\n",
      "update_step:  88 model loss: 3.04910, kl_loss: 3.00335, obs_loss: 0.04570, reward_loss: 0.00004, value_loss: 0.04018 action_loss: 19.68601\n",
      "update_step:  89 model loss: 3.03988, kl_loss: 3.00168, obs_loss: 0.03816, reward_loss: 0.00004, value_loss: 0.04008 action_loss: 19.68650\n",
      "update_step:  90 model loss: 3.04001, kl_loss: 3.00294, obs_loss: 0.03703, reward_loss: 0.00004, value_loss: 0.03940 action_loss: 19.70379\n",
      "update_step:  91 model loss: 3.05506, kl_loss: 3.00929, obs_loss: 0.04573, reward_loss: 0.00004, value_loss: 0.03965 action_loss: 19.72307\n",
      "update_step:  92 model loss: 3.03588, kl_loss: 3.00255, obs_loss: 0.03329, reward_loss: 0.00004, value_loss: 0.03877 action_loss: 19.72163\n",
      "update_step:  93 model loss: 3.04785, kl_loss: 3.00422, obs_loss: 0.04360, reward_loss: 0.00004, value_loss: 0.03920 action_loss: 19.72981\n",
      "update_step:  94 model loss: 3.04761, kl_loss: 3.00626, obs_loss: 0.04131, reward_loss: 0.00004, value_loss: 0.04031 action_loss: 19.72994\n",
      "update_step:  95 model loss: 3.04326, kl_loss: 3.00249, obs_loss: 0.04073, reward_loss: 0.00004, value_loss: 0.04022 action_loss: 19.72995\n",
      "update_step:  96 model loss: 3.04427, kl_loss: 3.00331, obs_loss: 0.04093, reward_loss: 0.00004, value_loss: 0.03905 action_loss: 19.72822\n",
      "update_step:  97 model loss: 3.05116, kl_loss: 3.00444, obs_loss: 0.04668, reward_loss: 0.00004, value_loss: 0.03862 action_loss: 19.72814\n",
      "update_step:  98 model loss: 3.04531, kl_loss: 3.00526, obs_loss: 0.04002, reward_loss: 0.00004, value_loss: 0.03914 action_loss: 19.72037\n",
      "update_step:  99 model loss: 3.04862, kl_loss: 3.00321, obs_loss: 0.04537, reward_loss: 0.00004, value_loss: 0.03865 action_loss: 19.71217\n",
      "update_step: 100 model loss: 3.05537, kl_loss: 3.00852, obs_loss: 0.04680, reward_loss: 0.00004, value_loss: 0.03880 action_loss: 19.69971\n",
      "elasped time for update: 20.29s\n",
      "episode [  10/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.05249, kl_loss: 3.00663, obs_loss: 0.04582, reward_loss: 0.00004, value_loss: 0.03791 action_loss: 19.69936\n",
      "update_step:   2 model loss: 3.03644, kl_loss: 3.00099, obs_loss: 0.03541, reward_loss: 0.00004, value_loss: 0.03797 action_loss: 19.68410\n",
      "update_step:   3 model loss: 3.05032, kl_loss: 3.00744, obs_loss: 0.04284, reward_loss: 0.00004, value_loss: 0.03768 action_loss: 19.67739\n",
      "update_step:   4 model loss: 3.05151, kl_loss: 3.00485, obs_loss: 0.04663, reward_loss: 0.00004, value_loss: 0.03859 action_loss: 19.67691\n",
      "update_step:   5 model loss: 3.04203, kl_loss: 3.00237, obs_loss: 0.03962, reward_loss: 0.00004, value_loss: 0.03741 action_loss: 19.67171\n",
      "update_step:   6 model loss: 3.06005, kl_loss: 3.00795, obs_loss: 0.05206, reward_loss: 0.00004, value_loss: 0.03823 action_loss: 19.67766\n",
      "update_step:   7 model loss: 3.05115, kl_loss: 3.00805, obs_loss: 0.04306, reward_loss: 0.00004, value_loss: 0.03802 action_loss: 19.68248\n",
      "update_step:   8 model loss: 3.04072, kl_loss: 3.00217, obs_loss: 0.03851, reward_loss: 0.00004, value_loss: 0.03741 action_loss: 19.68187\n",
      "update_step:   9 model loss: 3.05151, kl_loss: 3.00711, obs_loss: 0.04436, reward_loss: 0.00004, value_loss: 0.03716 action_loss: 19.69122\n",
      "update_step:  10 model loss: 3.03805, kl_loss: 3.00322, obs_loss: 0.03480, reward_loss: 0.00004, value_loss: 0.03879 action_loss: 19.69361\n",
      "update_step:  11 model loss: 3.04404, kl_loss: 3.00644, obs_loss: 0.03757, reward_loss: 0.00004, value_loss: 0.03849 action_loss: 19.70264\n",
      "update_step:  12 model loss: 3.04382, kl_loss: 3.00688, obs_loss: 0.03689, reward_loss: 0.00004, value_loss: 0.03767 action_loss: 19.70834\n",
      "update_step:  13 model loss: 3.03878, kl_loss: 3.00241, obs_loss: 0.03634, reward_loss: 0.00004, value_loss: 0.03746 action_loss: 19.70962\n",
      "update_step:  14 model loss: 3.04596, kl_loss: 3.00595, obs_loss: 0.03997, reward_loss: 0.00004, value_loss: 0.03831 action_loss: 19.71091\n",
      "update_step:  15 model loss: 3.04399, kl_loss: 3.00433, obs_loss: 0.03962, reward_loss: 0.00004, value_loss: 0.03772 action_loss: 19.72512\n",
      "update_step:  16 model loss: 3.03906, kl_loss: 3.00428, obs_loss: 0.03474, reward_loss: 0.00004, value_loss: 0.03750 action_loss: 19.73395\n",
      "update_step:  17 model loss: 3.04262, kl_loss: 3.00258, obs_loss: 0.04000, reward_loss: 0.00004, value_loss: 0.03740 action_loss: 19.73764\n",
      "update_step:  18 model loss: 3.05029, kl_loss: 3.00711, obs_loss: 0.04314, reward_loss: 0.00004, value_loss: 0.03742 action_loss: 19.72651\n",
      "update_step:  19 model loss: 3.04143, kl_loss: 3.00547, obs_loss: 0.03592, reward_loss: 0.00004, value_loss: 0.03694 action_loss: 19.72555\n",
      "update_step:  20 model loss: 3.03456, kl_loss: 3.00090, obs_loss: 0.03362, reward_loss: 0.00004, value_loss: 0.03692 action_loss: 19.71844\n",
      "update_step:  21 model loss: 3.04348, kl_loss: 3.00105, obs_loss: 0.04239, reward_loss: 0.00004, value_loss: 0.03759 action_loss: 19.71209\n",
      "update_step:  22 model loss: 3.03044, kl_loss: 3.00067, obs_loss: 0.02974, reward_loss: 0.00003, value_loss: 0.03633 action_loss: 19.70414\n",
      "update_step:  23 model loss: 3.04174, kl_loss: 3.00403, obs_loss: 0.03767, reward_loss: 0.00004, value_loss: 0.03599 action_loss: 19.69258\n",
      "update_step:  24 model loss: 3.04435, kl_loss: 3.00572, obs_loss: 0.03860, reward_loss: 0.00004, value_loss: 0.03659 action_loss: 19.68359\n",
      "update_step:  25 model loss: 3.03223, kl_loss: 3.00154, obs_loss: 0.03066, reward_loss: 0.00004, value_loss: 0.03611 action_loss: 19.68665\n",
      "update_step:  26 model loss: 3.03748, kl_loss: 3.00322, obs_loss: 0.03423, reward_loss: 0.00003, value_loss: 0.03606 action_loss: 19.69293\n",
      "update_step:  27 model loss: 3.04074, kl_loss: 3.00474, obs_loss: 0.03596, reward_loss: 0.00004, value_loss: 0.03570 action_loss: 19.68811\n",
      "update_step:  28 model loss: 3.03756, kl_loss: 3.00341, obs_loss: 0.03411, reward_loss: 0.00004, value_loss: 0.03631 action_loss: 19.69862\n",
      "update_step:  29 model loss: 3.04729, kl_loss: 3.00529, obs_loss: 0.04197, reward_loss: 0.00003, value_loss: 0.03537 action_loss: 19.70359\n",
      "update_step:  30 model loss: 3.03766, kl_loss: 3.00390, obs_loss: 0.03373, reward_loss: 0.00004, value_loss: 0.03629 action_loss: 19.70359\n",
      "update_step:  31 model loss: 3.04218, kl_loss: 3.00378, obs_loss: 0.03836, reward_loss: 0.00004, value_loss: 0.03558 action_loss: 19.71237\n",
      "update_step:  32 model loss: 3.03346, kl_loss: 3.00186, obs_loss: 0.03156, reward_loss: 0.00004, value_loss: 0.03558 action_loss: 19.71975\n",
      "update_step:  33 model loss: 3.04020, kl_loss: 3.00418, obs_loss: 0.03598, reward_loss: 0.00004, value_loss: 0.03534 action_loss: 19.71732\n",
      "update_step:  34 model loss: 3.04587, kl_loss: 3.00360, obs_loss: 0.04224, reward_loss: 0.00003, value_loss: 0.03584 action_loss: 19.71465\n",
      "update_step:  35 model loss: 3.04539, kl_loss: 3.00555, obs_loss: 0.03981, reward_loss: 0.00003, value_loss: 0.03538 action_loss: 19.70967\n",
      "update_step:  36 model loss: 3.04464, kl_loss: 3.00737, obs_loss: 0.03724, reward_loss: 0.00003, value_loss: 0.03638 action_loss: 19.69584\n",
      "update_step:  37 model loss: 3.04363, kl_loss: 3.00523, obs_loss: 0.03836, reward_loss: 0.00003, value_loss: 0.03542 action_loss: 19.69187\n",
      "update_step:  38 model loss: 3.03993, kl_loss: 3.00337, obs_loss: 0.03653, reward_loss: 0.00003, value_loss: 0.03603 action_loss: 19.68703\n",
      "update_step:  39 model loss: 3.04293, kl_loss: 3.00501, obs_loss: 0.03789, reward_loss: 0.00003, value_loss: 0.03524 action_loss: 19.68178\n",
      "update_step:  40 model loss: 3.04080, kl_loss: 3.00299, obs_loss: 0.03777, reward_loss: 0.00004, value_loss: 0.03584 action_loss: 19.67953\n",
      "update_step:  41 model loss: 3.03803, kl_loss: 3.00108, obs_loss: 0.03692, reward_loss: 0.00004, value_loss: 0.03539 action_loss: 19.68318\n",
      "update_step:  42 model loss: 3.03887, kl_loss: 3.00330, obs_loss: 0.03554, reward_loss: 0.00004, value_loss: 0.03507 action_loss: 19.69027\n",
      "update_step:  43 model loss: 3.04410, kl_loss: 3.00437, obs_loss: 0.03969, reward_loss: 0.00003, value_loss: 0.03541 action_loss: 19.69730\n",
      "update_step:  44 model loss: 3.04240, kl_loss: 3.00483, obs_loss: 0.03754, reward_loss: 0.00003, value_loss: 0.03537 action_loss: 19.69664\n",
      "update_step:  45 model loss: 3.05461, kl_loss: 3.00669, obs_loss: 0.04789, reward_loss: 0.00003, value_loss: 0.03570 action_loss: 19.71303\n",
      "update_step:  46 model loss: 3.03911, kl_loss: 3.00463, obs_loss: 0.03445, reward_loss: 0.00003, value_loss: 0.03533 action_loss: 19.71531\n",
      "update_step:  47 model loss: 3.03807, kl_loss: 3.00490, obs_loss: 0.03314, reward_loss: 0.00003, value_loss: 0.03585 action_loss: 19.72869\n",
      "update_step:  48 model loss: 3.04252, kl_loss: 3.00672, obs_loss: 0.03576, reward_loss: 0.00003, value_loss: 0.03507 action_loss: 19.73219\n",
      "update_step:  49 model loss: 3.04114, kl_loss: 3.00272, obs_loss: 0.03839, reward_loss: 0.00003, value_loss: 0.03655 action_loss: 19.73201\n",
      "update_step:  50 model loss: 3.04240, kl_loss: 3.00411, obs_loss: 0.03826, reward_loss: 0.00003, value_loss: 0.03522 action_loss: 19.73822\n",
      "update_step:  51 model loss: 3.03262, kl_loss: 3.00209, obs_loss: 0.03050, reward_loss: 0.00003, value_loss: 0.03492 action_loss: 19.74895\n",
      "update_step:  52 model loss: 3.03754, kl_loss: 3.00302, obs_loss: 0.03449, reward_loss: 0.00003, value_loss: 0.03520 action_loss: 19.73988\n",
      "update_step:  53 model loss: 3.04362, kl_loss: 3.00746, obs_loss: 0.03613, reward_loss: 0.00003, value_loss: 0.03526 action_loss: 19.74253\n",
      "update_step:  54 model loss: 3.04213, kl_loss: 3.00657, obs_loss: 0.03553, reward_loss: 0.00003, value_loss: 0.03550 action_loss: 19.73531\n",
      "update_step:  55 model loss: 3.04189, kl_loss: 3.00669, obs_loss: 0.03516, reward_loss: 0.00003, value_loss: 0.03514 action_loss: 19.72967\n",
      "update_step:  56 model loss: 3.05422, kl_loss: 3.01119, obs_loss: 0.04300, reward_loss: 0.00003, value_loss: 0.03521 action_loss: 19.72616\n",
      "update_step:  57 model loss: 3.03450, kl_loss: 3.00129, obs_loss: 0.03318, reward_loss: 0.00003, value_loss: 0.03509 action_loss: 19.71448\n",
      "update_step:  58 model loss: 3.03108, kl_loss: 3.00176, obs_loss: 0.02929, reward_loss: 0.00003, value_loss: 0.03454 action_loss: 19.70402\n",
      "update_step:  59 model loss: 3.03818, kl_loss: 3.00357, obs_loss: 0.03459, reward_loss: 0.00003, value_loss: 0.03439 action_loss: 19.70201\n",
      "update_step:  60 model loss: 3.02752, kl_loss: 3.00068, obs_loss: 0.02681, reward_loss: 0.00003, value_loss: 0.03377 action_loss: 19.69719\n",
      "update_step:  61 model loss: 3.03596, kl_loss: 3.00397, obs_loss: 0.03195, reward_loss: 0.00003, value_loss: 0.03468 action_loss: 19.69148\n",
      "update_step:  62 model loss: 3.03845, kl_loss: 3.00424, obs_loss: 0.03418, reward_loss: 0.00003, value_loss: 0.03484 action_loss: 19.69651\n",
      "update_step:  63 model loss: 3.02960, kl_loss: 3.00175, obs_loss: 0.02782, reward_loss: 0.00003, value_loss: 0.03451 action_loss: 19.70410\n",
      "update_step:  64 model loss: 3.04000, kl_loss: 3.00339, obs_loss: 0.03658, reward_loss: 0.00003, value_loss: 0.03480 action_loss: 19.70087\n",
      "update_step:  65 model loss: 3.03049, kl_loss: 3.00186, obs_loss: 0.02860, reward_loss: 0.00003, value_loss: 0.03395 action_loss: 19.70324\n",
      "update_step:  66 model loss: 3.04872, kl_loss: 3.00679, obs_loss: 0.04190, reward_loss: 0.00003, value_loss: 0.03480 action_loss: 19.71099\n",
      "update_step:  67 model loss: 3.03577, kl_loss: 3.00354, obs_loss: 0.03220, reward_loss: 0.00003, value_loss: 0.03475 action_loss: 19.71401\n",
      "update_step:  68 model loss: 3.03556, kl_loss: 3.00371, obs_loss: 0.03181, reward_loss: 0.00003, value_loss: 0.03405 action_loss: 19.71961\n",
      "update_step:  69 model loss: 3.04191, kl_loss: 3.00439, obs_loss: 0.03748, reward_loss: 0.00003, value_loss: 0.03361 action_loss: 19.72937\n",
      "update_step:  70 model loss: 3.03322, kl_loss: 3.00465, obs_loss: 0.02853, reward_loss: 0.00003, value_loss: 0.03432 action_loss: 19.73961\n",
      "update_step:  71 model loss: 3.03913, kl_loss: 3.00454, obs_loss: 0.03456, reward_loss: 0.00003, value_loss: 0.03386 action_loss: 19.75611\n",
      "update_step:  72 model loss: 3.03349, kl_loss: 3.00413, obs_loss: 0.02933, reward_loss: 0.00003, value_loss: 0.03446 action_loss: 19.77102\n",
      "update_step:  73 model loss: 3.03738, kl_loss: 3.00374, obs_loss: 0.03361, reward_loss: 0.00003, value_loss: 0.03415 action_loss: 19.77641\n",
      "update_step:  74 model loss: 3.03244, kl_loss: 3.00189, obs_loss: 0.03052, reward_loss: 0.00003, value_loss: 0.03438 action_loss: 19.79047\n",
      "update_step:  75 model loss: 3.04357, kl_loss: 3.00845, obs_loss: 0.03508, reward_loss: 0.00003, value_loss: 0.03374 action_loss: 19.78987\n",
      "update_step:  76 model loss: 3.03875, kl_loss: 3.00518, obs_loss: 0.03354, reward_loss: 0.00003, value_loss: 0.03268 action_loss: 19.77976\n",
      "update_step:  77 model loss: 3.03960, kl_loss: 3.00282, obs_loss: 0.03675, reward_loss: 0.00003, value_loss: 0.03327 action_loss: 19.76980\n",
      "update_step:  78 model loss: 3.02970, kl_loss: 3.00203, obs_loss: 0.02764, reward_loss: 0.00003, value_loss: 0.03320 action_loss: 19.74948\n",
      "update_step:  79 model loss: 3.02663, kl_loss: 3.00161, obs_loss: 0.02499, reward_loss: 0.00003, value_loss: 0.03329 action_loss: 19.72802\n",
      "update_step:  80 model loss: 3.03845, kl_loss: 3.00644, obs_loss: 0.03197, reward_loss: 0.00003, value_loss: 0.03270 action_loss: 19.71498\n",
      "update_step:  81 model loss: 3.02399, kl_loss: 3.00112, obs_loss: 0.02283, reward_loss: 0.00003, value_loss: 0.03310 action_loss: 19.70022\n",
      "update_step:  82 model loss: 3.03069, kl_loss: 3.00232, obs_loss: 0.02833, reward_loss: 0.00003, value_loss: 0.03179 action_loss: 19.68966\n",
      "update_step:  83 model loss: 3.04670, kl_loss: 3.00542, obs_loss: 0.04125, reward_loss: 0.00003, value_loss: 0.03319 action_loss: 19.69092\n",
      "update_step:  84 model loss: 3.03108, kl_loss: 3.00309, obs_loss: 0.02796, reward_loss: 0.00003, value_loss: 0.03266 action_loss: 19.69435\n",
      "update_step:  85 model loss: 3.03017, kl_loss: 3.00165, obs_loss: 0.02848, reward_loss: 0.00003, value_loss: 0.03241 action_loss: 19.69843\n",
      "update_step:  86 model loss: 3.02688, kl_loss: 3.00104, obs_loss: 0.02580, reward_loss: 0.00003, value_loss: 0.03185 action_loss: 19.70681\n",
      "update_step:  87 model loss: 3.02796, kl_loss: 3.00255, obs_loss: 0.02538, reward_loss: 0.00003, value_loss: 0.03249 action_loss: 19.71864\n",
      "update_step:  88 model loss: 3.02616, kl_loss: 3.00069, obs_loss: 0.02544, reward_loss: 0.00003, value_loss: 0.03165 action_loss: 19.73088\n",
      "update_step:  89 model loss: 3.03914, kl_loss: 3.00486, obs_loss: 0.03424, reward_loss: 0.00003, value_loss: 0.03228 action_loss: 19.73094\n",
      "update_step:  90 model loss: 3.03731, kl_loss: 3.00417, obs_loss: 0.03310, reward_loss: 0.00003, value_loss: 0.03219 action_loss: 19.73499\n",
      "update_step:  91 model loss: 3.02867, kl_loss: 3.00281, obs_loss: 0.02583, reward_loss: 0.00003, value_loss: 0.03250 action_loss: 19.74647\n",
      "update_step:  92 model loss: 3.03131, kl_loss: 3.00273, obs_loss: 0.02855, reward_loss: 0.00003, value_loss: 0.03227 action_loss: 19.75927\n",
      "update_step:  93 model loss: 3.03371, kl_loss: 3.00350, obs_loss: 0.03018, reward_loss: 0.00003, value_loss: 0.03179 action_loss: 19.75261\n",
      "update_step:  94 model loss: 3.02640, kl_loss: 3.00112, obs_loss: 0.02525, reward_loss: 0.00003, value_loss: 0.03197 action_loss: 19.74321\n",
      "update_step:  95 model loss: 3.02805, kl_loss: 3.00119, obs_loss: 0.02683, reward_loss: 0.00003, value_loss: 0.03214 action_loss: 19.73350\n",
      "update_step:  96 model loss: 3.03930, kl_loss: 3.00478, obs_loss: 0.03449, reward_loss: 0.00003, value_loss: 0.03233 action_loss: 19.73496\n",
      "update_step:  97 model loss: 3.03339, kl_loss: 3.00110, obs_loss: 0.03225, reward_loss: 0.00003, value_loss: 0.03156 action_loss: 19.73063\n",
      "update_step:  98 model loss: 3.02903, kl_loss: 3.00221, obs_loss: 0.02679, reward_loss: 0.00003, value_loss: 0.03110 action_loss: 19.72870\n",
      "update_step:  99 model loss: 3.03604, kl_loss: 3.00281, obs_loss: 0.03321, reward_loss: 0.00003, value_loss: 0.03087 action_loss: 19.73302\n",
      "update_step: 100 model loss: 3.03268, kl_loss: 3.00475, obs_loss: 0.02791, reward_loss: 0.00003, value_loss: 0.03160 action_loss: 19.74100\n",
      "elasped time for update: 20.28s\n",
      "Total test reward at episode [  10/ 100] is -2.000000\n",
      "elasped time for test: 0.05s\n",
      "episode [  11/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.02618, kl_loss: 3.00214, obs_loss: 0.02401, reward_loss: 0.00003, value_loss: 0.03079 action_loss: 19.74176\n",
      "update_step:   2 model loss: 3.03673, kl_loss: 3.00577, obs_loss: 0.03093, reward_loss: 0.00003, value_loss: 0.03161 action_loss: 19.74490\n",
      "update_step:   3 model loss: 3.03278, kl_loss: 3.00371, obs_loss: 0.02904, reward_loss: 0.00003, value_loss: 0.03112 action_loss: 19.74069\n",
      "update_step:   4 model loss: 3.03679, kl_loss: 3.00346, obs_loss: 0.03330, reward_loss: 0.00003, value_loss: 0.03101 action_loss: 19.74399\n",
      "update_step:   5 model loss: 3.02846, kl_loss: 3.00072, obs_loss: 0.02771, reward_loss: 0.00003, value_loss: 0.03137 action_loss: 19.74455\n",
      "update_step:   6 model loss: 3.04606, kl_loss: 3.00659, obs_loss: 0.03944, reward_loss: 0.00003, value_loss: 0.03117 action_loss: 19.74250\n",
      "update_step:   7 model loss: 3.04027, kl_loss: 3.00605, obs_loss: 0.03419, reward_loss: 0.00003, value_loss: 0.03148 action_loss: 19.72811\n",
      "update_step:   8 model loss: 3.02541, kl_loss: 3.00138, obs_loss: 0.02400, reward_loss: 0.00003, value_loss: 0.03076 action_loss: 19.72932\n",
      "update_step:   9 model loss: 3.03861, kl_loss: 3.00441, obs_loss: 0.03417, reward_loss: 0.00003, value_loss: 0.03059 action_loss: 19.72944\n",
      "update_step:  10 model loss: 3.03659, kl_loss: 3.00649, obs_loss: 0.03007, reward_loss: 0.00003, value_loss: 0.03049 action_loss: 19.72376\n",
      "update_step:  11 model loss: 3.02521, kl_loss: 3.00085, obs_loss: 0.02433, reward_loss: 0.00003, value_loss: 0.03101 action_loss: 19.73117\n",
      "update_step:  12 model loss: 3.03289, kl_loss: 3.00166, obs_loss: 0.03120, reward_loss: 0.00003, value_loss: 0.03009 action_loss: 19.73572\n",
      "update_step:  13 model loss: 3.02820, kl_loss: 3.00273, obs_loss: 0.02544, reward_loss: 0.00003, value_loss: 0.03003 action_loss: 19.74315\n",
      "update_step:  14 model loss: 3.03174, kl_loss: 3.00520, obs_loss: 0.02650, reward_loss: 0.00003, value_loss: 0.03010 action_loss: 19.75333\n",
      "update_step:  15 model loss: 3.03566, kl_loss: 3.00327, obs_loss: 0.03236, reward_loss: 0.00003, value_loss: 0.03043 action_loss: 19.75521\n",
      "update_step:  16 model loss: 3.03687, kl_loss: 3.00668, obs_loss: 0.03016, reward_loss: 0.00003, value_loss: 0.03056 action_loss: 19.76027\n",
      "update_step:  17 model loss: 3.02885, kl_loss: 3.00368, obs_loss: 0.02514, reward_loss: 0.00003, value_loss: 0.03008 action_loss: 19.75898\n",
      "update_step:  18 model loss: 3.04253, kl_loss: 3.00543, obs_loss: 0.03707, reward_loss: 0.00003, value_loss: 0.02984 action_loss: 19.75624\n",
      "update_step:  19 model loss: 3.02345, kl_loss: 3.00173, obs_loss: 0.02169, reward_loss: 0.00003, value_loss: 0.03066 action_loss: 19.74750\n",
      "update_step:  20 model loss: 3.03581, kl_loss: 3.00497, obs_loss: 0.03082, reward_loss: 0.00003, value_loss: 0.02954 action_loss: 19.74257\n",
      "update_step:  21 model loss: 3.02702, kl_loss: 3.00079, obs_loss: 0.02621, reward_loss: 0.00003, value_loss: 0.02956 action_loss: 19.73548\n",
      "update_step:  22 model loss: 3.03273, kl_loss: 3.00352, obs_loss: 0.02919, reward_loss: 0.00003, value_loss: 0.02987 action_loss: 19.73241\n",
      "update_step:  23 model loss: 3.03654, kl_loss: 3.00435, obs_loss: 0.03216, reward_loss: 0.00003, value_loss: 0.03007 action_loss: 19.72561\n",
      "update_step:  24 model loss: 3.04191, kl_loss: 3.00703, obs_loss: 0.03485, reward_loss: 0.00003, value_loss: 0.02977 action_loss: 19.72300\n",
      "update_step:  25 model loss: 3.03134, kl_loss: 3.00279, obs_loss: 0.02852, reward_loss: 0.00003, value_loss: 0.03007 action_loss: 19.73162\n",
      "update_step:  26 model loss: 3.03234, kl_loss: 3.00722, obs_loss: 0.02509, reward_loss: 0.00003, value_loss: 0.03021 action_loss: 19.73118\n",
      "update_step:  27 model loss: 3.03279, kl_loss: 3.00388, obs_loss: 0.02889, reward_loss: 0.00003, value_loss: 0.02972 action_loss: 19.74076\n",
      "update_step:  28 model loss: 3.03612, kl_loss: 3.00227, obs_loss: 0.03382, reward_loss: 0.00003, value_loss: 0.02997 action_loss: 19.74750\n",
      "update_step:  29 model loss: 3.02986, kl_loss: 3.00222, obs_loss: 0.02761, reward_loss: 0.00003, value_loss: 0.02935 action_loss: 19.75635\n",
      "update_step:  30 model loss: 3.03354, kl_loss: 3.00483, obs_loss: 0.02868, reward_loss: 0.00003, value_loss: 0.02917 action_loss: 19.75942\n",
      "update_step:  31 model loss: 3.02831, kl_loss: 3.00213, obs_loss: 0.02615, reward_loss: 0.00003, value_loss: 0.02918 action_loss: 19.76169\n",
      "update_step:  32 model loss: 3.03187, kl_loss: 3.00353, obs_loss: 0.02831, reward_loss: 0.00003, value_loss: 0.03001 action_loss: 19.75940\n",
      "update_step:  33 model loss: 3.02225, kl_loss: 3.00086, obs_loss: 0.02136, reward_loss: 0.00003, value_loss: 0.02968 action_loss: 19.75967\n",
      "update_step:  34 model loss: 3.03523, kl_loss: 3.00148, obs_loss: 0.03372, reward_loss: 0.00003, value_loss: 0.02960 action_loss: 19.75233\n",
      "update_step:  35 model loss: 3.02411, kl_loss: 3.00093, obs_loss: 0.02316, reward_loss: 0.00003, value_loss: 0.02964 action_loss: 19.74862\n",
      "update_step:  36 model loss: 3.02690, kl_loss: 3.00276, obs_loss: 0.02411, reward_loss: 0.00003, value_loss: 0.02923 action_loss: 19.74234\n",
      "update_step:  37 model loss: 3.03044, kl_loss: 3.00297, obs_loss: 0.02744, reward_loss: 0.00003, value_loss: 0.02949 action_loss: 19.74097\n",
      "update_step:  38 model loss: 3.03021, kl_loss: 3.00207, obs_loss: 0.02811, reward_loss: 0.00003, value_loss: 0.02901 action_loss: 19.73237\n",
      "update_step:  39 model loss: 3.03211, kl_loss: 3.00489, obs_loss: 0.02719, reward_loss: 0.00003, value_loss: 0.02915 action_loss: 19.73043\n",
      "update_step:  40 model loss: 3.04523, kl_loss: 3.00823, obs_loss: 0.03697, reward_loss: 0.00003, value_loss: 0.02915 action_loss: 19.73704\n",
      "update_step:  41 model loss: 3.03026, kl_loss: 3.00492, obs_loss: 0.02531, reward_loss: 0.00003, value_loss: 0.02932 action_loss: 19.74639\n",
      "update_step:  42 model loss: 3.03212, kl_loss: 3.00618, obs_loss: 0.02591, reward_loss: 0.00003, value_loss: 0.02893 action_loss: 19.75047\n",
      "update_step:  43 model loss: 3.03634, kl_loss: 3.00192, obs_loss: 0.03439, reward_loss: 0.00003, value_loss: 0.02890 action_loss: 19.75423\n",
      "update_step:  44 model loss: 3.03131, kl_loss: 3.00324, obs_loss: 0.02804, reward_loss: 0.00003, value_loss: 0.02891 action_loss: 19.75454\n",
      "update_step:  45 model loss: 3.02113, kl_loss: 3.00107, obs_loss: 0.02003, reward_loss: 0.00003, value_loss: 0.02879 action_loss: 19.76867\n",
      "update_step:  46 model loss: 3.02859, kl_loss: 3.00294, obs_loss: 0.02563, reward_loss: 0.00003, value_loss: 0.02811 action_loss: 19.77248\n",
      "update_step:  47 model loss: 3.02853, kl_loss: 3.00395, obs_loss: 0.02455, reward_loss: 0.00003, value_loss: 0.02847 action_loss: 19.76927\n",
      "update_step:  48 model loss: 3.02626, kl_loss: 3.00280, obs_loss: 0.02344, reward_loss: 0.00003, value_loss: 0.02849 action_loss: 19.76052\n",
      "update_step:  49 model loss: 3.03614, kl_loss: 3.00298, obs_loss: 0.03313, reward_loss: 0.00003, value_loss: 0.02912 action_loss: 19.75589\n",
      "update_step:  50 model loss: 3.02464, kl_loss: 3.00292, obs_loss: 0.02170, reward_loss: 0.00003, value_loss: 0.02860 action_loss: 19.74483\n",
      "update_step:  51 model loss: 3.03010, kl_loss: 3.00323, obs_loss: 0.02685, reward_loss: 0.00003, value_loss: 0.02858 action_loss: 19.73899\n",
      "update_step:  52 model loss: 3.03691, kl_loss: 3.00469, obs_loss: 0.03220, reward_loss: 0.00003, value_loss: 0.02881 action_loss: 19.73186\n",
      "update_step:  53 model loss: 3.02986, kl_loss: 3.00256, obs_loss: 0.02728, reward_loss: 0.00003, value_loss: 0.02838 action_loss: 19.73155\n",
      "update_step:  54 model loss: 3.03520, kl_loss: 3.00281, obs_loss: 0.03236, reward_loss: 0.00003, value_loss: 0.02845 action_loss: 19.73634\n",
      "update_step:  55 model loss: 3.02963, kl_loss: 3.00270, obs_loss: 0.02690, reward_loss: 0.00003, value_loss: 0.02859 action_loss: 19.73284\n",
      "update_step:  56 model loss: 3.02610, kl_loss: 3.00296, obs_loss: 0.02311, reward_loss: 0.00003, value_loss: 0.02812 action_loss: 19.72173\n",
      "update_step:  57 model loss: 3.02363, kl_loss: 3.00213, obs_loss: 0.02147, reward_loss: 0.00003, value_loss: 0.02776 action_loss: 19.73252\n",
      "update_step:  58 model loss: 3.03714, kl_loss: 3.00448, obs_loss: 0.03263, reward_loss: 0.00003, value_loss: 0.02753 action_loss: 19.74364\n",
      "update_step:  59 model loss: 3.02527, kl_loss: 3.00244, obs_loss: 0.02280, reward_loss: 0.00003, value_loss: 0.02835 action_loss: 19.75332\n",
      "update_step:  60 model loss: 3.02655, kl_loss: 3.00286, obs_loss: 0.02366, reward_loss: 0.00003, value_loss: 0.02756 action_loss: 19.76241\n",
      "update_step:  61 model loss: 3.02863, kl_loss: 3.00348, obs_loss: 0.02513, reward_loss: 0.00003, value_loss: 0.02754 action_loss: 19.77309\n",
      "update_step:  62 model loss: 3.02476, kl_loss: 3.00148, obs_loss: 0.02326, reward_loss: 0.00003, value_loss: 0.02795 action_loss: 19.78888\n",
      "update_step:  63 model loss: 3.02052, kl_loss: 3.00120, obs_loss: 0.01929, reward_loss: 0.00003, value_loss: 0.02791 action_loss: 19.79675\n",
      "update_step:  64 model loss: 3.02548, kl_loss: 3.00247, obs_loss: 0.02299, reward_loss: 0.00003, value_loss: 0.02754 action_loss: 19.79389\n",
      "update_step:  65 model loss: 3.03405, kl_loss: 3.00355, obs_loss: 0.03047, reward_loss: 0.00003, value_loss: 0.02812 action_loss: 19.79722\n",
      "update_step:  66 model loss: 3.02998, kl_loss: 3.00169, obs_loss: 0.02827, reward_loss: 0.00003, value_loss: 0.02773 action_loss: 19.79638\n",
      "update_step:  67 model loss: 3.02754, kl_loss: 3.00369, obs_loss: 0.02383, reward_loss: 0.00002, value_loss: 0.02768 action_loss: 19.78299\n",
      "update_step:  68 model loss: 3.02614, kl_loss: 3.00275, obs_loss: 0.02336, reward_loss: 0.00003, value_loss: 0.02740 action_loss: 19.76678\n",
      "update_step:  69 model loss: 3.02755, kl_loss: 3.00488, obs_loss: 0.02264, reward_loss: 0.00003, value_loss: 0.02732 action_loss: 19.75294\n",
      "update_step:  70 model loss: 3.02680, kl_loss: 3.00386, obs_loss: 0.02291, reward_loss: 0.00003, value_loss: 0.02710 action_loss: 19.74584\n",
      "update_step:  71 model loss: 3.02856, kl_loss: 3.00346, obs_loss: 0.02508, reward_loss: 0.00002, value_loss: 0.02732 action_loss: 19.73553\n",
      "update_step:  72 model loss: 3.03204, kl_loss: 3.00409, obs_loss: 0.02792, reward_loss: 0.00003, value_loss: 0.02751 action_loss: 19.73345\n",
      "update_step:  73 model loss: 3.03382, kl_loss: 3.00263, obs_loss: 0.03116, reward_loss: 0.00003, value_loss: 0.02713 action_loss: 19.72069\n",
      "update_step:  74 model loss: 3.03626, kl_loss: 3.00515, obs_loss: 0.03109, reward_loss: 0.00003, value_loss: 0.02743 action_loss: 19.73244\n",
      "update_step:  75 model loss: 3.03114, kl_loss: 3.00386, obs_loss: 0.02726, reward_loss: 0.00002, value_loss: 0.02722 action_loss: 19.72742\n",
      "update_step:  76 model loss: 3.03292, kl_loss: 3.00250, obs_loss: 0.03039, reward_loss: 0.00003, value_loss: 0.02681 action_loss: 19.72628\n",
      "update_step:  77 model loss: 3.03213, kl_loss: 3.00266, obs_loss: 0.02945, reward_loss: 0.00002, value_loss: 0.02732 action_loss: 19.73407\n",
      "update_step:  78 model loss: 3.03765, kl_loss: 3.00540, obs_loss: 0.03223, reward_loss: 0.00002, value_loss: 0.02700 action_loss: 19.73455\n",
      "update_step:  79 model loss: 3.03589, kl_loss: 3.00537, obs_loss: 0.03049, reward_loss: 0.00003, value_loss: 0.02694 action_loss: 19.74788\n",
      "update_step:  80 model loss: 3.02908, kl_loss: 3.00261, obs_loss: 0.02645, reward_loss: 0.00003, value_loss: 0.02699 action_loss: 19.74966\n",
      "update_step:  81 model loss: 3.02377, kl_loss: 3.00155, obs_loss: 0.02219, reward_loss: 0.00003, value_loss: 0.02741 action_loss: 19.74204\n",
      "update_step:  82 model loss: 3.02397, kl_loss: 3.00280, obs_loss: 0.02114, reward_loss: 0.00003, value_loss: 0.02669 action_loss: 19.75216\n",
      "update_step:  83 model loss: 3.03202, kl_loss: 3.00514, obs_loss: 0.02685, reward_loss: 0.00003, value_loss: 0.02586 action_loss: 19.75915\n",
      "update_step:  84 model loss: 3.03144, kl_loss: 3.00492, obs_loss: 0.02649, reward_loss: 0.00003, value_loss: 0.02730 action_loss: 19.75039\n",
      "update_step:  85 model loss: 3.02437, kl_loss: 3.00326, obs_loss: 0.02109, reward_loss: 0.00003, value_loss: 0.02668 action_loss: 19.74827\n",
      "update_step:  86 model loss: 3.03126, kl_loss: 3.00406, obs_loss: 0.02718, reward_loss: 0.00003, value_loss: 0.02640 action_loss: 19.74871\n",
      "update_step:  87 model loss: 3.03547, kl_loss: 3.00625, obs_loss: 0.02919, reward_loss: 0.00003, value_loss: 0.02667 action_loss: 19.75930\n",
      "update_step:  88 model loss: 3.02237, kl_loss: 3.00044, obs_loss: 0.02190, reward_loss: 0.00003, value_loss: 0.02650 action_loss: 19.75278\n",
      "update_step:  89 model loss: 3.02494, kl_loss: 3.00122, obs_loss: 0.02369, reward_loss: 0.00002, value_loss: 0.02631 action_loss: 19.75076\n",
      "update_step:  90 model loss: 3.03469, kl_loss: 3.00279, obs_loss: 0.03187, reward_loss: 0.00003, value_loss: 0.02624 action_loss: 19.74994\n",
      "update_step:  91 model loss: 3.02415, kl_loss: 3.00102, obs_loss: 0.02311, reward_loss: 0.00002, value_loss: 0.02634 action_loss: 19.74794\n",
      "update_step:  92 model loss: 3.03114, kl_loss: 3.00334, obs_loss: 0.02778, reward_loss: 0.00002, value_loss: 0.02625 action_loss: 19.74978\n",
      "update_step:  93 model loss: 3.02257, kl_loss: 3.00174, obs_loss: 0.02081, reward_loss: 0.00003, value_loss: 0.02610 action_loss: 19.73369\n",
      "update_step:  94 model loss: 3.03126, kl_loss: 3.00376, obs_loss: 0.02748, reward_loss: 0.00002, value_loss: 0.02634 action_loss: 19.73491\n",
      "update_step:  95 model loss: 3.01958, kl_loss: 3.00077, obs_loss: 0.01879, reward_loss: 0.00003, value_loss: 0.02575 action_loss: 19.74657\n",
      "update_step:  96 model loss: 3.03042, kl_loss: 3.00455, obs_loss: 0.02584, reward_loss: 0.00002, value_loss: 0.02567 action_loss: 19.74685\n",
      "update_step:  97 model loss: 3.02347, kl_loss: 3.00246, obs_loss: 0.02099, reward_loss: 0.00002, value_loss: 0.02540 action_loss: 19.75523\n",
      "update_step:  98 model loss: 3.03942, kl_loss: 3.00428, obs_loss: 0.03512, reward_loss: 0.00002, value_loss: 0.02607 action_loss: 19.75047\n",
      "update_step:  99 model loss: 3.02246, kl_loss: 3.00227, obs_loss: 0.02017, reward_loss: 0.00002, value_loss: 0.02590 action_loss: 19.76283\n",
      "update_step: 100 model loss: 3.02116, kl_loss: 3.00119, obs_loss: 0.01995, reward_loss: 0.00002, value_loss: 0.02536 action_loss: 19.77120\n",
      "elasped time for update: 20.07s\n",
      "episode [  12/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.02262, kl_loss: 3.00288, obs_loss: 0.01972, reward_loss: 0.00002, value_loss: 0.02531 action_loss: 19.77162\n",
      "update_step:   2 model loss: 3.02178, kl_loss: 3.00127, obs_loss: 0.02048, reward_loss: 0.00002, value_loss: 0.02559 action_loss: 19.77469\n",
      "update_step:   3 model loss: 3.03018, kl_loss: 3.00501, obs_loss: 0.02515, reward_loss: 0.00002, value_loss: 0.02602 action_loss: 19.77788\n",
      "update_step:   4 model loss: 3.02394, kl_loss: 3.00154, obs_loss: 0.02238, reward_loss: 0.00002, value_loss: 0.02527 action_loss: 19.78078\n",
      "update_step:   5 model loss: 3.02353, kl_loss: 3.00135, obs_loss: 0.02216, reward_loss: 0.00002, value_loss: 0.02532 action_loss: 19.77001\n",
      "update_step:   6 model loss: 3.03593, kl_loss: 3.00628, obs_loss: 0.02962, reward_loss: 0.00002, value_loss: 0.02579 action_loss: 19.76452\n",
      "update_step:   7 model loss: 3.03664, kl_loss: 3.00509, obs_loss: 0.03153, reward_loss: 0.00002, value_loss: 0.02544 action_loss: 19.75335\n",
      "update_step:   8 model loss: 3.02490, kl_loss: 3.00226, obs_loss: 0.02261, reward_loss: 0.00002, value_loss: 0.02535 action_loss: 19.74630\n",
      "update_step:   9 model loss: 3.02479, kl_loss: 3.00229, obs_loss: 0.02248, reward_loss: 0.00002, value_loss: 0.02496 action_loss: 19.73870\n",
      "update_step:  10 model loss: 3.03274, kl_loss: 3.00648, obs_loss: 0.02624, reward_loss: 0.00002, value_loss: 0.02509 action_loss: 19.73180\n",
      "update_step:  11 model loss: 3.02506, kl_loss: 3.00270, obs_loss: 0.02233, reward_loss: 0.00002, value_loss: 0.02461 action_loss: 19.73343\n",
      "update_step:  12 model loss: 3.02889, kl_loss: 3.00305, obs_loss: 0.02581, reward_loss: 0.00002, value_loss: 0.02507 action_loss: 19.73833\n",
      "update_step:  13 model loss: 3.02647, kl_loss: 3.00284, obs_loss: 0.02360, reward_loss: 0.00002, value_loss: 0.02542 action_loss: 19.73417\n",
      "update_step:  14 model loss: 3.02881, kl_loss: 3.00132, obs_loss: 0.02746, reward_loss: 0.00002, value_loss: 0.02485 action_loss: 19.74001\n",
      "update_step:  15 model loss: 3.02229, kl_loss: 3.00294, obs_loss: 0.01933, reward_loss: 0.00002, value_loss: 0.02497 action_loss: 19.74291\n",
      "update_step:  16 model loss: 3.02845, kl_loss: 3.00188, obs_loss: 0.02655, reward_loss: 0.00002, value_loss: 0.02497 action_loss: 19.75168\n",
      "update_step:  17 model loss: 3.02990, kl_loss: 3.00397, obs_loss: 0.02591, reward_loss: 0.00002, value_loss: 0.02455 action_loss: 19.74844\n",
      "update_step:  18 model loss: 3.02356, kl_loss: 3.00295, obs_loss: 0.02059, reward_loss: 0.00002, value_loss: 0.02493 action_loss: 19.75391\n",
      "update_step:  19 model loss: 3.02010, kl_loss: 3.00096, obs_loss: 0.01912, reward_loss: 0.00002, value_loss: 0.02461 action_loss: 19.76138\n",
      "update_step:  20 model loss: 3.02345, kl_loss: 3.00179, obs_loss: 0.02163, reward_loss: 0.00002, value_loss: 0.02472 action_loss: 19.75501\n",
      "update_step:  21 model loss: 3.03066, kl_loss: 3.00384, obs_loss: 0.02680, reward_loss: 0.00002, value_loss: 0.02506 action_loss: 19.76149\n",
      "update_step:  22 model loss: 3.02513, kl_loss: 3.00419, obs_loss: 0.02092, reward_loss: 0.00002, value_loss: 0.02471 action_loss: 19.76160\n",
      "update_step:  23 model loss: 3.02444, kl_loss: 3.00138, obs_loss: 0.02304, reward_loss: 0.00002, value_loss: 0.02451 action_loss: 19.76480\n",
      "update_step:  24 model loss: 3.02585, kl_loss: 3.00343, obs_loss: 0.02240, reward_loss: 0.00002, value_loss: 0.02409 action_loss: 19.75193\n",
      "update_step:  25 model loss: 3.01551, kl_loss: 3.00082, obs_loss: 0.01467, reward_loss: 0.00002, value_loss: 0.02399 action_loss: 19.75136\n",
      "update_step:  26 model loss: 3.02875, kl_loss: 3.00404, obs_loss: 0.02469, reward_loss: 0.00002, value_loss: 0.02444 action_loss: 19.75556\n",
      "update_step:  27 model loss: 3.02722, kl_loss: 3.00109, obs_loss: 0.02610, reward_loss: 0.00003, value_loss: 0.02422 action_loss: 19.74303\n",
      "update_step:  28 model loss: 3.02266, kl_loss: 3.00219, obs_loss: 0.02044, reward_loss: 0.00002, value_loss: 0.02465 action_loss: 19.72943\n",
      "update_step:  29 model loss: 3.02189, kl_loss: 3.00205, obs_loss: 0.01982, reward_loss: 0.00002, value_loss: 0.02436 action_loss: 19.72778\n",
      "update_step:  30 model loss: 3.02305, kl_loss: 3.00225, obs_loss: 0.02077, reward_loss: 0.00002, value_loss: 0.02445 action_loss: 19.73541\n",
      "update_step:  31 model loss: 3.03015, kl_loss: 3.00381, obs_loss: 0.02632, reward_loss: 0.00003, value_loss: 0.02395 action_loss: 19.72444\n",
      "update_step:  32 model loss: 3.03182, kl_loss: 3.00396, obs_loss: 0.02784, reward_loss: 0.00002, value_loss: 0.02389 action_loss: 19.71344\n",
      "update_step:  33 model loss: 3.02556, kl_loss: 3.00406, obs_loss: 0.02148, reward_loss: 0.00003, value_loss: 0.02427 action_loss: 19.72320\n",
      "update_step:  34 model loss: 3.02605, kl_loss: 3.00153, obs_loss: 0.02451, reward_loss: 0.00002, value_loss: 0.02416 action_loss: 19.72768\n",
      "update_step:  35 model loss: 3.02497, kl_loss: 3.00540, obs_loss: 0.01954, reward_loss: 0.00003, value_loss: 0.02381 action_loss: 19.72467\n",
      "update_step:  36 model loss: 3.02628, kl_loss: 3.00274, obs_loss: 0.02352, reward_loss: 0.00002, value_loss: 0.02392 action_loss: 19.71964\n",
      "update_step:  37 model loss: 3.02550, kl_loss: 3.00291, obs_loss: 0.02257, reward_loss: 0.00002, value_loss: 0.02411 action_loss: 19.73004\n",
      "update_step:  38 model loss: 3.02679, kl_loss: 3.00265, obs_loss: 0.02411, reward_loss: 0.00002, value_loss: 0.02419 action_loss: 19.72893\n",
      "update_step:  39 model loss: 3.02029, kl_loss: 3.00082, obs_loss: 0.01944, reward_loss: 0.00002, value_loss: 0.02341 action_loss: 19.72050\n",
      "update_step:  40 model loss: 3.02360, kl_loss: 3.00482, obs_loss: 0.01876, reward_loss: 0.00002, value_loss: 0.02356 action_loss: 19.72080\n",
      "update_step:  41 model loss: 3.02238, kl_loss: 3.00213, obs_loss: 0.02022, reward_loss: 0.00003, value_loss: 0.02405 action_loss: 19.74547\n",
      "update_step:  42 model loss: 3.02855, kl_loss: 3.00661, obs_loss: 0.02192, reward_loss: 0.00002, value_loss: 0.02364 action_loss: 19.74426\n",
      "update_step:  43 model loss: 3.02366, kl_loss: 3.00204, obs_loss: 0.02160, reward_loss: 0.00002, value_loss: 0.02416 action_loss: 19.75020\n",
      "update_step:  44 model loss: 3.02846, kl_loss: 3.00398, obs_loss: 0.02446, reward_loss: 0.00002, value_loss: 0.02354 action_loss: 19.75289\n",
      "update_step:  45 model loss: 3.01664, kl_loss: 3.00062, obs_loss: 0.01600, reward_loss: 0.00002, value_loss: 0.02361 action_loss: 19.76793\n",
      "update_step:  46 model loss: 3.02153, kl_loss: 3.00190, obs_loss: 0.01961, reward_loss: 0.00002, value_loss: 0.02380 action_loss: 19.77300\n",
      "update_step:  47 model loss: 3.02151, kl_loss: 3.00405, obs_loss: 0.01743, reward_loss: 0.00002, value_loss: 0.02392 action_loss: 19.76952\n",
      "update_step:  48 model loss: 3.01817, kl_loss: 3.00158, obs_loss: 0.01657, reward_loss: 0.00002, value_loss: 0.02385 action_loss: 19.77400\n",
      "update_step:  49 model loss: 3.02160, kl_loss: 3.00142, obs_loss: 0.02016, reward_loss: 0.00002, value_loss: 0.02332 action_loss: 19.78010\n",
      "update_step:  50 model loss: 3.02260, kl_loss: 3.00228, obs_loss: 0.02029, reward_loss: 0.00002, value_loss: 0.02350 action_loss: 19.78498\n",
      "update_step:  51 model loss: 3.02480, kl_loss: 3.00097, obs_loss: 0.02380, reward_loss: 0.00002, value_loss: 0.02371 action_loss: 19.77499\n",
      "update_step:  52 model loss: 3.02230, kl_loss: 3.00035, obs_loss: 0.02193, reward_loss: 0.00002, value_loss: 0.02411 action_loss: 19.77938\n",
      "update_step:  53 model loss: 3.02706, kl_loss: 3.00249, obs_loss: 0.02455, reward_loss: 0.00002, value_loss: 0.02408 action_loss: 19.77628\n",
      "update_step:  54 model loss: 3.02077, kl_loss: 3.00189, obs_loss: 0.01886, reward_loss: 0.00002, value_loss: 0.02312 action_loss: 19.76833\n",
      "update_step:  55 model loss: 3.03171, kl_loss: 3.00549, obs_loss: 0.02620, reward_loss: 0.00002, value_loss: 0.02348 action_loss: 19.74746\n",
      "update_step:  56 model loss: 3.02778, kl_loss: 3.00329, obs_loss: 0.02447, reward_loss: 0.00002, value_loss: 0.02300 action_loss: 19.74407\n",
      "update_step:  57 model loss: 3.02621, kl_loss: 3.00249, obs_loss: 0.02369, reward_loss: 0.00002, value_loss: 0.02319 action_loss: 19.73598\n",
      "update_step:  58 model loss: 3.02618, kl_loss: 3.00219, obs_loss: 0.02397, reward_loss: 0.00002, value_loss: 0.02342 action_loss: 19.73699\n",
      "update_step:  59 model loss: 3.02055, kl_loss: 3.00370, obs_loss: 0.01683, reward_loss: 0.00002, value_loss: 0.02300 action_loss: 19.73204\n",
      "update_step:  60 model loss: 3.02658, kl_loss: 3.00383, obs_loss: 0.02273, reward_loss: 0.00002, value_loss: 0.02256 action_loss: 19.73743\n",
      "update_step:  61 model loss: 3.02779, kl_loss: 3.00389, obs_loss: 0.02388, reward_loss: 0.00002, value_loss: 0.02286 action_loss: 19.73206\n",
      "update_step:  62 model loss: 3.03945, kl_loss: 3.00435, obs_loss: 0.03508, reward_loss: 0.00002, value_loss: 0.02304 action_loss: 19.74296\n",
      "update_step:  63 model loss: 3.02397, kl_loss: 3.00468, obs_loss: 0.01927, reward_loss: 0.00002, value_loss: 0.02264 action_loss: 19.73642\n",
      "update_step:  64 model loss: 3.02064, kl_loss: 3.00253, obs_loss: 0.01809, reward_loss: 0.00002, value_loss: 0.02349 action_loss: 19.74579\n",
      "update_step:  65 model loss: 3.02755, kl_loss: 3.00273, obs_loss: 0.02479, reward_loss: 0.00002, value_loss: 0.02230 action_loss: 19.74912\n",
      "update_step:  66 model loss: 3.03297, kl_loss: 3.00551, obs_loss: 0.02744, reward_loss: 0.00002, value_loss: 0.02299 action_loss: 19.75967\n",
      "update_step:  67 model loss: 3.02204, kl_loss: 3.00454, obs_loss: 0.01748, reward_loss: 0.00002, value_loss: 0.02277 action_loss: 19.75702\n",
      "update_step:  68 model loss: 3.02461, kl_loss: 3.00064, obs_loss: 0.02395, reward_loss: 0.00002, value_loss: 0.02219 action_loss: 19.75977\n",
      "update_step:  69 model loss: 3.02979, kl_loss: 3.00348, obs_loss: 0.02629, reward_loss: 0.00002, value_loss: 0.02293 action_loss: 19.75352\n",
      "update_step:  70 model loss: 3.03127, kl_loss: 3.00262, obs_loss: 0.02863, reward_loss: 0.00002, value_loss: 0.02266 action_loss: 19.74334\n",
      "update_step:  71 model loss: 3.02087, kl_loss: 3.00188, obs_loss: 0.01897, reward_loss: 0.00002, value_loss: 0.02242 action_loss: 19.73476\n",
      "update_step:  72 model loss: 3.03121, kl_loss: 3.00468, obs_loss: 0.02651, reward_loss: 0.00002, value_loss: 0.02252 action_loss: 19.72367\n",
      "update_step:  73 model loss: 3.01642, kl_loss: 3.00139, obs_loss: 0.01501, reward_loss: 0.00002, value_loss: 0.02246 action_loss: 19.72067\n",
      "update_step:  74 model loss: 3.02318, kl_loss: 3.00107, obs_loss: 0.02209, reward_loss: 0.00002, value_loss: 0.02225 action_loss: 19.72868\n",
      "update_step:  75 model loss: 3.02122, kl_loss: 3.00088, obs_loss: 0.02031, reward_loss: 0.00002, value_loss: 0.02238 action_loss: 19.73235\n",
      "update_step:  76 model loss: 3.01679, kl_loss: 3.00150, obs_loss: 0.01526, reward_loss: 0.00002, value_loss: 0.02221 action_loss: 19.73535\n",
      "update_step:  77 model loss: 3.02330, kl_loss: 3.00310, obs_loss: 0.02018, reward_loss: 0.00002, value_loss: 0.02218 action_loss: 19.74311\n",
      "update_step:  78 model loss: 3.02102, kl_loss: 3.00322, obs_loss: 0.01778, reward_loss: 0.00002, value_loss: 0.02228 action_loss: 19.76069\n",
      "update_step:  79 model loss: 3.02700, kl_loss: 3.00137, obs_loss: 0.02560, reward_loss: 0.00002, value_loss: 0.02197 action_loss: 19.75541\n",
      "update_step:  80 model loss: 3.01776, kl_loss: 3.00121, obs_loss: 0.01653, reward_loss: 0.00002, value_loss: 0.02232 action_loss: 19.76820\n",
      "update_step:  81 model loss: 3.02544, kl_loss: 3.00349, obs_loss: 0.02194, reward_loss: 0.00002, value_loss: 0.02245 action_loss: 19.76261\n",
      "update_step:  82 model loss: 3.02364, kl_loss: 3.00388, obs_loss: 0.01973, reward_loss: 0.00002, value_loss: 0.02198 action_loss: 19.76091\n",
      "update_step:  83 model loss: 3.02099, kl_loss: 3.00294, obs_loss: 0.01804, reward_loss: 0.00002, value_loss: 0.02233 action_loss: 19.75178\n",
      "update_step:  84 model loss: 3.01938, kl_loss: 3.00112, obs_loss: 0.01825, reward_loss: 0.00002, value_loss: 0.02200 action_loss: 19.75035\n",
      "update_step:  85 model loss: 3.02609, kl_loss: 3.00225, obs_loss: 0.02381, reward_loss: 0.00002, value_loss: 0.02180 action_loss: 19.75821\n",
      "update_step:  86 model loss: 3.02415, kl_loss: 3.00238, obs_loss: 0.02175, reward_loss: 0.00002, value_loss: 0.02203 action_loss: 19.75013\n",
      "update_step:  87 model loss: 3.01838, kl_loss: 3.00049, obs_loss: 0.01787, reward_loss: 0.00002, value_loss: 0.02185 action_loss: 19.76547\n",
      "update_step:  88 model loss: 3.02503, kl_loss: 3.00232, obs_loss: 0.02269, reward_loss: 0.00002, value_loss: 0.02187 action_loss: 19.75510\n",
      "update_step:  89 model loss: 3.03250, kl_loss: 3.00265, obs_loss: 0.02983, reward_loss: 0.00002, value_loss: 0.02168 action_loss: 19.75457\n",
      "update_step:  90 model loss: 3.02939, kl_loss: 3.00372, obs_loss: 0.02565, reward_loss: 0.00002, value_loss: 0.02127 action_loss: 19.73635\n",
      "update_step:  91 model loss: 3.02044, kl_loss: 3.00121, obs_loss: 0.01921, reward_loss: 0.00002, value_loss: 0.02166 action_loss: 19.74829\n",
      "update_step:  92 model loss: 3.01656, kl_loss: 3.00068, obs_loss: 0.01586, reward_loss: 0.00002, value_loss: 0.02207 action_loss: 19.73832\n",
      "update_step:  93 model loss: 3.01889, kl_loss: 3.00122, obs_loss: 0.01765, reward_loss: 0.00002, value_loss: 0.02075 action_loss: 19.72585\n",
      "update_step:  94 model loss: 3.01990, kl_loss: 3.00171, obs_loss: 0.01816, reward_loss: 0.00002, value_loss: 0.02202 action_loss: 19.73781\n",
      "update_step:  95 model loss: 3.02931, kl_loss: 3.00327, obs_loss: 0.02602, reward_loss: 0.00002, value_loss: 0.02154 action_loss: 19.73347\n",
      "update_step:  96 model loss: 3.02607, kl_loss: 3.00242, obs_loss: 0.02363, reward_loss: 0.00002, value_loss: 0.02132 action_loss: 19.75785\n",
      "update_step:  97 model loss: 3.02941, kl_loss: 3.00381, obs_loss: 0.02558, reward_loss: 0.00002, value_loss: 0.02192 action_loss: 19.74768\n",
      "update_step:  98 model loss: 3.04748, kl_loss: 3.00476, obs_loss: 0.04269, reward_loss: 0.00003, value_loss: 0.02246 action_loss: 19.79381\n",
      "update_step:  99 model loss: 3.04655, kl_loss: 3.00328, obs_loss: 0.04323, reward_loss: 0.00003, value_loss: 0.02149 action_loss: 19.76337\n",
      "update_step: 100 model loss: 3.07082, kl_loss: 3.00475, obs_loss: 0.06605, reward_loss: 0.00002, value_loss: 0.02301 action_loss: 19.80929\n",
      "elasped time for update: 20.31s\n",
      "episode [  13/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.38s\n",
      "update_step:   1 model loss: 3.06988, kl_loss: 3.00362, obs_loss: 0.06623, reward_loss: 0.00002, value_loss: 0.02127 action_loss: 19.77743\n",
      "update_step:   2 model loss: 3.07955, kl_loss: 3.00414, obs_loss: 0.07539, reward_loss: 0.00003, value_loss: 0.02297 action_loss: 19.83289\n",
      "update_step:   3 model loss: 3.06392, kl_loss: 3.00186, obs_loss: 0.06204, reward_loss: 0.00003, value_loss: 0.02171 action_loss: 19.77801\n",
      "update_step:   4 model loss: 3.05208, kl_loss: 3.00240, obs_loss: 0.04966, reward_loss: 0.00003, value_loss: 0.02241 action_loss: 19.78004\n",
      "update_step:   5 model loss: 3.02709, kl_loss: 3.00038, obs_loss: 0.02669, reward_loss: 0.00002, value_loss: 0.02212 action_loss: 19.76516\n",
      "update_step:   6 model loss: 3.02518, kl_loss: 3.00130, obs_loss: 0.02387, reward_loss: 0.00002, value_loss: 0.02223 action_loss: 19.73923\n",
      "update_step:   7 model loss: 3.03557, kl_loss: 3.00219, obs_loss: 0.03336, reward_loss: 0.00002, value_loss: 0.02256 action_loss: 19.74224\n",
      "update_step:   8 model loss: 3.04729, kl_loss: 3.00315, obs_loss: 0.04412, reward_loss: 0.00002, value_loss: 0.02180 action_loss: 19.71107\n",
      "update_step:   9 model loss: 3.02943, kl_loss: 3.00366, obs_loss: 0.02575, reward_loss: 0.00002, value_loss: 0.02238 action_loss: 19.72341\n",
      "update_step:  10 model loss: 3.02942, kl_loss: 3.00130, obs_loss: 0.02810, reward_loss: 0.00002, value_loss: 0.02211 action_loss: 19.73578\n",
      "update_step:  11 model loss: 3.02422, kl_loss: 3.00074, obs_loss: 0.02346, reward_loss: 0.00002, value_loss: 0.02195 action_loss: 19.72219\n",
      "update_step:  12 model loss: 3.03215, kl_loss: 3.00266, obs_loss: 0.02947, reward_loss: 0.00002, value_loss: 0.02213 action_loss: 19.74559\n",
      "update_step:  13 model loss: 3.03150, kl_loss: 3.00177, obs_loss: 0.02971, reward_loss: 0.00002, value_loss: 0.02246 action_loss: 19.77223\n",
      "update_step:  14 model loss: 3.03307, kl_loss: 3.00258, obs_loss: 0.03046, reward_loss: 0.00002, value_loss: 0.02211 action_loss: 19.78720\n",
      "update_step:  15 model loss: 3.03014, kl_loss: 3.00232, obs_loss: 0.02780, reward_loss: 0.00002, value_loss: 0.02252 action_loss: 19.80510\n",
      "update_step:  16 model loss: 3.03418, kl_loss: 3.00312, obs_loss: 0.03104, reward_loss: 0.00002, value_loss: 0.02236 action_loss: 19.79985\n",
      "update_step:  17 model loss: 3.02599, kl_loss: 3.00249, obs_loss: 0.02347, reward_loss: 0.00002, value_loss: 0.02263 action_loss: 19.81041\n",
      "update_step:  18 model loss: 3.02339, kl_loss: 3.00350, obs_loss: 0.01987, reward_loss: 0.00002, value_loss: 0.02226 action_loss: 19.80510\n",
      "update_step:  19 model loss: 3.02920, kl_loss: 3.00526, obs_loss: 0.02392, reward_loss: 0.00002, value_loss: 0.02180 action_loss: 19.78133\n",
      "update_step:  20 model loss: 3.02281, kl_loss: 3.00168, obs_loss: 0.02110, reward_loss: 0.00002, value_loss: 0.02217 action_loss: 19.78178\n",
      "update_step:  21 model loss: 3.02928, kl_loss: 3.00368, obs_loss: 0.02558, reward_loss: 0.00002, value_loss: 0.02184 action_loss: 19.77345\n",
      "update_step:  22 model loss: 3.02090, kl_loss: 3.00274, obs_loss: 0.01814, reward_loss: 0.00002, value_loss: 0.02179 action_loss: 19.75720\n",
      "update_step:  23 model loss: 3.02366, kl_loss: 3.00137, obs_loss: 0.02227, reward_loss: 0.00002, value_loss: 0.02176 action_loss: 19.74820\n",
      "update_step:  24 model loss: 3.02490, kl_loss: 3.00088, obs_loss: 0.02400, reward_loss: 0.00002, value_loss: 0.02152 action_loss: 19.73140\n",
      "update_step:  25 model loss: 3.03373, kl_loss: 3.00242, obs_loss: 0.03129, reward_loss: 0.00002, value_loss: 0.02241 action_loss: 19.75463\n",
      "update_step:  26 model loss: 3.02454, kl_loss: 3.00075, obs_loss: 0.02376, reward_loss: 0.00003, value_loss: 0.02167 action_loss: 19.74004\n",
      "update_step:  27 model loss: 3.02586, kl_loss: 3.00165, obs_loss: 0.02419, reward_loss: 0.00002, value_loss: 0.02168 action_loss: 19.74849\n",
      "update_step:  28 model loss: 3.01891, kl_loss: 3.00112, obs_loss: 0.01777, reward_loss: 0.00002, value_loss: 0.02225 action_loss: 19.76733\n",
      "update_step:  29 model loss: 3.01956, kl_loss: 3.00046, obs_loss: 0.01908, reward_loss: 0.00002, value_loss: 0.02133 action_loss: 19.78827\n",
      "update_step:  30 model loss: 3.02621, kl_loss: 3.00131, obs_loss: 0.02488, reward_loss: 0.00002, value_loss: 0.02213 action_loss: 19.80908\n",
      "update_step:  31 model loss: 3.02911, kl_loss: 3.00295, obs_loss: 0.02614, reward_loss: 0.00002, value_loss: 0.02178 action_loss: 19.79044\n",
      "update_step:  32 model loss: 3.02423, kl_loss: 3.00166, obs_loss: 0.02255, reward_loss: 0.00003, value_loss: 0.02188 action_loss: 19.82158\n",
      "update_step:  33 model loss: 3.02885, kl_loss: 3.00523, obs_loss: 0.02360, reward_loss: 0.00002, value_loss: 0.02157 action_loss: 19.81456\n",
      "update_step:  34 model loss: 3.02394, kl_loss: 3.00286, obs_loss: 0.02106, reward_loss: 0.00003, value_loss: 0.02187 action_loss: 19.79330\n",
      "update_step:  35 model loss: 3.02554, kl_loss: 3.00237, obs_loss: 0.02316, reward_loss: 0.00002, value_loss: 0.02142 action_loss: 19.79012\n",
      "update_step:  36 model loss: 3.02404, kl_loss: 3.00110, obs_loss: 0.02292, reward_loss: 0.00002, value_loss: 0.02152 action_loss: 19.77236\n",
      "update_step:  37 model loss: 3.03485, kl_loss: 3.00351, obs_loss: 0.03132, reward_loss: 0.00002, value_loss: 0.02170 action_loss: 19.76958\n",
      "update_step:  38 model loss: 3.02903, kl_loss: 3.00283, obs_loss: 0.02618, reward_loss: 0.00002, value_loss: 0.02097 action_loss: 19.72800\n",
      "update_step:  39 model loss: 3.03916, kl_loss: 3.00374, obs_loss: 0.03540, reward_loss: 0.00003, value_loss: 0.02169 action_loss: 19.73424\n",
      "update_step:  40 model loss: 3.02534, kl_loss: 3.00179, obs_loss: 0.02353, reward_loss: 0.00002, value_loss: 0.02152 action_loss: 19.72736\n",
      "update_step:  41 model loss: 3.02609, kl_loss: 3.00219, obs_loss: 0.02388, reward_loss: 0.00002, value_loss: 0.02190 action_loss: 19.73136\n",
      "update_step:  42 model loss: 3.02631, kl_loss: 3.00159, obs_loss: 0.02470, reward_loss: 0.00002, value_loss: 0.02156 action_loss: 19.73583\n",
      "update_step:  43 model loss: 3.02239, kl_loss: 3.00132, obs_loss: 0.02105, reward_loss: 0.00002, value_loss: 0.02158 action_loss: 19.75813\n",
      "update_step:  44 model loss: 3.02264, kl_loss: 3.00155, obs_loss: 0.02107, reward_loss: 0.00002, value_loss: 0.02131 action_loss: 19.78258\n",
      "update_step:  45 model loss: 3.01936, kl_loss: 3.00225, obs_loss: 0.01709, reward_loss: 0.00002, value_loss: 0.02090 action_loss: 19.77886\n",
      "update_step:  46 model loss: 3.01800, kl_loss: 3.00082, obs_loss: 0.01716, reward_loss: 0.00002, value_loss: 0.02093 action_loss: 19.78947\n",
      "update_step:  47 model loss: 3.02707, kl_loss: 3.00228, obs_loss: 0.02477, reward_loss: 0.00002, value_loss: 0.02044 action_loss: 19.80717\n",
      "update_step:  48 model loss: 3.02114, kl_loss: 3.00063, obs_loss: 0.02049, reward_loss: 0.00002, value_loss: 0.02089 action_loss: 19.80896\n",
      "update_step:  49 model loss: 3.01773, kl_loss: 3.00097, obs_loss: 0.01674, reward_loss: 0.00002, value_loss: 0.02081 action_loss: 19.79675\n",
      "update_step:  50 model loss: 3.02878, kl_loss: 3.00428, obs_loss: 0.02447, reward_loss: 0.00002, value_loss: 0.02111 action_loss: 19.80735\n",
      "update_step:  51 model loss: 3.02008, kl_loss: 3.00178, obs_loss: 0.01827, reward_loss: 0.00002, value_loss: 0.02049 action_loss: 19.79738\n",
      "update_step:  52 model loss: 3.02556, kl_loss: 3.00366, obs_loss: 0.02188, reward_loss: 0.00002, value_loss: 0.02109 action_loss: 19.78989\n",
      "update_step:  53 model loss: 3.02317, kl_loss: 3.00272, obs_loss: 0.02043, reward_loss: 0.00002, value_loss: 0.02125 action_loss: 19.78572\n",
      "update_step:  54 model loss: 3.02914, kl_loss: 3.00346, obs_loss: 0.02566, reward_loss: 0.00002, value_loss: 0.02068 action_loss: 19.78128\n",
      "update_step:  55 model loss: 3.03452, kl_loss: 3.00221, obs_loss: 0.03229, reward_loss: 0.00002, value_loss: 0.02101 action_loss: 19.79287\n",
      "update_step:  56 model loss: 3.02318, kl_loss: 3.00156, obs_loss: 0.02160, reward_loss: 0.00002, value_loss: 0.02044 action_loss: 19.77502\n",
      "update_step:  57 model loss: 3.01824, kl_loss: 3.00090, obs_loss: 0.01732, reward_loss: 0.00002, value_loss: 0.02094 action_loss: 19.77237\n",
      "update_step:  58 model loss: 3.02571, kl_loss: 3.00190, obs_loss: 0.02379, reward_loss: 0.00002, value_loss: 0.02092 action_loss: 19.77869\n",
      "update_step:  59 model loss: 3.01690, kl_loss: 3.00062, obs_loss: 0.01626, reward_loss: 0.00002, value_loss: 0.02112 action_loss: 19.78051\n",
      "update_step:  60 model loss: 3.02371, kl_loss: 3.00272, obs_loss: 0.02097, reward_loss: 0.00002, value_loss: 0.02079 action_loss: 19.77474\n",
      "update_step:  61 model loss: 3.02863, kl_loss: 3.00328, obs_loss: 0.02533, reward_loss: 0.00002, value_loss: 0.02113 action_loss: 19.76870\n",
      "update_step:  62 model loss: 3.03536, kl_loss: 3.00248, obs_loss: 0.03286, reward_loss: 0.00002, value_loss: 0.02057 action_loss: 19.77613\n",
      "update_step:  63 model loss: 3.01577, kl_loss: 3.00052, obs_loss: 0.01524, reward_loss: 0.00002, value_loss: 0.02038 action_loss: 19.77418\n",
      "update_step:  64 model loss: 3.01901, kl_loss: 3.00217, obs_loss: 0.01681, reward_loss: 0.00002, value_loss: 0.02016 action_loss: 19.76581\n",
      "update_step:  65 model loss: 3.02261, kl_loss: 3.00136, obs_loss: 0.02123, reward_loss: 0.00002, value_loss: 0.02039 action_loss: 19.75674\n",
      "update_step:  66 model loss: 3.01762, kl_loss: 3.00140, obs_loss: 0.01620, reward_loss: 0.00002, value_loss: 0.02057 action_loss: 19.75699\n",
      "update_step:  67 model loss: 3.03183, kl_loss: 3.00316, obs_loss: 0.02864, reward_loss: 0.00002, value_loss: 0.02035 action_loss: 19.75015\n",
      "update_step:  68 model loss: 3.01926, kl_loss: 3.00175, obs_loss: 0.01749, reward_loss: 0.00002, value_loss: 0.02016 action_loss: 19.74998\n",
      "update_step:  69 model loss: 3.02131, kl_loss: 3.00154, obs_loss: 0.01975, reward_loss: 0.00002, value_loss: 0.02067 action_loss: 19.74725\n",
      "update_step:  70 model loss: 3.02144, kl_loss: 3.00256, obs_loss: 0.01886, reward_loss: 0.00002, value_loss: 0.02052 action_loss: 19.75807\n",
      "update_step:  71 model loss: 3.02429, kl_loss: 3.00348, obs_loss: 0.02079, reward_loss: 0.00002, value_loss: 0.01997 action_loss: 19.76188\n",
      "update_step:  72 model loss: 3.02592, kl_loss: 3.00344, obs_loss: 0.02246, reward_loss: 0.00002, value_loss: 0.02016 action_loss: 19.77145\n",
      "update_step:  73 model loss: 3.01614, kl_loss: 3.00094, obs_loss: 0.01518, reward_loss: 0.00002, value_loss: 0.01991 action_loss: 19.77854\n",
      "update_step:  74 model loss: 3.02946, kl_loss: 3.00488, obs_loss: 0.02456, reward_loss: 0.00002, value_loss: 0.02015 action_loss: 19.79426\n",
      "update_step:  75 model loss: 3.03089, kl_loss: 3.00388, obs_loss: 0.02699, reward_loss: 0.00002, value_loss: 0.01990 action_loss: 19.79015\n",
      "update_step:  76 model loss: 3.01738, kl_loss: 3.00076, obs_loss: 0.01660, reward_loss: 0.00002, value_loss: 0.02041 action_loss: 19.79485\n",
      "update_step:  77 model loss: 3.02256, kl_loss: 3.00243, obs_loss: 0.02012, reward_loss: 0.00002, value_loss: 0.02005 action_loss: 19.78935\n",
      "update_step:  78 model loss: 3.01702, kl_loss: 3.00127, obs_loss: 0.01574, reward_loss: 0.00002, value_loss: 0.02034 action_loss: 19.80296\n",
      "update_step:  79 model loss: 3.02358, kl_loss: 3.00248, obs_loss: 0.02108, reward_loss: 0.00002, value_loss: 0.02009 action_loss: 19.78990\n",
      "update_step:  80 model loss: 3.01572, kl_loss: 3.00097, obs_loss: 0.01473, reward_loss: 0.00002, value_loss: 0.02012 action_loss: 19.78474\n",
      "update_step:  81 model loss: 3.01780, kl_loss: 3.00131, obs_loss: 0.01647, reward_loss: 0.00002, value_loss: 0.01967 action_loss: 19.77899\n",
      "update_step:  82 model loss: 3.02158, kl_loss: 3.00217, obs_loss: 0.01939, reward_loss: 0.00002, value_loss: 0.01998 action_loss: 19.78065\n",
      "update_step:  83 model loss: 3.01769, kl_loss: 3.00099, obs_loss: 0.01668, reward_loss: 0.00002, value_loss: 0.01955 action_loss: 19.77524\n",
      "update_step:  84 model loss: 3.01423, kl_loss: 3.00037, obs_loss: 0.01384, reward_loss: 0.00002, value_loss: 0.01984 action_loss: 19.76898\n",
      "update_step:  85 model loss: 3.02828, kl_loss: 3.00259, obs_loss: 0.02567, reward_loss: 0.00002, value_loss: 0.01991 action_loss: 19.77854\n",
      "update_step:  86 model loss: 3.01801, kl_loss: 3.00225, obs_loss: 0.01575, reward_loss: 0.00002, value_loss: 0.01989 action_loss: 19.77586\n",
      "update_step:  87 model loss: 3.01604, kl_loss: 3.00256, obs_loss: 0.01346, reward_loss: 0.00002, value_loss: 0.02036 action_loss: 19.78080\n",
      "update_step:  88 model loss: 3.01780, kl_loss: 3.00052, obs_loss: 0.01725, reward_loss: 0.00002, value_loss: 0.01987 action_loss: 19.78060\n",
      "update_step:  89 model loss: 3.01884, kl_loss: 3.00159, obs_loss: 0.01723, reward_loss: 0.00002, value_loss: 0.01999 action_loss: 19.78980\n",
      "update_step:  90 model loss: 3.01553, kl_loss: 3.00114, obs_loss: 0.01438, reward_loss: 0.00002, value_loss: 0.01959 action_loss: 19.77937\n",
      "update_step:  91 model loss: 3.01408, kl_loss: 3.00120, obs_loss: 0.01286, reward_loss: 0.00002, value_loss: 0.01982 action_loss: 19.78253\n",
      "update_step:  92 model loss: 3.02514, kl_loss: 3.00211, obs_loss: 0.02301, reward_loss: 0.00002, value_loss: 0.01969 action_loss: 19.77779\n",
      "update_step:  93 model loss: 3.02210, kl_loss: 3.00315, obs_loss: 0.01893, reward_loss: 0.00002, value_loss: 0.01936 action_loss: 19.78258\n",
      "update_step:  94 model loss: 3.02435, kl_loss: 3.00169, obs_loss: 0.02265, reward_loss: 0.00002, value_loss: 0.01916 action_loss: 19.76987\n",
      "update_step:  95 model loss: 3.03598, kl_loss: 3.00308, obs_loss: 0.03289, reward_loss: 0.00002, value_loss: 0.02008 action_loss: 19.77411\n",
      "update_step:  96 model loss: 3.03342, kl_loss: 3.00542, obs_loss: 0.02799, reward_loss: 0.00002, value_loss: 0.01967 action_loss: 19.76982\n",
      "update_step:  97 model loss: 3.03057, kl_loss: 3.00446, obs_loss: 0.02609, reward_loss: 0.00002, value_loss: 0.01947 action_loss: 19.77750\n",
      "update_step:  98 model loss: 3.01919, kl_loss: 3.00393, obs_loss: 0.01524, reward_loss: 0.00002, value_loss: 0.01978 action_loss: 19.78118\n",
      "update_step:  99 model loss: 3.01599, kl_loss: 3.00207, obs_loss: 0.01390, reward_loss: 0.00002, value_loss: 0.01968 action_loss: 19.78210\n",
      "update_step: 100 model loss: 3.02002, kl_loss: 3.00218, obs_loss: 0.01783, reward_loss: 0.00002, value_loss: 0.01921 action_loss: 19.79906\n",
      "elasped time for update: 20.25s\n",
      "episode [  14/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.02571, kl_loss: 3.00391, obs_loss: 0.02178, reward_loss: 0.00002, value_loss: 0.01954 action_loss: 19.78514\n",
      "update_step:   2 model loss: 3.02293, kl_loss: 3.00203, obs_loss: 0.02088, reward_loss: 0.00002, value_loss: 0.01938 action_loss: 19.79301\n",
      "update_step:   3 model loss: 3.02326, kl_loss: 3.00202, obs_loss: 0.02122, reward_loss: 0.00002, value_loss: 0.01924 action_loss: 19.78316\n",
      "update_step:   4 model loss: 3.02559, kl_loss: 3.00110, obs_loss: 0.02447, reward_loss: 0.00002, value_loss: 0.01937 action_loss: 19.80349\n",
      "update_step:   5 model loss: 3.02439, kl_loss: 3.00241, obs_loss: 0.02196, reward_loss: 0.00002, value_loss: 0.01897 action_loss: 19.76877\n",
      "update_step:   6 model loss: 3.04101, kl_loss: 3.00361, obs_loss: 0.03738, reward_loss: 0.00002, value_loss: 0.01926 action_loss: 19.77707\n",
      "update_step:   7 model loss: 3.02833, kl_loss: 3.00107, obs_loss: 0.02724, reward_loss: 0.00002, value_loss: 0.01895 action_loss: 19.74758\n",
      "update_step:   8 model loss: 3.03724, kl_loss: 3.00120, obs_loss: 0.03601, reward_loss: 0.00002, value_loss: 0.01984 action_loss: 19.76597\n",
      "update_step:   9 model loss: 3.03148, kl_loss: 3.00097, obs_loss: 0.03048, reward_loss: 0.00002, value_loss: 0.01898 action_loss: 19.73817\n",
      "update_step:  10 model loss: 3.03100, kl_loss: 3.00076, obs_loss: 0.03023, reward_loss: 0.00002, value_loss: 0.01907 action_loss: 19.75438\n",
      "update_step:  11 model loss: 3.03531, kl_loss: 3.00194, obs_loss: 0.03335, reward_loss: 0.00002, value_loss: 0.01974 action_loss: 19.76449\n",
      "update_step:  12 model loss: 3.03320, kl_loss: 3.00287, obs_loss: 0.03031, reward_loss: 0.00002, value_loss: 0.01945 action_loss: 19.77017\n",
      "update_step:  13 model loss: 3.02965, kl_loss: 3.00092, obs_loss: 0.02871, reward_loss: 0.00002, value_loss: 0.01930 action_loss: 19.78262\n",
      "update_step:  14 model loss: 3.02852, kl_loss: 3.00140, obs_loss: 0.02710, reward_loss: 0.00002, value_loss: 0.01944 action_loss: 19.79210\n",
      "update_step:  15 model loss: 3.02949, kl_loss: 3.00342, obs_loss: 0.02605, reward_loss: 0.00002, value_loss: 0.01942 action_loss: 19.83569\n",
      "update_step:  16 model loss: 3.03113, kl_loss: 3.00142, obs_loss: 0.02969, reward_loss: 0.00002, value_loss: 0.01924 action_loss: 19.82407\n",
      "update_step:  17 model loss: 3.02988, kl_loss: 3.00234, obs_loss: 0.02753, reward_loss: 0.00002, value_loss: 0.02012 action_loss: 19.84598\n",
      "update_step:  18 model loss: 3.02789, kl_loss: 3.00110, obs_loss: 0.02677, reward_loss: 0.00002, value_loss: 0.01983 action_loss: 19.83176\n",
      "update_step:  19 model loss: 3.03330, kl_loss: 3.00273, obs_loss: 0.03055, reward_loss: 0.00002, value_loss: 0.01910 action_loss: 19.85053\n",
      "update_step:  20 model loss: 3.03543, kl_loss: 3.00261, obs_loss: 0.03280, reward_loss: 0.00002, value_loss: 0.01901 action_loss: 19.80796\n",
      "update_step:  21 model loss: 3.04569, kl_loss: 3.00363, obs_loss: 0.04204, reward_loss: 0.00002, value_loss: 0.01958 action_loss: 19.79680\n",
      "update_step:  22 model loss: 3.03567, kl_loss: 3.00097, obs_loss: 0.03469, reward_loss: 0.00002, value_loss: 0.01949 action_loss: 19.78464\n",
      "update_step:  23 model loss: 3.03315, kl_loss: 3.00054, obs_loss: 0.03259, reward_loss: 0.00002, value_loss: 0.01941 action_loss: 19.77395\n",
      "update_step:  24 model loss: 3.04202, kl_loss: 3.00277, obs_loss: 0.03923, reward_loss: 0.00002, value_loss: 0.01921 action_loss: 19.74427\n",
      "update_step:  25 model loss: 3.03260, kl_loss: 3.00046, obs_loss: 0.03212, reward_loss: 0.00002, value_loss: 0.01914 action_loss: 19.75373\n",
      "update_step:  26 model loss: 3.03215, kl_loss: 3.00079, obs_loss: 0.03134, reward_loss: 0.00002, value_loss: 0.01915 action_loss: 19.74494\n",
      "update_step:  27 model loss: 3.02934, kl_loss: 3.00121, obs_loss: 0.02811, reward_loss: 0.00002, value_loss: 0.01937 action_loss: 19.75773\n",
      "update_step:  28 model loss: 3.02712, kl_loss: 3.00208, obs_loss: 0.02502, reward_loss: 0.00002, value_loss: 0.01901 action_loss: 19.74580\n",
      "update_step:  29 model loss: 3.03421, kl_loss: 3.00268, obs_loss: 0.03150, reward_loss: 0.00002, value_loss: 0.01977 action_loss: 19.78852\n",
      "update_step:  30 model loss: 3.02877, kl_loss: 3.00164, obs_loss: 0.02710, reward_loss: 0.00002, value_loss: 0.01857 action_loss: 19.78902\n",
      "update_step:  31 model loss: 3.02919, kl_loss: 3.00190, obs_loss: 0.02727, reward_loss: 0.00002, value_loss: 0.01906 action_loss: 19.81598\n",
      "update_step:  32 model loss: 3.02622, kl_loss: 3.00162, obs_loss: 0.02458, reward_loss: 0.00002, value_loss: 0.01876 action_loss: 19.80898\n",
      "update_step:  33 model loss: 3.01914, kl_loss: 3.00129, obs_loss: 0.01783, reward_loss: 0.00002, value_loss: 0.01869 action_loss: 19.83638\n",
      "update_step:  34 model loss: 3.01432, kl_loss: 3.00116, obs_loss: 0.01314, reward_loss: 0.00002, value_loss: 0.01881 action_loss: 19.83137\n",
      "update_step:  35 model loss: 3.01583, kl_loss: 3.00134, obs_loss: 0.01447, reward_loss: 0.00002, value_loss: 0.01905 action_loss: 19.81590\n",
      "update_step:  36 model loss: 3.02269, kl_loss: 3.00226, obs_loss: 0.02041, reward_loss: 0.00002, value_loss: 0.01940 action_loss: 19.82168\n",
      "update_step:  37 model loss: 3.03001, kl_loss: 3.00167, obs_loss: 0.02832, reward_loss: 0.00002, value_loss: 0.01873 action_loss: 19.78971\n",
      "update_step:  38 model loss: 3.03232, kl_loss: 3.00102, obs_loss: 0.03128, reward_loss: 0.00002, value_loss: 0.01925 action_loss: 19.78778\n",
      "update_step:  39 model loss: 3.02840, kl_loss: 3.00055, obs_loss: 0.02783, reward_loss: 0.00002, value_loss: 0.01933 action_loss: 19.73858\n",
      "update_step:  40 model loss: 3.02981, kl_loss: 3.00090, obs_loss: 0.02889, reward_loss: 0.00002, value_loss: 0.01991 action_loss: 19.74721\n",
      "update_step:  41 model loss: 3.02120, kl_loss: 3.00134, obs_loss: 0.01984, reward_loss: 0.00002, value_loss: 0.01936 action_loss: 19.74175\n",
      "update_step:  42 model loss: 3.02393, kl_loss: 3.00383, obs_loss: 0.02009, reward_loss: 0.00002, value_loss: 0.01952 action_loss: 19.72340\n",
      "update_step:  43 model loss: 3.02914, kl_loss: 3.00331, obs_loss: 0.02581, reward_loss: 0.00002, value_loss: 0.01903 action_loss: 19.73879\n",
      "update_step:  44 model loss: 3.05710, kl_loss: 3.00552, obs_loss: 0.05156, reward_loss: 0.00002, value_loss: 0.01915 action_loss: 19.73299\n",
      "update_step:  45 model loss: 3.04607, kl_loss: 3.00277, obs_loss: 0.04328, reward_loss: 0.00002, value_loss: 0.01940 action_loss: 19.78688\n",
      "update_step:  46 model loss: 3.03954, kl_loss: 3.00167, obs_loss: 0.03784, reward_loss: 0.00003, value_loss: 0.01900 action_loss: 19.76831\n",
      "update_step:  47 model loss: 3.03382, kl_loss: 3.00155, obs_loss: 0.03225, reward_loss: 0.00002, value_loss: 0.01900 action_loss: 19.80246\n",
      "update_step:  48 model loss: 3.02771, kl_loss: 3.00324, obs_loss: 0.02445, reward_loss: 0.00002, value_loss: 0.01890 action_loss: 19.81866\n",
      "update_step:  49 model loss: 3.01954, kl_loss: 3.00209, obs_loss: 0.01744, reward_loss: 0.00002, value_loss: 0.01903 action_loss: 19.82437\n",
      "update_step:  50 model loss: 3.02126, kl_loss: 3.00098, obs_loss: 0.02026, reward_loss: 0.00002, value_loss: 0.01944 action_loss: 19.82140\n",
      "update_step:  51 model loss: 3.02808, kl_loss: 3.00181, obs_loss: 0.02626, reward_loss: 0.00002, value_loss: 0.01904 action_loss: 19.80267\n",
      "update_step:  52 model loss: 3.02481, kl_loss: 3.00070, obs_loss: 0.02409, reward_loss: 0.00002, value_loss: 0.01899 action_loss: 19.82145\n",
      "update_step:  53 model loss: 3.02181, kl_loss: 3.00044, obs_loss: 0.02135, reward_loss: 0.00002, value_loss: 0.01910 action_loss: 19.80652\n",
      "update_step:  54 model loss: 3.03245, kl_loss: 3.00226, obs_loss: 0.03017, reward_loss: 0.00002, value_loss: 0.01875 action_loss: 19.79513\n",
      "update_step:  55 model loss: 3.01422, kl_loss: 3.00045, obs_loss: 0.01374, reward_loss: 0.00002, value_loss: 0.01870 action_loss: 19.78669\n",
      "update_step:  56 model loss: 3.02423, kl_loss: 3.00337, obs_loss: 0.02084, reward_loss: 0.00002, value_loss: 0.01876 action_loss: 19.78649\n",
      "update_step:  57 model loss: 3.02731, kl_loss: 3.00185, obs_loss: 0.02545, reward_loss: 0.00002, value_loss: 0.01868 action_loss: 19.78852\n",
      "update_step:  58 model loss: 3.01360, kl_loss: 3.00046, obs_loss: 0.01313, reward_loss: 0.00002, value_loss: 0.01840 action_loss: 19.77160\n",
      "update_step:  59 model loss: 3.01444, kl_loss: 3.00167, obs_loss: 0.01275, reward_loss: 0.00002, value_loss: 0.01850 action_loss: 19.75838\n",
      "update_step:  60 model loss: 3.01918, kl_loss: 3.00282, obs_loss: 0.01633, reward_loss: 0.00002, value_loss: 0.01873 action_loss: 19.77759\n",
      "update_step:  61 model loss: 3.02063, kl_loss: 3.00252, obs_loss: 0.01809, reward_loss: 0.00002, value_loss: 0.01866 action_loss: 19.76494\n",
      "update_step:  62 model loss: 3.01756, kl_loss: 3.00138, obs_loss: 0.01617, reward_loss: 0.00002, value_loss: 0.01860 action_loss: 19.76229\n",
      "update_step:  63 model loss: 3.02328, kl_loss: 3.00090, obs_loss: 0.02236, reward_loss: 0.00002, value_loss: 0.01827 action_loss: 19.75556\n",
      "update_step:  64 model loss: 3.02460, kl_loss: 3.00231, obs_loss: 0.02228, reward_loss: 0.00002, value_loss: 0.01914 action_loss: 19.78440\n",
      "update_step:  65 model loss: 3.02328, kl_loss: 3.00074, obs_loss: 0.02253, reward_loss: 0.00002, value_loss: 0.01822 action_loss: 19.77697\n",
      "update_step:  66 model loss: 3.02071, kl_loss: 3.00085, obs_loss: 0.01984, reward_loss: 0.00002, value_loss: 0.01836 action_loss: 19.78618\n",
      "update_step:  67 model loss: 3.02176, kl_loss: 3.00105, obs_loss: 0.02069, reward_loss: 0.00002, value_loss: 0.01849 action_loss: 19.78713\n",
      "update_step:  68 model loss: 3.02746, kl_loss: 3.00265, obs_loss: 0.02479, reward_loss: 0.00002, value_loss: 0.01836 action_loss: 19.80028\n",
      "update_step:  69 model loss: 3.02051, kl_loss: 3.00059, obs_loss: 0.01990, reward_loss: 0.00002, value_loss: 0.01834 action_loss: 19.79344\n",
      "update_step:  70 model loss: 3.02145, kl_loss: 3.00176, obs_loss: 0.01967, reward_loss: 0.00002, value_loss: 0.01813 action_loss: 19.79428\n",
      "update_step:  71 model loss: 3.01631, kl_loss: 3.00251, obs_loss: 0.01379, reward_loss: 0.00002, value_loss: 0.01814 action_loss: 19.79686\n",
      "update_step:  72 model loss: 3.02060, kl_loss: 3.00112, obs_loss: 0.01946, reward_loss: 0.00002, value_loss: 0.01786 action_loss: 19.80196\n",
      "update_step:  73 model loss: 3.02821, kl_loss: 3.00327, obs_loss: 0.02493, reward_loss: 0.00002, value_loss: 0.01833 action_loss: 19.79360\n",
      "update_step:  74 model loss: 3.01270, kl_loss: 3.00077, obs_loss: 0.01191, reward_loss: 0.00002, value_loss: 0.01862 action_loss: 19.79053\n",
      "update_step:  75 model loss: 3.01653, kl_loss: 3.00125, obs_loss: 0.01526, reward_loss: 0.00002, value_loss: 0.01847 action_loss: 19.77985\n",
      "update_step:  76 model loss: 3.01336, kl_loss: 3.00074, obs_loss: 0.01260, reward_loss: 0.00002, value_loss: 0.01854 action_loss: 19.79489\n",
      "update_step:  77 model loss: 3.01762, kl_loss: 3.00174, obs_loss: 0.01587, reward_loss: 0.00002, value_loss: 0.01811 action_loss: 19.77928\n",
      "update_step:  78 model loss: 3.02362, kl_loss: 3.00186, obs_loss: 0.02174, reward_loss: 0.00002, value_loss: 0.01824 action_loss: 19.78283\n",
      "update_step:  79 model loss: 3.02524, kl_loss: 3.00237, obs_loss: 0.02286, reward_loss: 0.00002, value_loss: 0.01819 action_loss: 19.77111\n",
      "update_step:  80 model loss: 3.02680, kl_loss: 3.00319, obs_loss: 0.02359, reward_loss: 0.00002, value_loss: 0.01857 action_loss: 19.78567\n",
      "update_step:  81 model loss: 3.02056, kl_loss: 3.00202, obs_loss: 0.01852, reward_loss: 0.00002, value_loss: 0.01848 action_loss: 19.78238\n",
      "update_step:  82 model loss: 3.02114, kl_loss: 3.00148, obs_loss: 0.01964, reward_loss: 0.00002, value_loss: 0.01825 action_loss: 19.78524\n",
      "update_step:  83 model loss: 3.01343, kl_loss: 3.00054, obs_loss: 0.01287, reward_loss: 0.00002, value_loss: 0.01839 action_loss: 19.79702\n",
      "update_step:  84 model loss: 3.01657, kl_loss: 3.00134, obs_loss: 0.01522, reward_loss: 0.00002, value_loss: 0.01872 action_loss: 19.80235\n",
      "update_step:  85 model loss: 3.01627, kl_loss: 3.00182, obs_loss: 0.01444, reward_loss: 0.00002, value_loss: 0.01813 action_loss: 19.80486\n",
      "update_step:  86 model loss: 3.02019, kl_loss: 3.00076, obs_loss: 0.01941, reward_loss: 0.00002, value_loss: 0.01810 action_loss: 19.78615\n",
      "update_step:  87 model loss: 3.02922, kl_loss: 3.00291, obs_loss: 0.02629, reward_loss: 0.00002, value_loss: 0.01840 action_loss: 19.79828\n",
      "update_step:  88 model loss: 3.03026, kl_loss: 3.00135, obs_loss: 0.02889, reward_loss: 0.00002, value_loss: 0.01794 action_loss: 19.77965\n",
      "update_step:  89 model loss: 3.02682, kl_loss: 3.00073, obs_loss: 0.02607, reward_loss: 0.00002, value_loss: 0.01802 action_loss: 19.79020\n",
      "update_step:  90 model loss: 3.02760, kl_loss: 3.00202, obs_loss: 0.02556, reward_loss: 0.00002, value_loss: 0.01824 action_loss: 19.75392\n",
      "update_step:  91 model loss: 3.03203, kl_loss: 3.00114, obs_loss: 0.03088, reward_loss: 0.00002, value_loss: 0.01822 action_loss: 19.77928\n",
      "update_step:  92 model loss: 3.03815, kl_loss: 3.00319, obs_loss: 0.03494, reward_loss: 0.00002, value_loss: 0.01821 action_loss: 19.76086\n",
      "update_step:  93 model loss: 3.02855, kl_loss: 3.00041, obs_loss: 0.02812, reward_loss: 0.00002, value_loss: 0.01838 action_loss: 19.75976\n",
      "update_step:  94 model loss: 3.02371, kl_loss: 3.00127, obs_loss: 0.02242, reward_loss: 0.00002, value_loss: 0.01792 action_loss: 19.75978\n",
      "update_step:  95 model loss: 3.02099, kl_loss: 3.00052, obs_loss: 0.02045, reward_loss: 0.00002, value_loss: 0.01785 action_loss: 19.74781\n",
      "update_step:  96 model loss: 3.04581, kl_loss: 3.00156, obs_loss: 0.04423, reward_loss: 0.00002, value_loss: 0.01811 action_loss: 19.79274\n",
      "update_step:  97 model loss: 3.06552, kl_loss: 3.00184, obs_loss: 0.06366, reward_loss: 0.00002, value_loss: 0.01791 action_loss: 19.76112\n",
      "update_step:  98 model loss: 3.06687, kl_loss: 3.00150, obs_loss: 0.06534, reward_loss: 0.00002, value_loss: 0.01862 action_loss: 19.80493\n",
      "update_step:  99 model loss: 3.04411, kl_loss: 3.00090, obs_loss: 0.04318, reward_loss: 0.00002, value_loss: 0.01796 action_loss: 19.77561\n",
      "update_step: 100 model loss: 3.03552, kl_loss: 3.00014, obs_loss: 0.03536, reward_loss: 0.00002, value_loss: 0.01806 action_loss: 19.79173\n",
      "elasped time for update: 20.40s\n",
      "episode [  15/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.02312, kl_loss: 3.00122, obs_loss: 0.02188, reward_loss: 0.00002, value_loss: 0.01828 action_loss: 19.78501\n",
      "update_step:   2 model loss: 3.01525, kl_loss: 3.00016, obs_loss: 0.01507, reward_loss: 0.00002, value_loss: 0.01790 action_loss: 19.78608\n",
      "update_step:   3 model loss: 3.02054, kl_loss: 3.00049, obs_loss: 0.02003, reward_loss: 0.00002, value_loss: 0.01832 action_loss: 19.79327\n",
      "update_step:   4 model loss: 3.02765, kl_loss: 3.00080, obs_loss: 0.02684, reward_loss: 0.00002, value_loss: 0.01819 action_loss: 19.78634\n",
      "update_step:   5 model loss: 3.03313, kl_loss: 3.00064, obs_loss: 0.03248, reward_loss: 0.00002, value_loss: 0.01825 action_loss: 19.79471\n",
      "update_step:   6 model loss: 3.02886, kl_loss: 3.00051, obs_loss: 0.02833, reward_loss: 0.00002, value_loss: 0.01816 action_loss: 19.78804\n",
      "update_step:   7 model loss: 3.02789, kl_loss: 3.00249, obs_loss: 0.02539, reward_loss: 0.00002, value_loss: 0.01811 action_loss: 19.78797\n",
      "update_step:   8 model loss: 3.03084, kl_loss: 3.00141, obs_loss: 0.02941, reward_loss: 0.00002, value_loss: 0.01789 action_loss: 19.80397\n",
      "update_step:   9 model loss: 3.03560, kl_loss: 3.00320, obs_loss: 0.03238, reward_loss: 0.00002, value_loss: 0.01852 action_loss: 19.79959\n",
      "update_step:  10 model loss: 3.03173, kl_loss: 3.00032, obs_loss: 0.03139, reward_loss: 0.00002, value_loss: 0.01852 action_loss: 19.82078\n",
      "update_step:  11 model loss: 3.04250, kl_loss: 3.00277, obs_loss: 0.03971, reward_loss: 0.00002, value_loss: 0.01811 action_loss: 19.80404\n",
      "update_step:  12 model loss: 3.04279, kl_loss: 3.00151, obs_loss: 0.04127, reward_loss: 0.00002, value_loss: 0.01793 action_loss: 19.82959\n",
      "update_step:  13 model loss: 3.03511, kl_loss: 3.00076, obs_loss: 0.03433, reward_loss: 0.00002, value_loss: 0.01807 action_loss: 19.82922\n",
      "update_step:  14 model loss: 3.03678, kl_loss: 3.00191, obs_loss: 0.03485, reward_loss: 0.00002, value_loss: 0.01831 action_loss: 19.82158\n",
      "update_step:  15 model loss: 3.03513, kl_loss: 3.00187, obs_loss: 0.03325, reward_loss: 0.00002, value_loss: 0.01776 action_loss: 19.81302\n",
      "update_step:  16 model loss: 3.04288, kl_loss: 3.00216, obs_loss: 0.04070, reward_loss: 0.00002, value_loss: 0.01776 action_loss: 19.80071\n",
      "update_step:  17 model loss: 3.04038, kl_loss: 3.00162, obs_loss: 0.03874, reward_loss: 0.00002, value_loss: 0.01779 action_loss: 19.80203\n",
      "update_step:  18 model loss: 3.03280, kl_loss: 3.00023, obs_loss: 0.03256, reward_loss: 0.00002, value_loss: 0.01764 action_loss: 19.78671\n",
      "update_step:  19 model loss: 3.02920, kl_loss: 3.00123, obs_loss: 0.02796, reward_loss: 0.00002, value_loss: 0.01804 action_loss: 19.76665\n",
      "update_step:  20 model loss: 3.02369, kl_loss: 3.00093, obs_loss: 0.02274, reward_loss: 0.00002, value_loss: 0.01788 action_loss: 19.77567\n",
      "update_step:  21 model loss: 3.02371, kl_loss: 3.00060, obs_loss: 0.02310, reward_loss: 0.00002, value_loss: 0.01749 action_loss: 19.76779\n",
      "update_step:  22 model loss: 3.02516, kl_loss: 3.00178, obs_loss: 0.02337, reward_loss: 0.00002, value_loss: 0.01796 action_loss: 19.77774\n",
      "update_step:  23 model loss: 3.01784, kl_loss: 3.00091, obs_loss: 0.01692, reward_loss: 0.00002, value_loss: 0.01792 action_loss: 19.77346\n",
      "update_step:  24 model loss: 3.01700, kl_loss: 3.00062, obs_loss: 0.01637, reward_loss: 0.00002, value_loss: 0.01782 action_loss: 19.79217\n",
      "update_step:  25 model loss: 3.02128, kl_loss: 3.00115, obs_loss: 0.02012, reward_loss: 0.00002, value_loss: 0.01736 action_loss: 19.79393\n",
      "update_step:  26 model loss: 3.01744, kl_loss: 3.00124, obs_loss: 0.01618, reward_loss: 0.00001, value_loss: 0.01761 action_loss: 19.80407\n",
      "update_step:  27 model loss: 3.01679, kl_loss: 3.00195, obs_loss: 0.01483, reward_loss: 0.00002, value_loss: 0.01745 action_loss: 19.81228\n",
      "update_step:  28 model loss: 3.01743, kl_loss: 3.00145, obs_loss: 0.01597, reward_loss: 0.00002, value_loss: 0.01751 action_loss: 19.80695\n",
      "update_step:  29 model loss: 3.01758, kl_loss: 3.00113, obs_loss: 0.01643, reward_loss: 0.00002, value_loss: 0.01785 action_loss: 19.82118\n",
      "update_step:  30 model loss: 3.02200, kl_loss: 3.00134, obs_loss: 0.02064, reward_loss: 0.00002, value_loss: 0.01771 action_loss: 19.81124\n",
      "update_step:  31 model loss: 3.03039, kl_loss: 3.00264, obs_loss: 0.02773, reward_loss: 0.00002, value_loss: 0.01767 action_loss: 19.83686\n",
      "update_step:  32 model loss: 3.04030, kl_loss: 3.00156, obs_loss: 0.03872, reward_loss: 0.00002, value_loss: 0.01744 action_loss: 19.80653\n",
      "update_step:  33 model loss: 3.06019, kl_loss: 3.00035, obs_loss: 0.05982, reward_loss: 0.00002, value_loss: 0.01797 action_loss: 19.83389\n",
      "update_step:  34 model loss: 3.07709, kl_loss: 3.00016, obs_loss: 0.07691, reward_loss: 0.00002, value_loss: 0.01761 action_loss: 19.78439\n",
      "update_step:  35 model loss: 3.11185, kl_loss: 3.00103, obs_loss: 0.11079, reward_loss: 0.00002, value_loss: 0.01808 action_loss: 19.82331\n",
      "update_step:  36 model loss: 3.13339, kl_loss: 3.00062, obs_loss: 0.13275, reward_loss: 0.00002, value_loss: 0.01768 action_loss: 19.77012\n",
      "update_step:  37 model loss: 3.15827, kl_loss: 3.00019, obs_loss: 0.15807, reward_loss: 0.00002, value_loss: 0.01867 action_loss: 19.79197\n",
      "update_step:  38 model loss: 3.16449, kl_loss: 3.00066, obs_loss: 0.16381, reward_loss: 0.00002, value_loss: 0.01798 action_loss: 19.77202\n",
      "update_step:  39 model loss: 3.16276, kl_loss: 3.00178, obs_loss: 0.16096, reward_loss: 0.00002, value_loss: 0.01866 action_loss: 19.78609\n",
      "update_step:  40 model loss: 3.12578, kl_loss: 3.00079, obs_loss: 0.12498, reward_loss: 0.00002, value_loss: 0.01833 action_loss: 19.78790\n",
      "update_step:  41 model loss: 3.08162, kl_loss: 3.00083, obs_loss: 0.08078, reward_loss: 0.00002, value_loss: 0.01827 action_loss: 19.76817\n",
      "update_step:  42 model loss: 3.05075, kl_loss: 3.00064, obs_loss: 0.05009, reward_loss: 0.00002, value_loss: 0.01832 action_loss: 19.80309\n",
      "update_step:  43 model loss: 3.04044, kl_loss: 3.00034, obs_loss: 0.04008, reward_loss: 0.00002, value_loss: 0.01840 action_loss: 19.77336\n",
      "update_step:  44 model loss: 3.04703, kl_loss: 3.00120, obs_loss: 0.04582, reward_loss: 0.00002, value_loss: 0.01834 action_loss: 19.78649\n",
      "update_step:  45 model loss: 3.06170, kl_loss: 3.00219, obs_loss: 0.05950, reward_loss: 0.00002, value_loss: 0.01854 action_loss: 19.77729\n",
      "update_step:  46 model loss: 3.07300, kl_loss: 3.00168, obs_loss: 0.07131, reward_loss: 0.00002, value_loss: 0.01876 action_loss: 19.79578\n",
      "update_step:  47 model loss: 3.07072, kl_loss: 3.00178, obs_loss: 0.06893, reward_loss: 0.00002, value_loss: 0.01853 action_loss: 19.79348\n",
      "update_step:  48 model loss: 3.06541, kl_loss: 3.00212, obs_loss: 0.06327, reward_loss: 0.00002, value_loss: 0.01828 action_loss: 19.79538\n",
      "update_step:  49 model loss: 3.02871, kl_loss: 3.00089, obs_loss: 0.02781, reward_loss: 0.00002, value_loss: 0.01886 action_loss: 19.80997\n",
      "update_step:  50 model loss: 3.02983, kl_loss: 3.00360, obs_loss: 0.02622, reward_loss: 0.00002, value_loss: 0.01810 action_loss: 19.82077\n",
      "update_step:  51 model loss: 3.04064, kl_loss: 3.00207, obs_loss: 0.03855, reward_loss: 0.00002, value_loss: 0.01834 action_loss: 19.82063\n",
      "update_step:  52 model loss: 3.06294, kl_loss: 3.00029, obs_loss: 0.06264, reward_loss: 0.00002, value_loss: 0.01824 action_loss: 19.79716\n",
      "update_step:  53 model loss: 3.08134, kl_loss: 3.00211, obs_loss: 0.07921, reward_loss: 0.00002, value_loss: 0.01860 action_loss: 19.81432\n",
      "update_step:  54 model loss: 3.06028, kl_loss: 3.00070, obs_loss: 0.05957, reward_loss: 0.00002, value_loss: 0.01833 action_loss: 19.81381\n",
      "update_step:  55 model loss: 3.03137, kl_loss: 3.00063, obs_loss: 0.03072, reward_loss: 0.00002, value_loss: 0.01818 action_loss: 19.81049\n",
      "update_step:  56 model loss: 3.01635, kl_loss: 3.00055, obs_loss: 0.01578, reward_loss: 0.00002, value_loss: 0.01815 action_loss: 19.79348\n",
      "update_step:  57 model loss: 3.02568, kl_loss: 3.00054, obs_loss: 0.02513, reward_loss: 0.00002, value_loss: 0.01777 action_loss: 19.79451\n",
      "update_step:  58 model loss: 3.06707, kl_loss: 3.00312, obs_loss: 0.06394, reward_loss: 0.00002, value_loss: 0.01844 action_loss: 19.79804\n",
      "update_step:  59 model loss: 3.04540, kl_loss: 3.00227, obs_loss: 0.04311, reward_loss: 0.00002, value_loss: 0.01822 action_loss: 19.79106\n",
      "update_step:  60 model loss: 3.03216, kl_loss: 3.00126, obs_loss: 0.03089, reward_loss: 0.00001, value_loss: 0.01787 action_loss: 19.78629\n",
      "update_step:  61 model loss: 3.02822, kl_loss: 3.00396, obs_loss: 0.02424, reward_loss: 0.00002, value_loss: 0.01779 action_loss: 19.78584\n",
      "update_step:  62 model loss: 3.02004, kl_loss: 3.00103, obs_loss: 0.01899, reward_loss: 0.00002, value_loss: 0.01744 action_loss: 19.78458\n",
      "update_step:  63 model loss: 3.02648, kl_loss: 3.00125, obs_loss: 0.02521, reward_loss: 0.00002, value_loss: 0.01773 action_loss: 19.79734\n",
      "update_step:  64 model loss: 3.03616, kl_loss: 3.00140, obs_loss: 0.03475, reward_loss: 0.00002, value_loss: 0.01757 action_loss: 19.79429\n",
      "update_step:  65 model loss: 3.04089, kl_loss: 3.00131, obs_loss: 0.03956, reward_loss: 0.00002, value_loss: 0.01774 action_loss: 19.81351\n",
      "update_step:  66 model loss: 3.03081, kl_loss: 3.00129, obs_loss: 0.02950, reward_loss: 0.00002, value_loss: 0.01746 action_loss: 19.82391\n",
      "update_step:  67 model loss: 3.01848, kl_loss: 3.00112, obs_loss: 0.01734, reward_loss: 0.00002, value_loss: 0.01777 action_loss: 19.82041\n",
      "update_step:  68 model loss: 3.01950, kl_loss: 3.00162, obs_loss: 0.01787, reward_loss: 0.00002, value_loss: 0.01751 action_loss: 19.81944\n",
      "update_step:  69 model loss: 3.02045, kl_loss: 3.00096, obs_loss: 0.01948, reward_loss: 0.00002, value_loss: 0.01747 action_loss: 19.80906\n",
      "update_step:  70 model loss: 3.02697, kl_loss: 3.00081, obs_loss: 0.02615, reward_loss: 0.00002, value_loss: 0.01752 action_loss: 19.81475\n",
      "update_step:  71 model loss: 3.02628, kl_loss: 3.00038, obs_loss: 0.02588, reward_loss: 0.00002, value_loss: 0.01745 action_loss: 19.79273\n",
      "update_step:  72 model loss: 3.02421, kl_loss: 3.00097, obs_loss: 0.02322, reward_loss: 0.00001, value_loss: 0.01749 action_loss: 19.79025\n",
      "update_step:  73 model loss: 3.02044, kl_loss: 3.00175, obs_loss: 0.01868, reward_loss: 0.00001, value_loss: 0.01735 action_loss: 19.78153\n",
      "update_step:  74 model loss: 3.01788, kl_loss: 3.00134, obs_loss: 0.01653, reward_loss: 0.00002, value_loss: 0.01743 action_loss: 19.78193\n",
      "update_step:  75 model loss: 3.01494, kl_loss: 3.00129, obs_loss: 0.01363, reward_loss: 0.00001, value_loss: 0.01717 action_loss: 19.78377\n",
      "update_step:  76 model loss: 3.01595, kl_loss: 3.00068, obs_loss: 0.01526, reward_loss: 0.00002, value_loss: 0.01705 action_loss: 19.78349\n",
      "update_step:  77 model loss: 3.02830, kl_loss: 3.00213, obs_loss: 0.02615, reward_loss: 0.00001, value_loss: 0.01779 action_loss: 19.80223\n",
      "update_step:  78 model loss: 3.02285, kl_loss: 3.00065, obs_loss: 0.02218, reward_loss: 0.00002, value_loss: 0.01734 action_loss: 19.80130\n",
      "update_step:  79 model loss: 3.01773, kl_loss: 3.00136, obs_loss: 0.01636, reward_loss: 0.00002, value_loss: 0.01741 action_loss: 19.80390\n",
      "update_step:  80 model loss: 3.01829, kl_loss: 3.00233, obs_loss: 0.01595, reward_loss: 0.00002, value_loss: 0.01749 action_loss: 19.80170\n",
      "update_step:  81 model loss: 3.01220, kl_loss: 3.00071, obs_loss: 0.01147, reward_loss: 0.00001, value_loss: 0.01691 action_loss: 19.80574\n",
      "update_step:  82 model loss: 3.01690, kl_loss: 3.00107, obs_loss: 0.01582, reward_loss: 0.00002, value_loss: 0.01749 action_loss: 19.80081\n",
      "update_step:  83 model loss: 3.02188, kl_loss: 3.00244, obs_loss: 0.01943, reward_loss: 0.00001, value_loss: 0.01719 action_loss: 19.78388\n",
      "update_step:  84 model loss: 3.01595, kl_loss: 3.00070, obs_loss: 0.01524, reward_loss: 0.00002, value_loss: 0.01730 action_loss: 19.79779\n",
      "update_step:  85 model loss: 3.01726, kl_loss: 3.00211, obs_loss: 0.01514, reward_loss: 0.00002, value_loss: 0.01744 action_loss: 19.79197\n",
      "update_step:  86 model loss: 3.02666, kl_loss: 3.00275, obs_loss: 0.02390, reward_loss: 0.00002, value_loss: 0.01727 action_loss: 19.79080\n",
      "update_step:  87 model loss: 3.01309, kl_loss: 3.00179, obs_loss: 0.01128, reward_loss: 0.00001, value_loss: 0.01694 action_loss: 19.78403\n",
      "update_step:  88 model loss: 3.01309, kl_loss: 3.00233, obs_loss: 0.01075, reward_loss: 0.00002, value_loss: 0.01715 action_loss: 19.78620\n",
      "update_step:  89 model loss: 3.01362, kl_loss: 3.00015, obs_loss: 0.01346, reward_loss: 0.00001, value_loss: 0.01714 action_loss: 19.79526\n",
      "update_step:  90 model loss: 3.01595, kl_loss: 3.00110, obs_loss: 0.01484, reward_loss: 0.00002, value_loss: 0.01700 action_loss: 19.78311\n",
      "update_step:  91 model loss: 3.01964, kl_loss: 3.00048, obs_loss: 0.01915, reward_loss: 0.00002, value_loss: 0.01706 action_loss: 19.78921\n",
      "update_step:  92 model loss: 3.01549, kl_loss: 3.00089, obs_loss: 0.01458, reward_loss: 0.00001, value_loss: 0.01697 action_loss: 19.79598\n",
      "update_step:  93 model loss: 3.01888, kl_loss: 3.00138, obs_loss: 0.01749, reward_loss: 0.00002, value_loss: 0.01718 action_loss: 19.80829\n",
      "update_step:  94 model loss: 3.01326, kl_loss: 3.00134, obs_loss: 0.01190, reward_loss: 0.00001, value_loss: 0.01683 action_loss: 19.81423\n",
      "update_step:  95 model loss: 3.01349, kl_loss: 3.00079, obs_loss: 0.01269, reward_loss: 0.00002, value_loss: 0.01725 action_loss: 19.81957\n",
      "update_step:  96 model loss: 3.01496, kl_loss: 3.00158, obs_loss: 0.01336, reward_loss: 0.00001, value_loss: 0.01684 action_loss: 19.83101\n",
      "update_step:  97 model loss: 3.01023, kl_loss: 3.00031, obs_loss: 0.00991, reward_loss: 0.00001, value_loss: 0.01688 action_loss: 19.82969\n",
      "update_step:  98 model loss: 3.01090, kl_loss: 3.00072, obs_loss: 0.01016, reward_loss: 0.00001, value_loss: 0.01696 action_loss: 19.82802\n",
      "update_step:  99 model loss: 3.01331, kl_loss: 3.00177, obs_loss: 0.01152, reward_loss: 0.00001, value_loss: 0.01672 action_loss: 19.82460\n",
      "update_step: 100 model loss: 3.01374, kl_loss: 3.00125, obs_loss: 0.01247, reward_loss: 0.00002, value_loss: 0.01638 action_loss: 19.82326\n",
      "elasped time for update: 20.27s\n",
      "episode [  16/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.01271, kl_loss: 3.00141, obs_loss: 0.01128, reward_loss: 0.00001, value_loss: 0.01676 action_loss: 19.81649\n",
      "update_step:   2 model loss: 3.01188, kl_loss: 3.00039, obs_loss: 0.01148, reward_loss: 0.00001, value_loss: 0.01650 action_loss: 19.80718\n",
      "update_step:   3 model loss: 3.01383, kl_loss: 3.00090, obs_loss: 0.01292, reward_loss: 0.00002, value_loss: 0.01716 action_loss: 19.80280\n",
      "update_step:   4 model loss: 3.01483, kl_loss: 3.00062, obs_loss: 0.01420, reward_loss: 0.00001, value_loss: 0.01613 action_loss: 19.80739\n",
      "update_step:   5 model loss: 3.01415, kl_loss: 3.00273, obs_loss: 0.01140, reward_loss: 0.00001, value_loss: 0.01662 action_loss: 19.80837\n",
      "update_step:   6 model loss: 3.01172, kl_loss: 3.00074, obs_loss: 0.01096, reward_loss: 0.00001, value_loss: 0.01664 action_loss: 19.81078\n",
      "update_step:   7 model loss: 3.01013, kl_loss: 3.00029, obs_loss: 0.00982, reward_loss: 0.00001, value_loss: 0.01658 action_loss: 19.80922\n",
      "update_step:   8 model loss: 3.01660, kl_loss: 3.00134, obs_loss: 0.01525, reward_loss: 0.00001, value_loss: 0.01663 action_loss: 19.81309\n",
      "update_step:   9 model loss: 3.01173, kl_loss: 3.00059, obs_loss: 0.01113, reward_loss: 0.00001, value_loss: 0.01641 action_loss: 19.81013\n",
      "update_step:  10 model loss: 3.01459, kl_loss: 3.00201, obs_loss: 0.01257, reward_loss: 0.00002, value_loss: 0.01665 action_loss: 19.80623\n",
      "update_step:  11 model loss: 3.02019, kl_loss: 3.00242, obs_loss: 0.01776, reward_loss: 0.00001, value_loss: 0.01624 action_loss: 19.79446\n",
      "update_step:  12 model loss: 3.01394, kl_loss: 3.00105, obs_loss: 0.01288, reward_loss: 0.00001, value_loss: 0.01613 action_loss: 19.79055\n",
      "update_step:  13 model loss: 3.01193, kl_loss: 3.00124, obs_loss: 0.01067, reward_loss: 0.00001, value_loss: 0.01653 action_loss: 19.78507\n",
      "update_step:  14 model loss: 3.01234, kl_loss: 3.00132, obs_loss: 0.01101, reward_loss: 0.00001, value_loss: 0.01643 action_loss: 19.78802\n",
      "update_step:  15 model loss: 3.01531, kl_loss: 3.00284, obs_loss: 0.01245, reward_loss: 0.00001, value_loss: 0.01628 action_loss: 19.78801\n",
      "update_step:  16 model loss: 3.02209, kl_loss: 3.00192, obs_loss: 0.02016, reward_loss: 0.00001, value_loss: 0.01616 action_loss: 19.79609\n",
      "update_step:  17 model loss: 3.01710, kl_loss: 3.00112, obs_loss: 0.01597, reward_loss: 0.00001, value_loss: 0.01630 action_loss: 19.79930\n",
      "update_step:  18 model loss: 3.01169, kl_loss: 3.00105, obs_loss: 0.01062, reward_loss: 0.00001, value_loss: 0.01651 action_loss: 19.80554\n",
      "update_step:  19 model loss: 3.01738, kl_loss: 3.00196, obs_loss: 0.01540, reward_loss: 0.00001, value_loss: 0.01604 action_loss: 19.79885\n",
      "update_step:  20 model loss: 3.01562, kl_loss: 3.00074, obs_loss: 0.01487, reward_loss: 0.00001, value_loss: 0.01625 action_loss: 19.80590\n",
      "update_step:  21 model loss: 3.02060, kl_loss: 3.00397, obs_loss: 0.01662, reward_loss: 0.00001, value_loss: 0.01648 action_loss: 19.79950\n",
      "update_step:  22 model loss: 3.02034, kl_loss: 3.00203, obs_loss: 0.01830, reward_loss: 0.00001, value_loss: 0.01598 action_loss: 19.79436\n",
      "update_step:  23 model loss: 3.01661, kl_loss: 3.00196, obs_loss: 0.01464, reward_loss: 0.00001, value_loss: 0.01621 action_loss: 19.79042\n",
      "update_step:  24 model loss: 3.01594, kl_loss: 3.00146, obs_loss: 0.01446, reward_loss: 0.00001, value_loss: 0.01637 action_loss: 19.77694\n",
      "update_step:  25 model loss: 3.01328, kl_loss: 3.00193, obs_loss: 0.01134, reward_loss: 0.00001, value_loss: 0.01640 action_loss: 19.77692\n",
      "update_step:  26 model loss: 3.01479, kl_loss: 3.00144, obs_loss: 0.01333, reward_loss: 0.00001, value_loss: 0.01632 action_loss: 19.76317\n",
      "update_step:  27 model loss: 3.01528, kl_loss: 3.00130, obs_loss: 0.01397, reward_loss: 0.00001, value_loss: 0.01632 action_loss: 19.77766\n",
      "update_step:  28 model loss: 3.02185, kl_loss: 3.00178, obs_loss: 0.02005, reward_loss: 0.00001, value_loss: 0.01616 action_loss: 19.77030\n",
      "update_step:  29 model loss: 3.01333, kl_loss: 3.00035, obs_loss: 0.01296, reward_loss: 0.00001, value_loss: 0.01607 action_loss: 19.79670\n",
      "update_step:  30 model loss: 3.02488, kl_loss: 3.00179, obs_loss: 0.02307, reward_loss: 0.00001, value_loss: 0.01588 action_loss: 19.80306\n",
      "update_step:  31 model loss: 3.01872, kl_loss: 3.00252, obs_loss: 0.01619, reward_loss: 0.00001, value_loss: 0.01594 action_loss: 19.82746\n",
      "update_step:  32 model loss: 3.02165, kl_loss: 3.00156, obs_loss: 0.02008, reward_loss: 0.00001, value_loss: 0.01629 action_loss: 19.82966\n",
      "update_step:  33 model loss: 3.01937, kl_loss: 3.00086, obs_loss: 0.01850, reward_loss: 0.00001, value_loss: 0.01622 action_loss: 19.85211\n",
      "update_step:  34 model loss: 3.02057, kl_loss: 3.00150, obs_loss: 0.01905, reward_loss: 0.00001, value_loss: 0.01596 action_loss: 19.84155\n",
      "update_step:  35 model loss: 3.01595, kl_loss: 3.00185, obs_loss: 0.01409, reward_loss: 0.00001, value_loss: 0.01624 action_loss: 19.84356\n",
      "update_step:  36 model loss: 3.01456, kl_loss: 3.00082, obs_loss: 0.01372, reward_loss: 0.00001, value_loss: 0.01588 action_loss: 19.82153\n",
      "update_step:  37 model loss: 3.02505, kl_loss: 3.00248, obs_loss: 0.02256, reward_loss: 0.00001, value_loss: 0.01593 action_loss: 19.81574\n",
      "update_step:  38 model loss: 3.01294, kl_loss: 3.00042, obs_loss: 0.01251, reward_loss: 0.00001, value_loss: 0.01606 action_loss: 19.80714\n",
      "update_step:  39 model loss: 3.01429, kl_loss: 3.00145, obs_loss: 0.01283, reward_loss: 0.00001, value_loss: 0.01587 action_loss: 19.79304\n",
      "update_step:  40 model loss: 3.01973, kl_loss: 3.00098, obs_loss: 0.01874, reward_loss: 0.00001, value_loss: 0.01588 action_loss: 19.78917\n",
      "update_step:  41 model loss: 3.01588, kl_loss: 3.00153, obs_loss: 0.01434, reward_loss: 0.00001, value_loss: 0.01582 action_loss: 19.78650\n",
      "update_step:  42 model loss: 3.02230, kl_loss: 3.00230, obs_loss: 0.01999, reward_loss: 0.00001, value_loss: 0.01597 action_loss: 19.80404\n",
      "update_step:  43 model loss: 3.01715, kl_loss: 3.00119, obs_loss: 0.01594, reward_loss: 0.00001, value_loss: 0.01594 action_loss: 19.78723\n",
      "update_step:  44 model loss: 3.01652, kl_loss: 3.00036, obs_loss: 0.01614, reward_loss: 0.00002, value_loss: 0.01590 action_loss: 19.81186\n",
      "update_step:  45 model loss: 3.02003, kl_loss: 3.00079, obs_loss: 0.01922, reward_loss: 0.00001, value_loss: 0.01555 action_loss: 19.79939\n",
      "update_step:  46 model loss: 3.02013, kl_loss: 3.00141, obs_loss: 0.01871, reward_loss: 0.00001, value_loss: 0.01624 action_loss: 19.81467\n",
      "update_step:  47 model loss: 3.01985, kl_loss: 3.00078, obs_loss: 0.01905, reward_loss: 0.00002, value_loss: 0.01546 action_loss: 19.79968\n",
      "update_step:  48 model loss: 3.03166, kl_loss: 3.00213, obs_loss: 0.02952, reward_loss: 0.00002, value_loss: 0.01598 action_loss: 19.82111\n",
      "update_step:  49 model loss: 3.01891, kl_loss: 3.00054, obs_loss: 0.01835, reward_loss: 0.00001, value_loss: 0.01567 action_loss: 19.80773\n",
      "update_step:  50 model loss: 3.02075, kl_loss: 3.00063, obs_loss: 0.02011, reward_loss: 0.00001, value_loss: 0.01595 action_loss: 19.81688\n",
      "update_step:  51 model loss: 3.02585, kl_loss: 3.00183, obs_loss: 0.02400, reward_loss: 0.00001, value_loss: 0.01580 action_loss: 19.79697\n",
      "update_step:  52 model loss: 3.02026, kl_loss: 3.00178, obs_loss: 0.01846, reward_loss: 0.00002, value_loss: 0.01594 action_loss: 19.81277\n",
      "update_step:  53 model loss: 3.02169, kl_loss: 3.00176, obs_loss: 0.01992, reward_loss: 0.00002, value_loss: 0.01582 action_loss: 19.79531\n",
      "update_step:  54 model loss: 3.02022, kl_loss: 3.00107, obs_loss: 0.01914, reward_loss: 0.00001, value_loss: 0.01585 action_loss: 19.80009\n",
      "update_step:  55 model loss: 3.02207, kl_loss: 3.00134, obs_loss: 0.02071, reward_loss: 0.00001, value_loss: 0.01582 action_loss: 19.78548\n",
      "update_step:  56 model loss: 3.01805, kl_loss: 3.00291, obs_loss: 0.01513, reward_loss: 0.00001, value_loss: 0.01602 action_loss: 19.79280\n",
      "update_step:  57 model loss: 3.01204, kl_loss: 3.00051, obs_loss: 0.01152, reward_loss: 0.00001, value_loss: 0.01601 action_loss: 19.78152\n",
      "update_step:  58 model loss: 3.01557, kl_loss: 3.00155, obs_loss: 0.01401, reward_loss: 0.00001, value_loss: 0.01560 action_loss: 19.77893\n",
      "update_step:  59 model loss: 3.01107, kl_loss: 3.00055, obs_loss: 0.01051, reward_loss: 0.00001, value_loss: 0.01561 action_loss: 19.77793\n",
      "update_step:  60 model loss: 3.02061, kl_loss: 3.00277, obs_loss: 0.01783, reward_loss: 0.00001, value_loss: 0.01600 action_loss: 19.78756\n",
      "update_step:  61 model loss: 3.01067, kl_loss: 3.00008, obs_loss: 0.01057, reward_loss: 0.00001, value_loss: 0.01550 action_loss: 19.79212\n",
      "update_step:  62 model loss: 3.02262, kl_loss: 3.00310, obs_loss: 0.01951, reward_loss: 0.00001, value_loss: 0.01535 action_loss: 19.79758\n",
      "update_step:  63 model loss: 3.01300, kl_loss: 3.00237, obs_loss: 0.01061, reward_loss: 0.00001, value_loss: 0.01561 action_loss: 19.81172\n",
      "update_step:  64 model loss: 3.01971, kl_loss: 3.00181, obs_loss: 0.01788, reward_loss: 0.00001, value_loss: 0.01530 action_loss: 19.81662\n",
      "update_step:  65 model loss: 3.01656, kl_loss: 3.00164, obs_loss: 0.01490, reward_loss: 0.00001, value_loss: 0.01567 action_loss: 19.82561\n",
      "update_step:  66 model loss: 3.02227, kl_loss: 3.00173, obs_loss: 0.02052, reward_loss: 0.00001, value_loss: 0.01553 action_loss: 19.81633\n",
      "update_step:  67 model loss: 3.01898, kl_loss: 3.00168, obs_loss: 0.01728, reward_loss: 0.00001, value_loss: 0.01550 action_loss: 19.82706\n",
      "update_step:  68 model loss: 3.01580, kl_loss: 3.00028, obs_loss: 0.01551, reward_loss: 0.00001, value_loss: 0.01542 action_loss: 19.80651\n",
      "update_step:  69 model loss: 3.01815, kl_loss: 3.00064, obs_loss: 0.01750, reward_loss: 0.00001, value_loss: 0.01567 action_loss: 19.82031\n",
      "update_step:  70 model loss: 3.03020, kl_loss: 3.00239, obs_loss: 0.02779, reward_loss: 0.00002, value_loss: 0.01549 action_loss: 19.79151\n",
      "update_step:  71 model loss: 3.03420, kl_loss: 3.00063, obs_loss: 0.03355, reward_loss: 0.00002, value_loss: 0.01579 action_loss: 19.82859\n",
      "update_step:  72 model loss: 3.05127, kl_loss: 3.00138, obs_loss: 0.04987, reward_loss: 0.00002, value_loss: 0.01558 action_loss: 19.80144\n",
      "update_step:  73 model loss: 3.05488, kl_loss: 3.00127, obs_loss: 0.05359, reward_loss: 0.00002, value_loss: 0.01574 action_loss: 19.82667\n",
      "update_step:  74 model loss: 3.04132, kl_loss: 3.00077, obs_loss: 0.04054, reward_loss: 0.00001, value_loss: 0.01543 action_loss: 19.79233\n",
      "update_step:  75 model loss: 3.04094, kl_loss: 3.00212, obs_loss: 0.03880, reward_loss: 0.00002, value_loss: 0.01585 action_loss: 19.82153\n",
      "update_step:  76 model loss: 3.03066, kl_loss: 3.00061, obs_loss: 0.03004, reward_loss: 0.00002, value_loss: 0.01555 action_loss: 19.80036\n",
      "update_step:  77 model loss: 3.02984, kl_loss: 3.00030, obs_loss: 0.02953, reward_loss: 0.00001, value_loss: 0.01558 action_loss: 19.80484\n",
      "update_step:  78 model loss: 3.02287, kl_loss: 3.00048, obs_loss: 0.02238, reward_loss: 0.00001, value_loss: 0.01537 action_loss: 19.79818\n",
      "update_step:  79 model loss: 3.01987, kl_loss: 3.00026, obs_loss: 0.01959, reward_loss: 0.00001, value_loss: 0.01567 action_loss: 19.82137\n",
      "update_step:  80 model loss: 3.01575, kl_loss: 3.00074, obs_loss: 0.01500, reward_loss: 0.00002, value_loss: 0.01582 action_loss: 19.83331\n",
      "update_step:  81 model loss: 3.02203, kl_loss: 3.00308, obs_loss: 0.01893, reward_loss: 0.00001, value_loss: 0.01593 action_loss: 19.82373\n",
      "update_step:  82 model loss: 3.02245, kl_loss: 3.00299, obs_loss: 0.01944, reward_loss: 0.00002, value_loss: 0.01620 action_loss: 19.85162\n",
      "update_step:  83 model loss: 3.03378, kl_loss: 3.00260, obs_loss: 0.03117, reward_loss: 0.00001, value_loss: 0.01579 action_loss: 19.84760\n",
      "update_step:  84 model loss: 3.02481, kl_loss: 3.00096, obs_loss: 0.02384, reward_loss: 0.00001, value_loss: 0.01593 action_loss: 19.85744\n",
      "update_step:  85 model loss: 3.02044, kl_loss: 3.00049, obs_loss: 0.01994, reward_loss: 0.00002, value_loss: 0.01574 action_loss: 19.82359\n",
      "update_step:  86 model loss: 3.02990, kl_loss: 3.00135, obs_loss: 0.02853, reward_loss: 0.00002, value_loss: 0.01598 action_loss: 19.82676\n",
      "update_step:  87 model loss: 3.03074, kl_loss: 3.00211, obs_loss: 0.02862, reward_loss: 0.00001, value_loss: 0.01587 action_loss: 19.81684\n",
      "update_step:  88 model loss: 3.03117, kl_loss: 3.00369, obs_loss: 0.02746, reward_loss: 0.00001, value_loss: 0.01580 action_loss: 19.80898\n",
      "update_step:  89 model loss: 3.01887, kl_loss: 3.00131, obs_loss: 0.01755, reward_loss: 0.00001, value_loss: 0.01540 action_loss: 19.79845\n",
      "update_step:  90 model loss: 3.02404, kl_loss: 3.00181, obs_loss: 0.02222, reward_loss: 0.00002, value_loss: 0.01551 action_loss: 19.80428\n",
      "update_step:  91 model loss: 3.02102, kl_loss: 3.00092, obs_loss: 0.02009, reward_loss: 0.00001, value_loss: 0.01589 action_loss: 19.82152\n",
      "update_step:  92 model loss: 3.01725, kl_loss: 3.00070, obs_loss: 0.01653, reward_loss: 0.00002, value_loss: 0.01563 action_loss: 19.81184\n",
      "update_step:  93 model loss: 3.02336, kl_loss: 3.00134, obs_loss: 0.02201, reward_loss: 0.00001, value_loss: 0.01591 action_loss: 19.82720\n",
      "update_step:  94 model loss: 3.01081, kl_loss: 3.00043, obs_loss: 0.01036, reward_loss: 0.00001, value_loss: 0.01552 action_loss: 19.83602\n",
      "update_step:  95 model loss: 3.01180, kl_loss: 3.00089, obs_loss: 0.01090, reward_loss: 0.00001, value_loss: 0.01587 action_loss: 19.84168\n",
      "update_step:  96 model loss: 3.01452, kl_loss: 3.00102, obs_loss: 0.01348, reward_loss: 0.00001, value_loss: 0.01554 action_loss: 19.84057\n",
      "update_step:  97 model loss: 3.02491, kl_loss: 3.00231, obs_loss: 0.02258, reward_loss: 0.00001, value_loss: 0.01580 action_loss: 19.83567\n",
      "update_step:  98 model loss: 3.01632, kl_loss: 3.00153, obs_loss: 0.01477, reward_loss: 0.00001, value_loss: 0.01581 action_loss: 19.84148\n",
      "update_step:  99 model loss: 3.01839, kl_loss: 3.00170, obs_loss: 0.01668, reward_loss: 0.00001, value_loss: 0.01565 action_loss: 19.83459\n",
      "update_step: 100 model loss: 3.01847, kl_loss: 3.00123, obs_loss: 0.01722, reward_loss: 0.00001, value_loss: 0.01552 action_loss: 19.82188\n",
      "elasped time for update: 20.04s\n",
      "episode [  17/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.01859, kl_loss: 3.00030, obs_loss: 0.01827, reward_loss: 0.00001, value_loss: 0.01539 action_loss: 19.80976\n",
      "update_step:   2 model loss: 3.02075, kl_loss: 3.00127, obs_loss: 0.01947, reward_loss: 0.00002, value_loss: 0.01557 action_loss: 19.81245\n",
      "update_step:   3 model loss: 3.01471, kl_loss: 3.00033, obs_loss: 0.01437, reward_loss: 0.00001, value_loss: 0.01542 action_loss: 19.80509\n",
      "update_step:   4 model loss: 3.01477, kl_loss: 3.00039, obs_loss: 0.01437, reward_loss: 0.00001, value_loss: 0.01562 action_loss: 19.78869\n",
      "update_step:   5 model loss: 3.01283, kl_loss: 3.00035, obs_loss: 0.01246, reward_loss: 0.00002, value_loss: 0.01571 action_loss: 19.80537\n",
      "update_step:   6 model loss: 3.01300, kl_loss: 3.00032, obs_loss: 0.01267, reward_loss: 0.00001, value_loss: 0.01519 action_loss: 19.80260\n",
      "update_step:   7 model loss: 3.02201, kl_loss: 3.00052, obs_loss: 0.02148, reward_loss: 0.00001, value_loss: 0.01546 action_loss: 19.81759\n",
      "update_step:   8 model loss: 3.02025, kl_loss: 3.00061, obs_loss: 0.01962, reward_loss: 0.00001, value_loss: 0.01577 action_loss: 19.79979\n",
      "update_step:   9 model loss: 3.03259, kl_loss: 3.00368, obs_loss: 0.02890, reward_loss: 0.00001, value_loss: 0.01533 action_loss: 19.81946\n",
      "update_step:  10 model loss: 3.02184, kl_loss: 3.00022, obs_loss: 0.02160, reward_loss: 0.00001, value_loss: 0.01534 action_loss: 19.81535\n",
      "update_step:  11 model loss: 3.02488, kl_loss: 3.00130, obs_loss: 0.02357, reward_loss: 0.00001, value_loss: 0.01550 action_loss: 19.82066\n",
      "update_step:  12 model loss: 3.02295, kl_loss: 3.00049, obs_loss: 0.02245, reward_loss: 0.00001, value_loss: 0.01526 action_loss: 19.80655\n",
      "update_step:  13 model loss: 3.02464, kl_loss: 3.00111, obs_loss: 0.02352, reward_loss: 0.00001, value_loss: 0.01559 action_loss: 19.81764\n",
      "update_step:  14 model loss: 3.02267, kl_loss: 3.00104, obs_loss: 0.02161, reward_loss: 0.00001, value_loss: 0.01517 action_loss: 19.80267\n",
      "update_step:  15 model loss: 3.03015, kl_loss: 3.00287, obs_loss: 0.02727, reward_loss: 0.00001, value_loss: 0.01552 action_loss: 19.81350\n",
      "update_step:  16 model loss: 3.02381, kl_loss: 3.00066, obs_loss: 0.02313, reward_loss: 0.00001, value_loss: 0.01531 action_loss: 19.80067\n",
      "update_step:  17 model loss: 3.02884, kl_loss: 3.00126, obs_loss: 0.02757, reward_loss: 0.00001, value_loss: 0.01549 action_loss: 19.80657\n",
      "update_step:  18 model loss: 3.03851, kl_loss: 3.00319, obs_loss: 0.03530, reward_loss: 0.00001, value_loss: 0.01533 action_loss: 19.79438\n",
      "update_step:  19 model loss: 3.02673, kl_loss: 3.00180, obs_loss: 0.02492, reward_loss: 0.00001, value_loss: 0.01575 action_loss: 19.80518\n",
      "update_step:  20 model loss: 3.02655, kl_loss: 3.00128, obs_loss: 0.02526, reward_loss: 0.00001, value_loss: 0.01525 action_loss: 19.78893\n",
      "update_step:  21 model loss: 3.02371, kl_loss: 3.00094, obs_loss: 0.02275, reward_loss: 0.00001, value_loss: 0.01580 action_loss: 19.80204\n",
      "update_step:  22 model loss: 3.02981, kl_loss: 3.00250, obs_loss: 0.02729, reward_loss: 0.00001, value_loss: 0.01557 action_loss: 19.80916\n",
      "update_step:  23 model loss: 3.02559, kl_loss: 3.00044, obs_loss: 0.02514, reward_loss: 0.00001, value_loss: 0.01506 action_loss: 19.82463\n",
      "update_step:  24 model loss: 3.02953, kl_loss: 3.00082, obs_loss: 0.02869, reward_loss: 0.00001, value_loss: 0.01547 action_loss: 19.82961\n",
      "update_step:  25 model loss: 3.02998, kl_loss: 3.00036, obs_loss: 0.02961, reward_loss: 0.00001, value_loss: 0.01523 action_loss: 19.84416\n",
      "update_step:  26 model loss: 3.03019, kl_loss: 3.00038, obs_loss: 0.02979, reward_loss: 0.00001, value_loss: 0.01522 action_loss: 19.85363\n",
      "update_step:  27 model loss: 3.03993, kl_loss: 3.00100, obs_loss: 0.03891, reward_loss: 0.00001, value_loss: 0.01539 action_loss: 19.84818\n",
      "update_step:  28 model loss: 3.03706, kl_loss: 3.00126, obs_loss: 0.03579, reward_loss: 0.00001, value_loss: 0.01545 action_loss: 19.84358\n",
      "update_step:  29 model loss: 3.03097, kl_loss: 3.00122, obs_loss: 0.02973, reward_loss: 0.00001, value_loss: 0.01544 action_loss: 19.84504\n",
      "update_step:  30 model loss: 3.02674, kl_loss: 3.00010, obs_loss: 0.02662, reward_loss: 0.00001, value_loss: 0.01523 action_loss: 19.83589\n",
      "update_step:  31 model loss: 3.02045, kl_loss: 3.00018, obs_loss: 0.02025, reward_loss: 0.00001, value_loss: 0.01512 action_loss: 19.83437\n",
      "update_step:  32 model loss: 3.01923, kl_loss: 3.00084, obs_loss: 0.01838, reward_loss: 0.00001, value_loss: 0.01507 action_loss: 19.81841\n",
      "update_step:  33 model loss: 3.01693, kl_loss: 3.00059, obs_loss: 0.01633, reward_loss: 0.00001, value_loss: 0.01521 action_loss: 19.82262\n",
      "update_step:  34 model loss: 3.01757, kl_loss: 3.00114, obs_loss: 0.01642, reward_loss: 0.00001, value_loss: 0.01498 action_loss: 19.80477\n",
      "update_step:  35 model loss: 3.01880, kl_loss: 3.00207, obs_loss: 0.01672, reward_loss: 0.00001, value_loss: 0.01491 action_loss: 19.80781\n",
      "update_step:  36 model loss: 3.01795, kl_loss: 3.00213, obs_loss: 0.01581, reward_loss: 0.00001, value_loss: 0.01507 action_loss: 19.79865\n",
      "update_step:  37 model loss: 3.01507, kl_loss: 3.00143, obs_loss: 0.01362, reward_loss: 0.00001, value_loss: 0.01538 action_loss: 19.80632\n",
      "update_step:  38 model loss: 3.01839, kl_loss: 3.00182, obs_loss: 0.01656, reward_loss: 0.00001, value_loss: 0.01487 action_loss: 19.80036\n",
      "update_step:  39 model loss: 3.02319, kl_loss: 3.00174, obs_loss: 0.02144, reward_loss: 0.00001, value_loss: 0.01495 action_loss: 19.80057\n",
      "update_step:  40 model loss: 3.02405, kl_loss: 3.00125, obs_loss: 0.02279, reward_loss: 0.00001, value_loss: 0.01548 action_loss: 19.81719\n",
      "update_step:  41 model loss: 3.02113, kl_loss: 3.00082, obs_loss: 0.02030, reward_loss: 0.00001, value_loss: 0.01520 action_loss: 19.81551\n",
      "update_step:  42 model loss: 3.02547, kl_loss: 3.00149, obs_loss: 0.02396, reward_loss: 0.00001, value_loss: 0.01525 action_loss: 19.82857\n",
      "update_step:  43 model loss: 3.02253, kl_loss: 3.00077, obs_loss: 0.02174, reward_loss: 0.00001, value_loss: 0.01497 action_loss: 19.81652\n",
      "update_step:  44 model loss: 3.02377, kl_loss: 3.00134, obs_loss: 0.02242, reward_loss: 0.00001, value_loss: 0.01519 action_loss: 19.83492\n",
      "update_step:  45 model loss: 3.02878, kl_loss: 3.00120, obs_loss: 0.02756, reward_loss: 0.00001, value_loss: 0.01525 action_loss: 19.81927\n",
      "update_step:  46 model loss: 3.02512, kl_loss: 3.00089, obs_loss: 0.02422, reward_loss: 0.00001, value_loss: 0.01512 action_loss: 19.82226\n",
      "update_step:  47 model loss: 3.02115, kl_loss: 3.00049, obs_loss: 0.02064, reward_loss: 0.00001, value_loss: 0.01492 action_loss: 19.80689\n",
      "update_step:  48 model loss: 3.02235, kl_loss: 3.00062, obs_loss: 0.02172, reward_loss: 0.00001, value_loss: 0.01499 action_loss: 19.82120\n",
      "update_step:  49 model loss: 3.02793, kl_loss: 3.00118, obs_loss: 0.02674, reward_loss: 0.00002, value_loss: 0.01517 action_loss: 19.80033\n",
      "update_step:  50 model loss: 3.02048, kl_loss: 3.00094, obs_loss: 0.01953, reward_loss: 0.00001, value_loss: 0.01497 action_loss: 19.82061\n",
      "update_step:  51 model loss: 3.02194, kl_loss: 3.00134, obs_loss: 0.02058, reward_loss: 0.00001, value_loss: 0.01507 action_loss: 19.81618\n",
      "update_step:  52 model loss: 3.02891, kl_loss: 3.00153, obs_loss: 0.02737, reward_loss: 0.00001, value_loss: 0.01540 action_loss: 19.84054\n",
      "update_step:  53 model loss: 3.01938, kl_loss: 3.00132, obs_loss: 0.01804, reward_loss: 0.00002, value_loss: 0.01496 action_loss: 19.82080\n",
      "update_step:  54 model loss: 3.02446, kl_loss: 3.00110, obs_loss: 0.02335, reward_loss: 0.00001, value_loss: 0.01497 action_loss: 19.83246\n",
      "update_step:  55 model loss: 3.02161, kl_loss: 3.00144, obs_loss: 0.02016, reward_loss: 0.00001, value_loss: 0.01528 action_loss: 19.81859\n",
      "update_step:  56 model loss: 3.01957, kl_loss: 3.00030, obs_loss: 0.01926, reward_loss: 0.00001, value_loss: 0.01496 action_loss: 19.82379\n",
      "update_step:  57 model loss: 3.02305, kl_loss: 3.00070, obs_loss: 0.02234, reward_loss: 0.00001, value_loss: 0.01503 action_loss: 19.79358\n",
      "update_step:  58 model loss: 3.01743, kl_loss: 3.00117, obs_loss: 0.01624, reward_loss: 0.00001, value_loss: 0.01535 action_loss: 19.79146\n",
      "update_step:  59 model loss: 3.02072, kl_loss: 3.00130, obs_loss: 0.01940, reward_loss: 0.00001, value_loss: 0.01512 action_loss: 19.79331\n",
      "update_step:  60 model loss: 3.01565, kl_loss: 3.00121, obs_loss: 0.01442, reward_loss: 0.00002, value_loss: 0.01529 action_loss: 19.78125\n",
      "update_step:  61 model loss: 3.01803, kl_loss: 3.00048, obs_loss: 0.01754, reward_loss: 0.00001, value_loss: 0.01522 action_loss: 19.78306\n",
      "update_step:  62 model loss: 3.02003, kl_loss: 3.00086, obs_loss: 0.01915, reward_loss: 0.00001, value_loss: 0.01476 action_loss: 19.77363\n",
      "update_step:  63 model loss: 3.02320, kl_loss: 3.00082, obs_loss: 0.02236, reward_loss: 0.00002, value_loss: 0.01556 action_loss: 19.81014\n",
      "update_step:  64 model loss: 3.02768, kl_loss: 3.00117, obs_loss: 0.02649, reward_loss: 0.00002, value_loss: 0.01501 action_loss: 19.79175\n",
      "update_step:  65 model loss: 3.02446, kl_loss: 3.00032, obs_loss: 0.02413, reward_loss: 0.00001, value_loss: 0.01508 action_loss: 19.81390\n",
      "update_step:  66 model loss: 3.02836, kl_loss: 3.00066, obs_loss: 0.02768, reward_loss: 0.00001, value_loss: 0.01500 action_loss: 19.81036\n",
      "update_step:  67 model loss: 3.01848, kl_loss: 3.00048, obs_loss: 0.01799, reward_loss: 0.00001, value_loss: 0.01521 action_loss: 19.84769\n",
      "update_step:  68 model loss: 3.01933, kl_loss: 3.00081, obs_loss: 0.01850, reward_loss: 0.00002, value_loss: 0.01481 action_loss: 19.83177\n",
      "update_step:  69 model loss: 3.01612, kl_loss: 3.00088, obs_loss: 0.01523, reward_loss: 0.00001, value_loss: 0.01490 action_loss: 19.84707\n",
      "update_step:  70 model loss: 3.02476, kl_loss: 3.00160, obs_loss: 0.02315, reward_loss: 0.00001, value_loss: 0.01510 action_loss: 19.84978\n",
      "update_step:  71 model loss: 3.01612, kl_loss: 3.00111, obs_loss: 0.01499, reward_loss: 0.00001, value_loss: 0.01518 action_loss: 19.86024\n",
      "update_step:  72 model loss: 3.01653, kl_loss: 3.00053, obs_loss: 0.01599, reward_loss: 0.00002, value_loss: 0.01487 action_loss: 19.85099\n",
      "update_step:  73 model loss: 3.02141, kl_loss: 3.00188, obs_loss: 0.01953, reward_loss: 0.00001, value_loss: 0.01495 action_loss: 19.83475\n",
      "update_step:  74 model loss: 3.01979, kl_loss: 3.00065, obs_loss: 0.01913, reward_loss: 0.00001, value_loss: 0.01540 action_loss: 19.83716\n",
      "update_step:  75 model loss: 3.02837, kl_loss: 3.00132, obs_loss: 0.02703, reward_loss: 0.00001, value_loss: 0.01493 action_loss: 19.82658\n",
      "update_step:  76 model loss: 3.02729, kl_loss: 3.00039, obs_loss: 0.02688, reward_loss: 0.00001, value_loss: 0.01500 action_loss: 19.81106\n",
      "update_step:  77 model loss: 3.03570, kl_loss: 3.00276, obs_loss: 0.03292, reward_loss: 0.00001, value_loss: 0.01514 action_loss: 19.81415\n",
      "update_step:  78 model loss: 3.03297, kl_loss: 3.00086, obs_loss: 0.03210, reward_loss: 0.00001, value_loss: 0.01511 action_loss: 19.81091\n",
      "update_step:  79 model loss: 3.04199, kl_loss: 3.00200, obs_loss: 0.03998, reward_loss: 0.00001, value_loss: 0.01490 action_loss: 19.84560\n",
      "update_step:  80 model loss: 3.04179, kl_loss: 3.00293, obs_loss: 0.03885, reward_loss: 0.00001, value_loss: 0.01502 action_loss: 19.83439\n",
      "update_step:  81 model loss: 3.04271, kl_loss: 3.00107, obs_loss: 0.04163, reward_loss: 0.00001, value_loss: 0.01501 action_loss: 19.86275\n",
      "update_step:  82 model loss: 3.04632, kl_loss: 3.00081, obs_loss: 0.04549, reward_loss: 0.00001, value_loss: 0.01510 action_loss: 19.84257\n",
      "update_step:  83 model loss: 3.05394, kl_loss: 3.00141, obs_loss: 0.05252, reward_loss: 0.00001, value_loss: 0.01519 action_loss: 19.86294\n",
      "update_step:  84 model loss: 3.04758, kl_loss: 3.00036, obs_loss: 0.04721, reward_loss: 0.00001, value_loss: 0.01490 action_loss: 19.83949\n",
      "update_step:  85 model loss: 3.05004, kl_loss: 3.00140, obs_loss: 0.04863, reward_loss: 0.00001, value_loss: 0.01532 action_loss: 19.84765\n",
      "update_step:  86 model loss: 3.04393, kl_loss: 3.00074, obs_loss: 0.04318, reward_loss: 0.00001, value_loss: 0.01490 action_loss: 19.80679\n",
      "update_step:  87 model loss: 3.04095, kl_loss: 3.00059, obs_loss: 0.04034, reward_loss: 0.00001, value_loss: 0.01474 action_loss: 19.82153\n",
      "update_step:  88 model loss: 3.04568, kl_loss: 3.00256, obs_loss: 0.04310, reward_loss: 0.00001, value_loss: 0.01482 action_loss: 19.80695\n",
      "update_step:  89 model loss: 3.02691, kl_loss: 3.00057, obs_loss: 0.02633, reward_loss: 0.00001, value_loss: 0.01504 action_loss: 19.82043\n",
      "update_step:  90 model loss: 3.02811, kl_loss: 3.00019, obs_loss: 0.02791, reward_loss: 0.00001, value_loss: 0.01491 action_loss: 19.80560\n",
      "update_step:  91 model loss: 3.03061, kl_loss: 3.00089, obs_loss: 0.02970, reward_loss: 0.00002, value_loss: 0.01508 action_loss: 19.82019\n",
      "update_step:  92 model loss: 3.02450, kl_loss: 3.00008, obs_loss: 0.02441, reward_loss: 0.00001, value_loss: 0.01492 action_loss: 19.81142\n",
      "update_step:  93 model loss: 3.03016, kl_loss: 3.00052, obs_loss: 0.02963, reward_loss: 0.00001, value_loss: 0.01475 action_loss: 19.82222\n",
      "update_step:  94 model loss: 3.03180, kl_loss: 3.00094, obs_loss: 0.03084, reward_loss: 0.00001, value_loss: 0.01481 action_loss: 19.79145\n",
      "update_step:  95 model loss: 3.03093, kl_loss: 3.00074, obs_loss: 0.03017, reward_loss: 0.00002, value_loss: 0.01493 action_loss: 19.80291\n",
      "update_step:  96 model loss: 3.02315, kl_loss: 3.00016, obs_loss: 0.02298, reward_loss: 0.00001, value_loss: 0.01467 action_loss: 19.78889\n",
      "update_step:  97 model loss: 3.02206, kl_loss: 3.00245, obs_loss: 0.01960, reward_loss: 0.00001, value_loss: 0.01506 action_loss: 19.78269\n",
      "update_step:  98 model loss: 3.02508, kl_loss: 3.00382, obs_loss: 0.02124, reward_loss: 0.00001, value_loss: 0.01524 action_loss: 19.77801\n",
      "update_step:  99 model loss: 3.01685, kl_loss: 3.00235, obs_loss: 0.01448, reward_loss: 0.00001, value_loss: 0.01507 action_loss: 19.78810\n",
      "update_step: 100 model loss: 3.02017, kl_loss: 3.00191, obs_loss: 0.01825, reward_loss: 0.00001, value_loss: 0.01531 action_loss: 19.82714\n",
      "elasped time for update: 19.99s\n",
      "episode [  18/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.02293, kl_loss: 3.00092, obs_loss: 0.02199, reward_loss: 0.00002, value_loss: 0.01464 action_loss: 19.80736\n",
      "update_step:   2 model loss: 3.02952, kl_loss: 3.00194, obs_loss: 0.02757, reward_loss: 0.00001, value_loss: 0.01482 action_loss: 19.83971\n",
      "update_step:   3 model loss: 3.02772, kl_loss: 3.00086, obs_loss: 0.02686, reward_loss: 0.00001, value_loss: 0.01468 action_loss: 19.83988\n",
      "update_step:   4 model loss: 3.03024, kl_loss: 3.00169, obs_loss: 0.02854, reward_loss: 0.00001, value_loss: 0.01494 action_loss: 19.87552\n",
      "update_step:   5 model loss: 3.02364, kl_loss: 3.00189, obs_loss: 0.02173, reward_loss: 0.00001, value_loss: 0.01479 action_loss: 19.85483\n",
      "update_step:   6 model loss: 3.02204, kl_loss: 3.00200, obs_loss: 0.02002, reward_loss: 0.00001, value_loss: 0.01506 action_loss: 19.86536\n",
      "update_step:   7 model loss: 3.01356, kl_loss: 3.00014, obs_loss: 0.01340, reward_loss: 0.00001, value_loss: 0.01475 action_loss: 19.86704\n",
      "update_step:   8 model loss: 3.01927, kl_loss: 3.00128, obs_loss: 0.01798, reward_loss: 0.00001, value_loss: 0.01431 action_loss: 19.85172\n",
      "update_step:   9 model loss: 3.01135, kl_loss: 3.00007, obs_loss: 0.01127, reward_loss: 0.00001, value_loss: 0.01489 action_loss: 19.84850\n",
      "update_step:  10 model loss: 3.01871, kl_loss: 3.00050, obs_loss: 0.01819, reward_loss: 0.00001, value_loss: 0.01479 action_loss: 19.82938\n",
      "update_step:  11 model loss: 3.02494, kl_loss: 3.00076, obs_loss: 0.02416, reward_loss: 0.00001, value_loss: 0.01504 action_loss: 19.85654\n",
      "update_step:  12 model loss: 3.02582, kl_loss: 3.00136, obs_loss: 0.02445, reward_loss: 0.00002, value_loss: 0.01469 action_loss: 19.82720\n",
      "update_step:  13 model loss: 3.02913, kl_loss: 3.00099, obs_loss: 0.02813, reward_loss: 0.00001, value_loss: 0.01456 action_loss: 19.84146\n",
      "update_step:  14 model loss: 3.02865, kl_loss: 3.00125, obs_loss: 0.02739, reward_loss: 0.00001, value_loss: 0.01468 action_loss: 19.83654\n",
      "update_step:  15 model loss: 3.02838, kl_loss: 3.00160, obs_loss: 0.02676, reward_loss: 0.00001, value_loss: 0.01511 action_loss: 19.85667\n",
      "update_step:  16 model loss: 3.02814, kl_loss: 3.00205, obs_loss: 0.02607, reward_loss: 0.00002, value_loss: 0.01472 action_loss: 19.82851\n",
      "update_step:  17 model loss: 3.01957, kl_loss: 3.00052, obs_loss: 0.01904, reward_loss: 0.00002, value_loss: 0.01477 action_loss: 19.84090\n",
      "update_step:  18 model loss: 3.01574, kl_loss: 3.00093, obs_loss: 0.01480, reward_loss: 0.00001, value_loss: 0.01486 action_loss: 19.83024\n",
      "update_step:  19 model loss: 3.01874, kl_loss: 3.00123, obs_loss: 0.01750, reward_loss: 0.00001, value_loss: 0.01479 action_loss: 19.83695\n",
      "update_step:  20 model loss: 3.01858, kl_loss: 3.00198, obs_loss: 0.01658, reward_loss: 0.00001, value_loss: 0.01482 action_loss: 19.81760\n",
      "update_step:  21 model loss: 3.01795, kl_loss: 3.00119, obs_loss: 0.01674, reward_loss: 0.00001, value_loss: 0.01523 action_loss: 19.81836\n",
      "update_step:  22 model loss: 3.02053, kl_loss: 3.00193, obs_loss: 0.01859, reward_loss: 0.00001, value_loss: 0.01460 action_loss: 19.82951\n",
      "update_step:  23 model loss: 3.01559, kl_loss: 3.00110, obs_loss: 0.01448, reward_loss: 0.00001, value_loss: 0.01505 action_loss: 19.81239\n",
      "update_step:  24 model loss: 3.02835, kl_loss: 3.00117, obs_loss: 0.02716, reward_loss: 0.00001, value_loss: 0.01503 action_loss: 19.80999\n",
      "update_step:  25 model loss: 3.03163, kl_loss: 3.00172, obs_loss: 0.02989, reward_loss: 0.00001, value_loss: 0.01494 action_loss: 19.79592\n",
      "update_step:  26 model loss: 3.02947, kl_loss: 3.00050, obs_loss: 0.02896, reward_loss: 0.00002, value_loss: 0.01517 action_loss: 19.83300\n",
      "update_step:  27 model loss: 3.03459, kl_loss: 3.00101, obs_loss: 0.03355, reward_loss: 0.00002, value_loss: 0.01466 action_loss: 19.79611\n",
      "update_step:  28 model loss: 3.04015, kl_loss: 3.00086, obs_loss: 0.03928, reward_loss: 0.00001, value_loss: 0.01493 action_loss: 19.81607\n",
      "update_step:  29 model loss: 3.03062, kl_loss: 3.00005, obs_loss: 0.03055, reward_loss: 0.00001, value_loss: 0.01463 action_loss: 19.81326\n",
      "update_step:  30 model loss: 3.01848, kl_loss: 3.00028, obs_loss: 0.01819, reward_loss: 0.00001, value_loss: 0.01513 action_loss: 19.83352\n",
      "update_step:  31 model loss: 3.02331, kl_loss: 3.00091, obs_loss: 0.02239, reward_loss: 0.00002, value_loss: 0.01465 action_loss: 19.80529\n",
      "update_step:  32 model loss: 3.01351, kl_loss: 3.00033, obs_loss: 0.01316, reward_loss: 0.00001, value_loss: 0.01514 action_loss: 19.80360\n",
      "update_step:  33 model loss: 3.01315, kl_loss: 3.00142, obs_loss: 0.01171, reward_loss: 0.00001, value_loss: 0.01484 action_loss: 19.82161\n",
      "update_step:  34 model loss: 3.01044, kl_loss: 3.00012, obs_loss: 0.01031, reward_loss: 0.00002, value_loss: 0.01504 action_loss: 19.81050\n",
      "update_step:  35 model loss: 3.01870, kl_loss: 3.00153, obs_loss: 0.01716, reward_loss: 0.00001, value_loss: 0.01522 action_loss: 19.80249\n",
      "update_step:  36 model loss: 3.02188, kl_loss: 3.00118, obs_loss: 0.02069, reward_loss: 0.00001, value_loss: 0.01470 action_loss: 19.79787\n",
      "update_step:  37 model loss: 3.01438, kl_loss: 3.00048, obs_loss: 0.01389, reward_loss: 0.00001, value_loss: 0.01464 action_loss: 19.80817\n",
      "update_step:  38 model loss: 3.02258, kl_loss: 3.00248, obs_loss: 0.02008, reward_loss: 0.00001, value_loss: 0.01427 action_loss: 19.78967\n",
      "update_step:  39 model loss: 3.01174, kl_loss: 3.00082, obs_loss: 0.01091, reward_loss: 0.00001, value_loss: 0.01439 action_loss: 19.77940\n",
      "update_step:  40 model loss: 3.01703, kl_loss: 3.00138, obs_loss: 0.01564, reward_loss: 0.00001, value_loss: 0.01400 action_loss: 19.77795\n",
      "update_step:  41 model loss: 3.01317, kl_loss: 3.00044, obs_loss: 0.01271, reward_loss: 0.00001, value_loss: 0.01415 action_loss: 19.76919\n",
      "update_step:  42 model loss: 3.01415, kl_loss: 3.00083, obs_loss: 0.01331, reward_loss: 0.00001, value_loss: 0.01386 action_loss: 19.76282\n",
      "update_step:  43 model loss: 3.01969, kl_loss: 3.00097, obs_loss: 0.01871, reward_loss: 0.00001, value_loss: 0.01362 action_loss: 19.74658\n",
      "update_step:  44 model loss: 3.02076, kl_loss: 3.00069, obs_loss: 0.02006, reward_loss: 0.00001, value_loss: 0.01378 action_loss: 19.76121\n",
      "update_step:  45 model loss: 3.01994, kl_loss: 3.00039, obs_loss: 0.01954, reward_loss: 0.00001, value_loss: 0.01371 action_loss: 19.75993\n",
      "update_step:  46 model loss: 3.02385, kl_loss: 3.00163, obs_loss: 0.02220, reward_loss: 0.00001, value_loss: 0.01350 action_loss: 19.76474\n",
      "update_step:  47 model loss: 3.03049, kl_loss: 3.00127, obs_loss: 0.02921, reward_loss: 0.00001, value_loss: 0.01357 action_loss: 19.77063\n",
      "update_step:  48 model loss: 3.03691, kl_loss: 3.00098, obs_loss: 0.03592, reward_loss: 0.00001, value_loss: 0.01365 action_loss: 19.79303\n",
      "update_step:  49 model loss: 3.04419, kl_loss: 3.00233, obs_loss: 0.04185, reward_loss: 0.00001, value_loss: 0.01335 action_loss: 19.80064\n",
      "update_step:  50 model loss: 3.05636, kl_loss: 3.00076, obs_loss: 0.05560, reward_loss: 0.00001, value_loss: 0.01388 action_loss: 19.80910\n",
      "update_step:  51 model loss: 3.06983, kl_loss: 3.00057, obs_loss: 0.06925, reward_loss: 0.00001, value_loss: 0.01401 action_loss: 19.81758\n",
      "update_step:  52 model loss: 3.08011, kl_loss: 3.00077, obs_loss: 0.07932, reward_loss: 0.00001, value_loss: 0.01369 action_loss: 19.81854\n",
      "update_step:  53 model loss: 3.08798, kl_loss: 3.00095, obs_loss: 0.08702, reward_loss: 0.00001, value_loss: 0.01383 action_loss: 19.81193\n",
      "update_step:  54 model loss: 3.08947, kl_loss: 3.00116, obs_loss: 0.08830, reward_loss: 0.00001, value_loss: 0.01327 action_loss: 19.78594\n",
      "update_step:  55 model loss: 3.08721, kl_loss: 3.00029, obs_loss: 0.08691, reward_loss: 0.00001, value_loss: 0.01343 action_loss: 19.79207\n",
      "update_step:  56 model loss: 3.09016, kl_loss: 3.00133, obs_loss: 0.08882, reward_loss: 0.00001, value_loss: 0.01331 action_loss: 19.76291\n",
      "update_step:  57 model loss: 3.07142, kl_loss: 3.00029, obs_loss: 0.07111, reward_loss: 0.00001, value_loss: 0.01316 action_loss: 19.76772\n",
      "update_step:  58 model loss: 3.05705, kl_loss: 3.00127, obs_loss: 0.05576, reward_loss: 0.00001, value_loss: 0.01378 action_loss: 19.74847\n",
      "update_step:  59 model loss: 3.03912, kl_loss: 3.00077, obs_loss: 0.03834, reward_loss: 0.00001, value_loss: 0.01332 action_loss: 19.77336\n",
      "update_step:  60 model loss: 3.02096, kl_loss: 3.00002, obs_loss: 0.02092, reward_loss: 0.00001, value_loss: 0.01334 action_loss: 19.76432\n",
      "update_step:  61 model loss: 3.01752, kl_loss: 3.00040, obs_loss: 0.01710, reward_loss: 0.00001, value_loss: 0.01354 action_loss: 19.77981\n",
      "update_step:  62 model loss: 3.01850, kl_loss: 3.00038, obs_loss: 0.01811, reward_loss: 0.00001, value_loss: 0.01299 action_loss: 19.77904\n",
      "update_step:  63 model loss: 3.02747, kl_loss: 3.00007, obs_loss: 0.02739, reward_loss: 0.00001, value_loss: 0.01339 action_loss: 19.79558\n",
      "update_step:  64 model loss: 3.03817, kl_loss: 3.00113, obs_loss: 0.03702, reward_loss: 0.00001, value_loss: 0.01345 action_loss: 19.79581\n",
      "update_step:  65 model loss: 3.03972, kl_loss: 3.00099, obs_loss: 0.03872, reward_loss: 0.00001, value_loss: 0.01370 action_loss: 19.79710\n",
      "update_step:  66 model loss: 3.03944, kl_loss: 3.00045, obs_loss: 0.03898, reward_loss: 0.00001, value_loss: 0.01334 action_loss: 19.79053\n",
      "update_step:  67 model loss: 3.03533, kl_loss: 3.00150, obs_loss: 0.03381, reward_loss: 0.00001, value_loss: 0.01326 action_loss: 19.78766\n",
      "update_step:  68 model loss: 3.02681, kl_loss: 3.00022, obs_loss: 0.02658, reward_loss: 0.00001, value_loss: 0.01292 action_loss: 19.77477\n",
      "update_step:  69 model loss: 3.01523, kl_loss: 3.00063, obs_loss: 0.01459, reward_loss: 0.00001, value_loss: 0.01338 action_loss: 19.76774\n",
      "update_step:  70 model loss: 3.01079, kl_loss: 3.00157, obs_loss: 0.00921, reward_loss: 0.00001, value_loss: 0.01319 action_loss: 19.75503\n",
      "update_step:  71 model loss: 3.01074, kl_loss: 3.00145, obs_loss: 0.00928, reward_loss: 0.00001, value_loss: 0.01323 action_loss: 19.74140\n",
      "update_step:  72 model loss: 3.01488, kl_loss: 3.00050, obs_loss: 0.01437, reward_loss: 0.00001, value_loss: 0.01287 action_loss: 19.74120\n",
      "update_step:  73 model loss: 3.02154, kl_loss: 3.00084, obs_loss: 0.02069, reward_loss: 0.00001, value_loss: 0.01342 action_loss: 19.74570\n",
      "update_step:  74 model loss: 3.02777, kl_loss: 3.00099, obs_loss: 0.02676, reward_loss: 0.00001, value_loss: 0.01327 action_loss: 19.76471\n",
      "update_step:  75 model loss: 3.04388, kl_loss: 3.00171, obs_loss: 0.04216, reward_loss: 0.00001, value_loss: 0.01285 action_loss: 19.77393\n",
      "update_step:  76 model loss: 3.03019, kl_loss: 3.00118, obs_loss: 0.02900, reward_loss: 0.00001, value_loss: 0.01323 action_loss: 19.79130\n",
      "update_step:  77 model loss: 3.02985, kl_loss: 3.00155, obs_loss: 0.02828, reward_loss: 0.00001, value_loss: 0.01302 action_loss: 19.80403\n",
      "update_step:  78 model loss: 3.02336, kl_loss: 3.00110, obs_loss: 0.02225, reward_loss: 0.00001, value_loss: 0.01341 action_loss: 19.81617\n",
      "update_step:  79 model loss: 3.02212, kl_loss: 3.00131, obs_loss: 0.02081, reward_loss: 0.00001, value_loss: 0.01314 action_loss: 19.81304\n",
      "update_step:  80 model loss: 3.01697, kl_loss: 3.00173, obs_loss: 0.01522, reward_loss: 0.00001, value_loss: 0.01331 action_loss: 19.81666\n",
      "update_step:  81 model loss: 3.00797, kl_loss: 3.00036, obs_loss: 0.00759, reward_loss: 0.00001, value_loss: 0.01345 action_loss: 19.80953\n",
      "update_step:  82 model loss: 3.01364, kl_loss: 3.00150, obs_loss: 0.01212, reward_loss: 0.00001, value_loss: 0.01312 action_loss: 19.79730\n",
      "update_step:  83 model loss: 3.01279, kl_loss: 3.00031, obs_loss: 0.01246, reward_loss: 0.00001, value_loss: 0.01316 action_loss: 19.79155\n",
      "update_step:  84 model loss: 3.01680, kl_loss: 3.00021, obs_loss: 0.01657, reward_loss: 0.00001, value_loss: 0.01312 action_loss: 19.78725\n",
      "update_step:  85 model loss: 3.02358, kl_loss: 3.00068, obs_loss: 0.02289, reward_loss: 0.00001, value_loss: 0.01290 action_loss: 19.77978\n",
      "update_step:  86 model loss: 3.02152, kl_loss: 3.00136, obs_loss: 0.02015, reward_loss: 0.00001, value_loss: 0.01317 action_loss: 19.78246\n",
      "update_step:  87 model loss: 3.02115, kl_loss: 3.00085, obs_loss: 0.02028, reward_loss: 0.00001, value_loss: 0.01304 action_loss: 19.77492\n",
      "update_step:  88 model loss: 3.01759, kl_loss: 3.00108, obs_loss: 0.01650, reward_loss: 0.00001, value_loss: 0.01296 action_loss: 19.78053\n",
      "update_step:  89 model loss: 3.01445, kl_loss: 3.00079, obs_loss: 0.01365, reward_loss: 0.00001, value_loss: 0.01285 action_loss: 19.77703\n",
      "update_step:  90 model loss: 3.01405, kl_loss: 3.00012, obs_loss: 0.01392, reward_loss: 0.00001, value_loss: 0.01269 action_loss: 19.78531\n",
      "update_step:  91 model loss: 3.01091, kl_loss: 3.00067, obs_loss: 0.01023, reward_loss: 0.00001, value_loss: 0.01275 action_loss: 19.78472\n",
      "update_step:  92 model loss: 3.02136, kl_loss: 3.00162, obs_loss: 0.01973, reward_loss: 0.00001, value_loss: 0.01275 action_loss: 19.79867\n",
      "update_step:  93 model loss: 3.01683, kl_loss: 3.00090, obs_loss: 0.01592, reward_loss: 0.00001, value_loss: 0.01298 action_loss: 19.77846\n",
      "update_step:  94 model loss: 3.02068, kl_loss: 3.00204, obs_loss: 0.01863, reward_loss: 0.00001, value_loss: 0.01301 action_loss: 19.79555\n",
      "update_step:  95 model loss: 3.02747, kl_loss: 3.00029, obs_loss: 0.02716, reward_loss: 0.00001, value_loss: 0.01276 action_loss: 19.77046\n",
      "update_step:  96 model loss: 3.04888, kl_loss: 3.00184, obs_loss: 0.04702, reward_loss: 0.00001, value_loss: 0.01338 action_loss: 19.79666\n",
      "update_step:  97 model loss: 3.06430, kl_loss: 3.00047, obs_loss: 0.06382, reward_loss: 0.00001, value_loss: 0.01248 action_loss: 19.73614\n",
      "update_step:  98 model loss: 3.11132, kl_loss: 3.00239, obs_loss: 0.10891, reward_loss: 0.00002, value_loss: 0.01345 action_loss: 19.78531\n",
      "update_step:  99 model loss: 3.11656, kl_loss: 3.00063, obs_loss: 0.11591, reward_loss: 0.00002, value_loss: 0.01276 action_loss: 19.74140\n",
      "update_step: 100 model loss: 3.15092, kl_loss: 3.00191, obs_loss: 0.14899, reward_loss: 0.00002, value_loss: 0.01398 action_loss: 19.82594\n",
      "elasped time for update: 20.13s\n",
      "episode [  19/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.19635, kl_loss: 3.00113, obs_loss: 0.19520, reward_loss: 0.00002, value_loss: 0.01379 action_loss: 19.74914\n",
      "update_step:   2 model loss: 3.37051, kl_loss: 3.00006, obs_loss: 0.37040, reward_loss: 0.00004, value_loss: 0.01589 action_loss: 19.87548\n",
      "update_step:   3 model loss: 3.40882, kl_loss: 3.00049, obs_loss: 0.40827, reward_loss: 0.00005, value_loss: 0.01404 action_loss: 19.76343\n",
      "update_step:   4 model loss: 3.38604, kl_loss: 3.00023, obs_loss: 0.38579, reward_loss: 0.00002, value_loss: 0.01474 action_loss: 19.77139\n",
      "update_step:   5 model loss: 3.14470, kl_loss: 3.00000, obs_loss: 0.14468, reward_loss: 0.00002, value_loss: 0.01491 action_loss: 19.74674\n",
      "update_step:   6 model loss: 3.03877, kl_loss: 3.00000, obs_loss: 0.03875, reward_loss: 0.00002, value_loss: 0.01560 action_loss: 19.73669\n",
      "update_step:   7 model loss: 3.18484, kl_loss: 3.00028, obs_loss: 0.18454, reward_loss: 0.00002, value_loss: 0.01569 action_loss: 19.77709\n",
      "update_step:   8 model loss: 3.22634, kl_loss: 3.00042, obs_loss: 0.22589, reward_loss: 0.00003, value_loss: 0.01561 action_loss: 19.71549\n",
      "update_step:   9 model loss: 3.12485, kl_loss: 3.00000, obs_loss: 0.12481, reward_loss: 0.00004, value_loss: 0.01581 action_loss: 19.79098\n",
      "update_step:  10 model loss: 3.06320, kl_loss: 3.00084, obs_loss: 0.06234, reward_loss: 0.00002, value_loss: 0.01697 action_loss: 19.86370\n",
      "update_step:  11 model loss: 3.07014, kl_loss: 3.00037, obs_loss: 0.06974, reward_loss: 0.00003, value_loss: 0.01661 action_loss: 19.85170\n",
      "update_step:  12 model loss: 3.11384, kl_loss: 3.00120, obs_loss: 0.11262, reward_loss: 0.00002, value_loss: 0.01777 action_loss: 19.87177\n",
      "update_step:  13 model loss: 3.06538, kl_loss: 3.00123, obs_loss: 0.06413, reward_loss: 0.00002, value_loss: 0.01665 action_loss: 19.85820\n",
      "update_step:  14 model loss: 3.02744, kl_loss: 3.00259, obs_loss: 0.02483, reward_loss: 0.00002, value_loss: 0.01600 action_loss: 19.87188\n",
      "update_step:  15 model loss: 3.05548, kl_loss: 3.00250, obs_loss: 0.05296, reward_loss: 0.00002, value_loss: 0.01585 action_loss: 19.88296\n",
      "update_step:  16 model loss: 3.06802, kl_loss: 3.00181, obs_loss: 0.06618, reward_loss: 0.00003, value_loss: 0.01499 action_loss: 19.82205\n",
      "update_step:  17 model loss: 3.03513, kl_loss: 3.00137, obs_loss: 0.03374, reward_loss: 0.00002, value_loss: 0.01536 action_loss: 19.79320\n",
      "update_step:  18 model loss: 3.02492, kl_loss: 3.00087, obs_loss: 0.02402, reward_loss: 0.00002, value_loss: 0.01563 action_loss: 19.79856\n",
      "update_step:  19 model loss: 3.04316, kl_loss: 3.00095, obs_loss: 0.04218, reward_loss: 0.00002, value_loss: 0.01677 action_loss: 19.79078\n",
      "update_step:  20 model loss: 3.03615, kl_loss: 3.00222, obs_loss: 0.03390, reward_loss: 0.00002, value_loss: 0.01638 action_loss: 19.80119\n",
      "update_step:  21 model loss: 3.02149, kl_loss: 3.00129, obs_loss: 0.02018, reward_loss: 0.00002, value_loss: 0.01563 action_loss: 19.82047\n",
      "update_step:  22 model loss: 3.02989, kl_loss: 3.00132, obs_loss: 0.02856, reward_loss: 0.00002, value_loss: 0.01566 action_loss: 19.83654\n",
      "update_step:  23 model loss: 3.03714, kl_loss: 3.00015, obs_loss: 0.03697, reward_loss: 0.00002, value_loss: 0.01630 action_loss: 19.89801\n",
      "update_step:  24 model loss: 3.02787, kl_loss: 3.00060, obs_loss: 0.02725, reward_loss: 0.00002, value_loss: 0.01629 action_loss: 19.91395\n",
      "update_step:  25 model loss: 3.01566, kl_loss: 3.00075, obs_loss: 0.01490, reward_loss: 0.00002, value_loss: 0.01609 action_loss: 19.90281\n",
      "update_step:  26 model loss: 3.03356, kl_loss: 3.00153, obs_loss: 0.03201, reward_loss: 0.00002, value_loss: 0.01694 action_loss: 19.92307\n",
      "update_step:  27 model loss: 3.04763, kl_loss: 3.00145, obs_loss: 0.04616, reward_loss: 0.00002, value_loss: 0.01563 action_loss: 19.91215\n",
      "update_step:  28 model loss: 3.02946, kl_loss: 3.00069, obs_loss: 0.02876, reward_loss: 0.00001, value_loss: 0.01610 action_loss: 19.91501\n",
      "update_step:  29 model loss: 3.01679, kl_loss: 3.00069, obs_loss: 0.01608, reward_loss: 0.00002, value_loss: 0.01544 action_loss: 19.89391\n",
      "update_step:  30 model loss: 3.02494, kl_loss: 3.00114, obs_loss: 0.02379, reward_loss: 0.00001, value_loss: 0.01499 action_loss: 19.84238\n",
      "update_step:  31 model loss: 3.04506, kl_loss: 3.00151, obs_loss: 0.04354, reward_loss: 0.00002, value_loss: 0.01527 action_loss: 19.84254\n",
      "update_step:  32 model loss: 3.03067, kl_loss: 3.00160, obs_loss: 0.02906, reward_loss: 0.00001, value_loss: 0.01570 action_loss: 19.81978\n",
      "update_step:  33 model loss: 3.02197, kl_loss: 3.00133, obs_loss: 0.02063, reward_loss: 0.00002, value_loss: 0.01567 action_loss: 19.79921\n",
      "update_step:  34 model loss: 3.02310, kl_loss: 3.00061, obs_loss: 0.02247, reward_loss: 0.00001, value_loss: 0.01559 action_loss: 19.79259\n",
      "update_step:  35 model loss: 3.02758, kl_loss: 3.00039, obs_loss: 0.02717, reward_loss: 0.00001, value_loss: 0.01537 action_loss: 19.76612\n",
      "update_step:  36 model loss: 3.01949, kl_loss: 3.00038, obs_loss: 0.01910, reward_loss: 0.00001, value_loss: 0.01549 action_loss: 19.77752\n",
      "update_step:  37 model loss: 3.01218, kl_loss: 3.00055, obs_loss: 0.01162, reward_loss: 0.00001, value_loss: 0.01525 action_loss: 19.78295\n",
      "update_step:  38 model loss: 3.01991, kl_loss: 3.00109, obs_loss: 0.01881, reward_loss: 0.00001, value_loss: 0.01565 action_loss: 19.78001\n",
      "update_step:  39 model loss: 3.02274, kl_loss: 3.00111, obs_loss: 0.02161, reward_loss: 0.00001, value_loss: 0.01489 action_loss: 19.80985\n",
      "update_step:  40 model loss: 3.02141, kl_loss: 3.00174, obs_loss: 0.01966, reward_loss: 0.00001, value_loss: 0.01480 action_loss: 19.83314\n",
      "update_step:  41 model loss: 3.01398, kl_loss: 3.00182, obs_loss: 0.01215, reward_loss: 0.00001, value_loss: 0.01548 action_loss: 19.84825\n",
      "update_step:  42 model loss: 3.02042, kl_loss: 3.00100, obs_loss: 0.01941, reward_loss: 0.00001, value_loss: 0.01514 action_loss: 19.86300\n",
      "update_step:  43 model loss: 3.01531, kl_loss: 3.00057, obs_loss: 0.01473, reward_loss: 0.00001, value_loss: 0.01528 action_loss: 19.84819\n",
      "update_step:  44 model loss: 3.01612, kl_loss: 3.00064, obs_loss: 0.01546, reward_loss: 0.00001, value_loss: 0.01501 action_loss: 19.83685\n",
      "update_step:  45 model loss: 3.02789, kl_loss: 3.00194, obs_loss: 0.02594, reward_loss: 0.00001, value_loss: 0.01488 action_loss: 19.81491\n",
      "update_step:  46 model loss: 3.01432, kl_loss: 3.00058, obs_loss: 0.01373, reward_loss: 0.00001, value_loss: 0.01437 action_loss: 19.78445\n",
      "update_step:  47 model loss: 3.01335, kl_loss: 3.00080, obs_loss: 0.01254, reward_loss: 0.00001, value_loss: 0.01506 action_loss: 19.76874\n",
      "update_step:  48 model loss: 3.01014, kl_loss: 3.00049, obs_loss: 0.00964, reward_loss: 0.00001, value_loss: 0.01509 action_loss: 19.74841\n",
      "update_step:  49 model loss: 3.01000, kl_loss: 3.00087, obs_loss: 0.00912, reward_loss: 0.00001, value_loss: 0.01529 action_loss: 19.74604\n",
      "update_step:  50 model loss: 3.01695, kl_loss: 3.00106, obs_loss: 0.01587, reward_loss: 0.00001, value_loss: 0.01539 action_loss: 19.75469\n",
      "update_step:  51 model loss: 3.02037, kl_loss: 3.00145, obs_loss: 0.01892, reward_loss: 0.00001, value_loss: 0.01484 action_loss: 19.76560\n",
      "update_step:  52 model loss: 3.01296, kl_loss: 3.00137, obs_loss: 0.01158, reward_loss: 0.00001, value_loss: 0.01460 action_loss: 19.78232\n",
      "update_step:  53 model loss: 3.01064, kl_loss: 3.00023, obs_loss: 0.01040, reward_loss: 0.00001, value_loss: 0.01457 action_loss: 19.80515\n",
      "update_step:  54 model loss: 3.01077, kl_loss: 3.00060, obs_loss: 0.01016, reward_loss: 0.00001, value_loss: 0.01463 action_loss: 19.81885\n",
      "update_step:  55 model loss: 3.01117, kl_loss: 3.00041, obs_loss: 0.01074, reward_loss: 0.00001, value_loss: 0.01489 action_loss: 19.84313\n",
      "update_step:  56 model loss: 3.01545, kl_loss: 3.00068, obs_loss: 0.01476, reward_loss: 0.00001, value_loss: 0.01467 action_loss: 19.85179\n",
      "update_step:  57 model loss: 3.01239, kl_loss: 3.00045, obs_loss: 0.01193, reward_loss: 0.00001, value_loss: 0.01450 action_loss: 19.85917\n",
      "update_step:  58 model loss: 3.00956, kl_loss: 3.00062, obs_loss: 0.00893, reward_loss: 0.00001, value_loss: 0.01453 action_loss: 19.85766\n",
      "update_step:  59 model loss: 3.00882, kl_loss: 3.00056, obs_loss: 0.00824, reward_loss: 0.00001, value_loss: 0.01421 action_loss: 19.84597\n",
      "update_step:  60 model loss: 3.00975, kl_loss: 3.00062, obs_loss: 0.00912, reward_loss: 0.00001, value_loss: 0.01433 action_loss: 19.83584\n",
      "update_step:  61 model loss: 3.01093, kl_loss: 3.00192, obs_loss: 0.00899, reward_loss: 0.00001, value_loss: 0.01443 action_loss: 19.82375\n",
      "update_step:  62 model loss: 3.00926, kl_loss: 3.00035, obs_loss: 0.00889, reward_loss: 0.00001, value_loss: 0.01409 action_loss: 19.80644\n",
      "update_step:  63 model loss: 3.01656, kl_loss: 3.00198, obs_loss: 0.01456, reward_loss: 0.00001, value_loss: 0.01424 action_loss: 19.80774\n",
      "update_step:  64 model loss: 3.01015, kl_loss: 3.00072, obs_loss: 0.00941, reward_loss: 0.00001, value_loss: 0.01425 action_loss: 19.79999\n",
      "update_step:  65 model loss: 3.01350, kl_loss: 3.00064, obs_loss: 0.01284, reward_loss: 0.00001, value_loss: 0.01435 action_loss: 19.80371\n",
      "update_step:  66 model loss: 3.00958, kl_loss: 3.00080, obs_loss: 0.00876, reward_loss: 0.00001, value_loss: 0.01422 action_loss: 19.80942\n",
      "update_step:  67 model loss: 3.01254, kl_loss: 3.00059, obs_loss: 0.01193, reward_loss: 0.00001, value_loss: 0.01420 action_loss: 19.81594\n",
      "update_step:  68 model loss: 3.01307, kl_loss: 3.00117, obs_loss: 0.01188, reward_loss: 0.00001, value_loss: 0.01414 action_loss: 19.82832\n",
      "update_step:  69 model loss: 3.01760, kl_loss: 3.00061, obs_loss: 0.01698, reward_loss: 0.00001, value_loss: 0.01401 action_loss: 19.82299\n",
      "update_step:  70 model loss: 3.01270, kl_loss: 3.00051, obs_loss: 0.01218, reward_loss: 0.00001, value_loss: 0.01425 action_loss: 19.82007\n",
      "update_step:  71 model loss: 3.01568, kl_loss: 3.00218, obs_loss: 0.01349, reward_loss: 0.00001, value_loss: 0.01385 action_loss: 19.81134\n",
      "update_step:  72 model loss: 3.01107, kl_loss: 3.00144, obs_loss: 0.00962, reward_loss: 0.00001, value_loss: 0.01381 action_loss: 19.80179\n",
      "update_step:  73 model loss: 3.01278, kl_loss: 3.00179, obs_loss: 0.01097, reward_loss: 0.00001, value_loss: 0.01381 action_loss: 19.79459\n",
      "update_step:  74 model loss: 3.01192, kl_loss: 3.00066, obs_loss: 0.01125, reward_loss: 0.00001, value_loss: 0.01367 action_loss: 19.79256\n",
      "update_step:  75 model loss: 3.01103, kl_loss: 3.00085, obs_loss: 0.01017, reward_loss: 0.00001, value_loss: 0.01351 action_loss: 19.80255\n",
      "update_step:  76 model loss: 3.01583, kl_loss: 3.00180, obs_loss: 0.01402, reward_loss: 0.00001, value_loss: 0.01356 action_loss: 19.80242\n",
      "update_step:  77 model loss: 3.01434, kl_loss: 3.00156, obs_loss: 0.01276, reward_loss: 0.00001, value_loss: 0.01364 action_loss: 19.80501\n",
      "update_step:  78 model loss: 3.00849, kl_loss: 3.00034, obs_loss: 0.00814, reward_loss: 0.00001, value_loss: 0.01375 action_loss: 19.80648\n",
      "update_step:  79 model loss: 3.01358, kl_loss: 3.00086, obs_loss: 0.01270, reward_loss: 0.00001, value_loss: 0.01391 action_loss: 19.80845\n",
      "update_step:  80 model loss: 3.00669, kl_loss: 3.00005, obs_loss: 0.00662, reward_loss: 0.00001, value_loss: 0.01353 action_loss: 19.80937\n",
      "update_step:  81 model loss: 3.00786, kl_loss: 3.00015, obs_loss: 0.00769, reward_loss: 0.00001, value_loss: 0.01352 action_loss: 19.80585\n",
      "update_step:  82 model loss: 3.01511, kl_loss: 3.00139, obs_loss: 0.01371, reward_loss: 0.00001, value_loss: 0.01374 action_loss: 19.80346\n",
      "update_step:  83 model loss: 3.00748, kl_loss: 3.00033, obs_loss: 0.00713, reward_loss: 0.00001, value_loss: 0.01354 action_loss: 19.79843\n",
      "update_step:  84 model loss: 3.00923, kl_loss: 3.00029, obs_loss: 0.00893, reward_loss: 0.00001, value_loss: 0.01381 action_loss: 19.80070\n",
      "update_step:  85 model loss: 3.01028, kl_loss: 3.00086, obs_loss: 0.00941, reward_loss: 0.00001, value_loss: 0.01350 action_loss: 19.79919\n",
      "update_step:  86 model loss: 3.01164, kl_loss: 3.00095, obs_loss: 0.01068, reward_loss: 0.00001, value_loss: 0.01366 action_loss: 19.80697\n",
      "update_step:  87 model loss: 3.01266, kl_loss: 3.00081, obs_loss: 0.01183, reward_loss: 0.00001, value_loss: 0.01379 action_loss: 19.81339\n",
      "update_step:  88 model loss: 3.00682, kl_loss: 3.00028, obs_loss: 0.00652, reward_loss: 0.00001, value_loss: 0.01314 action_loss: 19.81823\n",
      "update_step:  89 model loss: 3.00801, kl_loss: 3.00104, obs_loss: 0.00696, reward_loss: 0.00001, value_loss: 0.01351 action_loss: 19.82266\n",
      "update_step:  90 model loss: 3.01634, kl_loss: 3.00107, obs_loss: 0.01525, reward_loss: 0.00001, value_loss: 0.01348 action_loss: 19.81629\n",
      "update_step:  91 model loss: 3.01124, kl_loss: 3.00167, obs_loss: 0.00955, reward_loss: 0.00001, value_loss: 0.01343 action_loss: 19.81344\n",
      "update_step:  92 model loss: 3.01002, kl_loss: 3.00062, obs_loss: 0.00939, reward_loss: 0.00001, value_loss: 0.01321 action_loss: 19.80937\n",
      "update_step:  93 model loss: 3.01343, kl_loss: 3.00103, obs_loss: 0.01238, reward_loss: 0.00001, value_loss: 0.01362 action_loss: 19.79716\n",
      "update_step:  94 model loss: 3.00893, kl_loss: 3.00045, obs_loss: 0.00847, reward_loss: 0.00001, value_loss: 0.01304 action_loss: 19.78749\n",
      "update_step:  95 model loss: 3.01288, kl_loss: 3.00055, obs_loss: 0.01232, reward_loss: 0.00001, value_loss: 0.01322 action_loss: 19.78208\n",
      "update_step:  96 model loss: 3.01119, kl_loss: 3.00087, obs_loss: 0.01031, reward_loss: 0.00001, value_loss: 0.01333 action_loss: 19.78512\n",
      "update_step:  97 model loss: 3.00931, kl_loss: 3.00051, obs_loss: 0.00879, reward_loss: 0.00001, value_loss: 0.01321 action_loss: 19.78442\n",
      "update_step:  98 model loss: 3.02084, kl_loss: 3.00180, obs_loss: 0.01903, reward_loss: 0.00001, value_loss: 0.01308 action_loss: 19.78586\n",
      "update_step:  99 model loss: 3.01051, kl_loss: 3.00120, obs_loss: 0.00929, reward_loss: 0.00001, value_loss: 0.01336 action_loss: 19.79511\n",
      "update_step: 100 model loss: 3.01848, kl_loss: 3.00159, obs_loss: 0.01688, reward_loss: 0.00001, value_loss: 0.01295 action_loss: 19.80427\n",
      "elasped time for update: 20.36s\n",
      "episode [  20/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.00986, kl_loss: 3.00096, obs_loss: 0.00889, reward_loss: 0.00001, value_loss: 0.01297 action_loss: 19.80876\n",
      "update_step:   2 model loss: 3.00929, kl_loss: 3.00092, obs_loss: 0.00836, reward_loss: 0.00001, value_loss: 0.01321 action_loss: 19.80804\n",
      "update_step:   3 model loss: 3.01195, kl_loss: 3.00094, obs_loss: 0.01100, reward_loss: 0.00001, value_loss: 0.01311 action_loss: 19.80874\n",
      "update_step:   4 model loss: 3.01656, kl_loss: 3.00213, obs_loss: 0.01442, reward_loss: 0.00001, value_loss: 0.01318 action_loss: 19.80852\n",
      "update_step:   5 model loss: 3.00978, kl_loss: 3.00105, obs_loss: 0.00871, reward_loss: 0.00001, value_loss: 0.01316 action_loss: 19.80214\n",
      "update_step:   6 model loss: 3.01115, kl_loss: 3.00101, obs_loss: 0.01013, reward_loss: 0.00001, value_loss: 0.01291 action_loss: 19.79475\n",
      "update_step:   7 model loss: 3.01569, kl_loss: 3.00105, obs_loss: 0.01463, reward_loss: 0.00001, value_loss: 0.01316 action_loss: 19.79243\n",
      "update_step:   8 model loss: 3.01309, kl_loss: 3.00130, obs_loss: 0.01177, reward_loss: 0.00001, value_loss: 0.01294 action_loss: 19.79205\n",
      "update_step:   9 model loss: 3.01238, kl_loss: 3.00175, obs_loss: 0.01062, reward_loss: 0.00001, value_loss: 0.01311 action_loss: 19.79350\n",
      "update_step:  10 model loss: 3.00977, kl_loss: 3.00062, obs_loss: 0.00914, reward_loss: 0.00001, value_loss: 0.01290 action_loss: 19.79334\n",
      "update_step:  11 model loss: 3.00701, kl_loss: 3.00049, obs_loss: 0.00651, reward_loss: 0.00001, value_loss: 0.01321 action_loss: 19.79632\n",
      "update_step:  12 model loss: 3.01051, kl_loss: 3.00094, obs_loss: 0.00956, reward_loss: 0.00001, value_loss: 0.01317 action_loss: 19.80768\n",
      "update_step:  13 model loss: 3.00681, kl_loss: 3.00020, obs_loss: 0.00660, reward_loss: 0.00001, value_loss: 0.01293 action_loss: 19.81247\n",
      "update_step:  14 model loss: 3.00841, kl_loss: 3.00027, obs_loss: 0.00812, reward_loss: 0.00001, value_loss: 0.01321 action_loss: 19.81076\n",
      "update_step:  15 model loss: 3.02071, kl_loss: 3.00266, obs_loss: 0.01803, reward_loss: 0.00001, value_loss: 0.01294 action_loss: 19.81048\n",
      "update_step:  16 model loss: 3.01488, kl_loss: 3.00047, obs_loss: 0.01440, reward_loss: 0.00001, value_loss: 0.01335 action_loss: 19.81662\n",
      "update_step:  17 model loss: 3.00939, kl_loss: 3.00051, obs_loss: 0.00887, reward_loss: 0.00001, value_loss: 0.01328 action_loss: 19.81962\n",
      "update_step:  18 model loss: 3.02047, kl_loss: 3.00101, obs_loss: 0.01945, reward_loss: 0.00001, value_loss: 0.01280 action_loss: 19.81835\n",
      "update_step:  19 model loss: 3.01589, kl_loss: 3.00053, obs_loss: 0.01535, reward_loss: 0.00001, value_loss: 0.01303 action_loss: 19.82065\n",
      "update_step:  20 model loss: 3.01736, kl_loss: 3.00129, obs_loss: 0.01606, reward_loss: 0.00001, value_loss: 0.01303 action_loss: 19.82141\n",
      "update_step:  21 model loss: 3.01713, kl_loss: 3.00109, obs_loss: 0.01602, reward_loss: 0.00001, value_loss: 0.01274 action_loss: 19.81851\n",
      "update_step:  22 model loss: 3.02336, kl_loss: 3.00239, obs_loss: 0.02095, reward_loss: 0.00001, value_loss: 0.01294 action_loss: 19.81718\n",
      "update_step:  23 model loss: 3.01936, kl_loss: 3.00062, obs_loss: 0.01873, reward_loss: 0.00001, value_loss: 0.01272 action_loss: 19.81931\n",
      "update_step:  24 model loss: 3.02638, kl_loss: 3.00100, obs_loss: 0.02538, reward_loss: 0.00001, value_loss: 0.01277 action_loss: 19.82022\n",
      "update_step:  25 model loss: 3.03483, kl_loss: 3.00203, obs_loss: 0.03278, reward_loss: 0.00001, value_loss: 0.01305 action_loss: 19.82153\n",
      "update_step:  26 model loss: 3.03542, kl_loss: 3.00154, obs_loss: 0.03388, reward_loss: 0.00001, value_loss: 0.01305 action_loss: 19.82425\n",
      "update_step:  27 model loss: 3.03935, kl_loss: 3.00136, obs_loss: 0.03798, reward_loss: 0.00001, value_loss: 0.01270 action_loss: 19.82272\n",
      "update_step:  28 model loss: 3.04219, kl_loss: 3.00044, obs_loss: 0.04174, reward_loss: 0.00001, value_loss: 0.01275 action_loss: 19.82015\n",
      "update_step:  29 model loss: 3.05069, kl_loss: 3.00044, obs_loss: 0.05024, reward_loss: 0.00001, value_loss: 0.01225 action_loss: 19.81814\n",
      "update_step:  30 model loss: 3.05887, kl_loss: 3.00171, obs_loss: 0.05714, reward_loss: 0.00001, value_loss: 0.01270 action_loss: 19.82625\n",
      "update_step:  31 model loss: 3.05092, kl_loss: 3.00017, obs_loss: 0.05074, reward_loss: 0.00001, value_loss: 0.01242 action_loss: 19.82137\n",
      "update_step:  32 model loss: 3.05103, kl_loss: 3.00048, obs_loss: 0.05054, reward_loss: 0.00001, value_loss: 0.01265 action_loss: 19.81830\n",
      "update_step:  33 model loss: 3.04626, kl_loss: 3.00021, obs_loss: 0.04604, reward_loss: 0.00001, value_loss: 0.01253 action_loss: 19.81561\n",
      "update_step:  34 model loss: 3.04236, kl_loss: 3.00091, obs_loss: 0.04144, reward_loss: 0.00001, value_loss: 0.01237 action_loss: 19.81639\n",
      "update_step:  35 model loss: 3.03620, kl_loss: 3.00160, obs_loss: 0.03459, reward_loss: 0.00001, value_loss: 0.01261 action_loss: 19.81365\n",
      "update_step:  36 model loss: 3.02242, kl_loss: 3.00074, obs_loss: 0.02168, reward_loss: 0.00001, value_loss: 0.01223 action_loss: 19.80613\n",
      "update_step:  37 model loss: 3.02243, kl_loss: 3.00136, obs_loss: 0.02106, reward_loss: 0.00001, value_loss: 0.01263 action_loss: 19.79576\n",
      "update_step:  38 model loss: 3.00759, kl_loss: 3.00021, obs_loss: 0.00736, reward_loss: 0.00001, value_loss: 0.01237 action_loss: 19.79699\n",
      "update_step:  39 model loss: 3.01056, kl_loss: 3.00115, obs_loss: 0.00940, reward_loss: 0.00001, value_loss: 0.01265 action_loss: 19.79566\n",
      "update_step:  40 model loss: 3.01181, kl_loss: 3.00037, obs_loss: 0.01143, reward_loss: 0.00001, value_loss: 0.01236 action_loss: 19.79065\n",
      "update_step:  41 model loss: 3.01588, kl_loss: 3.00077, obs_loss: 0.01510, reward_loss: 0.00001, value_loss: 0.01255 action_loss: 19.78745\n",
      "update_step:  42 model loss: 3.03401, kl_loss: 3.00286, obs_loss: 0.03114, reward_loss: 0.00001, value_loss: 0.01260 action_loss: 19.78978\n",
      "update_step:  43 model loss: 3.02274, kl_loss: 3.00164, obs_loss: 0.02108, reward_loss: 0.00001, value_loss: 0.01257 action_loss: 19.79688\n",
      "update_step:  44 model loss: 3.02221, kl_loss: 3.00171, obs_loss: 0.02049, reward_loss: 0.00001, value_loss: 0.01270 action_loss: 19.80568\n",
      "update_step:  45 model loss: 3.02596, kl_loss: 3.00120, obs_loss: 0.02476, reward_loss: 0.00001, value_loss: 0.01269 action_loss: 19.81222\n",
      "update_step:  46 model loss: 3.01671, kl_loss: 3.00054, obs_loss: 0.01615, reward_loss: 0.00001, value_loss: 0.01258 action_loss: 19.81894\n",
      "update_step:  47 model loss: 3.02485, kl_loss: 3.00198, obs_loss: 0.02286, reward_loss: 0.00001, value_loss: 0.01273 action_loss: 19.82908\n",
      "update_step:  48 model loss: 3.02307, kl_loss: 3.00234, obs_loss: 0.02072, reward_loss: 0.00001, value_loss: 0.01246 action_loss: 19.83699\n",
      "update_step:  49 model loss: 3.00976, kl_loss: 3.00058, obs_loss: 0.00917, reward_loss: 0.00001, value_loss: 0.01250 action_loss: 19.83053\n",
      "update_step:  50 model loss: 3.01121, kl_loss: 3.00067, obs_loss: 0.01052, reward_loss: 0.00001, value_loss: 0.01252 action_loss: 19.82533\n",
      "update_step:  51 model loss: 3.00621, kl_loss: 3.00054, obs_loss: 0.00566, reward_loss: 0.00001, value_loss: 0.01244 action_loss: 19.82179\n",
      "update_step:  52 model loss: 3.01111, kl_loss: 3.00183, obs_loss: 0.00927, reward_loss: 0.00001, value_loss: 0.01218 action_loss: 19.81097\n",
      "update_step:  53 model loss: 3.01313, kl_loss: 3.00103, obs_loss: 0.01208, reward_loss: 0.00001, value_loss: 0.01241 action_loss: 19.80343\n",
      "update_step:  54 model loss: 3.01065, kl_loss: 3.00077, obs_loss: 0.00986, reward_loss: 0.00001, value_loss: 0.01198 action_loss: 19.80738\n",
      "update_step:  55 model loss: 3.00842, kl_loss: 3.00035, obs_loss: 0.00806, reward_loss: 0.00001, value_loss: 0.01244 action_loss: 19.81092\n",
      "update_step:  56 model loss: 3.01020, kl_loss: 3.00047, obs_loss: 0.00972, reward_loss: 0.00001, value_loss: 0.01223 action_loss: 19.81312\n",
      "update_step:  57 model loss: 3.01469, kl_loss: 3.00112, obs_loss: 0.01356, reward_loss: 0.00001, value_loss: 0.01222 action_loss: 19.81871\n",
      "update_step:  58 model loss: 3.00910, kl_loss: 3.00015, obs_loss: 0.00893, reward_loss: 0.00001, value_loss: 0.01242 action_loss: 19.82704\n",
      "update_step:  59 model loss: 3.00821, kl_loss: 3.00043, obs_loss: 0.00777, reward_loss: 0.00001, value_loss: 0.01244 action_loss: 19.83278\n",
      "update_step:  60 model loss: 3.01132, kl_loss: 3.00073, obs_loss: 0.01058, reward_loss: 0.00001, value_loss: 0.01217 action_loss: 19.83121\n",
      "update_step:  61 model loss: 3.00904, kl_loss: 3.00110, obs_loss: 0.00793, reward_loss: 0.00001, value_loss: 0.01255 action_loss: 19.82303\n",
      "update_step:  62 model loss: 3.02097, kl_loss: 3.00135, obs_loss: 0.01960, reward_loss: 0.00001, value_loss: 0.01205 action_loss: 19.81829\n",
      "update_step:  63 model loss: 3.01576, kl_loss: 3.00198, obs_loss: 0.01377, reward_loss: 0.00001, value_loss: 0.01236 action_loss: 19.81717\n",
      "update_step:  64 model loss: 3.00927, kl_loss: 3.00117, obs_loss: 0.00809, reward_loss: 0.00001, value_loss: 0.01250 action_loss: 19.81224\n",
      "update_step:  65 model loss: 3.01355, kl_loss: 3.00138, obs_loss: 0.01216, reward_loss: 0.00001, value_loss: 0.01234 action_loss: 19.80644\n",
      "update_step:  66 model loss: 3.00885, kl_loss: 3.00118, obs_loss: 0.00766, reward_loss: 0.00001, value_loss: 0.01238 action_loss: 19.80628\n",
      "update_step:  67 model loss: 3.00871, kl_loss: 3.00081, obs_loss: 0.00788, reward_loss: 0.00001, value_loss: 0.01237 action_loss: 19.80800\n",
      "update_step:  68 model loss: 3.01074, kl_loss: 3.00075, obs_loss: 0.00998, reward_loss: 0.00001, value_loss: 0.01248 action_loss: 19.81277\n",
      "update_step:  69 model loss: 3.00892, kl_loss: 3.00019, obs_loss: 0.00872, reward_loss: 0.00001, value_loss: 0.01250 action_loss: 19.81754\n",
      "update_step:  70 model loss: 3.01073, kl_loss: 3.00021, obs_loss: 0.01051, reward_loss: 0.00001, value_loss: 0.01215 action_loss: 19.82393\n",
      "update_step:  71 model loss: 3.01224, kl_loss: 3.00031, obs_loss: 0.01192, reward_loss: 0.00001, value_loss: 0.01210 action_loss: 19.83019\n",
      "update_step:  72 model loss: 3.01665, kl_loss: 3.00127, obs_loss: 0.01537, reward_loss: 0.00001, value_loss: 0.01224 action_loss: 19.82601\n",
      "update_step:  73 model loss: 3.01961, kl_loss: 3.00076, obs_loss: 0.01884, reward_loss: 0.00001, value_loss: 0.01217 action_loss: 19.83234\n",
      "update_step:  74 model loss: 3.01594, kl_loss: 3.00047, obs_loss: 0.01546, reward_loss: 0.00001, value_loss: 0.01252 action_loss: 19.82851\n",
      "update_step:  75 model loss: 3.02315, kl_loss: 3.00094, obs_loss: 0.02220, reward_loss: 0.00001, value_loss: 0.01225 action_loss: 19.83420\n",
      "update_step:  76 model loss: 3.01670, kl_loss: 3.00088, obs_loss: 0.01581, reward_loss: 0.00001, value_loss: 0.01218 action_loss: 19.82533\n",
      "update_step:  77 model loss: 3.01960, kl_loss: 3.00091, obs_loss: 0.01868, reward_loss: 0.00001, value_loss: 0.01226 action_loss: 19.81995\n",
      "update_step:  78 model loss: 3.02085, kl_loss: 3.00085, obs_loss: 0.01999, reward_loss: 0.00001, value_loss: 0.01229 action_loss: 19.81139\n",
      "update_step:  79 model loss: 3.01867, kl_loss: 3.00088, obs_loss: 0.01778, reward_loss: 0.00001, value_loss: 0.01222 action_loss: 19.80717\n",
      "update_step:  80 model loss: 3.02523, kl_loss: 3.00173, obs_loss: 0.02348, reward_loss: 0.00001, value_loss: 0.01224 action_loss: 19.79683\n",
      "update_step:  81 model loss: 3.02009, kl_loss: 3.00037, obs_loss: 0.01971, reward_loss: 0.00001, value_loss: 0.01238 action_loss: 19.78965\n",
      "update_step:  82 model loss: 3.02427, kl_loss: 3.00073, obs_loss: 0.02353, reward_loss: 0.00001, value_loss: 0.01191 action_loss: 19.79527\n",
      "update_step:  83 model loss: 3.03059, kl_loss: 3.00173, obs_loss: 0.02885, reward_loss: 0.00001, value_loss: 0.01224 action_loss: 19.79403\n",
      "update_step:  84 model loss: 3.03292, kl_loss: 3.00152, obs_loss: 0.03139, reward_loss: 0.00001, value_loss: 0.01212 action_loss: 19.79877\n",
      "update_step:  85 model loss: 3.02747, kl_loss: 3.00099, obs_loss: 0.02647, reward_loss: 0.00001, value_loss: 0.01189 action_loss: 19.80909\n",
      "update_step:  86 model loss: 3.02757, kl_loss: 3.00111, obs_loss: 0.02644, reward_loss: 0.00001, value_loss: 0.01190 action_loss: 19.81526\n",
      "update_step:  87 model loss: 3.02972, kl_loss: 3.00105, obs_loss: 0.02866, reward_loss: 0.00001, value_loss: 0.01193 action_loss: 19.82958\n",
      "update_step:  88 model loss: 3.03222, kl_loss: 3.00082, obs_loss: 0.03140, reward_loss: 0.00001, value_loss: 0.01202 action_loss: 19.83215\n",
      "update_step:  89 model loss: 3.02644, kl_loss: 3.00121, obs_loss: 0.02522, reward_loss: 0.00001, value_loss: 0.01235 action_loss: 19.84173\n",
      "update_step:  90 model loss: 3.03065, kl_loss: 3.00093, obs_loss: 0.02971, reward_loss: 0.00001, value_loss: 0.01227 action_loss: 19.83447\n",
      "update_step:  91 model loss: 3.02340, kl_loss: 3.00087, obs_loss: 0.02252, reward_loss: 0.00001, value_loss: 0.01210 action_loss: 19.83163\n",
      "update_step:  92 model loss: 3.02629, kl_loss: 3.00109, obs_loss: 0.02520, reward_loss: 0.00001, value_loss: 0.01201 action_loss: 19.81982\n",
      "update_step:  93 model loss: 3.01849, kl_loss: 3.00044, obs_loss: 0.01805, reward_loss: 0.00001, value_loss: 0.01190 action_loss: 19.81898\n",
      "update_step:  94 model loss: 3.02515, kl_loss: 3.00199, obs_loss: 0.02314, reward_loss: 0.00001, value_loss: 0.01202 action_loss: 19.80363\n",
      "update_step:  95 model loss: 3.01330, kl_loss: 3.00072, obs_loss: 0.01257, reward_loss: 0.00001, value_loss: 0.01210 action_loss: 19.79502\n",
      "update_step:  96 model loss: 3.00885, kl_loss: 3.00023, obs_loss: 0.00861, reward_loss: 0.00001, value_loss: 0.01176 action_loss: 19.79726\n",
      "update_step:  97 model loss: 3.01097, kl_loss: 3.00060, obs_loss: 0.01035, reward_loss: 0.00001, value_loss: 0.01185 action_loss: 19.80521\n",
      "update_step:  98 model loss: 3.00845, kl_loss: 3.00048, obs_loss: 0.00795, reward_loss: 0.00001, value_loss: 0.01212 action_loss: 19.81626\n",
      "update_step:  99 model loss: 3.01090, kl_loss: 3.00075, obs_loss: 0.01014, reward_loss: 0.00001, value_loss: 0.01193 action_loss: 19.83088\n",
      "update_step: 100 model loss: 3.00629, kl_loss: 3.00031, obs_loss: 0.00597, reward_loss: 0.00001, value_loss: 0.01193 action_loss: 19.84100\n",
      "elasped time for update: 20.23s\n",
      "Total test reward at episode [  20/ 100] is -2.000000\n",
      "elasped time for test: 0.05s\n",
      "episode [  21/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01981, kl_loss: 3.00159, obs_loss: 0.01821, reward_loss: 0.00001, value_loss: 0.01211 action_loss: 19.85191\n",
      "update_step:   2 model loss: 3.01250, kl_loss: 3.00036, obs_loss: 0.01213, reward_loss: 0.00001, value_loss: 0.01177 action_loss: 19.84341\n",
      "update_step:   3 model loss: 3.01440, kl_loss: 3.00054, obs_loss: 0.01386, reward_loss: 0.00001, value_loss: 0.01216 action_loss: 19.84637\n",
      "update_step:   4 model loss: 3.01514, kl_loss: 3.00019, obs_loss: 0.01494, reward_loss: 0.00001, value_loss: 0.01205 action_loss: 19.83347\n",
      "update_step:   5 model loss: 3.01431, kl_loss: 3.00062, obs_loss: 0.01368, reward_loss: 0.00001, value_loss: 0.01186 action_loss: 19.83572\n",
      "update_step:   6 model loss: 3.01610, kl_loss: 3.00110, obs_loss: 0.01499, reward_loss: 0.00001, value_loss: 0.01183 action_loss: 19.81607\n",
      "update_step:   7 model loss: 3.00698, kl_loss: 3.00024, obs_loss: 0.00673, reward_loss: 0.00001, value_loss: 0.01178 action_loss: 19.80623\n",
      "update_step:   8 model loss: 3.01622, kl_loss: 3.00184, obs_loss: 0.01437, reward_loss: 0.00001, value_loss: 0.01175 action_loss: 19.80947\n",
      "update_step:   9 model loss: 3.01096, kl_loss: 3.00244, obs_loss: 0.00852, reward_loss: 0.00001, value_loss: 0.01183 action_loss: 19.81368\n",
      "update_step:  10 model loss: 3.00770, kl_loss: 3.00060, obs_loss: 0.00709, reward_loss: 0.00001, value_loss: 0.01172 action_loss: 19.81280\n",
      "update_step:  11 model loss: 3.01051, kl_loss: 3.00124, obs_loss: 0.00926, reward_loss: 0.00001, value_loss: 0.01192 action_loss: 19.80932\n",
      "update_step:  12 model loss: 3.00698, kl_loss: 3.00050, obs_loss: 0.00647, reward_loss: 0.00001, value_loss: 0.01161 action_loss: 19.82060\n",
      "update_step:  13 model loss: 3.01261, kl_loss: 3.00107, obs_loss: 0.01153, reward_loss: 0.00001, value_loss: 0.01153 action_loss: 19.82018\n",
      "update_step:  14 model loss: 3.01209, kl_loss: 3.00109, obs_loss: 0.01099, reward_loss: 0.00001, value_loss: 0.01175 action_loss: 19.81975\n",
      "update_step:  15 model loss: 3.01064, kl_loss: 3.00069, obs_loss: 0.00995, reward_loss: 0.00001, value_loss: 0.01182 action_loss: 19.81739\n",
      "update_step:  16 model loss: 3.00785, kl_loss: 3.00024, obs_loss: 0.00760, reward_loss: 0.00001, value_loss: 0.01190 action_loss: 19.81973\n",
      "update_step:  17 model loss: 3.00747, kl_loss: 3.00044, obs_loss: 0.00702, reward_loss: 0.00001, value_loss: 0.01164 action_loss: 19.80704\n",
      "update_step:  18 model loss: 3.00981, kl_loss: 3.00008, obs_loss: 0.00973, reward_loss: 0.00001, value_loss: 0.01162 action_loss: 19.79628\n",
      "update_step:  19 model loss: 3.00716, kl_loss: 3.00010, obs_loss: 0.00705, reward_loss: 0.00001, value_loss: 0.01151 action_loss: 19.78905\n",
      "update_step:  20 model loss: 3.01286, kl_loss: 3.00080, obs_loss: 0.01205, reward_loss: 0.00001, value_loss: 0.01158 action_loss: 19.78706\n",
      "update_step:  21 model loss: 3.01698, kl_loss: 3.00159, obs_loss: 0.01538, reward_loss: 0.00001, value_loss: 0.01186 action_loss: 19.78597\n",
      "update_step:  22 model loss: 3.01453, kl_loss: 3.00256, obs_loss: 0.01196, reward_loss: 0.00001, value_loss: 0.01166 action_loss: 19.79099\n",
      "update_step:  23 model loss: 3.01127, kl_loss: 3.00137, obs_loss: 0.00989, reward_loss: 0.00001, value_loss: 0.01178 action_loss: 19.80154\n",
      "update_step:  24 model loss: 3.01334, kl_loss: 3.00231, obs_loss: 0.01102, reward_loss: 0.00001, value_loss: 0.01171 action_loss: 19.81993\n",
      "update_step:  25 model loss: 3.00972, kl_loss: 3.00021, obs_loss: 0.00950, reward_loss: 0.00001, value_loss: 0.01170 action_loss: 19.83143\n",
      "update_step:  26 model loss: 3.01920, kl_loss: 3.00115, obs_loss: 0.01804, reward_loss: 0.00001, value_loss: 0.01157 action_loss: 19.84699\n",
      "update_step:  27 model loss: 3.01890, kl_loss: 3.00152, obs_loss: 0.01737, reward_loss: 0.00001, value_loss: 0.01166 action_loss: 19.85485\n",
      "update_step:  28 model loss: 3.01476, kl_loss: 3.00057, obs_loss: 0.01418, reward_loss: 0.00001, value_loss: 0.01174 action_loss: 19.85070\n",
      "update_step:  29 model loss: 3.01541, kl_loss: 3.00017, obs_loss: 0.01523, reward_loss: 0.00001, value_loss: 0.01175 action_loss: 19.83863\n",
      "update_step:  30 model loss: 3.01514, kl_loss: 3.00006, obs_loss: 0.01506, reward_loss: 0.00001, value_loss: 0.01126 action_loss: 19.81842\n",
      "update_step:  31 model loss: 3.02077, kl_loss: 3.00066, obs_loss: 0.02010, reward_loss: 0.00001, value_loss: 0.01156 action_loss: 19.80402\n",
      "update_step:  32 model loss: 3.02200, kl_loss: 3.00043, obs_loss: 0.02156, reward_loss: 0.00001, value_loss: 0.01153 action_loss: 19.78811\n",
      "update_step:  33 model loss: 3.03530, kl_loss: 3.00156, obs_loss: 0.03372, reward_loss: 0.00001, value_loss: 0.01158 action_loss: 19.79264\n",
      "update_step:  34 model loss: 3.04387, kl_loss: 3.00257, obs_loss: 0.04129, reward_loss: 0.00001, value_loss: 0.01164 action_loss: 19.78228\n",
      "update_step:  35 model loss: 3.04650, kl_loss: 3.00135, obs_loss: 0.04513, reward_loss: 0.00001, value_loss: 0.01154 action_loss: 19.80454\n",
      "update_step:  36 model loss: 3.05243, kl_loss: 3.00088, obs_loss: 0.05154, reward_loss: 0.00001, value_loss: 0.01155 action_loss: 19.80421\n",
      "update_step:  37 model loss: 3.06230, kl_loss: 3.00093, obs_loss: 0.06136, reward_loss: 0.00001, value_loss: 0.01148 action_loss: 19.83634\n",
      "update_step:  38 model loss: 3.07596, kl_loss: 3.00041, obs_loss: 0.07554, reward_loss: 0.00001, value_loss: 0.01147 action_loss: 19.83678\n",
      "update_step:  39 model loss: 3.09348, kl_loss: 3.00037, obs_loss: 0.09310, reward_loss: 0.00001, value_loss: 0.01164 action_loss: 19.85375\n",
      "update_step:  40 model loss: 3.10881, kl_loss: 3.00047, obs_loss: 0.10833, reward_loss: 0.00001, value_loss: 0.01132 action_loss: 19.83049\n",
      "update_step:  41 model loss: 3.12729, kl_loss: 3.00100, obs_loss: 0.12628, reward_loss: 0.00001, value_loss: 0.01129 action_loss: 19.83656\n",
      "update_step:  42 model loss: 3.12977, kl_loss: 3.00071, obs_loss: 0.12905, reward_loss: 0.00001, value_loss: 0.01140 action_loss: 19.82459\n",
      "update_step:  43 model loss: 3.12560, kl_loss: 3.00092, obs_loss: 0.12467, reward_loss: 0.00001, value_loss: 0.01149 action_loss: 19.82862\n",
      "update_step:  44 model loss: 3.10867, kl_loss: 3.00094, obs_loss: 0.10773, reward_loss: 0.00001, value_loss: 0.01140 action_loss: 19.83398\n",
      "update_step:  45 model loss: 3.08740, kl_loss: 3.00064, obs_loss: 0.08675, reward_loss: 0.00001, value_loss: 0.01117 action_loss: 19.83192\n",
      "update_step:  46 model loss: 3.04223, kl_loss: 3.00017, obs_loss: 0.04205, reward_loss: 0.00001, value_loss: 0.01130 action_loss: 19.85474\n",
      "update_step:  47 model loss: 3.02219, kl_loss: 3.00070, obs_loss: 0.02149, reward_loss: 0.00001, value_loss: 0.01133 action_loss: 19.84670\n",
      "update_step:  48 model loss: 3.02745, kl_loss: 3.00012, obs_loss: 0.02732, reward_loss: 0.00001, value_loss: 0.01141 action_loss: 19.85492\n",
      "update_step:  49 model loss: 3.05671, kl_loss: 3.00065, obs_loss: 0.05605, reward_loss: 0.00001, value_loss: 0.01116 action_loss: 19.83750\n",
      "update_step:  50 model loss: 3.08090, kl_loss: 3.00151, obs_loss: 0.07938, reward_loss: 0.00001, value_loss: 0.01125 action_loss: 19.83909\n",
      "update_step:  51 model loss: 3.07081, kl_loss: 3.00003, obs_loss: 0.07077, reward_loss: 0.00001, value_loss: 0.01135 action_loss: 19.80794\n",
      "update_step:  52 model loss: 3.05989, kl_loss: 3.00143, obs_loss: 0.05845, reward_loss: 0.00001, value_loss: 0.01123 action_loss: 19.80203\n",
      "update_step:  53 model loss: 3.02964, kl_loss: 3.00130, obs_loss: 0.02833, reward_loss: 0.00001, value_loss: 0.01115 action_loss: 19.79077\n",
      "update_step:  54 model loss: 3.01990, kl_loss: 3.00129, obs_loss: 0.01860, reward_loss: 0.00001, value_loss: 0.01118 action_loss: 19.79649\n",
      "update_step:  55 model loss: 3.01504, kl_loss: 3.00070, obs_loss: 0.01433, reward_loss: 0.00001, value_loss: 0.01151 action_loss: 19.79874\n",
      "update_step:  56 model loss: 3.01901, kl_loss: 3.00064, obs_loss: 0.01836, reward_loss: 0.00001, value_loss: 0.01142 action_loss: 19.80675\n",
      "update_step:  57 model loss: 3.02958, kl_loss: 3.00152, obs_loss: 0.02805, reward_loss: 0.00001, value_loss: 0.01137 action_loss: 19.81313\n",
      "update_step:  58 model loss: 3.03051, kl_loss: 3.00046, obs_loss: 0.03004, reward_loss: 0.00001, value_loss: 0.01143 action_loss: 19.82930\n",
      "update_step:  59 model loss: 3.02535, kl_loss: 3.00022, obs_loss: 0.02511, reward_loss: 0.00001, value_loss: 0.01137 action_loss: 19.82697\n",
      "update_step:  60 model loss: 3.01791, kl_loss: 3.00053, obs_loss: 0.01737, reward_loss: 0.00001, value_loss: 0.01160 action_loss: 19.81612\n",
      "update_step:  61 model loss: 3.00835, kl_loss: 3.00010, obs_loss: 0.00824, reward_loss: 0.00001, value_loss: 0.01150 action_loss: 19.80916\n",
      "update_step:  62 model loss: 3.01819, kl_loss: 3.00069, obs_loss: 0.01749, reward_loss: 0.00001, value_loss: 0.01168 action_loss: 19.80266\n",
      "update_step:  63 model loss: 3.01987, kl_loss: 3.00096, obs_loss: 0.01890, reward_loss: 0.00001, value_loss: 0.01148 action_loss: 19.80256\n",
      "update_step:  64 model loss: 3.02029, kl_loss: 3.00008, obs_loss: 0.02020, reward_loss: 0.00001, value_loss: 0.01159 action_loss: 19.79289\n",
      "update_step:  65 model loss: 3.02190, kl_loss: 3.00043, obs_loss: 0.02145, reward_loss: 0.00001, value_loss: 0.01136 action_loss: 19.79937\n",
      "update_step:  66 model loss: 3.02035, kl_loss: 3.00018, obs_loss: 0.02016, reward_loss: 0.00001, value_loss: 0.01147 action_loss: 19.79021\n",
      "update_step:  67 model loss: 3.01651, kl_loss: 3.00057, obs_loss: 0.01593, reward_loss: 0.00001, value_loss: 0.01124 action_loss: 19.81215\n",
      "update_step:  68 model loss: 3.01458, kl_loss: 3.00073, obs_loss: 0.01385, reward_loss: 0.00001, value_loss: 0.01140 action_loss: 19.81821\n",
      "update_step:  69 model loss: 3.01733, kl_loss: 3.00141, obs_loss: 0.01591, reward_loss: 0.00001, value_loss: 0.01137 action_loss: 19.83404\n",
      "update_step:  70 model loss: 3.01807, kl_loss: 3.00085, obs_loss: 0.01721, reward_loss: 0.00001, value_loss: 0.01144 action_loss: 19.84841\n",
      "update_step:  71 model loss: 3.01329, kl_loss: 3.00043, obs_loss: 0.01285, reward_loss: 0.00001, value_loss: 0.01133 action_loss: 19.85190\n",
      "update_step:  72 model loss: 3.01576, kl_loss: 3.00140, obs_loss: 0.01435, reward_loss: 0.00001, value_loss: 0.01158 action_loss: 19.86363\n",
      "update_step:  73 model loss: 3.01316, kl_loss: 3.00073, obs_loss: 0.01243, reward_loss: 0.00001, value_loss: 0.01159 action_loss: 19.85070\n",
      "update_step:  74 model loss: 3.01917, kl_loss: 3.00237, obs_loss: 0.01679, reward_loss: 0.00001, value_loss: 0.01116 action_loss: 19.85929\n",
      "update_step:  75 model loss: 3.01917, kl_loss: 3.00063, obs_loss: 0.01853, reward_loss: 0.00001, value_loss: 0.01131 action_loss: 19.83652\n",
      "update_step:  76 model loss: 3.01964, kl_loss: 3.00016, obs_loss: 0.01947, reward_loss: 0.00001, value_loss: 0.01157 action_loss: 19.84153\n",
      "update_step:  77 model loss: 3.02600, kl_loss: 3.00039, obs_loss: 0.02559, reward_loss: 0.00001, value_loss: 0.01127 action_loss: 19.81158\n",
      "update_step:  78 model loss: 3.03188, kl_loss: 3.00105, obs_loss: 0.03082, reward_loss: 0.00001, value_loss: 0.01140 action_loss: 19.81686\n",
      "update_step:  79 model loss: 3.02115, kl_loss: 3.00029, obs_loss: 0.02085, reward_loss: 0.00001, value_loss: 0.01126 action_loss: 19.81175\n",
      "update_step:  80 model loss: 3.02891, kl_loss: 3.00191, obs_loss: 0.02699, reward_loss: 0.00001, value_loss: 0.01119 action_loss: 19.83156\n",
      "update_step:  81 model loss: 3.01306, kl_loss: 3.00075, obs_loss: 0.01229, reward_loss: 0.00001, value_loss: 0.01123 action_loss: 19.83712\n",
      "update_step:  82 model loss: 3.01241, kl_loss: 3.00094, obs_loss: 0.01147, reward_loss: 0.00001, value_loss: 0.01120 action_loss: 19.84277\n",
      "update_step:  83 model loss: 3.01002, kl_loss: 3.00036, obs_loss: 0.00965, reward_loss: 0.00001, value_loss: 0.01098 action_loss: 19.85244\n",
      "update_step:  84 model loss: 3.01368, kl_loss: 3.00054, obs_loss: 0.01312, reward_loss: 0.00001, value_loss: 0.01098 action_loss: 19.83878\n",
      "update_step:  85 model loss: 3.01690, kl_loss: 3.00038, obs_loss: 0.01651, reward_loss: 0.00001, value_loss: 0.01107 action_loss: 19.84326\n",
      "update_step:  86 model loss: 3.01602, kl_loss: 3.00103, obs_loss: 0.01499, reward_loss: 0.00001, value_loss: 0.01127 action_loss: 19.83316\n",
      "update_step:  87 model loss: 3.02076, kl_loss: 3.00112, obs_loss: 0.01963, reward_loss: 0.00001, value_loss: 0.01129 action_loss: 19.84394\n",
      "update_step:  88 model loss: 3.01445, kl_loss: 3.00097, obs_loss: 0.01346, reward_loss: 0.00001, value_loss: 0.01117 action_loss: 19.83320\n",
      "update_step:  89 model loss: 3.02128, kl_loss: 3.00105, obs_loss: 0.02022, reward_loss: 0.00001, value_loss: 0.01130 action_loss: 19.84631\n",
      "update_step:  90 model loss: 3.02467, kl_loss: 3.00063, obs_loss: 0.02403, reward_loss: 0.00001, value_loss: 0.01124 action_loss: 19.83867\n",
      "update_step:  91 model loss: 3.02161, kl_loss: 3.00028, obs_loss: 0.02132, reward_loss: 0.00001, value_loss: 0.01127 action_loss: 19.85805\n",
      "update_step:  92 model loss: 3.01843, kl_loss: 3.00039, obs_loss: 0.01803, reward_loss: 0.00001, value_loss: 0.01116 action_loss: 19.82405\n",
      "update_step:  93 model loss: 3.02167, kl_loss: 3.00115, obs_loss: 0.02051, reward_loss: 0.00001, value_loss: 0.01110 action_loss: 19.82821\n",
      "update_step:  94 model loss: 3.01956, kl_loss: 3.00039, obs_loss: 0.01915, reward_loss: 0.00001, value_loss: 0.01124 action_loss: 19.80343\n",
      "update_step:  95 model loss: 3.02377, kl_loss: 3.00213, obs_loss: 0.02163, reward_loss: 0.00001, value_loss: 0.01125 action_loss: 19.81328\n",
      "update_step:  96 model loss: 3.01402, kl_loss: 3.00003, obs_loss: 0.01397, reward_loss: 0.00001, value_loss: 0.01090 action_loss: 19.79715\n",
      "update_step:  97 model loss: 3.01319, kl_loss: 3.00041, obs_loss: 0.01277, reward_loss: 0.00001, value_loss: 0.01129 action_loss: 19.81216\n",
      "update_step:  98 model loss: 3.01851, kl_loss: 3.00193, obs_loss: 0.01657, reward_loss: 0.00001, value_loss: 0.01128 action_loss: 19.82477\n",
      "update_step:  99 model loss: 3.00987, kl_loss: 3.00095, obs_loss: 0.00891, reward_loss: 0.00001, value_loss: 0.01120 action_loss: 19.84315\n",
      "update_step: 100 model loss: 3.01050, kl_loss: 3.00045, obs_loss: 0.01004, reward_loss: 0.00001, value_loss: 0.01130 action_loss: 19.85159\n",
      "elasped time for update: 20.34s\n",
      "episode [  22/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01325, kl_loss: 3.00091, obs_loss: 0.01233, reward_loss: 0.00001, value_loss: 0.01113 action_loss: 19.85478\n",
      "update_step:   2 model loss: 3.01302, kl_loss: 3.00103, obs_loss: 0.01198, reward_loss: 0.00001, value_loss: 0.01132 action_loss: 19.86044\n",
      "update_step:   3 model loss: 3.01795, kl_loss: 3.00203, obs_loss: 0.01591, reward_loss: 0.00001, value_loss: 0.01123 action_loss: 19.84664\n",
      "update_step:   4 model loss: 3.00876, kl_loss: 3.00084, obs_loss: 0.00791, reward_loss: 0.00001, value_loss: 0.01131 action_loss: 19.83423\n",
      "update_step:   5 model loss: 3.01127, kl_loss: 3.00148, obs_loss: 0.00978, reward_loss: 0.00001, value_loss: 0.01117 action_loss: 19.81470\n",
      "update_step:   6 model loss: 3.01021, kl_loss: 3.00031, obs_loss: 0.00989, reward_loss: 0.00001, value_loss: 0.01153 action_loss: 19.81521\n",
      "update_step:   7 model loss: 3.01287, kl_loss: 3.00040, obs_loss: 0.01246, reward_loss: 0.00001, value_loss: 0.01134 action_loss: 19.80975\n",
      "update_step:   8 model loss: 3.00850, kl_loss: 3.00001, obs_loss: 0.00849, reward_loss: 0.00001, value_loss: 0.01135 action_loss: 19.81138\n",
      "update_step:   9 model loss: 3.01337, kl_loss: 3.00093, obs_loss: 0.01243, reward_loss: 0.00001, value_loss: 0.01113 action_loss: 19.81961\n",
      "update_step:  10 model loss: 3.00926, kl_loss: 3.00030, obs_loss: 0.00895, reward_loss: 0.00001, value_loss: 0.01124 action_loss: 19.84233\n",
      "update_step:  11 model loss: 3.00950, kl_loss: 3.00064, obs_loss: 0.00885, reward_loss: 0.00001, value_loss: 0.01116 action_loss: 19.85874\n",
      "update_step:  12 model loss: 3.00723, kl_loss: 3.00001, obs_loss: 0.00721, reward_loss: 0.00001, value_loss: 0.01136 action_loss: 19.85462\n",
      "update_step:  13 model loss: 3.00942, kl_loss: 3.00053, obs_loss: 0.00888, reward_loss: 0.00001, value_loss: 0.01138 action_loss: 19.86366\n",
      "update_step:  14 model loss: 3.00824, kl_loss: 3.00016, obs_loss: 0.00807, reward_loss: 0.00001, value_loss: 0.01092 action_loss: 19.86121\n",
      "update_step:  15 model loss: 3.01833, kl_loss: 3.00166, obs_loss: 0.01666, reward_loss: 0.00001, value_loss: 0.01107 action_loss: 19.85926\n",
      "update_step:  16 model loss: 3.02038, kl_loss: 3.00187, obs_loss: 0.01850, reward_loss: 0.00001, value_loss: 0.01082 action_loss: 19.83758\n",
      "update_step:  17 model loss: 3.03368, kl_loss: 3.00479, obs_loss: 0.02888, reward_loss: 0.00001, value_loss: 0.01113 action_loss: 19.83372\n",
      "update_step:  18 model loss: 3.01685, kl_loss: 3.00235, obs_loss: 0.01449, reward_loss: 0.00001, value_loss: 0.01105 action_loss: 19.81267\n",
      "update_step:  19 model loss: 3.01171, kl_loss: 3.00090, obs_loss: 0.01080, reward_loss: 0.00001, value_loss: 0.01113 action_loss: 19.80944\n",
      "update_step:  20 model loss: 3.01891, kl_loss: 3.00159, obs_loss: 0.01731, reward_loss: 0.00001, value_loss: 0.01081 action_loss: 19.79057\n",
      "update_step:  21 model loss: 3.01279, kl_loss: 3.00090, obs_loss: 0.01187, reward_loss: 0.00001, value_loss: 0.01096 action_loss: 19.79530\n",
      "update_step:  22 model loss: 3.00917, kl_loss: 3.00043, obs_loss: 0.00873, reward_loss: 0.00001, value_loss: 0.01072 action_loss: 19.79661\n",
      "update_step:  23 model loss: 3.00691, kl_loss: 3.00037, obs_loss: 0.00653, reward_loss: 0.00001, value_loss: 0.01082 action_loss: 19.79849\n",
      "update_step:  24 model loss: 3.01327, kl_loss: 3.00029, obs_loss: 0.01297, reward_loss: 0.00001, value_loss: 0.01080 action_loss: 19.81663\n",
      "update_step:  25 model loss: 3.03030, kl_loss: 3.00219, obs_loss: 0.02810, reward_loss: 0.00001, value_loss: 0.01088 action_loss: 19.81254\n",
      "update_step:  26 model loss: 3.03429, kl_loss: 3.00116, obs_loss: 0.03312, reward_loss: 0.00001, value_loss: 0.01078 action_loss: 19.84992\n",
      "update_step:  27 model loss: 3.04631, kl_loss: 3.00051, obs_loss: 0.04579, reward_loss: 0.00001, value_loss: 0.01091 action_loss: 19.82352\n",
      "update_step:  28 model loss: 3.05622, kl_loss: 3.00120, obs_loss: 0.05501, reward_loss: 0.00001, value_loss: 0.01109 action_loss: 19.86096\n",
      "update_step:  29 model loss: 3.06235, kl_loss: 3.00087, obs_loss: 0.06147, reward_loss: 0.00001, value_loss: 0.01075 action_loss: 19.83232\n",
      "update_step:  30 model loss: 3.05930, kl_loss: 3.00100, obs_loss: 0.05829, reward_loss: 0.00001, value_loss: 0.01081 action_loss: 19.86382\n",
      "update_step:  31 model loss: 3.06260, kl_loss: 3.00141, obs_loss: 0.06118, reward_loss: 0.00001, value_loss: 0.01068 action_loss: 19.84184\n",
      "update_step:  32 model loss: 3.03214, kl_loss: 3.00134, obs_loss: 0.03079, reward_loss: 0.00001, value_loss: 0.01074 action_loss: 19.85070\n",
      "update_step:  33 model loss: 3.01785, kl_loss: 3.00066, obs_loss: 0.01718, reward_loss: 0.00001, value_loss: 0.01089 action_loss: 19.85270\n",
      "update_step:  34 model loss: 3.02228, kl_loss: 3.00009, obs_loss: 0.02218, reward_loss: 0.00001, value_loss: 0.01105 action_loss: 19.82416\n",
      "update_step:  35 model loss: 3.03757, kl_loss: 3.00052, obs_loss: 0.03704, reward_loss: 0.00001, value_loss: 0.01114 action_loss: 19.83605\n",
      "update_step:  36 model loss: 3.07808, kl_loss: 3.00023, obs_loss: 0.07783, reward_loss: 0.00001, value_loss: 0.01065 action_loss: 19.79857\n",
      "update_step:  37 model loss: 3.06289, kl_loss: 3.00003, obs_loss: 0.06285, reward_loss: 0.00001, value_loss: 0.01081 action_loss: 19.83810\n",
      "update_step:  38 model loss: 3.05423, kl_loss: 3.00007, obs_loss: 0.05415, reward_loss: 0.00001, value_loss: 0.01092 action_loss: 19.81470\n",
      "update_step:  39 model loss: 3.03888, kl_loss: 3.00000, obs_loss: 0.03887, reward_loss: 0.00001, value_loss: 0.01124 action_loss: 19.84986\n",
      "update_step:  40 model loss: 3.03830, kl_loss: 3.00072, obs_loss: 0.03756, reward_loss: 0.00001, value_loss: 0.01111 action_loss: 19.83582\n",
      "update_step:  41 model loss: 3.02486, kl_loss: 3.00022, obs_loss: 0.02463, reward_loss: 0.00001, value_loss: 0.01082 action_loss: 19.83812\n",
      "update_step:  42 model loss: 3.02086, kl_loss: 3.00049, obs_loss: 0.02036, reward_loss: 0.00001, value_loss: 0.01089 action_loss: 19.84660\n",
      "update_step:  43 model loss: 3.02675, kl_loss: 3.00044, obs_loss: 0.02630, reward_loss: 0.00001, value_loss: 0.01100 action_loss: 19.86033\n",
      "update_step:  44 model loss: 3.01933, kl_loss: 3.00064, obs_loss: 0.01868, reward_loss: 0.00001, value_loss: 0.01100 action_loss: 19.86816\n",
      "update_step:  45 model loss: 3.02270, kl_loss: 3.00079, obs_loss: 0.02189, reward_loss: 0.00001, value_loss: 0.01084 action_loss: 19.85899\n",
      "update_step:  46 model loss: 3.01523, kl_loss: 3.00064, obs_loss: 0.01458, reward_loss: 0.00001, value_loss: 0.01073 action_loss: 19.87279\n",
      "update_step:  47 model loss: 3.01532, kl_loss: 3.00160, obs_loss: 0.01371, reward_loss: 0.00001, value_loss: 0.01091 action_loss: 19.86542\n",
      "update_step:  48 model loss: 3.01069, kl_loss: 3.00063, obs_loss: 0.01005, reward_loss: 0.00001, value_loss: 0.01068 action_loss: 19.83992\n",
      "update_step:  49 model loss: 3.00937, kl_loss: 3.00056, obs_loss: 0.00880, reward_loss: 0.00001, value_loss: 0.01094 action_loss: 19.80921\n",
      "update_step:  50 model loss: 3.01476, kl_loss: 3.00111, obs_loss: 0.01364, reward_loss: 0.00001, value_loss: 0.01082 action_loss: 19.79948\n",
      "update_step:  51 model loss: 3.01609, kl_loss: 3.00101, obs_loss: 0.01506, reward_loss: 0.00001, value_loss: 0.01120 action_loss: 19.80051\n",
      "update_step:  52 model loss: 3.01231, kl_loss: 3.00066, obs_loss: 0.01164, reward_loss: 0.00001, value_loss: 0.01096 action_loss: 19.79994\n",
      "update_step:  53 model loss: 3.01228, kl_loss: 3.00068, obs_loss: 0.01159, reward_loss: 0.00001, value_loss: 0.01046 action_loss: 19.81318\n",
      "update_step:  54 model loss: 3.00987, kl_loss: 3.00031, obs_loss: 0.00955, reward_loss: 0.00001, value_loss: 0.01065 action_loss: 19.83085\n",
      "update_step:  55 model loss: 3.01109, kl_loss: 3.00102, obs_loss: 0.01006, reward_loss: 0.00001, value_loss: 0.01083 action_loss: 19.85693\n",
      "update_step:  56 model loss: 3.01054, kl_loss: 3.00024, obs_loss: 0.01029, reward_loss: 0.00001, value_loss: 0.01081 action_loss: 19.85482\n",
      "update_step:  57 model loss: 3.00986, kl_loss: 3.00033, obs_loss: 0.00952, reward_loss: 0.00001, value_loss: 0.01086 action_loss: 19.86136\n",
      "update_step:  58 model loss: 3.02030, kl_loss: 3.00316, obs_loss: 0.01714, reward_loss: 0.00001, value_loss: 0.01047 action_loss: 19.85896\n",
      "update_step:  59 model loss: 3.01094, kl_loss: 3.00064, obs_loss: 0.01029, reward_loss: 0.00001, value_loss: 0.01041 action_loss: 19.85430\n",
      "update_step:  60 model loss: 3.00898, kl_loss: 3.00033, obs_loss: 0.00864, reward_loss: 0.00001, value_loss: 0.01038 action_loss: 19.82979\n",
      "update_step:  61 model loss: 3.00705, kl_loss: 3.00058, obs_loss: 0.00647, reward_loss: 0.00001, value_loss: 0.01040 action_loss: 19.81445\n",
      "update_step:  62 model loss: 3.01428, kl_loss: 3.00100, obs_loss: 0.01327, reward_loss: 0.00001, value_loss: 0.01042 action_loss: 19.81138\n",
      "update_step:  63 model loss: 3.00858, kl_loss: 3.00064, obs_loss: 0.00793, reward_loss: 0.00001, value_loss: 0.01057 action_loss: 19.80172\n",
      "update_step:  64 model loss: 3.02385, kl_loss: 3.00137, obs_loss: 0.02246, reward_loss: 0.00001, value_loss: 0.01054 action_loss: 19.80783\n",
      "update_step:  65 model loss: 3.01670, kl_loss: 3.00084, obs_loss: 0.01585, reward_loss: 0.00001, value_loss: 0.01037 action_loss: 19.80269\n",
      "update_step:  66 model loss: 3.00892, kl_loss: 3.00055, obs_loss: 0.00835, reward_loss: 0.00001, value_loss: 0.01034 action_loss: 19.82535\n",
      "update_step:  67 model loss: 3.01051, kl_loss: 3.00127, obs_loss: 0.00923, reward_loss: 0.00001, value_loss: 0.01036 action_loss: 19.84334\n",
      "update_step:  68 model loss: 3.01274, kl_loss: 3.00231, obs_loss: 0.01043, reward_loss: 0.00001, value_loss: 0.01036 action_loss: 19.85979\n",
      "update_step:  69 model loss: 3.00634, kl_loss: 3.00138, obs_loss: 0.00494, reward_loss: 0.00001, value_loss: 0.01062 action_loss: 19.87750\n",
      "update_step:  70 model loss: 3.01251, kl_loss: 3.00120, obs_loss: 0.01130, reward_loss: 0.00001, value_loss: 0.01045 action_loss: 19.88966\n",
      "update_step:  71 model loss: 3.00954, kl_loss: 3.00036, obs_loss: 0.00917, reward_loss: 0.00001, value_loss: 0.01046 action_loss: 19.89112\n",
      "update_step:  72 model loss: 3.01160, kl_loss: 3.00089, obs_loss: 0.01070, reward_loss: 0.00001, value_loss: 0.01031 action_loss: 19.87402\n",
      "update_step:  73 model loss: 3.01411, kl_loss: 3.00069, obs_loss: 0.01340, reward_loss: 0.00001, value_loss: 0.01038 action_loss: 19.86422\n",
      "update_step:  74 model loss: 3.01080, kl_loss: 3.00051, obs_loss: 0.01028, reward_loss: 0.00001, value_loss: 0.01050 action_loss: 19.85291\n",
      "update_step:  75 model loss: 3.00667, kl_loss: 3.00012, obs_loss: 0.00654, reward_loss: 0.00001, value_loss: 0.01029 action_loss: 19.83730\n",
      "update_step:  76 model loss: 3.00732, kl_loss: 3.00032, obs_loss: 0.00700, reward_loss: 0.00001, value_loss: 0.01029 action_loss: 19.82603\n",
      "update_step:  77 model loss: 3.01070, kl_loss: 3.00049, obs_loss: 0.01020, reward_loss: 0.00001, value_loss: 0.01021 action_loss: 19.82117\n",
      "update_step:  78 model loss: 3.01038, kl_loss: 3.00105, obs_loss: 0.00931, reward_loss: 0.00001, value_loss: 0.00983 action_loss: 19.82413\n",
      "update_step:  79 model loss: 3.00834, kl_loss: 3.00017, obs_loss: 0.00817, reward_loss: 0.00001, value_loss: 0.01002 action_loss: 19.81352\n",
      "update_step:  80 model loss: 3.01112, kl_loss: 3.00055, obs_loss: 0.01057, reward_loss: 0.00001, value_loss: 0.01066 action_loss: 19.82185\n",
      "update_step:  81 model loss: 3.01797, kl_loss: 3.00152, obs_loss: 0.01644, reward_loss: 0.00001, value_loss: 0.01040 action_loss: 19.81427\n",
      "update_step:  82 model loss: 3.02076, kl_loss: 3.00248, obs_loss: 0.01826, reward_loss: 0.00001, value_loss: 0.01028 action_loss: 19.81849\n",
      "update_step:  83 model loss: 3.01404, kl_loss: 3.00143, obs_loss: 0.01259, reward_loss: 0.00001, value_loss: 0.01007 action_loss: 19.80921\n",
      "update_step:  84 model loss: 3.01300, kl_loss: 3.00058, obs_loss: 0.01241, reward_loss: 0.00001, value_loss: 0.01054 action_loss: 19.82643\n",
      "update_step:  85 model loss: 3.01154, kl_loss: 3.00046, obs_loss: 0.01106, reward_loss: 0.00001, value_loss: 0.01054 action_loss: 19.82547\n",
      "update_step:  86 model loss: 3.01437, kl_loss: 3.00139, obs_loss: 0.01297, reward_loss: 0.00001, value_loss: 0.01024 action_loss: 19.83597\n",
      "update_step:  87 model loss: 3.01195, kl_loss: 3.00054, obs_loss: 0.01140, reward_loss: 0.00001, value_loss: 0.01040 action_loss: 19.84847\n",
      "update_step:  88 model loss: 3.01264, kl_loss: 3.00061, obs_loss: 0.01202, reward_loss: 0.00001, value_loss: 0.01022 action_loss: 19.86695\n",
      "update_step:  89 model loss: 3.00751, kl_loss: 3.00073, obs_loss: 0.00677, reward_loss: 0.00001, value_loss: 0.01058 action_loss: 19.86627\n",
      "update_step:  90 model loss: 3.00692, kl_loss: 3.00068, obs_loss: 0.00623, reward_loss: 0.00001, value_loss: 0.01015 action_loss: 19.85696\n",
      "update_step:  91 model loss: 3.01296, kl_loss: 3.00143, obs_loss: 0.01151, reward_loss: 0.00001, value_loss: 0.01064 action_loss: 19.85873\n",
      "update_step:  92 model loss: 3.01027, kl_loss: 3.00085, obs_loss: 0.00941, reward_loss: 0.00001, value_loss: 0.01012 action_loss: 19.85319\n",
      "update_step:  93 model loss: 3.01540, kl_loss: 3.00089, obs_loss: 0.01450, reward_loss: 0.00001, value_loss: 0.01028 action_loss: 19.84283\n",
      "update_step:  94 model loss: 3.01119, kl_loss: 3.00095, obs_loss: 0.01023, reward_loss: 0.00001, value_loss: 0.01014 action_loss: 19.82752\n",
      "update_step:  95 model loss: 3.00897, kl_loss: 3.00053, obs_loss: 0.00843, reward_loss: 0.00001, value_loss: 0.01029 action_loss: 19.82930\n",
      "update_step:  96 model loss: 3.01531, kl_loss: 3.00164, obs_loss: 0.01366, reward_loss: 0.00001, value_loss: 0.01027 action_loss: 19.82219\n",
      "update_step:  97 model loss: 3.01180, kl_loss: 3.00049, obs_loss: 0.01130, reward_loss: 0.00001, value_loss: 0.01006 action_loss: 19.83232\n",
      "update_step:  98 model loss: 3.01102, kl_loss: 3.00087, obs_loss: 0.01014, reward_loss: 0.00001, value_loss: 0.01006 action_loss: 19.82484\n",
      "update_step:  99 model loss: 3.01197, kl_loss: 3.00016, obs_loss: 0.01179, reward_loss: 0.00001, value_loss: 0.01034 action_loss: 19.85261\n",
      "update_step: 100 model loss: 3.01736, kl_loss: 3.00052, obs_loss: 0.01683, reward_loss: 0.00001, value_loss: 0.01012 action_loss: 19.85299\n",
      "elasped time for update: 20.34s\n",
      "episode [  23/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01566, kl_loss: 3.00029, obs_loss: 0.01537, reward_loss: 0.00001, value_loss: 0.01004 action_loss: 19.86883\n",
      "update_step:   2 model loss: 3.02170, kl_loss: 3.00047, obs_loss: 0.02121, reward_loss: 0.00001, value_loss: 0.01012 action_loss: 19.84970\n",
      "update_step:   3 model loss: 3.02497, kl_loss: 3.00030, obs_loss: 0.02466, reward_loss: 0.00001, value_loss: 0.00988 action_loss: 19.87110\n",
      "update_step:   4 model loss: 3.03364, kl_loss: 3.00062, obs_loss: 0.03301, reward_loss: 0.00001, value_loss: 0.00972 action_loss: 19.84443\n",
      "update_step:   5 model loss: 3.02815, kl_loss: 3.00017, obs_loss: 0.02797, reward_loss: 0.00001, value_loss: 0.00989 action_loss: 19.84398\n",
      "update_step:   6 model loss: 3.02524, kl_loss: 3.00073, obs_loss: 0.02450, reward_loss: 0.00001, value_loss: 0.00991 action_loss: 19.82142\n",
      "update_step:   7 model loss: 3.02005, kl_loss: 3.00032, obs_loss: 0.01972, reward_loss: 0.00001, value_loss: 0.01002 action_loss: 19.84277\n",
      "update_step:   8 model loss: 3.01977, kl_loss: 3.00092, obs_loss: 0.01884, reward_loss: 0.00001, value_loss: 0.00998 action_loss: 19.84348\n",
      "update_step:   9 model loss: 3.01308, kl_loss: 3.00015, obs_loss: 0.01293, reward_loss: 0.00001, value_loss: 0.00997 action_loss: 19.85820\n",
      "update_step:  10 model loss: 3.01289, kl_loss: 3.00087, obs_loss: 0.01201, reward_loss: 0.00001, value_loss: 0.00977 action_loss: 19.86632\n",
      "update_step:  11 model loss: 3.01602, kl_loss: 3.00207, obs_loss: 0.01394, reward_loss: 0.00001, value_loss: 0.00987 action_loss: 19.87184\n",
      "update_step:  12 model loss: 3.00781, kl_loss: 3.00071, obs_loss: 0.00709, reward_loss: 0.00001, value_loss: 0.01002 action_loss: 19.87434\n",
      "update_step:  13 model loss: 3.01080, kl_loss: 3.00041, obs_loss: 0.01038, reward_loss: 0.00001, value_loss: 0.00986 action_loss: 19.85353\n",
      "update_step:  14 model loss: 3.01892, kl_loss: 3.00127, obs_loss: 0.01764, reward_loss: 0.00001, value_loss: 0.00997 action_loss: 19.86801\n",
      "update_step:  15 model loss: 3.02604, kl_loss: 3.00011, obs_loss: 0.02592, reward_loss: 0.00001, value_loss: 0.00981 action_loss: 19.84469\n",
      "update_step:  16 model loss: 3.03649, kl_loss: 3.00038, obs_loss: 0.03611, reward_loss: 0.00001, value_loss: 0.00995 action_loss: 19.86042\n",
      "update_step:  17 model loss: 3.05118, kl_loss: 3.00076, obs_loss: 0.05041, reward_loss: 0.00001, value_loss: 0.00986 action_loss: 19.82762\n",
      "update_step:  18 model loss: 3.06035, kl_loss: 3.00047, obs_loss: 0.05986, reward_loss: 0.00001, value_loss: 0.00991 action_loss: 19.84097\n",
      "update_step:  19 model loss: 3.06710, kl_loss: 3.00047, obs_loss: 0.06662, reward_loss: 0.00001, value_loss: 0.01011 action_loss: 19.78595\n",
      "update_step:  20 model loss: 3.08779, kl_loss: 3.00110, obs_loss: 0.08668, reward_loss: 0.00001, value_loss: 0.01018 action_loss: 19.78535\n",
      "update_step:  21 model loss: 3.07562, kl_loss: 3.00059, obs_loss: 0.07502, reward_loss: 0.00001, value_loss: 0.01045 action_loss: 19.75250\n",
      "update_step:  22 model loss: 3.08780, kl_loss: 3.00063, obs_loss: 0.08716, reward_loss: 0.00001, value_loss: 0.01038 action_loss: 19.78801\n",
      "update_step:  23 model loss: 3.08544, kl_loss: 3.00073, obs_loss: 0.08470, reward_loss: 0.00001, value_loss: 0.01002 action_loss: 19.79779\n",
      "update_step:  24 model loss: 3.09701, kl_loss: 3.00131, obs_loss: 0.09569, reward_loss: 0.00001, value_loss: 0.01008 action_loss: 19.83339\n",
      "update_step:  25 model loss: 3.09418, kl_loss: 3.00025, obs_loss: 0.09392, reward_loss: 0.00001, value_loss: 0.00998 action_loss: 19.86733\n",
      "update_step:  26 model loss: 3.10684, kl_loss: 3.00094, obs_loss: 0.10590, reward_loss: 0.00001, value_loss: 0.01029 action_loss: 19.89485\n",
      "update_step:  27 model loss: 3.11663, kl_loss: 3.00203, obs_loss: 0.11459, reward_loss: 0.00001, value_loss: 0.01085 action_loss: 19.92333\n",
      "update_step:  28 model loss: 3.10486, kl_loss: 3.00069, obs_loss: 0.10417, reward_loss: 0.00001, value_loss: 0.01050 action_loss: 19.89790\n",
      "update_step:  29 model loss: 3.10490, kl_loss: 3.00146, obs_loss: 0.10342, reward_loss: 0.00001, value_loss: 0.01041 action_loss: 19.88963\n",
      "update_step:  30 model loss: 3.07310, kl_loss: 3.00037, obs_loss: 0.07272, reward_loss: 0.00001, value_loss: 0.00970 action_loss: 19.82582\n",
      "update_step:  31 model loss: 3.04412, kl_loss: 3.00015, obs_loss: 0.04396, reward_loss: 0.00001, value_loss: 0.00991 action_loss: 19.80078\n",
      "update_step:  32 model loss: 3.03010, kl_loss: 3.00144, obs_loss: 0.02864, reward_loss: 0.00001, value_loss: 0.01013 action_loss: 19.76079\n",
      "update_step:  33 model loss: 3.02459, kl_loss: 3.00172, obs_loss: 0.02285, reward_loss: 0.00001, value_loss: 0.01016 action_loss: 19.76122\n",
      "update_step:  34 model loss: 3.03512, kl_loss: 3.00110, obs_loss: 0.03400, reward_loss: 0.00001, value_loss: 0.01012 action_loss: 19.77550\n",
      "update_step:  35 model loss: 3.04429, kl_loss: 3.00010, obs_loss: 0.04418, reward_loss: 0.00001, value_loss: 0.01008 action_loss: 19.79984\n",
      "update_step:  36 model loss: 3.05222, kl_loss: 3.00058, obs_loss: 0.05163, reward_loss: 0.00001, value_loss: 0.01022 action_loss: 19.84301\n",
      "update_step:  37 model loss: 3.04903, kl_loss: 3.00093, obs_loss: 0.04809, reward_loss: 0.00001, value_loss: 0.00989 action_loss: 19.86008\n",
      "update_step:  38 model loss: 3.04072, kl_loss: 3.00083, obs_loss: 0.03988, reward_loss: 0.00001, value_loss: 0.01042 action_loss: 19.88442\n",
      "update_step:  39 model loss: 3.02103, kl_loss: 3.00090, obs_loss: 0.02012, reward_loss: 0.00001, value_loss: 0.00993 action_loss: 19.88277\n",
      "update_step:  40 model loss: 3.01006, kl_loss: 3.00084, obs_loss: 0.00921, reward_loss: 0.00001, value_loss: 0.00980 action_loss: 19.87594\n",
      "update_step:  41 model loss: 3.01324, kl_loss: 3.00096, obs_loss: 0.01227, reward_loss: 0.00001, value_loss: 0.00951 action_loss: 19.85544\n",
      "update_step:  42 model loss: 3.02670, kl_loss: 3.00077, obs_loss: 0.02592, reward_loss: 0.00001, value_loss: 0.00947 action_loss: 19.82806\n",
      "update_step:  43 model loss: 3.03572, kl_loss: 3.00120, obs_loss: 0.03451, reward_loss: 0.00001, value_loss: 0.00949 action_loss: 19.82397\n",
      "update_step:  44 model loss: 3.04053, kl_loss: 3.00069, obs_loss: 0.03984, reward_loss: 0.00001, value_loss: 0.00954 action_loss: 19.80578\n",
      "update_step:  45 model loss: 3.03570, kl_loss: 3.00116, obs_loss: 0.03454, reward_loss: 0.00001, value_loss: 0.00959 action_loss: 19.80596\n",
      "update_step:  46 model loss: 3.02692, kl_loss: 3.00167, obs_loss: 0.02523, reward_loss: 0.00001, value_loss: 0.00961 action_loss: 19.80728\n",
      "update_step:  47 model loss: 3.01118, kl_loss: 3.00003, obs_loss: 0.01113, reward_loss: 0.00001, value_loss: 0.00964 action_loss: 19.83224\n",
      "update_step:  48 model loss: 3.01075, kl_loss: 3.00027, obs_loss: 0.01047, reward_loss: 0.00001, value_loss: 0.00959 action_loss: 19.84415\n",
      "update_step:  49 model loss: 3.01185, kl_loss: 3.00030, obs_loss: 0.01155, reward_loss: 0.00001, value_loss: 0.00957 action_loss: 19.84455\n",
      "update_step:  50 model loss: 3.01736, kl_loss: 3.00056, obs_loss: 0.01679, reward_loss: 0.00001, value_loss: 0.00956 action_loss: 19.85808\n",
      "update_step:  51 model loss: 3.02148, kl_loss: 3.00023, obs_loss: 0.02124, reward_loss: 0.00001, value_loss: 0.00945 action_loss: 19.85941\n",
      "update_step:  52 model loss: 3.02451, kl_loss: 3.00099, obs_loss: 0.02351, reward_loss: 0.00001, value_loss: 0.00961 action_loss: 19.86199\n",
      "update_step:  53 model loss: 3.01303, kl_loss: 3.00056, obs_loss: 0.01246, reward_loss: 0.00001, value_loss: 0.00951 action_loss: 19.84596\n",
      "update_step:  54 model loss: 3.02363, kl_loss: 3.00312, obs_loss: 0.02049, reward_loss: 0.00001, value_loss: 0.00954 action_loss: 19.83952\n",
      "update_step:  55 model loss: 3.00659, kl_loss: 3.00053, obs_loss: 0.00605, reward_loss: 0.00001, value_loss: 0.00977 action_loss: 19.83365\n",
      "update_step:  56 model loss: 3.01093, kl_loss: 3.00177, obs_loss: 0.00915, reward_loss: 0.00001, value_loss: 0.00953 action_loss: 19.82470\n",
      "update_step:  57 model loss: 3.01014, kl_loss: 3.00027, obs_loss: 0.00986, reward_loss: 0.00001, value_loss: 0.00964 action_loss: 19.82099\n",
      "update_step:  58 model loss: 3.02136, kl_loss: 3.00096, obs_loss: 0.02038, reward_loss: 0.00001, value_loss: 0.00964 action_loss: 19.81325\n",
      "update_step:  59 model loss: 3.01708, kl_loss: 3.00061, obs_loss: 0.01646, reward_loss: 0.00001, value_loss: 0.00960 action_loss: 19.81962\n",
      "update_step:  60 model loss: 3.02291, kl_loss: 3.00084, obs_loss: 0.02206, reward_loss: 0.00001, value_loss: 0.00969 action_loss: 19.80310\n",
      "update_step:  61 model loss: 3.01895, kl_loss: 3.00179, obs_loss: 0.01715, reward_loss: 0.00001, value_loss: 0.00944 action_loss: 19.82174\n",
      "update_step:  62 model loss: 3.01461, kl_loss: 3.00045, obs_loss: 0.01415, reward_loss: 0.00001, value_loss: 0.00945 action_loss: 19.82610\n",
      "update_step:  63 model loss: 3.01219, kl_loss: 3.00019, obs_loss: 0.01199, reward_loss: 0.00001, value_loss: 0.00955 action_loss: 19.83828\n",
      "update_step:  64 model loss: 3.01235, kl_loss: 3.00041, obs_loss: 0.01193, reward_loss: 0.00001, value_loss: 0.00934 action_loss: 19.83375\n",
      "update_step:  65 model loss: 3.01374, kl_loss: 3.00109, obs_loss: 0.01264, reward_loss: 0.00001, value_loss: 0.00933 action_loss: 19.84643\n",
      "update_step:  66 model loss: 3.01022, kl_loss: 3.00013, obs_loss: 0.01008, reward_loss: 0.00001, value_loss: 0.00955 action_loss: 19.84277\n",
      "update_step:  67 model loss: 3.01425, kl_loss: 3.00125, obs_loss: 0.01300, reward_loss: 0.00001, value_loss: 0.00938 action_loss: 19.83669\n",
      "update_step:  68 model loss: 3.01363, kl_loss: 3.00077, obs_loss: 0.01285, reward_loss: 0.00001, value_loss: 0.00934 action_loss: 19.84056\n",
      "update_step:  69 model loss: 3.01394, kl_loss: 3.00060, obs_loss: 0.01333, reward_loss: 0.00001, value_loss: 0.00943 action_loss: 19.83607\n",
      "update_step:  70 model loss: 3.01011, kl_loss: 3.00020, obs_loss: 0.00990, reward_loss: 0.00001, value_loss: 0.00958 action_loss: 19.84529\n",
      "update_step:  71 model loss: 3.01584, kl_loss: 3.00054, obs_loss: 0.01530, reward_loss: 0.00001, value_loss: 0.00923 action_loss: 19.83707\n",
      "update_step:  72 model loss: 3.02061, kl_loss: 3.00089, obs_loss: 0.01971, reward_loss: 0.00001, value_loss: 0.00932 action_loss: 19.85554\n",
      "update_step:  73 model loss: 3.01989, kl_loss: 3.00084, obs_loss: 0.01904, reward_loss: 0.00001, value_loss: 0.00934 action_loss: 19.85060\n",
      "update_step:  74 model loss: 3.01575, kl_loss: 3.00134, obs_loss: 0.01440, reward_loss: 0.00001, value_loss: 0.00964 action_loss: 19.86892\n",
      "update_step:  75 model loss: 3.01240, kl_loss: 3.00049, obs_loss: 0.01190, reward_loss: 0.00001, value_loss: 0.00927 action_loss: 19.86954\n",
      "update_step:  76 model loss: 3.01333, kl_loss: 3.00051, obs_loss: 0.01281, reward_loss: 0.00001, value_loss: 0.00955 action_loss: 19.87792\n",
      "update_step:  77 model loss: 3.01088, kl_loss: 3.00054, obs_loss: 0.01033, reward_loss: 0.00001, value_loss: 0.00929 action_loss: 19.86127\n",
      "update_step:  78 model loss: 3.00868, kl_loss: 3.00019, obs_loss: 0.00848, reward_loss: 0.00001, value_loss: 0.00929 action_loss: 19.85357\n",
      "update_step:  79 model loss: 3.01963, kl_loss: 3.00242, obs_loss: 0.01720, reward_loss: 0.00001, value_loss: 0.00949 action_loss: 19.83940\n",
      "update_step:  80 model loss: 3.01125, kl_loss: 3.00093, obs_loss: 0.01031, reward_loss: 0.00001, value_loss: 0.00924 action_loss: 19.83107\n",
      "update_step:  81 model loss: 3.00808, kl_loss: 3.00063, obs_loss: 0.00744, reward_loss: 0.00001, value_loss: 0.00930 action_loss: 19.82276\n",
      "update_step:  82 model loss: 3.00771, kl_loss: 3.00019, obs_loss: 0.00750, reward_loss: 0.00001, value_loss: 0.00935 action_loss: 19.82554\n",
      "update_step:  83 model loss: 3.01608, kl_loss: 3.00117, obs_loss: 0.01490, reward_loss: 0.00001, value_loss: 0.00929 action_loss: 19.83976\n",
      "update_step:  84 model loss: 3.02561, kl_loss: 3.00273, obs_loss: 0.02287, reward_loss: 0.00001, value_loss: 0.00956 action_loss: 19.84026\n",
      "update_step:  85 model loss: 3.01211, kl_loss: 3.00077, obs_loss: 0.01134, reward_loss: 0.00001, value_loss: 0.00926 action_loss: 19.85190\n",
      "update_step:  86 model loss: 3.01276, kl_loss: 3.00134, obs_loss: 0.01141, reward_loss: 0.00001, value_loss: 0.00907 action_loss: 19.84873\n",
      "update_step:  87 model loss: 3.01272, kl_loss: 3.00115, obs_loss: 0.01157, reward_loss: 0.00001, value_loss: 0.00936 action_loss: 19.86498\n",
      "update_step:  88 model loss: 3.02380, kl_loss: 3.00178, obs_loss: 0.02201, reward_loss: 0.00001, value_loss: 0.00958 action_loss: 19.84499\n",
      "update_step:  89 model loss: 3.03172, kl_loss: 3.00015, obs_loss: 0.03156, reward_loss: 0.00001, value_loss: 0.00961 action_loss: 19.86665\n",
      "update_step:  90 model loss: 3.04458, kl_loss: 3.00049, obs_loss: 0.04408, reward_loss: 0.00001, value_loss: 0.00937 action_loss: 19.83442\n",
      "update_step:  91 model loss: 3.04125, kl_loss: 3.00018, obs_loss: 0.04106, reward_loss: 0.00001, value_loss: 0.00937 action_loss: 19.83661\n",
      "update_step:  92 model loss: 3.04294, kl_loss: 3.00005, obs_loss: 0.04287, reward_loss: 0.00001, value_loss: 0.00958 action_loss: 19.79650\n",
      "update_step:  93 model loss: 3.04027, kl_loss: 3.00091, obs_loss: 0.03935, reward_loss: 0.00001, value_loss: 0.00956 action_loss: 19.81765\n",
      "update_step:  94 model loss: 3.03496, kl_loss: 3.00029, obs_loss: 0.03465, reward_loss: 0.00001, value_loss: 0.00955 action_loss: 19.80419\n",
      "update_step:  95 model loss: 3.03444, kl_loss: 3.00019, obs_loss: 0.03424, reward_loss: 0.00001, value_loss: 0.00963 action_loss: 19.82778\n",
      "update_step:  96 model loss: 3.03824, kl_loss: 3.00016, obs_loss: 0.03808, reward_loss: 0.00001, value_loss: 0.00960 action_loss: 19.81438\n",
      "update_step:  97 model loss: 3.03362, kl_loss: 3.00066, obs_loss: 0.03296, reward_loss: 0.00001, value_loss: 0.00992 action_loss: 19.84971\n",
      "update_step:  98 model loss: 3.03567, kl_loss: 3.00058, obs_loss: 0.03507, reward_loss: 0.00001, value_loss: 0.00957 action_loss: 19.83998\n",
      "update_step:  99 model loss: 3.03443, kl_loss: 3.00056, obs_loss: 0.03386, reward_loss: 0.00001, value_loss: 0.00979 action_loss: 19.84517\n",
      "update_step: 100 model loss: 3.04182, kl_loss: 3.00145, obs_loss: 0.04036, reward_loss: 0.00001, value_loss: 0.00999 action_loss: 19.80734\n",
      "elasped time for update: 20.31s\n",
      "episode [  24/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.02623, kl_loss: 3.00022, obs_loss: 0.02600, reward_loss: 0.00001, value_loss: 0.01014 action_loss: 19.81530\n",
      "update_step:   2 model loss: 3.02972, kl_loss: 3.00166, obs_loss: 0.02805, reward_loss: 0.00001, value_loss: 0.00971 action_loss: 19.79959\n",
      "update_step:   3 model loss: 3.02058, kl_loss: 3.00249, obs_loss: 0.01808, reward_loss: 0.00001, value_loss: 0.00939 action_loss: 19.81039\n",
      "update_step:   4 model loss: 3.02070, kl_loss: 3.00247, obs_loss: 0.01822, reward_loss: 0.00001, value_loss: 0.00967 action_loss: 19.83113\n",
      "update_step:   5 model loss: 3.01044, kl_loss: 3.00061, obs_loss: 0.00982, reward_loss: 0.00001, value_loss: 0.01001 action_loss: 19.86885\n",
      "update_step:   6 model loss: 3.01448, kl_loss: 3.00093, obs_loss: 0.01355, reward_loss: 0.00001, value_loss: 0.00975 action_loss: 19.88786\n",
      "update_step:   7 model loss: 3.00976, kl_loss: 3.00016, obs_loss: 0.00960, reward_loss: 0.00001, value_loss: 0.00992 action_loss: 19.87995\n",
      "update_step:   8 model loss: 3.01124, kl_loss: 3.00013, obs_loss: 0.01110, reward_loss: 0.00001, value_loss: 0.00974 action_loss: 19.86830\n",
      "update_step:   9 model loss: 3.01246, kl_loss: 3.00011, obs_loss: 0.01235, reward_loss: 0.00001, value_loss: 0.00975 action_loss: 19.86472\n",
      "update_step:  10 model loss: 3.01114, kl_loss: 3.00037, obs_loss: 0.01076, reward_loss: 0.00001, value_loss: 0.00947 action_loss: 19.83251\n",
      "update_step:  11 model loss: 3.01518, kl_loss: 3.00064, obs_loss: 0.01453, reward_loss: 0.00001, value_loss: 0.00958 action_loss: 19.80674\n",
      "update_step:  12 model loss: 3.01107, kl_loss: 3.00073, obs_loss: 0.01033, reward_loss: 0.00001, value_loss: 0.01007 action_loss: 19.80172\n",
      "update_step:  13 model loss: 3.01897, kl_loss: 3.00057, obs_loss: 0.01839, reward_loss: 0.00001, value_loss: 0.00991 action_loss: 19.82070\n",
      "update_step:  14 model loss: 3.00820, kl_loss: 3.00023, obs_loss: 0.00796, reward_loss: 0.00001, value_loss: 0.00963 action_loss: 19.83650\n",
      "update_step:  15 model loss: 3.01067, kl_loss: 3.00080, obs_loss: 0.00985, reward_loss: 0.00001, value_loss: 0.00953 action_loss: 19.85055\n",
      "update_step:  16 model loss: 3.01350, kl_loss: 3.00097, obs_loss: 0.01252, reward_loss: 0.00001, value_loss: 0.00971 action_loss: 19.88812\n",
      "update_step:  17 model loss: 3.01125, kl_loss: 3.00093, obs_loss: 0.01031, reward_loss: 0.00001, value_loss: 0.00956 action_loss: 19.90493\n",
      "update_step:  18 model loss: 3.01487, kl_loss: 3.00181, obs_loss: 0.01305, reward_loss: 0.00001, value_loss: 0.00966 action_loss: 19.90515\n",
      "update_step:  19 model loss: 3.01109, kl_loss: 3.00169, obs_loss: 0.00940, reward_loss: 0.00001, value_loss: 0.00972 action_loss: 19.88735\n",
      "update_step:  20 model loss: 3.01797, kl_loss: 3.00234, obs_loss: 0.01562, reward_loss: 0.00001, value_loss: 0.00946 action_loss: 19.87673\n",
      "update_step:  21 model loss: 3.00606, kl_loss: 3.00044, obs_loss: 0.00560, reward_loss: 0.00001, value_loss: 0.00939 action_loss: 19.85206\n",
      "update_step:  22 model loss: 3.00580, kl_loss: 3.00004, obs_loss: 0.00575, reward_loss: 0.00001, value_loss: 0.00940 action_loss: 19.83141\n",
      "update_step:  23 model loss: 3.00845, kl_loss: 3.00054, obs_loss: 0.00790, reward_loss: 0.00001, value_loss: 0.00913 action_loss: 19.81736\n",
      "update_step:  24 model loss: 3.00617, kl_loss: 3.00009, obs_loss: 0.00607, reward_loss: 0.00001, value_loss: 0.00935 action_loss: 19.82969\n",
      "update_step:  25 model loss: 3.02115, kl_loss: 3.00104, obs_loss: 0.02011, reward_loss: 0.00001, value_loss: 0.00926 action_loss: 19.84906\n",
      "update_step:  26 model loss: 3.00746, kl_loss: 3.00070, obs_loss: 0.00675, reward_loss: 0.00001, value_loss: 0.00908 action_loss: 19.86719\n",
      "update_step:  27 model loss: 3.00744, kl_loss: 3.00021, obs_loss: 0.00722, reward_loss: 0.00001, value_loss: 0.00922 action_loss: 19.88404\n",
      "update_step:  28 model loss: 3.00998, kl_loss: 3.00134, obs_loss: 0.00863, reward_loss: 0.00001, value_loss: 0.00911 action_loss: 19.90446\n",
      "update_step:  29 model loss: 3.00994, kl_loss: 3.00046, obs_loss: 0.00947, reward_loss: 0.00001, value_loss: 0.00929 action_loss: 19.89981\n",
      "update_step:  30 model loss: 3.00887, kl_loss: 3.00031, obs_loss: 0.00856, reward_loss: 0.00001, value_loss: 0.00917 action_loss: 19.89049\n",
      "update_step:  31 model loss: 3.01177, kl_loss: 3.00121, obs_loss: 0.01055, reward_loss: 0.00001, value_loss: 0.00897 action_loss: 19.85757\n",
      "update_step:  32 model loss: 3.02387, kl_loss: 3.00206, obs_loss: 0.02181, reward_loss: 0.00001, value_loss: 0.00910 action_loss: 19.85235\n",
      "update_step:  33 model loss: 3.02427, kl_loss: 3.00103, obs_loss: 0.02324, reward_loss: 0.00001, value_loss: 0.00934 action_loss: 19.81372\n",
      "update_step:  34 model loss: 3.02408, kl_loss: 3.00022, obs_loss: 0.02384, reward_loss: 0.00001, value_loss: 0.00920 action_loss: 19.82352\n",
      "update_step:  35 model loss: 3.02755, kl_loss: 3.00102, obs_loss: 0.02652, reward_loss: 0.00001, value_loss: 0.00919 action_loss: 19.79824\n",
      "update_step:  36 model loss: 3.02487, kl_loss: 3.00005, obs_loss: 0.02481, reward_loss: 0.00001, value_loss: 0.00903 action_loss: 19.82239\n",
      "update_step:  37 model loss: 3.02242, kl_loss: 3.00057, obs_loss: 0.02184, reward_loss: 0.00001, value_loss: 0.00911 action_loss: 19.82183\n",
      "update_step:  38 model loss: 3.01861, kl_loss: 3.00009, obs_loss: 0.01852, reward_loss: 0.00001, value_loss: 0.00923 action_loss: 19.84841\n",
      "update_step:  39 model loss: 3.02225, kl_loss: 3.00089, obs_loss: 0.02135, reward_loss: 0.00001, value_loss: 0.00913 action_loss: 19.86171\n",
      "update_step:  40 model loss: 3.01622, kl_loss: 3.00085, obs_loss: 0.01537, reward_loss: 0.00001, value_loss: 0.00904 action_loss: 19.88775\n",
      "update_step:  41 model loss: 3.01470, kl_loss: 3.00138, obs_loss: 0.01331, reward_loss: 0.00001, value_loss: 0.00915 action_loss: 19.88874\n",
      "update_step:  42 model loss: 3.01188, kl_loss: 3.00117, obs_loss: 0.01070, reward_loss: 0.00001, value_loss: 0.00912 action_loss: 19.87839\n",
      "update_step:  43 model loss: 3.01135, kl_loss: 3.00131, obs_loss: 0.01003, reward_loss: 0.00001, value_loss: 0.00916 action_loss: 19.86041\n",
      "update_step:  44 model loss: 3.01354, kl_loss: 3.00124, obs_loss: 0.01229, reward_loss: 0.00001, value_loss: 0.00912 action_loss: 19.83639\n",
      "update_step:  45 model loss: 3.01033, kl_loss: 3.00166, obs_loss: 0.00866, reward_loss: 0.00001, value_loss: 0.00936 action_loss: 19.82959\n",
      "update_step:  46 model loss: 3.01212, kl_loss: 3.00053, obs_loss: 0.01159, reward_loss: 0.00001, value_loss: 0.00934 action_loss: 19.80769\n",
      "update_step:  47 model loss: 3.01876, kl_loss: 3.00118, obs_loss: 0.01757, reward_loss: 0.00001, value_loss: 0.00920 action_loss: 19.82225\n",
      "update_step:  48 model loss: 3.02072, kl_loss: 3.00023, obs_loss: 0.02048, reward_loss: 0.00001, value_loss: 0.00912 action_loss: 19.80584\n",
      "update_step:  49 model loss: 3.02811, kl_loss: 3.00102, obs_loss: 0.02708, reward_loss: 0.00001, value_loss: 0.00912 action_loss: 19.83068\n",
      "update_step:  50 model loss: 3.02139, kl_loss: 3.00015, obs_loss: 0.02123, reward_loss: 0.00001, value_loss: 0.00911 action_loss: 19.83057\n",
      "update_step:  51 model loss: 3.02715, kl_loss: 3.00038, obs_loss: 0.02677, reward_loss: 0.00001, value_loss: 0.00920 action_loss: 19.87552\n",
      "update_step:  52 model loss: 3.02847, kl_loss: 3.00069, obs_loss: 0.02777, reward_loss: 0.00001, value_loss: 0.00889 action_loss: 19.88786\n",
      "update_step:  53 model loss: 3.03340, kl_loss: 3.00115, obs_loss: 0.03224, reward_loss: 0.00001, value_loss: 0.00942 action_loss: 19.92431\n",
      "update_step:  54 model loss: 3.02523, kl_loss: 3.00042, obs_loss: 0.02480, reward_loss: 0.00001, value_loss: 0.00958 action_loss: 19.91218\n",
      "update_step:  55 model loss: 3.01900, kl_loss: 3.00077, obs_loss: 0.01823, reward_loss: 0.00001, value_loss: 0.00936 action_loss: 19.91596\n",
      "update_step:  56 model loss: 3.01768, kl_loss: 3.00044, obs_loss: 0.01724, reward_loss: 0.00001, value_loss: 0.00905 action_loss: 19.89292\n",
      "update_step:  57 model loss: 3.01620, kl_loss: 3.00189, obs_loss: 0.01430, reward_loss: 0.00001, value_loss: 0.00917 action_loss: 19.87738\n",
      "update_step:  58 model loss: 3.01508, kl_loss: 3.00106, obs_loss: 0.01401, reward_loss: 0.00001, value_loss: 0.00903 action_loss: 19.85519\n",
      "update_step:  59 model loss: 3.01967, kl_loss: 3.00152, obs_loss: 0.01815, reward_loss: 0.00001, value_loss: 0.00882 action_loss: 19.83942\n",
      "update_step:  60 model loss: 3.01471, kl_loss: 3.00056, obs_loss: 0.01414, reward_loss: 0.00001, value_loss: 0.00954 action_loss: 19.84276\n",
      "update_step:  61 model loss: 3.01034, kl_loss: 3.00097, obs_loss: 0.00936, reward_loss: 0.00001, value_loss: 0.00924 action_loss: 19.83973\n",
      "update_step:  62 model loss: 3.00958, kl_loss: 3.00005, obs_loss: 0.00952, reward_loss: 0.00001, value_loss: 0.00895 action_loss: 19.85439\n",
      "update_step:  63 model loss: 3.00995, kl_loss: 3.00003, obs_loss: 0.00991, reward_loss: 0.00001, value_loss: 0.00904 action_loss: 19.85340\n",
      "update_step:  64 model loss: 3.02001, kl_loss: 3.00078, obs_loss: 0.01922, reward_loss: 0.00001, value_loss: 0.00893 action_loss: 19.87094\n",
      "update_step:  65 model loss: 3.02435, kl_loss: 3.00104, obs_loss: 0.02330, reward_loss: 0.00001, value_loss: 0.00901 action_loss: 19.84923\n",
      "update_step:  66 model loss: 3.03227, kl_loss: 3.00097, obs_loss: 0.03129, reward_loss: 0.00001, value_loss: 0.00938 action_loss: 19.86705\n",
      "update_step:  67 model loss: 3.03013, kl_loss: 3.00047, obs_loss: 0.02965, reward_loss: 0.00001, value_loss: 0.00883 action_loss: 19.84681\n",
      "update_step:  68 model loss: 3.04710, kl_loss: 3.00137, obs_loss: 0.04571, reward_loss: 0.00001, value_loss: 0.00908 action_loss: 19.87971\n",
      "update_step:  69 model loss: 3.04934, kl_loss: 3.00002, obs_loss: 0.04931, reward_loss: 0.00001, value_loss: 0.00901 action_loss: 19.84599\n",
      "update_step:  70 model loss: 3.07276, kl_loss: 3.00095, obs_loss: 0.07181, reward_loss: 0.00001, value_loss: 0.00917 action_loss: 19.87434\n",
      "update_step:  71 model loss: 3.07502, kl_loss: 3.00148, obs_loss: 0.07353, reward_loss: 0.00001, value_loss: 0.00892 action_loss: 19.83887\n",
      "update_step:  72 model loss: 3.10854, kl_loss: 3.00108, obs_loss: 0.10744, reward_loss: 0.00001, value_loss: 0.00901 action_loss: 19.89218\n",
      "update_step:  73 model loss: 3.12829, kl_loss: 3.00037, obs_loss: 0.12790, reward_loss: 0.00002, value_loss: 0.00867 action_loss: 19.82901\n",
      "update_step:  74 model loss: 3.17624, kl_loss: 3.00095, obs_loss: 0.17527, reward_loss: 0.00002, value_loss: 0.00943 action_loss: 19.87343\n",
      "update_step:  75 model loss: 3.16570, kl_loss: 3.00028, obs_loss: 0.16541, reward_loss: 0.00001, value_loss: 0.00907 action_loss: 19.82276\n",
      "update_step:  76 model loss: 3.14729, kl_loss: 3.00017, obs_loss: 0.14711, reward_loss: 0.00001, value_loss: 0.00925 action_loss: 19.86408\n",
      "update_step:  77 model loss: 3.08522, kl_loss: 3.00054, obs_loss: 0.08467, reward_loss: 0.00001, value_loss: 0.00940 action_loss: 19.84827\n",
      "update_step:  78 model loss: 3.03632, kl_loss: 3.00007, obs_loss: 0.03623, reward_loss: 0.00001, value_loss: 0.00939 action_loss: 19.88016\n",
      "update_step:  79 model loss: 3.02203, kl_loss: 3.00031, obs_loss: 0.02171, reward_loss: 0.00001, value_loss: 0.00960 action_loss: 19.92678\n",
      "update_step:  80 model loss: 3.04182, kl_loss: 3.00077, obs_loss: 0.04104, reward_loss: 0.00001, value_loss: 0.00948 action_loss: 19.92306\n",
      "update_step:  81 model loss: 3.06860, kl_loss: 3.00087, obs_loss: 0.06772, reward_loss: 0.00001, value_loss: 0.00980 action_loss: 19.94862\n",
      "update_step:  82 model loss: 3.06577, kl_loss: 3.00102, obs_loss: 0.06474, reward_loss: 0.00001, value_loss: 0.00939 action_loss: 19.91309\n",
      "update_step:  83 model loss: 3.05510, kl_loss: 3.00041, obs_loss: 0.05468, reward_loss: 0.00001, value_loss: 0.00986 action_loss: 19.91570\n",
      "update_step:  84 model loss: 3.03637, kl_loss: 3.00061, obs_loss: 0.03574, reward_loss: 0.00001, value_loss: 0.00953 action_loss: 19.87450\n",
      "update_step:  85 model loss: 3.01752, kl_loss: 3.00062, obs_loss: 0.01688, reward_loss: 0.00001, value_loss: 0.00974 action_loss: 19.83569\n",
      "update_step:  86 model loss: 3.02746, kl_loss: 3.00144, obs_loss: 0.02601, reward_loss: 0.00001, value_loss: 0.00990 action_loss: 19.84341\n",
      "update_step:  87 model loss: 3.06532, kl_loss: 3.00136, obs_loss: 0.06394, reward_loss: 0.00001, value_loss: 0.01026 action_loss: 19.81125\n",
      "update_step:  88 model loss: 3.10289, kl_loss: 3.00166, obs_loss: 0.10121, reward_loss: 0.00001, value_loss: 0.01025 action_loss: 19.84491\n",
      "update_step:  89 model loss: 3.10228, kl_loss: 3.00237, obs_loss: 0.09990, reward_loss: 0.00001, value_loss: 0.01013 action_loss: 19.82068\n",
      "update_step:  90 model loss: 3.05119, kl_loss: 3.00076, obs_loss: 0.05043, reward_loss: 0.00001, value_loss: 0.00981 action_loss: 19.85175\n",
      "update_step:  91 model loss: 3.01527, kl_loss: 3.00051, obs_loss: 0.01475, reward_loss: 0.00001, value_loss: 0.00973 action_loss: 19.86343\n",
      "update_step:  92 model loss: 3.01591, kl_loss: 3.00086, obs_loss: 0.01504, reward_loss: 0.00001, value_loss: 0.00969 action_loss: 19.87380\n",
      "update_step:  93 model loss: 3.03605, kl_loss: 3.00017, obs_loss: 0.03587, reward_loss: 0.00001, value_loss: 0.00994 action_loss: 19.91862\n",
      "update_step:  94 model loss: 3.05709, kl_loss: 3.00044, obs_loss: 0.05664, reward_loss: 0.00001, value_loss: 0.00965 action_loss: 19.89424\n",
      "update_step:  95 model loss: 3.04767, kl_loss: 3.00022, obs_loss: 0.04744, reward_loss: 0.00001, value_loss: 0.00986 action_loss: 19.89597\n",
      "update_step:  96 model loss: 3.02478, kl_loss: 3.00060, obs_loss: 0.02417, reward_loss: 0.00001, value_loss: 0.00981 action_loss: 19.87609\n",
      "update_step:  97 model loss: 3.01369, kl_loss: 3.00070, obs_loss: 0.01298, reward_loss: 0.00001, value_loss: 0.01015 action_loss: 19.87331\n",
      "update_step:  98 model loss: 3.02732, kl_loss: 3.00121, obs_loss: 0.02610, reward_loss: 0.00001, value_loss: 0.00976 action_loss: 19.87588\n",
      "update_step:  99 model loss: 3.01496, kl_loss: 3.00070, obs_loss: 0.01425, reward_loss: 0.00001, value_loss: 0.00972 action_loss: 19.86267\n",
      "update_step: 100 model loss: 3.01711, kl_loss: 3.00044, obs_loss: 0.01666, reward_loss: 0.00001, value_loss: 0.01001 action_loss: 19.89094\n",
      "elasped time for update: 20.30s\n",
      "episode [  25/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01203, kl_loss: 3.00043, obs_loss: 0.01160, reward_loss: 0.00001, value_loss: 0.00965 action_loss: 19.89973\n",
      "update_step:   2 model loss: 3.01579, kl_loss: 3.00161, obs_loss: 0.01416, reward_loss: 0.00001, value_loss: 0.00963 action_loss: 19.90946\n",
      "update_step:   3 model loss: 3.01739, kl_loss: 3.00185, obs_loss: 0.01554, reward_loss: 0.00001, value_loss: 0.00993 action_loss: 19.92103\n",
      "update_step:   4 model loss: 3.01772, kl_loss: 3.00074, obs_loss: 0.01696, reward_loss: 0.00001, value_loss: 0.00967 action_loss: 19.91617\n",
      "update_step:   5 model loss: 3.02125, kl_loss: 3.00021, obs_loss: 0.02103, reward_loss: 0.00001, value_loss: 0.00963 action_loss: 19.92761\n",
      "update_step:   6 model loss: 3.01726, kl_loss: 3.00025, obs_loss: 0.01699, reward_loss: 0.00001, value_loss: 0.00943 action_loss: 19.90455\n",
      "update_step:   7 model loss: 3.01952, kl_loss: 3.00060, obs_loss: 0.01891, reward_loss: 0.00001, value_loss: 0.00954 action_loss: 19.89324\n",
      "update_step:   8 model loss: 3.01311, kl_loss: 3.00058, obs_loss: 0.01252, reward_loss: 0.00001, value_loss: 0.00945 action_loss: 19.87378\n",
      "update_step:   9 model loss: 3.01346, kl_loss: 3.00036, obs_loss: 0.01309, reward_loss: 0.00001, value_loss: 0.00996 action_loss: 19.84914\n",
      "update_step:  10 model loss: 3.00949, kl_loss: 3.00028, obs_loss: 0.00921, reward_loss: 0.00001, value_loss: 0.00966 action_loss: 19.84354\n",
      "update_step:  11 model loss: 3.01605, kl_loss: 3.00116, obs_loss: 0.01489, reward_loss: 0.00001, value_loss: 0.00938 action_loss: 19.83284\n",
      "update_step:  12 model loss: 3.00911, kl_loss: 3.00073, obs_loss: 0.00837, reward_loss: 0.00001, value_loss: 0.00921 action_loss: 19.85007\n",
      "update_step:  13 model loss: 3.00961, kl_loss: 3.00125, obs_loss: 0.00835, reward_loss: 0.00001, value_loss: 0.00918 action_loss: 19.87378\n",
      "update_step:  14 model loss: 3.01400, kl_loss: 3.00078, obs_loss: 0.01321, reward_loss: 0.00001, value_loss: 0.00919 action_loss: 19.89665\n",
      "update_step:  15 model loss: 3.00818, kl_loss: 3.00061, obs_loss: 0.00756, reward_loss: 0.00001, value_loss: 0.00903 action_loss: 19.92246\n",
      "update_step:  16 model loss: 3.01338, kl_loss: 3.00086, obs_loss: 0.01251, reward_loss: 0.00001, value_loss: 0.00922 action_loss: 19.92725\n",
      "update_step:  17 model loss: 3.01488, kl_loss: 3.00070, obs_loss: 0.01417, reward_loss: 0.00001, value_loss: 0.00925 action_loss: 19.93302\n",
      "update_step:  18 model loss: 3.01107, kl_loss: 3.00056, obs_loss: 0.01050, reward_loss: 0.00001, value_loss: 0.00930 action_loss: 19.90728\n",
      "update_step:  19 model loss: 3.00861, kl_loss: 3.00027, obs_loss: 0.00833, reward_loss: 0.00001, value_loss: 0.00908 action_loss: 19.88185\n",
      "update_step:  20 model loss: 3.00794, kl_loss: 3.00058, obs_loss: 0.00736, reward_loss: 0.00001, value_loss: 0.00905 action_loss: 19.85301\n",
      "update_step:  21 model loss: 3.00689, kl_loss: 3.00034, obs_loss: 0.00654, reward_loss: 0.00001, value_loss: 0.00902 action_loss: 19.82854\n",
      "update_step:  22 model loss: 3.01045, kl_loss: 3.00086, obs_loss: 0.00958, reward_loss: 0.00001, value_loss: 0.00928 action_loss: 19.82415\n",
      "update_step:  23 model loss: 3.00753, kl_loss: 3.00060, obs_loss: 0.00692, reward_loss: 0.00001, value_loss: 0.00926 action_loss: 19.81351\n",
      "update_step:  24 model loss: 3.00587, kl_loss: 3.00031, obs_loss: 0.00555, reward_loss: 0.00001, value_loss: 0.00896 action_loss: 19.82576\n",
      "update_step:  25 model loss: 3.00644, kl_loss: 3.00031, obs_loss: 0.00612, reward_loss: 0.00001, value_loss: 0.00885 action_loss: 19.83527\n",
      "update_step:  26 model loss: 3.01108, kl_loss: 3.00100, obs_loss: 0.01007, reward_loss: 0.00001, value_loss: 0.00897 action_loss: 19.86029\n",
      "update_step:  27 model loss: 3.00914, kl_loss: 3.00092, obs_loss: 0.00821, reward_loss: 0.00001, value_loss: 0.00903 action_loss: 19.88079\n",
      "update_step:  28 model loss: 3.00664, kl_loss: 3.00050, obs_loss: 0.00613, reward_loss: 0.00001, value_loss: 0.00929 action_loss: 19.88963\n",
      "update_step:  29 model loss: 3.00776, kl_loss: 3.00041, obs_loss: 0.00734, reward_loss: 0.00001, value_loss: 0.00926 action_loss: 19.89343\n",
      "update_step:  30 model loss: 3.00665, kl_loss: 3.00018, obs_loss: 0.00646, reward_loss: 0.00001, value_loss: 0.00925 action_loss: 19.88808\n",
      "update_step:  31 model loss: 3.00971, kl_loss: 3.00053, obs_loss: 0.00918, reward_loss: 0.00001, value_loss: 0.00917 action_loss: 19.88142\n",
      "update_step:  32 model loss: 3.00535, kl_loss: 3.00013, obs_loss: 0.00520, reward_loss: 0.00001, value_loss: 0.00900 action_loss: 19.86913\n",
      "update_step:  33 model loss: 3.01440, kl_loss: 3.00166, obs_loss: 0.01273, reward_loss: 0.00001, value_loss: 0.00904 action_loss: 19.85450\n",
      "update_step:  34 model loss: 3.00682, kl_loss: 3.00025, obs_loss: 0.00656, reward_loss: 0.00001, value_loss: 0.00913 action_loss: 19.84502\n",
      "update_step:  35 model loss: 3.00674, kl_loss: 3.00105, obs_loss: 0.00568, reward_loss: 0.00001, value_loss: 0.00916 action_loss: 19.84585\n",
      "update_step:  36 model loss: 3.00759, kl_loss: 3.00058, obs_loss: 0.00700, reward_loss: 0.00001, value_loss: 0.00904 action_loss: 19.85493\n",
      "update_step:  37 model loss: 3.00770, kl_loss: 3.00038, obs_loss: 0.00731, reward_loss: 0.00001, value_loss: 0.00912 action_loss: 19.87535\n",
      "update_step:  38 model loss: 3.00738, kl_loss: 3.00035, obs_loss: 0.00702, reward_loss: 0.00001, value_loss: 0.00907 action_loss: 19.89479\n",
      "update_step:  39 model loss: 3.01557, kl_loss: 3.00092, obs_loss: 0.01464, reward_loss: 0.00001, value_loss: 0.00923 action_loss: 19.91955\n",
      "update_step:  40 model loss: 3.01460, kl_loss: 3.00104, obs_loss: 0.01355, reward_loss: 0.00001, value_loss: 0.00896 action_loss: 19.91701\n",
      "update_step:  41 model loss: 3.01026, kl_loss: 3.00056, obs_loss: 0.00969, reward_loss: 0.00001, value_loss: 0.00940 action_loss: 19.92807\n",
      "update_step:  42 model loss: 3.01675, kl_loss: 3.00174, obs_loss: 0.01500, reward_loss: 0.00001, value_loss: 0.00899 action_loss: 19.91840\n",
      "update_step:  43 model loss: 3.01886, kl_loss: 3.00076, obs_loss: 0.01809, reward_loss: 0.00001, value_loss: 0.00907 action_loss: 19.91855\n",
      "update_step:  44 model loss: 3.00861, kl_loss: 3.00056, obs_loss: 0.00804, reward_loss: 0.00001, value_loss: 0.00874 action_loss: 19.90540\n",
      "update_step:  45 model loss: 3.00930, kl_loss: 3.00091, obs_loss: 0.00839, reward_loss: 0.00001, value_loss: 0.00888 action_loss: 19.88375\n",
      "update_step:  46 model loss: 3.01201, kl_loss: 3.00128, obs_loss: 0.01072, reward_loss: 0.00001, value_loss: 0.00922 action_loss: 19.86876\n",
      "update_step:  47 model loss: 3.01286, kl_loss: 3.00192, obs_loss: 0.01094, reward_loss: 0.00001, value_loss: 0.00889 action_loss: 19.84985\n",
      "update_step:  48 model loss: 3.00911, kl_loss: 3.00053, obs_loss: 0.00857, reward_loss: 0.00001, value_loss: 0.00894 action_loss: 19.85832\n",
      "update_step:  49 model loss: 3.01198, kl_loss: 3.00082, obs_loss: 0.01115, reward_loss: 0.00001, value_loss: 0.00897 action_loss: 19.85297\n",
      "update_step:  50 model loss: 3.02126, kl_loss: 3.00184, obs_loss: 0.01941, reward_loss: 0.00001, value_loss: 0.00872 action_loss: 19.86551\n",
      "update_step:  51 model loss: 3.01366, kl_loss: 3.00065, obs_loss: 0.01301, reward_loss: 0.00001, value_loss: 0.00885 action_loss: 19.87547\n",
      "update_step:  52 model loss: 3.00877, kl_loss: 3.00015, obs_loss: 0.00862, reward_loss: 0.00001, value_loss: 0.00879 action_loss: 19.89086\n",
      "update_step:  53 model loss: 3.01214, kl_loss: 3.00035, obs_loss: 0.01179, reward_loss: 0.00001, value_loss: 0.00879 action_loss: 19.90006\n",
      "update_step:  54 model loss: 3.01773, kl_loss: 3.00127, obs_loss: 0.01645, reward_loss: 0.00001, value_loss: 0.00890 action_loss: 19.90881\n",
      "update_step:  55 model loss: 3.01227, kl_loss: 3.00028, obs_loss: 0.01198, reward_loss: 0.00001, value_loss: 0.00879 action_loss: 19.91158\n",
      "update_step:  56 model loss: 3.00947, kl_loss: 3.00000, obs_loss: 0.00946, reward_loss: 0.00001, value_loss: 0.00858 action_loss: 19.89535\n",
      "update_step:  57 model loss: 3.01191, kl_loss: 3.00000, obs_loss: 0.01190, reward_loss: 0.00001, value_loss: 0.00876 action_loss: 19.88154\n",
      "update_step:  58 model loss: 3.01431, kl_loss: 3.00013, obs_loss: 0.01417, reward_loss: 0.00001, value_loss: 0.00911 action_loss: 19.85629\n",
      "update_step:  59 model loss: 3.01621, kl_loss: 3.00048, obs_loss: 0.01572, reward_loss: 0.00001, value_loss: 0.00898 action_loss: 19.85695\n",
      "update_step:  60 model loss: 3.01713, kl_loss: 3.00024, obs_loss: 0.01688, reward_loss: 0.00001, value_loss: 0.00867 action_loss: 19.84481\n",
      "update_step:  61 model loss: 3.01613, kl_loss: 3.00017, obs_loss: 0.01595, reward_loss: 0.00001, value_loss: 0.00892 action_loss: 19.86298\n",
      "update_step:  62 model loss: 3.01905, kl_loss: 3.00017, obs_loss: 0.01888, reward_loss: 0.00001, value_loss: 0.00860 action_loss: 19.88286\n",
      "update_step:  63 model loss: 3.02198, kl_loss: 3.00016, obs_loss: 0.02182, reward_loss: 0.00001, value_loss: 0.00855 action_loss: 19.89796\n",
      "update_step:  64 model loss: 3.02564, kl_loss: 3.00020, obs_loss: 0.02543, reward_loss: 0.00001, value_loss: 0.00864 action_loss: 19.91271\n",
      "update_step:  65 model loss: 3.04394, kl_loss: 3.00214, obs_loss: 0.04179, reward_loss: 0.00001, value_loss: 0.00858 action_loss: 19.90919\n",
      "update_step:  66 model loss: 3.03820, kl_loss: 3.00020, obs_loss: 0.03799, reward_loss: 0.00001, value_loss: 0.00850 action_loss: 19.90907\n",
      "update_step:  67 model loss: 3.04892, kl_loss: 3.00058, obs_loss: 0.04834, reward_loss: 0.00001, value_loss: 0.00850 action_loss: 19.88253\n",
      "update_step:  68 model loss: 3.05446, kl_loss: 3.00000, obs_loss: 0.05446, reward_loss: 0.00001, value_loss: 0.00850 action_loss: 19.87220\n",
      "update_step:  69 model loss: 3.06692, kl_loss: 3.00077, obs_loss: 0.06614, reward_loss: 0.00001, value_loss: 0.00845 action_loss: 19.85442\n",
      "update_step:  70 model loss: 3.08044, kl_loss: 3.00059, obs_loss: 0.07985, reward_loss: 0.00001, value_loss: 0.00858 action_loss: 19.85416\n",
      "update_step:  71 model loss: 3.08019, kl_loss: 3.00079, obs_loss: 0.07939, reward_loss: 0.00001, value_loss: 0.00861 action_loss: 19.84904\n",
      "update_step:  72 model loss: 3.07448, kl_loss: 3.00011, obs_loss: 0.07436, reward_loss: 0.00001, value_loss: 0.00845 action_loss: 19.86244\n",
      "update_step:  73 model loss: 3.06509, kl_loss: 3.00102, obs_loss: 0.06405, reward_loss: 0.00001, value_loss: 0.00864 action_loss: 19.88986\n",
      "update_step:  74 model loss: 3.05933, kl_loss: 3.00080, obs_loss: 0.05852, reward_loss: 0.00001, value_loss: 0.00841 action_loss: 19.89521\n",
      "update_step:  75 model loss: 3.05276, kl_loss: 3.00032, obs_loss: 0.05244, reward_loss: 0.00001, value_loss: 0.00854 action_loss: 19.92181\n",
      "update_step:  76 model loss: 3.04830, kl_loss: 3.00042, obs_loss: 0.04787, reward_loss: 0.00001, value_loss: 0.00867 action_loss: 19.90970\n",
      "update_step:  77 model loss: 3.04066, kl_loss: 3.00022, obs_loss: 0.04043, reward_loss: 0.00001, value_loss: 0.00859 action_loss: 19.92759\n",
      "update_step:  78 model loss: 3.03009, kl_loss: 3.00006, obs_loss: 0.03002, reward_loss: 0.00001, value_loss: 0.00836 action_loss: 19.89882\n",
      "update_step:  79 model loss: 3.02303, kl_loss: 3.00042, obs_loss: 0.02260, reward_loss: 0.00001, value_loss: 0.00840 action_loss: 19.88519\n",
      "update_step:  80 model loss: 3.01582, kl_loss: 3.00039, obs_loss: 0.01543, reward_loss: 0.00001, value_loss: 0.00840 action_loss: 19.86824\n",
      "update_step:  81 model loss: 3.01028, kl_loss: 3.00002, obs_loss: 0.01025, reward_loss: 0.00001, value_loss: 0.00850 action_loss: 19.86210\n",
      "update_step:  82 model loss: 3.01862, kl_loss: 3.00052, obs_loss: 0.01809, reward_loss: 0.00001, value_loss: 0.00856 action_loss: 19.86197\n",
      "update_step:  83 model loss: 3.01299, kl_loss: 3.00011, obs_loss: 0.01287, reward_loss: 0.00001, value_loss: 0.00837 action_loss: 19.85236\n",
      "update_step:  84 model loss: 3.01520, kl_loss: 3.00019, obs_loss: 0.01500, reward_loss: 0.00001, value_loss: 0.00821 action_loss: 19.86927\n",
      "update_step:  85 model loss: 3.02065, kl_loss: 3.00070, obs_loss: 0.01994, reward_loss: 0.00001, value_loss: 0.00843 action_loss: 19.86707\n",
      "update_step:  86 model loss: 3.01956, kl_loss: 3.00108, obs_loss: 0.01847, reward_loss: 0.00001, value_loss: 0.00856 action_loss: 19.88130\n",
      "update_step:  87 model loss: 3.01509, kl_loss: 3.00037, obs_loss: 0.01471, reward_loss: 0.00001, value_loss: 0.00864 action_loss: 19.87728\n",
      "update_step:  88 model loss: 3.01224, kl_loss: 3.00091, obs_loss: 0.01132, reward_loss: 0.00001, value_loss: 0.00864 action_loss: 19.88471\n",
      "update_step:  89 model loss: 3.01565, kl_loss: 3.00170, obs_loss: 0.01395, reward_loss: 0.00001, value_loss: 0.00875 action_loss: 19.89141\n",
      "update_step:  90 model loss: 3.01818, kl_loss: 3.00126, obs_loss: 0.01691, reward_loss: 0.00001, value_loss: 0.00813 action_loss: 19.87972\n",
      "update_step:  91 model loss: 3.01627, kl_loss: 3.00031, obs_loss: 0.01596, reward_loss: 0.00001, value_loss: 0.00833 action_loss: 19.88744\n",
      "update_step:  92 model loss: 3.01872, kl_loss: 3.00044, obs_loss: 0.01827, reward_loss: 0.00001, value_loss: 0.00836 action_loss: 19.87497\n",
      "update_step:  93 model loss: 3.01905, kl_loss: 3.00015, obs_loss: 0.01890, reward_loss: 0.00001, value_loss: 0.00804 action_loss: 19.87801\n",
      "update_step:  94 model loss: 3.01474, kl_loss: 3.00030, obs_loss: 0.01443, reward_loss: 0.00001, value_loss: 0.00819 action_loss: 19.85881\n",
      "update_step:  95 model loss: 3.02516, kl_loss: 3.00166, obs_loss: 0.02348, reward_loss: 0.00001, value_loss: 0.00830 action_loss: 19.87102\n",
      "update_step:  96 model loss: 3.00960, kl_loss: 3.00036, obs_loss: 0.00923, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 19.87066\n",
      "update_step:  97 model loss: 3.01239, kl_loss: 3.00115, obs_loss: 0.01123, reward_loss: 0.00001, value_loss: 0.00813 action_loss: 19.87048\n",
      "update_step:  98 model loss: 3.00911, kl_loss: 3.00066, obs_loss: 0.00844, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 19.88228\n",
      "update_step:  99 model loss: 3.01373, kl_loss: 3.00104, obs_loss: 0.01269, reward_loss: 0.00001, value_loss: 0.00822 action_loss: 19.88675\n",
      "update_step: 100 model loss: 3.01004, kl_loss: 3.00054, obs_loss: 0.00949, reward_loss: 0.00001, value_loss: 0.00830 action_loss: 19.89567\n",
      "elasped time for update: 20.36s\n",
      "episode [  26/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.37s\n",
      "update_step:   1 model loss: 3.01206, kl_loss: 3.00031, obs_loss: 0.01174, reward_loss: 0.00001, value_loss: 0.00820 action_loss: 19.88139\n",
      "update_step:   2 model loss: 3.02170, kl_loss: 3.00067, obs_loss: 0.02102, reward_loss: 0.00001, value_loss: 0.00818 action_loss: 19.89813\n",
      "update_step:   3 model loss: 3.02325, kl_loss: 3.00045, obs_loss: 0.02279, reward_loss: 0.00001, value_loss: 0.00805 action_loss: 19.87817\n",
      "update_step:   4 model loss: 3.02994, kl_loss: 3.00076, obs_loss: 0.02916, reward_loss: 0.00001, value_loss: 0.00803 action_loss: 19.88511\n",
      "update_step:   5 model loss: 3.01493, kl_loss: 3.00010, obs_loss: 0.01482, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 19.88688\n",
      "update_step:   6 model loss: 3.00772, kl_loss: 3.00024, obs_loss: 0.00747, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.88584\n",
      "update_step:   7 model loss: 3.02109, kl_loss: 3.00075, obs_loss: 0.02033, reward_loss: 0.00001, value_loss: 0.00793 action_loss: 19.87617\n",
      "update_step:   8 model loss: 3.01919, kl_loss: 3.00025, obs_loss: 0.01894, reward_loss: 0.00001, value_loss: 0.00811 action_loss: 19.85036\n",
      "update_step:   9 model loss: 3.03307, kl_loss: 3.00048, obs_loss: 0.03258, reward_loss: 0.00001, value_loss: 0.00831 action_loss: 19.88773\n",
      "update_step:  10 model loss: 3.05022, kl_loss: 3.00046, obs_loss: 0.04975, reward_loss: 0.00001, value_loss: 0.00812 action_loss: 19.84626\n",
      "update_step:  11 model loss: 3.06290, kl_loss: 3.00016, obs_loss: 0.06273, reward_loss: 0.00001, value_loss: 0.00807 action_loss: 19.86022\n",
      "update_step:  12 model loss: 3.07956, kl_loss: 3.00137, obs_loss: 0.07818, reward_loss: 0.00001, value_loss: 0.00803 action_loss: 19.84526\n",
      "update_step:  13 model loss: 3.06799, kl_loss: 3.00181, obs_loss: 0.06617, reward_loss: 0.00001, value_loss: 0.00823 action_loss: 19.89365\n",
      "update_step:  14 model loss: 3.03263, kl_loss: 3.00110, obs_loss: 0.03151, reward_loss: 0.00001, value_loss: 0.00848 action_loss: 19.89144\n",
      "update_step:  15 model loss: 3.01754, kl_loss: 3.00054, obs_loss: 0.01699, reward_loss: 0.00001, value_loss: 0.00874 action_loss: 19.89853\n",
      "update_step:  16 model loss: 3.01279, kl_loss: 3.00078, obs_loss: 0.01200, reward_loss: 0.00001, value_loss: 0.00844 action_loss: 19.91337\n",
      "update_step:  17 model loss: 3.02944, kl_loss: 3.00165, obs_loss: 0.02778, reward_loss: 0.00001, value_loss: 0.00813 action_loss: 19.90076\n",
      "update_step:  18 model loss: 3.04163, kl_loss: 3.00059, obs_loss: 0.04103, reward_loss: 0.00001, value_loss: 0.00844 action_loss: 19.90412\n",
      "update_step:  19 model loss: 3.05164, kl_loss: 3.00030, obs_loss: 0.05133, reward_loss: 0.00001, value_loss: 0.00838 action_loss: 19.84882\n",
      "update_step:  20 model loss: 3.05427, kl_loss: 3.00014, obs_loss: 0.05411, reward_loss: 0.00001, value_loss: 0.00863 action_loss: 19.85322\n",
      "update_step:  21 model loss: 3.03773, kl_loss: 3.00040, obs_loss: 0.03732, reward_loss: 0.00001, value_loss: 0.00879 action_loss: 19.82885\n",
      "update_step:  22 model loss: 3.01407, kl_loss: 3.00006, obs_loss: 0.01400, reward_loss: 0.00001, value_loss: 0.00831 action_loss: 19.83225\n",
      "update_step:  23 model loss: 3.02303, kl_loss: 3.00024, obs_loss: 0.02278, reward_loss: 0.00001, value_loss: 0.00832 action_loss: 19.82801\n",
      "update_step:  24 model loss: 3.02736, kl_loss: 3.00103, obs_loss: 0.02632, reward_loss: 0.00001, value_loss: 0.00827 action_loss: 19.87715\n",
      "update_step:  25 model loss: 3.02399, kl_loss: 3.00089, obs_loss: 0.02309, reward_loss: 0.00001, value_loss: 0.00814 action_loss: 19.89223\n",
      "update_step:  26 model loss: 3.02377, kl_loss: 3.00088, obs_loss: 0.02288, reward_loss: 0.00001, value_loss: 0.00832 action_loss: 19.90064\n",
      "update_step:  27 model loss: 3.03021, kl_loss: 3.00083, obs_loss: 0.02937, reward_loss: 0.00001, value_loss: 0.00833 action_loss: 19.88352\n",
      "update_step:  28 model loss: 3.03877, kl_loss: 3.00126, obs_loss: 0.03750, reward_loss: 0.00002, value_loss: 0.00851 action_loss: 19.93568\n",
      "update_step:  29 model loss: 3.04225, kl_loss: 3.00076, obs_loss: 0.04147, reward_loss: 0.00002, value_loss: 0.00831 action_loss: 19.90740\n",
      "update_step:  30 model loss: 3.04379, kl_loss: 3.00098, obs_loss: 0.04281, reward_loss: 0.00001, value_loss: 0.00821 action_loss: 19.89105\n",
      "update_step:  31 model loss: 3.02345, kl_loss: 3.00011, obs_loss: 0.02333, reward_loss: 0.00001, value_loss: 0.00822 action_loss: 19.87093\n",
      "update_step:  32 model loss: 3.02094, kl_loss: 3.00100, obs_loss: 0.01992, reward_loss: 0.00001, value_loss: 0.00898 action_loss: 19.88322\n",
      "update_step:  33 model loss: 3.01141, kl_loss: 3.00043, obs_loss: 0.01096, reward_loss: 0.00002, value_loss: 0.00851 action_loss: 19.88072\n",
      "update_step:  34 model loss: 3.01586, kl_loss: 3.00070, obs_loss: 0.01515, reward_loss: 0.00001, value_loss: 0.00836 action_loss: 19.85337\n",
      "update_step:  35 model loss: 3.01878, kl_loss: 3.00056, obs_loss: 0.01820, reward_loss: 0.00002, value_loss: 0.00844 action_loss: 19.89299\n",
      "update_step:  36 model loss: 3.02735, kl_loss: 3.00070, obs_loss: 0.02665, reward_loss: 0.00001, value_loss: 0.00851 action_loss: 19.91861\n",
      "update_step:  37 model loss: 3.01939, kl_loss: 3.00116, obs_loss: 0.01822, reward_loss: 0.00001, value_loss: 0.00864 action_loss: 19.94913\n",
      "update_step:  38 model loss: 3.01953, kl_loss: 3.00104, obs_loss: 0.01848, reward_loss: 0.00001, value_loss: 0.00918 action_loss: 19.95036\n",
      "update_step:  39 model loss: 3.01463, kl_loss: 3.00102, obs_loss: 0.01359, reward_loss: 0.00002, value_loss: 0.00906 action_loss: 19.96827\n",
      "update_step:  40 model loss: 3.00896, kl_loss: 3.00057, obs_loss: 0.00839, reward_loss: 0.00001, value_loss: 0.00857 action_loss: 19.96871\n",
      "update_step:  41 model loss: 3.00872, kl_loss: 3.00048, obs_loss: 0.00822, reward_loss: 0.00001, value_loss: 0.00861 action_loss: 19.92994\n",
      "update_step:  42 model loss: 3.01068, kl_loss: 3.00156, obs_loss: 0.00911, reward_loss: 0.00001, value_loss: 0.00840 action_loss: 19.90071\n",
      "update_step:  43 model loss: 3.01584, kl_loss: 3.00098, obs_loss: 0.01484, reward_loss: 0.00001, value_loss: 0.00840 action_loss: 19.87225\n",
      "update_step:  44 model loss: 3.01176, kl_loss: 3.00015, obs_loss: 0.01159, reward_loss: 0.00001, value_loss: 0.00913 action_loss: 19.86097\n",
      "update_step:  45 model loss: 3.01674, kl_loss: 3.00081, obs_loss: 0.01592, reward_loss: 0.00001, value_loss: 0.00869 action_loss: 19.83314\n",
      "update_step:  46 model loss: 3.01486, kl_loss: 3.00068, obs_loss: 0.01417, reward_loss: 0.00001, value_loss: 0.00841 action_loss: 19.84328\n",
      "update_step:  47 model loss: 3.00949, kl_loss: 3.00009, obs_loss: 0.00939, reward_loss: 0.00001, value_loss: 0.00858 action_loss: 19.86418\n",
      "update_step:  48 model loss: 3.01214, kl_loss: 3.00034, obs_loss: 0.01179, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.87425\n",
      "update_step:  49 model loss: 3.00686, kl_loss: 3.00011, obs_loss: 0.00674, reward_loss: 0.00001, value_loss: 0.00833 action_loss: 19.88225\n",
      "update_step:  50 model loss: 3.01710, kl_loss: 3.00121, obs_loss: 0.01588, reward_loss: 0.00001, value_loss: 0.00836 action_loss: 19.88790\n",
      "update_step:  51 model loss: 3.01061, kl_loss: 3.00050, obs_loss: 0.01010, reward_loss: 0.00001, value_loss: 0.00832 action_loss: 19.91187\n",
      "update_step:  52 model loss: 3.01385, kl_loss: 3.00081, obs_loss: 0.01303, reward_loss: 0.00001, value_loss: 0.00827 action_loss: 19.89685\n",
      "update_step:  53 model loss: 3.01442, kl_loss: 3.00110, obs_loss: 0.01332, reward_loss: 0.00001, value_loss: 0.00825 action_loss: 19.89947\n",
      "update_step:  54 model loss: 3.02151, kl_loss: 3.00146, obs_loss: 0.02004, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.88784\n",
      "update_step:  55 model loss: 3.01337, kl_loss: 3.00055, obs_loss: 0.01281, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.88480\n",
      "update_step:  56 model loss: 3.01007, kl_loss: 3.00116, obs_loss: 0.00890, reward_loss: 0.00001, value_loss: 0.00833 action_loss: 19.86362\n",
      "update_step:  57 model loss: 3.00753, kl_loss: 3.00022, obs_loss: 0.00730, reward_loss: 0.00001, value_loss: 0.00825 action_loss: 19.86006\n",
      "update_step:  58 model loss: 3.01585, kl_loss: 3.00161, obs_loss: 0.01424, reward_loss: 0.00001, value_loss: 0.00852 action_loss: 19.86967\n",
      "update_step:  59 model loss: 3.01234, kl_loss: 3.00042, obs_loss: 0.01192, reward_loss: 0.00001, value_loss: 0.00836 action_loss: 19.86330\n",
      "update_step:  60 model loss: 3.01836, kl_loss: 3.00028, obs_loss: 0.01807, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.89013\n",
      "update_step:  61 model loss: 3.01792, kl_loss: 3.00021, obs_loss: 0.01770, reward_loss: 0.00001, value_loss: 0.00835 action_loss: 19.88908\n",
      "update_step:  62 model loss: 3.02336, kl_loss: 3.00102, obs_loss: 0.02232, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 19.91480\n",
      "update_step:  63 model loss: 3.01710, kl_loss: 3.00058, obs_loss: 0.01650, reward_loss: 0.00001, value_loss: 0.00822 action_loss: 19.90456\n",
      "update_step:  64 model loss: 3.01484, kl_loss: 3.00014, obs_loss: 0.01469, reward_loss: 0.00001, value_loss: 0.00824 action_loss: 19.90860\n",
      "update_step:  65 model loss: 3.01632, kl_loss: 3.00067, obs_loss: 0.01564, reward_loss: 0.00001, value_loss: 0.00829 action_loss: 19.90541\n",
      "update_step:  66 model loss: 3.01313, kl_loss: 3.00105, obs_loss: 0.01207, reward_loss: 0.00001, value_loss: 0.00826 action_loss: 19.90656\n",
      "update_step:  67 model loss: 3.00753, kl_loss: 3.00045, obs_loss: 0.00708, reward_loss: 0.00001, value_loss: 0.00811 action_loss: 19.90414\n",
      "update_step:  68 model loss: 3.01458, kl_loss: 3.00087, obs_loss: 0.01370, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.89561\n",
      "update_step:  69 model loss: 3.01438, kl_loss: 3.00070, obs_loss: 0.01367, reward_loss: 0.00001, value_loss: 0.00833 action_loss: 19.91944\n",
      "update_step:  70 model loss: 3.01899, kl_loss: 3.00045, obs_loss: 0.01853, reward_loss: 0.00001, value_loss: 0.00820 action_loss: 19.91514\n",
      "update_step:  71 model loss: 3.02751, kl_loss: 3.00144, obs_loss: 0.02606, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.93470\n",
      "update_step:  72 model loss: 3.01594, kl_loss: 3.00073, obs_loss: 0.01520, reward_loss: 0.00001, value_loss: 0.00846 action_loss: 19.93914\n",
      "update_step:  73 model loss: 3.01694, kl_loss: 3.00156, obs_loss: 0.01537, reward_loss: 0.00001, value_loss: 0.00844 action_loss: 19.94934\n",
      "update_step:  74 model loss: 3.01259, kl_loss: 3.00048, obs_loss: 0.01211, reward_loss: 0.00001, value_loss: 0.00842 action_loss: 19.93469\n",
      "update_step:  75 model loss: 3.01214, kl_loss: 3.00077, obs_loss: 0.01137, reward_loss: 0.00001, value_loss: 0.00850 action_loss: 19.92474\n",
      "update_step:  76 model loss: 3.00883, kl_loss: 3.00047, obs_loss: 0.00835, reward_loss: 0.00001, value_loss: 0.00834 action_loss: 19.89840\n",
      "update_step:  77 model loss: 3.01280, kl_loss: 3.00065, obs_loss: 0.01214, reward_loss: 0.00001, value_loss: 0.00821 action_loss: 19.86701\n",
      "update_step:  78 model loss: 3.00897, kl_loss: 3.00045, obs_loss: 0.00852, reward_loss: 0.00001, value_loss: 0.00842 action_loss: 19.86419\n",
      "update_step:  79 model loss: 3.01283, kl_loss: 3.00007, obs_loss: 0.01275, reward_loss: 0.00001, value_loss: 0.00845 action_loss: 19.85402\n",
      "update_step:  80 model loss: 3.02519, kl_loss: 3.00037, obs_loss: 0.02482, reward_loss: 0.00001, value_loss: 0.00825 action_loss: 19.86736\n",
      "update_step:  81 model loss: 3.02754, kl_loss: 3.00064, obs_loss: 0.02688, reward_loss: 0.00001, value_loss: 0.00819 action_loss: 19.86154\n",
      "update_step:  82 model loss: 3.02261, kl_loss: 3.00009, obs_loss: 0.02251, reward_loss: 0.00001, value_loss: 0.00849 action_loss: 19.88489\n",
      "update_step:  83 model loss: 3.01696, kl_loss: 3.00020, obs_loss: 0.01675, reward_loss: 0.00001, value_loss: 0.00845 action_loss: 19.90779\n",
      "update_step:  84 model loss: 3.02735, kl_loss: 3.00175, obs_loss: 0.02560, reward_loss: 0.00001, value_loss: 0.00828 action_loss: 19.90523\n",
      "update_step:  85 model loss: 3.04304, kl_loss: 3.00031, obs_loss: 0.04272, reward_loss: 0.00001, value_loss: 0.00833 action_loss: 19.92861\n",
      "update_step:  86 model loss: 3.07617, kl_loss: 3.00100, obs_loss: 0.07517, reward_loss: 0.00001, value_loss: 0.00809 action_loss: 19.90188\n",
      "update_step:  87 model loss: 3.09182, kl_loss: 3.00051, obs_loss: 0.09130, reward_loss: 0.00001, value_loss: 0.00827 action_loss: 19.91858\n",
      "update_step:  88 model loss: 3.09065, kl_loss: 3.00031, obs_loss: 0.09033, reward_loss: 0.00001, value_loss: 0.00824 action_loss: 19.87041\n",
      "update_step:  89 model loss: 3.08670, kl_loss: 3.00023, obs_loss: 0.08646, reward_loss: 0.00001, value_loss: 0.00845 action_loss: 19.89978\n",
      "update_step:  90 model loss: 3.05544, kl_loss: 3.00036, obs_loss: 0.05507, reward_loss: 0.00001, value_loss: 0.00824 action_loss: 19.89606\n",
      "update_step:  91 model loss: 3.03291, kl_loss: 3.00047, obs_loss: 0.03243, reward_loss: 0.00001, value_loss: 0.00824 action_loss: 19.90218\n",
      "update_step:  92 model loss: 3.01914, kl_loss: 3.00075, obs_loss: 0.01838, reward_loss: 0.00001, value_loss: 0.00810 action_loss: 19.89502\n",
      "update_step:  93 model loss: 3.02480, kl_loss: 3.00008, obs_loss: 0.02472, reward_loss: 0.00001, value_loss: 0.00839 action_loss: 19.86745\n",
      "update_step:  94 model loss: 3.04592, kl_loss: 3.00082, obs_loss: 0.04509, reward_loss: 0.00001, value_loss: 0.00837 action_loss: 19.88062\n",
      "update_step:  95 model loss: 3.05399, kl_loss: 3.00016, obs_loss: 0.05382, reward_loss: 0.00001, value_loss: 0.00829 action_loss: 19.85432\n",
      "update_step:  96 model loss: 3.07487, kl_loss: 3.00059, obs_loss: 0.07427, reward_loss: 0.00001, value_loss: 0.00832 action_loss: 19.91138\n",
      "update_step:  97 model loss: 3.06538, kl_loss: 3.00005, obs_loss: 0.06532, reward_loss: 0.00001, value_loss: 0.00837 action_loss: 19.89773\n",
      "update_step:  98 model loss: 3.06646, kl_loss: 3.00033, obs_loss: 0.06612, reward_loss: 0.00001, value_loss: 0.00851 action_loss: 19.94330\n",
      "update_step:  99 model loss: 3.05151, kl_loss: 3.00178, obs_loss: 0.04972, reward_loss: 0.00001, value_loss: 0.00853 action_loss: 19.95224\n",
      "update_step: 100 model loss: 3.03072, kl_loss: 3.00104, obs_loss: 0.02967, reward_loss: 0.00001, value_loss: 0.00858 action_loss: 19.96634\n",
      "elasped time for update: 20.52s\n",
      "episode [  27/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.02756, kl_loss: 3.00042, obs_loss: 0.02713, reward_loss: 0.00001, value_loss: 0.00884 action_loss: 19.98092\n",
      "update_step:   2 model loss: 3.05976, kl_loss: 3.00135, obs_loss: 0.05840, reward_loss: 0.00001, value_loss: 0.00860 action_loss: 19.91625\n",
      "update_step:   3 model loss: 3.08666, kl_loss: 3.00068, obs_loss: 0.08597, reward_loss: 0.00001, value_loss: 0.00900 action_loss: 19.90365\n",
      "update_step:   4 model loss: 3.09554, kl_loss: 3.00062, obs_loss: 0.09491, reward_loss: 0.00001, value_loss: 0.00982 action_loss: 19.84051\n",
      "update_step:   5 model loss: 3.08375, kl_loss: 3.00016, obs_loss: 0.08358, reward_loss: 0.00001, value_loss: 0.00976 action_loss: 19.87355\n",
      "update_step:   6 model loss: 3.04904, kl_loss: 3.00057, obs_loss: 0.04846, reward_loss: 0.00001, value_loss: 0.00914 action_loss: 19.86654\n",
      "update_step:   7 model loss: 3.02424, kl_loss: 3.00108, obs_loss: 0.02315, reward_loss: 0.00001, value_loss: 0.00882 action_loss: 19.88430\n",
      "update_step:   8 model loss: 3.01216, kl_loss: 3.00013, obs_loss: 0.01201, reward_loss: 0.00001, value_loss: 0.00853 action_loss: 19.92929\n",
      "update_step:   9 model loss: 3.03779, kl_loss: 3.00027, obs_loss: 0.03752, reward_loss: 0.00001, value_loss: 0.00848 action_loss: 19.92197\n",
      "update_step:  10 model loss: 3.05678, kl_loss: 3.00054, obs_loss: 0.05624, reward_loss: 0.00001, value_loss: 0.00897 action_loss: 19.95646\n",
      "update_step:  11 model loss: 3.04751, kl_loss: 3.00025, obs_loss: 0.04725, reward_loss: 0.00001, value_loss: 0.00876 action_loss: 19.93777\n",
      "update_step:  12 model loss: 3.02985, kl_loss: 3.00030, obs_loss: 0.02954, reward_loss: 0.00001, value_loss: 0.00837 action_loss: 19.95114\n",
      "update_step:  13 model loss: 3.01981, kl_loss: 3.00227, obs_loss: 0.01753, reward_loss: 0.00001, value_loss: 0.00830 action_loss: 19.93378\n",
      "update_step:  14 model loss: 3.00998, kl_loss: 3.00024, obs_loss: 0.00974, reward_loss: 0.00001, value_loss: 0.00838 action_loss: 19.89698\n",
      "update_step:  15 model loss: 3.02040, kl_loss: 3.00016, obs_loss: 0.02023, reward_loss: 0.00001, value_loss: 0.00851 action_loss: 19.90089\n",
      "update_step:  16 model loss: 3.03791, kl_loss: 3.00145, obs_loss: 0.03645, reward_loss: 0.00001, value_loss: 0.00885 action_loss: 19.86706\n",
      "update_step:  17 model loss: 3.04051, kl_loss: 3.00103, obs_loss: 0.03946, reward_loss: 0.00001, value_loss: 0.00905 action_loss: 19.88264\n",
      "update_step:  18 model loss: 3.05150, kl_loss: 3.00460, obs_loss: 0.04689, reward_loss: 0.00001, value_loss: 0.00849 action_loss: 19.86828\n",
      "update_step:  19 model loss: 3.01715, kl_loss: 3.00150, obs_loss: 0.01564, reward_loss: 0.00001, value_loss: 0.00839 action_loss: 19.90041\n",
      "update_step:  20 model loss: 3.00777, kl_loss: 3.00037, obs_loss: 0.00740, reward_loss: 0.00001, value_loss: 0.00840 action_loss: 19.93711\n",
      "update_step:  21 model loss: 3.01536, kl_loss: 3.00097, obs_loss: 0.01438, reward_loss: 0.00001, value_loss: 0.00811 action_loss: 19.93783\n",
      "update_step:  22 model loss: 3.02664, kl_loss: 3.00115, obs_loss: 0.02548, reward_loss: 0.00001, value_loss: 0.00878 action_loss: 19.96795\n",
      "update_step:  23 model loss: 3.03035, kl_loss: 3.00097, obs_loss: 0.02937, reward_loss: 0.00001, value_loss: 0.00875 action_loss: 19.94266\n",
      "update_step:  24 model loss: 3.02439, kl_loss: 3.00027, obs_loss: 0.02411, reward_loss: 0.00001, value_loss: 0.00860 action_loss: 19.94396\n",
      "update_step:  25 model loss: 3.01287, kl_loss: 3.00033, obs_loss: 0.01253, reward_loss: 0.00001, value_loss: 0.00869 action_loss: 19.90600\n",
      "update_step:  26 model loss: 3.00633, kl_loss: 3.00037, obs_loss: 0.00595, reward_loss: 0.00001, value_loss: 0.00866 action_loss: 19.88244\n",
      "update_step:  27 model loss: 3.00827, kl_loss: 3.00039, obs_loss: 0.00787, reward_loss: 0.00001, value_loss: 0.00846 action_loss: 19.87874\n",
      "update_step:  28 model loss: 3.01471, kl_loss: 3.00043, obs_loss: 0.01427, reward_loss: 0.00001, value_loss: 0.00853 action_loss: 19.86761\n",
      "update_step:  29 model loss: 3.01612, kl_loss: 3.00019, obs_loss: 0.01592, reward_loss: 0.00001, value_loss: 0.00847 action_loss: 19.87513\n",
      "update_step:  30 model loss: 3.01241, kl_loss: 3.00052, obs_loss: 0.01189, reward_loss: 0.00001, value_loss: 0.00846 action_loss: 19.86350\n",
      "update_step:  31 model loss: 3.00809, kl_loss: 3.00027, obs_loss: 0.00781, reward_loss: 0.00001, value_loss: 0.00858 action_loss: 19.87172\n",
      "update_step:  32 model loss: 3.01204, kl_loss: 3.00089, obs_loss: 0.01114, reward_loss: 0.00001, value_loss: 0.00847 action_loss: 19.89397\n",
      "update_step:  33 model loss: 3.00865, kl_loss: 3.00028, obs_loss: 0.00836, reward_loss: 0.00001, value_loss: 0.00831 action_loss: 19.90654\n",
      "update_step:  34 model loss: 3.01352, kl_loss: 3.00092, obs_loss: 0.01260, reward_loss: 0.00001, value_loss: 0.00820 action_loss: 19.94146\n",
      "update_step:  35 model loss: 3.01358, kl_loss: 3.00031, obs_loss: 0.01325, reward_loss: 0.00001, value_loss: 0.00802 action_loss: 19.94408\n",
      "update_step:  36 model loss: 3.01684, kl_loss: 3.00039, obs_loss: 0.01643, reward_loss: 0.00001, value_loss: 0.00839 action_loss: 19.97058\n",
      "update_step:  37 model loss: 3.00913, kl_loss: 3.00033, obs_loss: 0.00879, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 19.97058\n",
      "update_step:  38 model loss: 3.01208, kl_loss: 3.00111, obs_loss: 0.01096, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 19.94798\n",
      "update_step:  39 model loss: 3.01405, kl_loss: 3.00060, obs_loss: 0.01344, reward_loss: 0.00001, value_loss: 0.00824 action_loss: 19.94385\n",
      "update_step:  40 model loss: 3.02666, kl_loss: 3.00067, obs_loss: 0.02598, reward_loss: 0.00001, value_loss: 0.00807 action_loss: 19.91483\n",
      "update_step:  41 model loss: 3.02435, kl_loss: 3.00098, obs_loss: 0.02337, reward_loss: 0.00001, value_loss: 0.00808 action_loss: 19.90158\n",
      "update_step:  42 model loss: 3.01793, kl_loss: 3.00093, obs_loss: 0.01700, reward_loss: 0.00001, value_loss: 0.00811 action_loss: 19.86555\n",
      "update_step:  43 model loss: 3.01085, kl_loss: 3.00077, obs_loss: 0.01007, reward_loss: 0.00001, value_loss: 0.00811 action_loss: 19.87734\n",
      "update_step:  44 model loss: 3.00867, kl_loss: 3.00084, obs_loss: 0.00782, reward_loss: 0.00001, value_loss: 0.00796 action_loss: 19.90698\n",
      "update_step:  45 model loss: 3.00751, kl_loss: 3.00105, obs_loss: 0.00645, reward_loss: 0.00001, value_loss: 0.00776 action_loss: 19.92129\n",
      "update_step:  46 model loss: 3.01302, kl_loss: 3.00034, obs_loss: 0.01267, reward_loss: 0.00001, value_loss: 0.00802 action_loss: 19.95330\n",
      "update_step:  47 model loss: 3.01309, kl_loss: 3.00018, obs_loss: 0.01290, reward_loss: 0.00001, value_loss: 0.00818 action_loss: 19.95729\n",
      "update_step:  48 model loss: 3.02427, kl_loss: 3.00102, obs_loss: 0.02324, reward_loss: 0.00001, value_loss: 0.00824 action_loss: 19.97754\n",
      "update_step:  49 model loss: 3.01801, kl_loss: 3.00067, obs_loss: 0.01733, reward_loss: 0.00001, value_loss: 0.00818 action_loss: 19.95792\n",
      "update_step:  50 model loss: 3.00728, kl_loss: 3.00009, obs_loss: 0.00719, reward_loss: 0.00001, value_loss: 0.00808 action_loss: 19.92765\n",
      "update_step:  51 model loss: 3.00828, kl_loss: 3.00003, obs_loss: 0.00825, reward_loss: 0.00001, value_loss: 0.00793 action_loss: 19.91098\n",
      "update_step:  52 model loss: 3.01172, kl_loss: 3.00009, obs_loss: 0.01161, reward_loss: 0.00001, value_loss: 0.00804 action_loss: 19.87695\n",
      "update_step:  53 model loss: 3.01625, kl_loss: 3.00048, obs_loss: 0.01577, reward_loss: 0.00001, value_loss: 0.00830 action_loss: 19.86414\n",
      "update_step:  54 model loss: 3.01952, kl_loss: 3.00036, obs_loss: 0.01915, reward_loss: 0.00001, value_loss: 0.00829 action_loss: 19.84873\n",
      "update_step:  55 model loss: 3.01264, kl_loss: 3.00047, obs_loss: 0.01216, reward_loss: 0.00001, value_loss: 0.00798 action_loss: 19.87855\n",
      "update_step:  56 model loss: 3.01207, kl_loss: 3.00045, obs_loss: 0.01161, reward_loss: 0.00001, value_loss: 0.00797 action_loss: 19.91239\n",
      "update_step:  57 model loss: 3.01595, kl_loss: 3.00083, obs_loss: 0.01511, reward_loss: 0.00001, value_loss: 0.00818 action_loss: 19.93580\n",
      "update_step:  58 model loss: 3.01208, kl_loss: 3.00055, obs_loss: 0.01153, reward_loss: 0.00001, value_loss: 0.00834 action_loss: 19.95768\n",
      "update_step:  59 model loss: 3.01723, kl_loss: 3.00116, obs_loss: 0.01607, reward_loss: 0.00001, value_loss: 0.00801 action_loss: 19.94436\n",
      "update_step:  60 model loss: 3.01814, kl_loss: 3.00022, obs_loss: 0.01791, reward_loss: 0.00001, value_loss: 0.00799 action_loss: 19.93472\n",
      "update_step:  61 model loss: 3.01853, kl_loss: 3.00004, obs_loss: 0.01849, reward_loss: 0.00001, value_loss: 0.00784 action_loss: 19.89631\n",
      "update_step:  62 model loss: 3.02448, kl_loss: 3.00027, obs_loss: 0.02421, reward_loss: 0.00001, value_loss: 0.00786 action_loss: 19.87006\n",
      "update_step:  63 model loss: 3.03113, kl_loss: 3.00073, obs_loss: 0.03039, reward_loss: 0.00001, value_loss: 0.00827 action_loss: 19.84816\n",
      "update_step:  64 model loss: 3.03608, kl_loss: 3.00059, obs_loss: 0.03548, reward_loss: 0.00001, value_loss: 0.00839 action_loss: 19.84387\n",
      "update_step:  65 model loss: 3.04687, kl_loss: 3.00094, obs_loss: 0.04593, reward_loss: 0.00001, value_loss: 0.00823 action_loss: 19.84694\n",
      "update_step:  66 model loss: 3.04459, kl_loss: 3.00011, obs_loss: 0.04447, reward_loss: 0.00001, value_loss: 0.00786 action_loss: 19.85912\n",
      "update_step:  67 model loss: 3.05546, kl_loss: 3.00029, obs_loss: 0.05516, reward_loss: 0.00001, value_loss: 0.00784 action_loss: 19.88226\n",
      "update_step:  68 model loss: 3.05944, kl_loss: 3.00091, obs_loss: 0.05852, reward_loss: 0.00001, value_loss: 0.00758 action_loss: 19.91645\n",
      "update_step:  69 model loss: 3.05745, kl_loss: 3.00093, obs_loss: 0.05651, reward_loss: 0.00001, value_loss: 0.00750 action_loss: 19.93666\n",
      "update_step:  70 model loss: 3.05823, kl_loss: 3.00094, obs_loss: 0.05728, reward_loss: 0.00001, value_loss: 0.00802 action_loss: 19.95572\n",
      "update_step:  71 model loss: 3.05703, kl_loss: 3.00041, obs_loss: 0.05661, reward_loss: 0.00001, value_loss: 0.00765 action_loss: 19.94930\n",
      "update_step:  72 model loss: 3.06566, kl_loss: 3.00257, obs_loss: 0.06309, reward_loss: 0.00001, value_loss: 0.00783 action_loss: 19.96208\n",
      "update_step:  73 model loss: 3.04206, kl_loss: 3.00044, obs_loss: 0.04161, reward_loss: 0.00001, value_loss: 0.00733 action_loss: 19.93516\n",
      "update_step:  74 model loss: 3.03172, kl_loss: 3.00030, obs_loss: 0.03141, reward_loss: 0.00001, value_loss: 0.00750 action_loss: 19.92600\n",
      "update_step:  75 model loss: 3.02599, kl_loss: 3.00132, obs_loss: 0.02465, reward_loss: 0.00001, value_loss: 0.00746 action_loss: 19.90162\n",
      "update_step:  76 model loss: 3.01187, kl_loss: 3.00000, obs_loss: 0.01186, reward_loss: 0.00001, value_loss: 0.00755 action_loss: 19.91211\n",
      "update_step:  77 model loss: 3.00749, kl_loss: 3.00060, obs_loss: 0.00688, reward_loss: 0.00001, value_loss: 0.00741 action_loss: 19.90686\n",
      "update_step:  78 model loss: 3.00588, kl_loss: 3.00015, obs_loss: 0.00572, reward_loss: 0.00001, value_loss: 0.00742 action_loss: 19.89931\n",
      "update_step:  79 model loss: 3.01447, kl_loss: 3.00114, obs_loss: 0.01333, reward_loss: 0.00001, value_loss: 0.00759 action_loss: 19.90505\n",
      "update_step:  80 model loss: 3.01693, kl_loss: 3.00082, obs_loss: 0.01610, reward_loss: 0.00001, value_loss: 0.00745 action_loss: 19.89764\n",
      "update_step:  81 model loss: 3.02498, kl_loss: 3.00089, obs_loss: 0.02409, reward_loss: 0.00001, value_loss: 0.00728 action_loss: 19.90310\n",
      "update_step:  82 model loss: 3.02764, kl_loss: 3.00113, obs_loss: 0.02650, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.88665\n",
      "update_step:  83 model loss: 3.02212, kl_loss: 3.00081, obs_loss: 0.02130, reward_loss: 0.00001, value_loss: 0.00733 action_loss: 19.89291\n",
      "update_step:  84 model loss: 3.01942, kl_loss: 3.00084, obs_loss: 0.01857, reward_loss: 0.00001, value_loss: 0.00745 action_loss: 19.89305\n",
      "update_step:  85 model loss: 3.01675, kl_loss: 3.00057, obs_loss: 0.01617, reward_loss: 0.00001, value_loss: 0.00744 action_loss: 19.88944\n",
      "update_step:  86 model loss: 3.01410, kl_loss: 3.00058, obs_loss: 0.01351, reward_loss: 0.00001, value_loss: 0.00730 action_loss: 19.88692\n",
      "update_step:  87 model loss: 3.00957, kl_loss: 3.00025, obs_loss: 0.00932, reward_loss: 0.00001, value_loss: 0.00752 action_loss: 19.89215\n",
      "update_step:  88 model loss: 3.01643, kl_loss: 3.00062, obs_loss: 0.01581, reward_loss: 0.00001, value_loss: 0.00745 action_loss: 19.90381\n",
      "update_step:  89 model loss: 3.00577, kl_loss: 3.00027, obs_loss: 0.00549, reward_loss: 0.00001, value_loss: 0.00748 action_loss: 19.89939\n",
      "update_step:  90 model loss: 3.00570, kl_loss: 3.00005, obs_loss: 0.00564, reward_loss: 0.00001, value_loss: 0.00734 action_loss: 19.90131\n",
      "update_step:  91 model loss: 3.00780, kl_loss: 3.00016, obs_loss: 0.00764, reward_loss: 0.00001, value_loss: 0.00722 action_loss: 19.90983\n",
      "update_step:  92 model loss: 3.01540, kl_loss: 3.00097, obs_loss: 0.01443, reward_loss: 0.00001, value_loss: 0.00735 action_loss: 19.92943\n",
      "update_step:  93 model loss: 3.01762, kl_loss: 3.00166, obs_loss: 0.01594, reward_loss: 0.00001, value_loss: 0.00737 action_loss: 19.92767\n",
      "update_step:  94 model loss: 3.01331, kl_loss: 3.00021, obs_loss: 0.01309, reward_loss: 0.00001, value_loss: 0.00744 action_loss: 19.92951\n",
      "update_step:  95 model loss: 3.01545, kl_loss: 3.00088, obs_loss: 0.01456, reward_loss: 0.00001, value_loss: 0.00721 action_loss: 19.91882\n",
      "update_step:  96 model loss: 3.01129, kl_loss: 3.00021, obs_loss: 0.01108, reward_loss: 0.00001, value_loss: 0.00717 action_loss: 19.91417\n",
      "update_step:  97 model loss: 3.01605, kl_loss: 3.00131, obs_loss: 0.01473, reward_loss: 0.00001, value_loss: 0.00721 action_loss: 19.89269\n",
      "update_step:  98 model loss: 3.01261, kl_loss: 3.00056, obs_loss: 0.01204, reward_loss: 0.00001, value_loss: 0.00731 action_loss: 19.88858\n",
      "update_step:  99 model loss: 3.00635, kl_loss: 3.00065, obs_loss: 0.00569, reward_loss: 0.00001, value_loss: 0.00735 action_loss: 19.89626\n",
      "update_step: 100 model loss: 3.00923, kl_loss: 3.00094, obs_loss: 0.00829, reward_loss: 0.00001, value_loss: 0.00735 action_loss: 19.91084\n",
      "elasped time for update: 20.31s\n",
      "episode [  28/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.00448, kl_loss: 3.00014, obs_loss: 0.00434, reward_loss: 0.00001, value_loss: 0.00721 action_loss: 19.92124\n",
      "update_step:   2 model loss: 3.00413, kl_loss: 3.00021, obs_loss: 0.00390, reward_loss: 0.00001, value_loss: 0.00729 action_loss: 19.93377\n",
      "update_step:   3 model loss: 3.00960, kl_loss: 3.00135, obs_loss: 0.00824, reward_loss: 0.00001, value_loss: 0.00737 action_loss: 19.95128\n",
      "update_step:   4 model loss: 3.00886, kl_loss: 3.00046, obs_loss: 0.00839, reward_loss: 0.00001, value_loss: 0.00718 action_loss: 19.94292\n",
      "update_step:   5 model loss: 3.01920, kl_loss: 3.00094, obs_loss: 0.01825, reward_loss: 0.00001, value_loss: 0.00735 action_loss: 19.93066\n",
      "update_step:   6 model loss: 3.01688, kl_loss: 3.00088, obs_loss: 0.01600, reward_loss: 0.00001, value_loss: 0.00725 action_loss: 19.91795\n",
      "update_step:   7 model loss: 3.00952, kl_loss: 3.00067, obs_loss: 0.00884, reward_loss: 0.00001, value_loss: 0.00731 action_loss: 19.92474\n",
      "update_step:   8 model loss: 3.00980, kl_loss: 3.00087, obs_loss: 0.00893, reward_loss: 0.00001, value_loss: 0.00742 action_loss: 19.91618\n",
      "update_step:   9 model loss: 3.01937, kl_loss: 3.00176, obs_loss: 0.01760, reward_loss: 0.00001, value_loss: 0.00725 action_loss: 19.91438\n",
      "update_step:  10 model loss: 3.00787, kl_loss: 3.00113, obs_loss: 0.00673, reward_loss: 0.00001, value_loss: 0.00728 action_loss: 19.92097\n",
      "update_step:  11 model loss: 3.00869, kl_loss: 3.00062, obs_loss: 0.00807, reward_loss: 0.00001, value_loss: 0.00730 action_loss: 19.92378\n",
      "update_step:  12 model loss: 3.01832, kl_loss: 3.00118, obs_loss: 0.01713, reward_loss: 0.00001, value_loss: 0.00722 action_loss: 19.90483\n",
      "update_step:  13 model loss: 3.00973, kl_loss: 3.00088, obs_loss: 0.00884, reward_loss: 0.00001, value_loss: 0.00720 action_loss: 19.89912\n",
      "update_step:  14 model loss: 3.00949, kl_loss: 3.00029, obs_loss: 0.00919, reward_loss: 0.00001, value_loss: 0.00709 action_loss: 19.89994\n",
      "update_step:  15 model loss: 3.00581, kl_loss: 3.00029, obs_loss: 0.00552, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.89541\n",
      "update_step:  16 model loss: 3.01036, kl_loss: 3.00088, obs_loss: 0.00947, reward_loss: 0.00001, value_loss: 0.00733 action_loss: 19.90119\n",
      "update_step:  17 model loss: 3.00538, kl_loss: 3.00059, obs_loss: 0.00479, reward_loss: 0.00001, value_loss: 0.00729 action_loss: 19.91528\n",
      "update_step:  18 model loss: 3.00462, kl_loss: 3.00037, obs_loss: 0.00424, reward_loss: 0.00001, value_loss: 0.00723 action_loss: 19.92974\n",
      "update_step:  19 model loss: 3.01855, kl_loss: 3.00187, obs_loss: 0.01667, reward_loss: 0.00001, value_loss: 0.00730 action_loss: 19.93602\n",
      "update_step:  20 model loss: 3.00634, kl_loss: 3.00032, obs_loss: 0.00601, reward_loss: 0.00001, value_loss: 0.00716 action_loss: 19.93365\n",
      "update_step:  21 model loss: 3.01926, kl_loss: 3.00381, obs_loss: 0.01544, reward_loss: 0.00001, value_loss: 0.00704 action_loss: 19.92774\n",
      "update_step:  22 model loss: 3.00521, kl_loss: 3.00055, obs_loss: 0.00465, reward_loss: 0.00001, value_loss: 0.00734 action_loss: 19.92566\n",
      "update_step:  23 model loss: 3.01258, kl_loss: 3.00116, obs_loss: 0.01141, reward_loss: 0.00001, value_loss: 0.00717 action_loss: 19.91298\n",
      "update_step:  24 model loss: 3.00824, kl_loss: 3.00045, obs_loss: 0.00778, reward_loss: 0.00001, value_loss: 0.00731 action_loss: 19.90364\n",
      "update_step:  25 model loss: 3.00683, kl_loss: 3.00004, obs_loss: 0.00679, reward_loss: 0.00001, value_loss: 0.00725 action_loss: 19.89607\n",
      "update_step:  26 model loss: 3.01103, kl_loss: 3.00032, obs_loss: 0.01070, reward_loss: 0.00001, value_loss: 0.00708 action_loss: 19.90100\n",
      "update_step:  27 model loss: 3.00685, kl_loss: 3.00002, obs_loss: 0.00682, reward_loss: 0.00001, value_loss: 0.00707 action_loss: 19.89417\n",
      "update_step:  28 model loss: 3.01051, kl_loss: 3.00040, obs_loss: 0.01010, reward_loss: 0.00001, value_loss: 0.00730 action_loss: 19.89795\n",
      "update_step:  29 model loss: 3.01483, kl_loss: 3.00059, obs_loss: 0.01424, reward_loss: 0.00001, value_loss: 0.00725 action_loss: 19.89786\n",
      "update_step:  30 model loss: 3.00978, kl_loss: 3.00005, obs_loss: 0.00973, reward_loss: 0.00001, value_loss: 0.00720 action_loss: 19.90878\n",
      "update_step:  31 model loss: 3.01079, kl_loss: 3.00050, obs_loss: 0.01028, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 19.90645\n",
      "update_step:  32 model loss: 3.01271, kl_loss: 3.00099, obs_loss: 0.01172, reward_loss: 0.00001, value_loss: 0.00711 action_loss: 19.91829\n",
      "update_step:  33 model loss: 3.01308, kl_loss: 3.00023, obs_loss: 0.01284, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 19.91545\n",
      "update_step:  34 model loss: 3.01534, kl_loss: 3.00042, obs_loss: 0.01491, reward_loss: 0.00001, value_loss: 0.00729 action_loss: 19.92080\n",
      "update_step:  35 model loss: 3.01675, kl_loss: 3.00051, obs_loss: 0.01623, reward_loss: 0.00001, value_loss: 0.00728 action_loss: 19.90945\n",
      "update_step:  36 model loss: 3.01601, kl_loss: 3.00082, obs_loss: 0.01519, reward_loss: 0.00001, value_loss: 0.00736 action_loss: 19.91977\n",
      "update_step:  37 model loss: 3.01593, kl_loss: 3.00020, obs_loss: 0.01572, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.91175\n",
      "update_step:  38 model loss: 3.02033, kl_loss: 3.00062, obs_loss: 0.01971, reward_loss: 0.00001, value_loss: 0.00732 action_loss: 19.93419\n",
      "update_step:  39 model loss: 3.01225, kl_loss: 3.00017, obs_loss: 0.01208, reward_loss: 0.00001, value_loss: 0.00714 action_loss: 19.94097\n",
      "update_step:  40 model loss: 3.01587, kl_loss: 3.00109, obs_loss: 0.01478, reward_loss: 0.00001, value_loss: 0.00719 action_loss: 19.94793\n",
      "update_step:  41 model loss: 3.00987, kl_loss: 3.00061, obs_loss: 0.00924, reward_loss: 0.00001, value_loss: 0.00716 action_loss: 19.93959\n",
      "update_step:  42 model loss: 3.00741, kl_loss: 3.00030, obs_loss: 0.00710, reward_loss: 0.00001, value_loss: 0.00717 action_loss: 19.93707\n",
      "update_step:  43 model loss: 3.00699, kl_loss: 3.00048, obs_loss: 0.00650, reward_loss: 0.00001, value_loss: 0.00730 action_loss: 19.92652\n",
      "update_step:  44 model loss: 3.01367, kl_loss: 3.00091, obs_loss: 0.01275, reward_loss: 0.00001, value_loss: 0.00698 action_loss: 19.91576\n",
      "update_step:  45 model loss: 3.00929, kl_loss: 3.00110, obs_loss: 0.00818, reward_loss: 0.00001, value_loss: 0.00723 action_loss: 19.90568\n",
      "update_step:  46 model loss: 3.00752, kl_loss: 3.00045, obs_loss: 0.00706, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.89187\n",
      "update_step:  47 model loss: 3.00720, kl_loss: 3.00050, obs_loss: 0.00669, reward_loss: 0.00001, value_loss: 0.00718 action_loss: 19.88677\n",
      "update_step:  48 model loss: 3.01102, kl_loss: 3.00047, obs_loss: 0.01054, reward_loss: 0.00001, value_loss: 0.00709 action_loss: 19.87777\n",
      "update_step:  49 model loss: 3.00905, kl_loss: 3.00067, obs_loss: 0.00837, reward_loss: 0.00001, value_loss: 0.00709 action_loss: 19.89285\n",
      "update_step:  50 model loss: 3.00991, kl_loss: 3.00042, obs_loss: 0.00949, reward_loss: 0.00001, value_loss: 0.00720 action_loss: 19.89454\n",
      "update_step:  51 model loss: 3.00998, kl_loss: 3.00123, obs_loss: 0.00874, reward_loss: 0.00001, value_loss: 0.00717 action_loss: 19.91048\n",
      "update_step:  52 model loss: 3.01072, kl_loss: 3.00043, obs_loss: 0.01028, reward_loss: 0.00001, value_loss: 0.00695 action_loss: 19.91499\n",
      "update_step:  53 model loss: 3.00606, kl_loss: 3.00016, obs_loss: 0.00590, reward_loss: 0.00001, value_loss: 0.00705 action_loss: 19.93740\n",
      "update_step:  54 model loss: 3.00656, kl_loss: 3.00024, obs_loss: 0.00631, reward_loss: 0.00001, value_loss: 0.00707 action_loss: 19.93260\n",
      "update_step:  55 model loss: 3.00901, kl_loss: 3.00008, obs_loss: 0.00892, reward_loss: 0.00001, value_loss: 0.00722 action_loss: 19.93449\n",
      "update_step:  56 model loss: 3.00701, kl_loss: 3.00036, obs_loss: 0.00665, reward_loss: 0.00001, value_loss: 0.00693 action_loss: 19.92885\n",
      "update_step:  57 model loss: 3.01127, kl_loss: 3.00095, obs_loss: 0.01031, reward_loss: 0.00001, value_loss: 0.00696 action_loss: 19.93253\n",
      "update_step:  58 model loss: 3.00553, kl_loss: 3.00053, obs_loss: 0.00499, reward_loss: 0.00001, value_loss: 0.00701 action_loss: 19.91806\n",
      "update_step:  59 model loss: 3.00600, kl_loss: 3.00047, obs_loss: 0.00552, reward_loss: 0.00001, value_loss: 0.00678 action_loss: 19.90911\n",
      "update_step:  60 model loss: 3.01069, kl_loss: 3.00160, obs_loss: 0.00908, reward_loss: 0.00001, value_loss: 0.00702 action_loss: 19.90767\n",
      "update_step:  61 model loss: 3.00524, kl_loss: 3.00058, obs_loss: 0.00465, reward_loss: 0.00001, value_loss: 0.00698 action_loss: 19.91714\n",
      "update_step:  62 model loss: 3.00691, kl_loss: 3.00024, obs_loss: 0.00666, reward_loss: 0.00001, value_loss: 0.00677 action_loss: 19.91360\n",
      "update_step:  63 model loss: 3.00738, kl_loss: 3.00044, obs_loss: 0.00694, reward_loss: 0.00001, value_loss: 0.00685 action_loss: 19.92408\n",
      "update_step:  64 model loss: 3.00644, kl_loss: 3.00040, obs_loss: 0.00603, reward_loss: 0.00001, value_loss: 0.00683 action_loss: 19.93353\n",
      "update_step:  65 model loss: 3.00669, kl_loss: 3.00061, obs_loss: 0.00607, reward_loss: 0.00001, value_loss: 0.00700 action_loss: 19.94139\n",
      "update_step:  66 model loss: 3.01353, kl_loss: 3.00119, obs_loss: 0.01234, reward_loss: 0.00001, value_loss: 0.00685 action_loss: 19.92847\n",
      "update_step:  67 model loss: 3.01369, kl_loss: 3.00125, obs_loss: 0.01243, reward_loss: 0.00001, value_loss: 0.00684 action_loss: 19.92532\n",
      "update_step:  68 model loss: 3.01310, kl_loss: 3.00095, obs_loss: 0.01214, reward_loss: 0.00001, value_loss: 0.00676 action_loss: 19.91552\n",
      "update_step:  69 model loss: 3.01600, kl_loss: 3.00080, obs_loss: 0.01519, reward_loss: 0.00001, value_loss: 0.00688 action_loss: 19.90744\n",
      "update_step:  70 model loss: 3.01950, kl_loss: 3.00104, obs_loss: 0.01846, reward_loss: 0.00001, value_loss: 0.00675 action_loss: 19.88305\n",
      "update_step:  71 model loss: 3.02564, kl_loss: 3.00048, obs_loss: 0.02515, reward_loss: 0.00001, value_loss: 0.00707 action_loss: 19.89886\n",
      "update_step:  72 model loss: 3.04479, kl_loss: 3.00125, obs_loss: 0.04353, reward_loss: 0.00001, value_loss: 0.00695 action_loss: 19.87998\n",
      "update_step:  73 model loss: 3.06870, kl_loss: 3.00078, obs_loss: 0.06791, reward_loss: 0.00001, value_loss: 0.00688 action_loss: 19.91158\n",
      "update_step:  74 model loss: 3.09507, kl_loss: 3.00006, obs_loss: 0.09500, reward_loss: 0.00001, value_loss: 0.00677 action_loss: 19.88430\n",
      "update_step:  75 model loss: 3.15664, kl_loss: 3.00047, obs_loss: 0.15616, reward_loss: 0.00001, value_loss: 0.00717 action_loss: 19.93586\n",
      "update_step:  76 model loss: 3.21000, kl_loss: 3.00002, obs_loss: 0.20997, reward_loss: 0.00001, value_loss: 0.00691 action_loss: 19.89252\n",
      "update_step:  77 model loss: 3.31224, kl_loss: 3.00077, obs_loss: 0.31145, reward_loss: 0.00001, value_loss: 0.00731 action_loss: 19.94962\n",
      "update_step:  78 model loss: 3.32298, kl_loss: 3.00045, obs_loss: 0.32252, reward_loss: 0.00001, value_loss: 0.00688 action_loss: 19.92477\n",
      "update_step:  79 model loss: 3.32710, kl_loss: 3.00062, obs_loss: 0.32646, reward_loss: 0.00001, value_loss: 0.00780 action_loss: 19.99414\n",
      "update_step:  80 model loss: 3.19632, kl_loss: 3.00065, obs_loss: 0.19565, reward_loss: 0.00001, value_loss: 0.00714 action_loss: 19.96807\n",
      "update_step:  81 model loss: 3.05952, kl_loss: 3.00090, obs_loss: 0.05861, reward_loss: 0.00001, value_loss: 0.00738 action_loss: 19.94922\n",
      "update_step:  82 model loss: 3.02158, kl_loss: 3.00027, obs_loss: 0.02130, reward_loss: 0.00001, value_loss: 0.00766 action_loss: 19.94802\n",
      "update_step:  83 model loss: 3.11857, kl_loss: 3.00079, obs_loss: 0.11777, reward_loss: 0.00001, value_loss: 0.00762 action_loss: 19.88325\n",
      "update_step:  84 model loss: 3.24519, kl_loss: 3.00027, obs_loss: 0.24491, reward_loss: 0.00001, value_loss: 0.00786 action_loss: 19.91234\n",
      "update_step:  85 model loss: 3.21688, kl_loss: 3.00019, obs_loss: 0.21668, reward_loss: 0.00001, value_loss: 0.00800 action_loss: 19.86798\n",
      "update_step:  86 model loss: 3.11461, kl_loss: 3.00060, obs_loss: 0.11400, reward_loss: 0.00001, value_loss: 0.00817 action_loss: 19.88705\n",
      "update_step:  87 model loss: 3.02844, kl_loss: 3.00061, obs_loss: 0.02782, reward_loss: 0.00001, value_loss: 0.00802 action_loss: 19.91451\n",
      "update_step:  88 model loss: 3.04355, kl_loss: 3.00036, obs_loss: 0.04318, reward_loss: 0.00001, value_loss: 0.00812 action_loss: 19.90406\n",
      "update_step:  89 model loss: 3.11888, kl_loss: 3.00062, obs_loss: 0.11825, reward_loss: 0.00001, value_loss: 0.00826 action_loss: 19.96640\n",
      "update_step:  90 model loss: 3.12267, kl_loss: 3.00042, obs_loss: 0.12224, reward_loss: 0.00001, value_loss: 0.00783 action_loss: 19.93866\n",
      "update_step:  91 model loss: 3.06446, kl_loss: 3.00044, obs_loss: 0.06400, reward_loss: 0.00001, value_loss: 0.00794 action_loss: 19.95912\n",
      "update_step:  92 model loss: 3.01656, kl_loss: 3.00041, obs_loss: 0.01615, reward_loss: 0.00001, value_loss: 0.00784 action_loss: 19.96006\n",
      "update_step:  93 model loss: 3.03605, kl_loss: 3.00057, obs_loss: 0.03547, reward_loss: 0.00001, value_loss: 0.00779 action_loss: 19.93828\n",
      "update_step:  94 model loss: 3.07620, kl_loss: 3.00066, obs_loss: 0.07553, reward_loss: 0.00001, value_loss: 0.00802 action_loss: 19.96782\n",
      "update_step:  95 model loss: 3.06289, kl_loss: 3.00096, obs_loss: 0.06193, reward_loss: 0.00001, value_loss: 0.00801 action_loss: 19.94562\n",
      "update_step:  96 model loss: 3.02607, kl_loss: 3.00112, obs_loss: 0.02494, reward_loss: 0.00001, value_loss: 0.00779 action_loss: 19.95089\n",
      "update_step:  97 model loss: 3.01037, kl_loss: 3.00029, obs_loss: 0.01007, reward_loss: 0.00001, value_loss: 0.00759 action_loss: 19.94615\n",
      "update_step:  98 model loss: 3.03325, kl_loss: 3.00022, obs_loss: 0.03302, reward_loss: 0.00001, value_loss: 0.00768 action_loss: 19.92482\n",
      "update_step:  99 model loss: 3.04859, kl_loss: 3.00044, obs_loss: 0.04814, reward_loss: 0.00001, value_loss: 0.00756 action_loss: 19.93081\n",
      "update_step: 100 model loss: 3.02666, kl_loss: 3.00049, obs_loss: 0.02617, reward_loss: 0.00001, value_loss: 0.00739 action_loss: 19.91129\n",
      "elasped time for update: 20.39s\n",
      "episode [  29/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01003, kl_loss: 3.00071, obs_loss: 0.00931, reward_loss: 0.00001, value_loss: 0.00782 action_loss: 19.91177\n",
      "update_step:   2 model loss: 3.01779, kl_loss: 3.00019, obs_loss: 0.01759, reward_loss: 0.00001, value_loss: 0.00772 action_loss: 19.92786\n",
      "update_step:   3 model loss: 3.02725, kl_loss: 3.00029, obs_loss: 0.02695, reward_loss: 0.00001, value_loss: 0.00783 action_loss: 19.92261\n",
      "update_step:   4 model loss: 3.02730, kl_loss: 3.00042, obs_loss: 0.02687, reward_loss: 0.00001, value_loss: 0.00791 action_loss: 19.94126\n",
      "update_step:   5 model loss: 3.01371, kl_loss: 3.00049, obs_loss: 0.01321, reward_loss: 0.00001, value_loss: 0.00779 action_loss: 19.95005\n",
      "update_step:   6 model loss: 3.00903, kl_loss: 3.00078, obs_loss: 0.00824, reward_loss: 0.00001, value_loss: 0.00769 action_loss: 19.94324\n",
      "update_step:   7 model loss: 3.01519, kl_loss: 3.00035, obs_loss: 0.01483, reward_loss: 0.00001, value_loss: 0.00761 action_loss: 19.93871\n",
      "update_step:   8 model loss: 3.02464, kl_loss: 3.00126, obs_loss: 0.02338, reward_loss: 0.00001, value_loss: 0.00760 action_loss: 19.92098\n",
      "update_step:   9 model loss: 3.01362, kl_loss: 3.00006, obs_loss: 0.01355, reward_loss: 0.00001, value_loss: 0.00758 action_loss: 19.90677\n",
      "update_step:  10 model loss: 3.01379, kl_loss: 3.00032, obs_loss: 0.01346, reward_loss: 0.00001, value_loss: 0.00753 action_loss: 19.90203\n",
      "update_step:  11 model loss: 3.00798, kl_loss: 3.00051, obs_loss: 0.00746, reward_loss: 0.00001, value_loss: 0.00738 action_loss: 19.90085\n",
      "update_step:  12 model loss: 3.01550, kl_loss: 3.00022, obs_loss: 0.01527, reward_loss: 0.00001, value_loss: 0.00733 action_loss: 19.92964\n",
      "update_step:  13 model loss: 3.02497, kl_loss: 3.00107, obs_loss: 0.02389, reward_loss: 0.00001, value_loss: 0.00712 action_loss: 19.93199\n",
      "update_step:  14 model loss: 3.02691, kl_loss: 3.00278, obs_loss: 0.02413, reward_loss: 0.00001, value_loss: 0.00725 action_loss: 19.94280\n",
      "update_step:  15 model loss: 3.00837, kl_loss: 3.00099, obs_loss: 0.00737, reward_loss: 0.00001, value_loss: 0.00710 action_loss: 19.94705\n",
      "update_step:  16 model loss: 3.01264, kl_loss: 3.00116, obs_loss: 0.01147, reward_loss: 0.00001, value_loss: 0.00712 action_loss: 19.92859\n",
      "update_step:  17 model loss: 3.01253, kl_loss: 3.00064, obs_loss: 0.01188, reward_loss: 0.00001, value_loss: 0.00716 action_loss: 19.91968\n",
      "update_step:  18 model loss: 3.01439, kl_loss: 3.00072, obs_loss: 0.01367, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 19.89113\n",
      "update_step:  19 model loss: 3.00554, kl_loss: 3.00035, obs_loss: 0.00519, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 19.88737\n",
      "update_step:  20 model loss: 3.00972, kl_loss: 3.00055, obs_loss: 0.00916, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.89710\n",
      "update_step:  21 model loss: 3.00855, kl_loss: 3.00004, obs_loss: 0.00851, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 19.89884\n",
      "update_step:  22 model loss: 3.01043, kl_loss: 3.00000, obs_loss: 0.01042, reward_loss: 0.00001, value_loss: 0.00704 action_loss: 19.91607\n",
      "update_step:  23 model loss: 3.01847, kl_loss: 3.00084, obs_loss: 0.01762, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.92258\n",
      "update_step:  24 model loss: 3.00798, kl_loss: 3.00060, obs_loss: 0.00737, reward_loss: 0.00001, value_loss: 0.00716 action_loss: 19.92914\n",
      "update_step:  25 model loss: 3.00560, kl_loss: 3.00070, obs_loss: 0.00489, reward_loss: 0.00001, value_loss: 0.00705 action_loss: 19.92739\n",
      "update_step:  26 model loss: 3.00862, kl_loss: 3.00047, obs_loss: 0.00814, reward_loss: 0.00001, value_loss: 0.00703 action_loss: 19.92854\n",
      "update_step:  27 model loss: 3.01142, kl_loss: 3.00134, obs_loss: 0.01008, reward_loss: 0.00001, value_loss: 0.00696 action_loss: 19.93519\n",
      "update_step:  28 model loss: 3.00602, kl_loss: 3.00028, obs_loss: 0.00573, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.93694\n",
      "update_step:  29 model loss: 3.00488, kl_loss: 3.00015, obs_loss: 0.00472, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.92457\n",
      "update_step:  30 model loss: 3.00705, kl_loss: 3.00024, obs_loss: 0.00680, reward_loss: 0.00001, value_loss: 0.00714 action_loss: 19.92743\n",
      "update_step:  31 model loss: 3.00870, kl_loss: 3.00016, obs_loss: 0.00853, reward_loss: 0.00001, value_loss: 0.00681 action_loss: 19.91845\n",
      "update_step:  32 model loss: 3.00588, kl_loss: 3.00039, obs_loss: 0.00548, reward_loss: 0.00001, value_loss: 0.00695 action_loss: 19.91482\n",
      "update_step:  33 model loss: 3.01035, kl_loss: 3.00055, obs_loss: 0.00979, reward_loss: 0.00001, value_loss: 0.00676 action_loss: 19.91170\n",
      "update_step:  34 model loss: 3.01167, kl_loss: 3.00110, obs_loss: 0.01056, reward_loss: 0.00001, value_loss: 0.00681 action_loss: 19.91447\n",
      "update_step:  35 model loss: 3.00990, kl_loss: 3.00098, obs_loss: 0.00891, reward_loss: 0.00001, value_loss: 0.00693 action_loss: 19.93738\n",
      "update_step:  36 model loss: 3.00852, kl_loss: 3.00055, obs_loss: 0.00796, reward_loss: 0.00001, value_loss: 0.00679 action_loss: 19.95325\n",
      "update_step:  37 model loss: 3.00555, kl_loss: 3.00044, obs_loss: 0.00510, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.96661\n",
      "update_step:  38 model loss: 3.00471, kl_loss: 3.00050, obs_loss: 0.00420, reward_loss: 0.00001, value_loss: 0.00703 action_loss: 19.97134\n",
      "update_step:  39 model loss: 3.00777, kl_loss: 3.00072, obs_loss: 0.00704, reward_loss: 0.00001, value_loss: 0.00684 action_loss: 19.96523\n",
      "update_step:  40 model loss: 3.01200, kl_loss: 3.00097, obs_loss: 0.01102, reward_loss: 0.00001, value_loss: 0.00687 action_loss: 19.94240\n",
      "update_step:  41 model loss: 3.00556, kl_loss: 3.00048, obs_loss: 0.00508, reward_loss: 0.00001, value_loss: 0.00665 action_loss: 19.90909\n",
      "update_step:  42 model loss: 3.00741, kl_loss: 3.00081, obs_loss: 0.00660, reward_loss: 0.00001, value_loss: 0.00701 action_loss: 19.88778\n",
      "update_step:  43 model loss: 3.00629, kl_loss: 3.00048, obs_loss: 0.00580, reward_loss: 0.00001, value_loss: 0.00699 action_loss: 19.88282\n",
      "update_step:  44 model loss: 3.00379, kl_loss: 3.00016, obs_loss: 0.00362, reward_loss: 0.00001, value_loss: 0.00677 action_loss: 19.89025\n",
      "update_step:  45 model loss: 3.00605, kl_loss: 3.00051, obs_loss: 0.00553, reward_loss: 0.00001, value_loss: 0.00670 action_loss: 19.91047\n",
      "update_step:  46 model loss: 3.00528, kl_loss: 3.00076, obs_loss: 0.00451, reward_loss: 0.00001, value_loss: 0.00685 action_loss: 19.93656\n",
      "update_step:  47 model loss: 3.01125, kl_loss: 3.00087, obs_loss: 0.01037, reward_loss: 0.00001, value_loss: 0.00680 action_loss: 19.95070\n",
      "update_step:  48 model loss: 3.01230, kl_loss: 3.00117, obs_loss: 0.01112, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.95630\n",
      "update_step:  49 model loss: 3.00532, kl_loss: 3.00028, obs_loss: 0.00504, reward_loss: 0.00001, value_loss: 0.00683 action_loss: 19.94508\n",
      "update_step:  50 model loss: 3.00737, kl_loss: 3.00053, obs_loss: 0.00683, reward_loss: 0.00001, value_loss: 0.00682 action_loss: 19.94134\n",
      "update_step:  51 model loss: 3.00583, kl_loss: 3.00008, obs_loss: 0.00574, reward_loss: 0.00001, value_loss: 0.00667 action_loss: 19.92454\n",
      "update_step:  52 model loss: 3.00723, kl_loss: 3.00016, obs_loss: 0.00706, reward_loss: 0.00001, value_loss: 0.00682 action_loss: 19.91117\n",
      "update_step:  53 model loss: 3.00490, kl_loss: 3.00043, obs_loss: 0.00445, reward_loss: 0.00001, value_loss: 0.00690 action_loss: 19.89169\n",
      "update_step:  54 model loss: 3.00627, kl_loss: 3.00013, obs_loss: 0.00614, reward_loss: 0.00001, value_loss: 0.00669 action_loss: 19.89223\n",
      "update_step:  55 model loss: 3.00800, kl_loss: 3.00042, obs_loss: 0.00758, reward_loss: 0.00001, value_loss: 0.00656 action_loss: 19.90517\n",
      "update_step:  56 model loss: 3.00494, kl_loss: 3.00016, obs_loss: 0.00476, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.91034\n",
      "update_step:  57 model loss: 3.01045, kl_loss: 3.00015, obs_loss: 0.01029, reward_loss: 0.00001, value_loss: 0.00657 action_loss: 19.93487\n",
      "update_step:  58 model loss: 3.00785, kl_loss: 3.00048, obs_loss: 0.00736, reward_loss: 0.00001, value_loss: 0.00652 action_loss: 19.94119\n",
      "update_step:  59 model loss: 3.00822, kl_loss: 3.00022, obs_loss: 0.00799, reward_loss: 0.00001, value_loss: 0.00658 action_loss: 19.96194\n",
      "update_step:  60 model loss: 3.01718, kl_loss: 3.00075, obs_loss: 0.01642, reward_loss: 0.00001, value_loss: 0.00688 action_loss: 19.94960\n",
      "update_step:  61 model loss: 3.00929, kl_loss: 3.00041, obs_loss: 0.00888, reward_loss: 0.00001, value_loss: 0.00685 action_loss: 19.94933\n",
      "update_step:  62 model loss: 3.01912, kl_loss: 3.00192, obs_loss: 0.01720, reward_loss: 0.00001, value_loss: 0.00664 action_loss: 19.93913\n",
      "update_step:  63 model loss: 3.00662, kl_loss: 3.00020, obs_loss: 0.00642, reward_loss: 0.00001, value_loss: 0.00656 action_loss: 19.92374\n",
      "update_step:  64 model loss: 3.00765, kl_loss: 3.00041, obs_loss: 0.00723, reward_loss: 0.00001, value_loss: 0.00664 action_loss: 19.91122\n",
      "update_step:  65 model loss: 3.00457, kl_loss: 3.00002, obs_loss: 0.00454, reward_loss: 0.00001, value_loss: 0.00684 action_loss: 19.90281\n",
      "update_step:  66 model loss: 3.00693, kl_loss: 3.00015, obs_loss: 0.00677, reward_loss: 0.00001, value_loss: 0.00676 action_loss: 19.90115\n",
      "update_step:  67 model loss: 3.01064, kl_loss: 3.00043, obs_loss: 0.01020, reward_loss: 0.00001, value_loss: 0.00664 action_loss: 19.88611\n",
      "update_step:  68 model loss: 3.01004, kl_loss: 3.00007, obs_loss: 0.00996, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.89672\n",
      "update_step:  69 model loss: 3.01217, kl_loss: 3.00028, obs_loss: 0.01189, reward_loss: 0.00001, value_loss: 0.00654 action_loss: 19.90035\n",
      "update_step:  70 model loss: 3.01996, kl_loss: 3.00074, obs_loss: 0.01921, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.91988\n",
      "update_step:  71 model loss: 3.01394, kl_loss: 3.00023, obs_loss: 0.01371, reward_loss: 0.00001, value_loss: 0.00659 action_loss: 19.91950\n",
      "update_step:  72 model loss: 3.01536, kl_loss: 3.00125, obs_loss: 0.01410, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.93410\n",
      "update_step:  73 model loss: 3.01050, kl_loss: 3.00068, obs_loss: 0.00981, reward_loss: 0.00001, value_loss: 0.00643 action_loss: 19.93278\n",
      "update_step:  74 model loss: 3.00989, kl_loss: 3.00140, obs_loss: 0.00848, reward_loss: 0.00001, value_loss: 0.00649 action_loss: 19.94315\n",
      "update_step:  75 model loss: 3.00909, kl_loss: 3.00151, obs_loss: 0.00758, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.92443\n",
      "update_step:  76 model loss: 3.01185, kl_loss: 3.00121, obs_loss: 0.01063, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.92574\n",
      "update_step:  77 model loss: 3.01372, kl_loss: 3.00095, obs_loss: 0.01276, reward_loss: 0.00001, value_loss: 0.00642 action_loss: 19.92448\n",
      "update_step:  78 model loss: 3.01008, kl_loss: 3.00064, obs_loss: 0.00943, reward_loss: 0.00001, value_loss: 0.00657 action_loss: 19.93555\n",
      "update_step:  79 model loss: 3.01048, kl_loss: 3.00029, obs_loss: 0.01018, reward_loss: 0.00001, value_loss: 0.00639 action_loss: 19.92792\n",
      "update_step:  80 model loss: 3.00991, kl_loss: 3.00044, obs_loss: 0.00946, reward_loss: 0.00001, value_loss: 0.00638 action_loss: 19.93090\n",
      "update_step:  81 model loss: 3.00737, kl_loss: 3.00044, obs_loss: 0.00692, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.93107\n",
      "update_step:  82 model loss: 3.00658, kl_loss: 3.00019, obs_loss: 0.00639, reward_loss: 0.00001, value_loss: 0.00637 action_loss: 19.92774\n",
      "update_step:  83 model loss: 3.00463, kl_loss: 3.00022, obs_loss: 0.00441, reward_loss: 0.00001, value_loss: 0.00646 action_loss: 19.92490\n",
      "update_step:  84 model loss: 3.00567, kl_loss: 3.00052, obs_loss: 0.00514, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 19.92583\n",
      "update_step:  85 model loss: 3.00434, kl_loss: 3.00032, obs_loss: 0.00401, reward_loss: 0.00001, value_loss: 0.00649 action_loss: 19.92416\n",
      "update_step:  86 model loss: 3.00563, kl_loss: 3.00039, obs_loss: 0.00523, reward_loss: 0.00001, value_loss: 0.00652 action_loss: 19.92533\n",
      "update_step:  87 model loss: 3.00392, kl_loss: 3.00007, obs_loss: 0.00384, reward_loss: 0.00001, value_loss: 0.00663 action_loss: 19.93316\n",
      "update_step:  88 model loss: 3.00739, kl_loss: 3.00020, obs_loss: 0.00718, reward_loss: 0.00001, value_loss: 0.00649 action_loss: 19.93658\n",
      "update_step:  89 model loss: 3.01001, kl_loss: 3.00088, obs_loss: 0.00912, reward_loss: 0.00001, value_loss: 0.00651 action_loss: 19.93858\n",
      "update_step:  90 model loss: 3.01390, kl_loss: 3.00101, obs_loss: 0.01288, reward_loss: 0.00001, value_loss: 0.00643 action_loss: 19.93413\n",
      "update_step:  91 model loss: 3.00737, kl_loss: 3.00043, obs_loss: 0.00694, reward_loss: 0.00001, value_loss: 0.00643 action_loss: 19.94192\n",
      "update_step:  92 model loss: 3.00862, kl_loss: 3.00020, obs_loss: 0.00841, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.92127\n",
      "update_step:  93 model loss: 3.01118, kl_loss: 3.00057, obs_loss: 0.01060, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.92737\n",
      "update_step:  94 model loss: 3.01128, kl_loss: 3.00064, obs_loss: 0.01064, reward_loss: 0.00001, value_loss: 0.00631 action_loss: 19.91322\n",
      "update_step:  95 model loss: 3.01561, kl_loss: 3.00068, obs_loss: 0.01492, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.92444\n",
      "update_step:  96 model loss: 3.01813, kl_loss: 3.00070, obs_loss: 0.01742, reward_loss: 0.00001, value_loss: 0.00629 action_loss: 19.91474\n",
      "update_step:  97 model loss: 3.02076, kl_loss: 3.00121, obs_loss: 0.01954, reward_loss: 0.00001, value_loss: 0.00645 action_loss: 19.93318\n",
      "update_step:  98 model loss: 3.01699, kl_loss: 3.00034, obs_loss: 0.01664, reward_loss: 0.00001, value_loss: 0.00634 action_loss: 19.92871\n",
      "update_step:  99 model loss: 3.02260, kl_loss: 3.00166, obs_loss: 0.02093, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.93760\n",
      "update_step: 100 model loss: 3.01596, kl_loss: 3.00041, obs_loss: 0.01555, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.92862\n",
      "elasped time for update: 20.18s\n",
      "episode [  30/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01608, kl_loss: 3.00086, obs_loss: 0.01522, reward_loss: 0.00001, value_loss: 0.00650 action_loss: 19.92841\n",
      "update_step:   2 model loss: 3.01077, kl_loss: 3.00036, obs_loss: 0.01040, reward_loss: 0.00001, value_loss: 0.00651 action_loss: 19.91389\n",
      "update_step:   3 model loss: 3.01026, kl_loss: 3.00045, obs_loss: 0.00980, reward_loss: 0.00001, value_loss: 0.00666 action_loss: 19.91232\n",
      "update_step:   4 model loss: 3.00935, kl_loss: 3.00021, obs_loss: 0.00913, reward_loss: 0.00001, value_loss: 0.00663 action_loss: 19.90495\n",
      "update_step:   5 model loss: 3.00757, kl_loss: 3.00007, obs_loss: 0.00749, reward_loss: 0.00001, value_loss: 0.00675 action_loss: 19.91722\n",
      "update_step:   6 model loss: 3.00790, kl_loss: 3.00017, obs_loss: 0.00772, reward_loss: 0.00001, value_loss: 0.00659 action_loss: 19.91755\n",
      "update_step:   7 model loss: 3.00674, kl_loss: 3.00032, obs_loss: 0.00642, reward_loss: 0.00001, value_loss: 0.00684 action_loss: 19.93997\n",
      "update_step:   8 model loss: 3.00892, kl_loss: 3.00019, obs_loss: 0.00872, reward_loss: 0.00001, value_loss: 0.00670 action_loss: 19.93920\n",
      "update_step:   9 model loss: 3.00478, kl_loss: 3.00003, obs_loss: 0.00474, reward_loss: 0.00001, value_loss: 0.00660 action_loss: 19.93748\n",
      "update_step:  10 model loss: 3.00577, kl_loss: 3.00004, obs_loss: 0.00573, reward_loss: 0.00001, value_loss: 0.00669 action_loss: 19.92386\n",
      "update_step:  11 model loss: 3.00560, kl_loss: 3.00006, obs_loss: 0.00554, reward_loss: 0.00001, value_loss: 0.00666 action_loss: 19.91222\n",
      "update_step:  12 model loss: 3.00555, kl_loss: 3.00003, obs_loss: 0.00551, reward_loss: 0.00001, value_loss: 0.00659 action_loss: 19.90432\n",
      "update_step:  13 model loss: 3.01272, kl_loss: 3.00069, obs_loss: 0.01202, reward_loss: 0.00001, value_loss: 0.00650 action_loss: 19.90414\n",
      "update_step:  14 model loss: 3.00876, kl_loss: 3.00070, obs_loss: 0.00806, reward_loss: 0.00001, value_loss: 0.00651 action_loss: 19.90289\n",
      "update_step:  15 model loss: 3.01010, kl_loss: 3.00084, obs_loss: 0.00925, reward_loss: 0.00001, value_loss: 0.00643 action_loss: 19.91913\n",
      "update_step:  16 model loss: 3.00736, kl_loss: 3.00083, obs_loss: 0.00652, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 19.92657\n",
      "update_step:  17 model loss: 3.00918, kl_loss: 3.00072, obs_loss: 0.00845, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.94921\n",
      "update_step:  18 model loss: 3.01010, kl_loss: 3.00020, obs_loss: 0.00989, reward_loss: 0.00001, value_loss: 0.00661 action_loss: 19.95146\n",
      "update_step:  19 model loss: 3.01051, kl_loss: 3.00011, obs_loss: 0.01040, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.97765\n",
      "update_step:  20 model loss: 3.01363, kl_loss: 3.00042, obs_loss: 0.01320, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.96596\n",
      "update_step:  21 model loss: 3.01890, kl_loss: 3.00017, obs_loss: 0.01873, reward_loss: 0.00001, value_loss: 0.00655 action_loss: 19.97882\n",
      "update_step:  22 model loss: 3.02010, kl_loss: 3.00001, obs_loss: 0.02008, reward_loss: 0.00001, value_loss: 0.00632 action_loss: 19.95748\n",
      "update_step:  23 model loss: 3.02732, kl_loss: 3.00045, obs_loss: 0.02687, reward_loss: 0.00001, value_loss: 0.00660 action_loss: 19.97211\n",
      "update_step:  24 model loss: 3.03855, kl_loss: 3.00167, obs_loss: 0.03688, reward_loss: 0.00001, value_loss: 0.00643 action_loss: 19.93889\n",
      "update_step:  25 model loss: 3.04452, kl_loss: 3.00071, obs_loss: 0.04380, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.95782\n",
      "update_step:  26 model loss: 3.04488, kl_loss: 3.00083, obs_loss: 0.04404, reward_loss: 0.00001, value_loss: 0.00649 action_loss: 19.92448\n",
      "update_step:  27 model loss: 3.05447, kl_loss: 3.00095, obs_loss: 0.05351, reward_loss: 0.00001, value_loss: 0.00673 action_loss: 19.94781\n",
      "update_step:  28 model loss: 3.05836, kl_loss: 3.00088, obs_loss: 0.05747, reward_loss: 0.00001, value_loss: 0.00673 action_loss: 19.92130\n",
      "update_step:  29 model loss: 3.06272, kl_loss: 3.00029, obs_loss: 0.06242, reward_loss: 0.00001, value_loss: 0.00655 action_loss: 19.95612\n",
      "update_step:  30 model loss: 3.04118, kl_loss: 3.00033, obs_loss: 0.04084, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 19.95263\n",
      "update_step:  31 model loss: 3.03978, kl_loss: 3.00056, obs_loss: 0.03921, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.96063\n",
      "update_step:  32 model loss: 3.01510, kl_loss: 3.00002, obs_loss: 0.01508, reward_loss: 0.00001, value_loss: 0.00662 action_loss: 19.95277\n",
      "update_step:  33 model loss: 3.01500, kl_loss: 3.00042, obs_loss: 0.01457, reward_loss: 0.00001, value_loss: 0.00654 action_loss: 19.93291\n",
      "update_step:  34 model loss: 3.01325, kl_loss: 3.00083, obs_loss: 0.01241, reward_loss: 0.00001, value_loss: 0.00671 action_loss: 19.91788\n",
      "update_step:  35 model loss: 3.01005, kl_loss: 3.00005, obs_loss: 0.01000, reward_loss: 0.00001, value_loss: 0.00694 action_loss: 19.90352\n",
      "update_step:  36 model loss: 3.01978, kl_loss: 3.00088, obs_loss: 0.01889, reward_loss: 0.00001, value_loss: 0.00676 action_loss: 19.90995\n",
      "update_step:  37 model loss: 3.01347, kl_loss: 3.00034, obs_loss: 0.01312, reward_loss: 0.00001, value_loss: 0.00682 action_loss: 19.91459\n",
      "update_step:  38 model loss: 3.01556, kl_loss: 3.00016, obs_loss: 0.01540, reward_loss: 0.00001, value_loss: 0.00668 action_loss: 19.93377\n",
      "update_step:  39 model loss: 3.01323, kl_loss: 3.00050, obs_loss: 0.01272, reward_loss: 0.00001, value_loss: 0.00677 action_loss: 19.94345\n",
      "update_step:  40 model loss: 3.02710, kl_loss: 3.00191, obs_loss: 0.02519, reward_loss: 0.00001, value_loss: 0.00689 action_loss: 19.97732\n",
      "update_step:  41 model loss: 3.02630, kl_loss: 3.00139, obs_loss: 0.02490, reward_loss: 0.00001, value_loss: 0.00716 action_loss: 19.96586\n",
      "update_step:  42 model loss: 3.03268, kl_loss: 3.00034, obs_loss: 0.03234, reward_loss: 0.00001, value_loss: 0.00690 action_loss: 19.99047\n",
      "update_step:  43 model loss: 3.02003, kl_loss: 3.00036, obs_loss: 0.01966, reward_loss: 0.00001, value_loss: 0.00672 action_loss: 19.97853\n",
      "update_step:  44 model loss: 3.04668, kl_loss: 3.00035, obs_loss: 0.04632, reward_loss: 0.00001, value_loss: 0.00673 action_loss: 19.96306\n",
      "update_step:  45 model loss: 3.00954, kl_loss: 3.00013, obs_loss: 0.00940, reward_loss: 0.00001, value_loss: 0.00689 action_loss: 19.95088\n",
      "update_step:  46 model loss: 3.03788, kl_loss: 3.00054, obs_loss: 0.03734, reward_loss: 0.00001, value_loss: 0.00669 action_loss: 19.91906\n",
      "update_step:  47 model loss: 3.02544, kl_loss: 3.00000, obs_loss: 0.02544, reward_loss: 0.00001, value_loss: 0.00691 action_loss: 19.91990\n",
      "update_step:  48 model loss: 3.05240, kl_loss: 3.00032, obs_loss: 0.05208, reward_loss: 0.00001, value_loss: 0.00683 action_loss: 19.88980\n",
      "update_step:  49 model loss: 3.06676, kl_loss: 3.00000, obs_loss: 0.06675, reward_loss: 0.00001, value_loss: 0.00721 action_loss: 19.96452\n",
      "update_step:  50 model loss: 3.09398, kl_loss: 3.00082, obs_loss: 0.09315, reward_loss: 0.00001, value_loss: 0.00679 action_loss: 19.97534\n",
      "update_step:  51 model loss: 3.08812, kl_loss: 3.00000, obs_loss: 0.08811, reward_loss: 0.00001, value_loss: 0.00723 action_loss: 20.01608\n",
      "update_step:  52 model loss: 3.06448, kl_loss: 3.00029, obs_loss: 0.06418, reward_loss: 0.00001, value_loss: 0.00700 action_loss: 20.00140\n",
      "update_step:  53 model loss: 3.04811, kl_loss: 3.00093, obs_loss: 0.04717, reward_loss: 0.00001, value_loss: 0.00722 action_loss: 19.99798\n",
      "update_step:  54 model loss: 3.02298, kl_loss: 3.00022, obs_loss: 0.02275, reward_loss: 0.00001, value_loss: 0.00707 action_loss: 19.96597\n",
      "update_step:  55 model loss: 3.01707, kl_loss: 3.00060, obs_loss: 0.01646, reward_loss: 0.00001, value_loss: 0.00700 action_loss: 19.91491\n",
      "update_step:  56 model loss: 3.01862, kl_loss: 3.00068, obs_loss: 0.01793, reward_loss: 0.00001, value_loss: 0.00726 action_loss: 19.91900\n",
      "update_step:  57 model loss: 3.02921, kl_loss: 3.00142, obs_loss: 0.02777, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.89826\n",
      "update_step:  58 model loss: 3.04504, kl_loss: 3.00090, obs_loss: 0.04414, reward_loss: 0.00001, value_loss: 0.00675 action_loss: 19.93493\n",
      "update_step:  59 model loss: 3.04218, kl_loss: 3.00026, obs_loss: 0.04191, reward_loss: 0.00001, value_loss: 0.00687 action_loss: 19.95901\n",
      "update_step:  60 model loss: 3.03089, kl_loss: 3.00035, obs_loss: 0.03053, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 20.01340\n",
      "update_step:  61 model loss: 3.01710, kl_loss: 3.00021, obs_loss: 0.01688, reward_loss: 0.00001, value_loss: 0.00697 action_loss: 20.02990\n",
      "update_step:  62 model loss: 3.00895, kl_loss: 3.00041, obs_loss: 0.00853, reward_loss: 0.00001, value_loss: 0.00718 action_loss: 20.01442\n",
      "update_step:  63 model loss: 3.01286, kl_loss: 3.00045, obs_loss: 0.01241, reward_loss: 0.00001, value_loss: 0.00659 action_loss: 20.01503\n",
      "update_step:  64 model loss: 3.02159, kl_loss: 3.00004, obs_loss: 0.02153, reward_loss: 0.00001, value_loss: 0.00652 action_loss: 19.97310\n",
      "update_step:  65 model loss: 3.04189, kl_loss: 3.00047, obs_loss: 0.04141, reward_loss: 0.00001, value_loss: 0.00661 action_loss: 19.95663\n",
      "update_step:  66 model loss: 3.04093, kl_loss: 3.00018, obs_loss: 0.04074, reward_loss: 0.00001, value_loss: 0.00681 action_loss: 19.90943\n",
      "update_step:  67 model loss: 3.03325, kl_loss: 3.00052, obs_loss: 0.03272, reward_loss: 0.00001, value_loss: 0.00681 action_loss: 19.92272\n",
      "update_step:  68 model loss: 3.02157, kl_loss: 3.00100, obs_loss: 0.02057, reward_loss: 0.00001, value_loss: 0.00666 action_loss: 19.91827\n",
      "update_step:  69 model loss: 3.01813, kl_loss: 3.00154, obs_loss: 0.01658, reward_loss: 0.00001, value_loss: 0.00658 action_loss: 19.93986\n",
      "update_step:  70 model loss: 3.01602, kl_loss: 3.00165, obs_loss: 0.01436, reward_loss: 0.00001, value_loss: 0.00670 action_loss: 19.95975\n",
      "update_step:  71 model loss: 3.01405, kl_loss: 3.00126, obs_loss: 0.01278, reward_loss: 0.00001, value_loss: 0.00681 action_loss: 19.97772\n",
      "update_step:  72 model loss: 3.01375, kl_loss: 3.00085, obs_loss: 0.01290, reward_loss: 0.00001, value_loss: 0.00685 action_loss: 20.00210\n",
      "update_step:  73 model loss: 3.01656, kl_loss: 3.00013, obs_loss: 0.01643, reward_loss: 0.00001, value_loss: 0.00682 action_loss: 19.98700\n",
      "update_step:  74 model loss: 3.01921, kl_loss: 3.00008, obs_loss: 0.01912, reward_loss: 0.00001, value_loss: 0.00661 action_loss: 19.98703\n",
      "update_step:  75 model loss: 3.02160, kl_loss: 3.00071, obs_loss: 0.02088, reward_loss: 0.00001, value_loss: 0.00651 action_loss: 19.94038\n",
      "update_step:  76 model loss: 3.02257, kl_loss: 3.00075, obs_loss: 0.02182, reward_loss: 0.00001, value_loss: 0.00693 action_loss: 19.92272\n",
      "update_step:  77 model loss: 3.01208, kl_loss: 3.00049, obs_loss: 0.01158, reward_loss: 0.00001, value_loss: 0.00697 action_loss: 19.88728\n",
      "update_step:  78 model loss: 3.00904, kl_loss: 3.00066, obs_loss: 0.00837, reward_loss: 0.00001, value_loss: 0.00697 action_loss: 19.88275\n",
      "update_step:  79 model loss: 3.00995, kl_loss: 3.00074, obs_loss: 0.00920, reward_loss: 0.00001, value_loss: 0.00688 action_loss: 19.89564\n",
      "update_step:  80 model loss: 3.00950, kl_loss: 3.00068, obs_loss: 0.00882, reward_loss: 0.00001, value_loss: 0.00674 action_loss: 19.91253\n",
      "update_step:  81 model loss: 3.01150, kl_loss: 3.00050, obs_loss: 0.01100, reward_loss: 0.00001, value_loss: 0.00666 action_loss: 19.95162\n",
      "update_step:  82 model loss: 3.01469, kl_loss: 3.00077, obs_loss: 0.01391, reward_loss: 0.00001, value_loss: 0.00684 action_loss: 19.96935\n",
      "update_step:  83 model loss: 3.01827, kl_loss: 3.00125, obs_loss: 0.01701, reward_loss: 0.00001, value_loss: 0.00678 action_loss: 20.01038\n",
      "update_step:  84 model loss: 3.01086, kl_loss: 3.00021, obs_loss: 0.01065, reward_loss: 0.00001, value_loss: 0.00663 action_loss: 20.01545\n",
      "update_step:  85 model loss: 3.00670, kl_loss: 3.00021, obs_loss: 0.00648, reward_loss: 0.00001, value_loss: 0.00689 action_loss: 20.01128\n",
      "update_step:  86 model loss: 3.01187, kl_loss: 3.00068, obs_loss: 0.01118, reward_loss: 0.00001, value_loss: 0.00669 action_loss: 19.99806\n",
      "update_step:  87 model loss: 3.01354, kl_loss: 3.00085, obs_loss: 0.01268, reward_loss: 0.00001, value_loss: 0.00656 action_loss: 19.98018\n",
      "update_step:  88 model loss: 3.01873, kl_loss: 3.00073, obs_loss: 0.01799, reward_loss: 0.00001, value_loss: 0.00665 action_loss: 19.98881\n",
      "update_step:  89 model loss: 3.01350, kl_loss: 3.00028, obs_loss: 0.01321, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.96276\n",
      "update_step:  90 model loss: 3.01593, kl_loss: 3.00014, obs_loss: 0.01577, reward_loss: 0.00001, value_loss: 0.00642 action_loss: 19.97178\n",
      "update_step:  91 model loss: 3.01985, kl_loss: 3.00031, obs_loss: 0.01953, reward_loss: 0.00001, value_loss: 0.00668 action_loss: 19.95476\n",
      "update_step:  92 model loss: 3.01742, kl_loss: 3.00043, obs_loss: 0.01699, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 19.97148\n",
      "update_step:  93 model loss: 3.01409, kl_loss: 3.00034, obs_loss: 0.01374, reward_loss: 0.00001, value_loss: 0.00662 action_loss: 19.95643\n",
      "update_step:  94 model loss: 3.01737, kl_loss: 3.00151, obs_loss: 0.01584, reward_loss: 0.00001, value_loss: 0.00668 action_loss: 19.97255\n",
      "update_step:  95 model loss: 3.00759, kl_loss: 3.00039, obs_loss: 0.00719, reward_loss: 0.00001, value_loss: 0.00676 action_loss: 19.98696\n",
      "update_step:  96 model loss: 3.00440, kl_loss: 3.00018, obs_loss: 0.00421, reward_loss: 0.00001, value_loss: 0.00681 action_loss: 20.00236\n",
      "update_step:  97 model loss: 3.00693, kl_loss: 3.00049, obs_loss: 0.00644, reward_loss: 0.00001, value_loss: 0.00710 action_loss: 20.00492\n",
      "update_step:  98 model loss: 3.00673, kl_loss: 3.00024, obs_loss: 0.00648, reward_loss: 0.00001, value_loss: 0.00658 action_loss: 19.99273\n",
      "update_step:  99 model loss: 3.00471, kl_loss: 3.00031, obs_loss: 0.00439, reward_loss: 0.00001, value_loss: 0.00649 action_loss: 19.97231\n",
      "update_step: 100 model loss: 3.00765, kl_loss: 3.00047, obs_loss: 0.00718, reward_loss: 0.00001, value_loss: 0.00662 action_loss: 19.92436\n",
      "elasped time for update: 20.18s\n",
      "Total test reward at episode [  30/ 100] is -2.000000\n",
      "elasped time for test: 0.05s\n",
      "episode [  31/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.01804, kl_loss: 3.00140, obs_loss: 0.01663, reward_loss: 0.00001, value_loss: 0.00687 action_loss: 19.90076\n",
      "update_step:   2 model loss: 3.00749, kl_loss: 3.00002, obs_loss: 0.00746, reward_loss: 0.00001, value_loss: 0.00695 action_loss: 19.87783\n",
      "update_step:   3 model loss: 3.01566, kl_loss: 3.00138, obs_loss: 0.01427, reward_loss: 0.00001, value_loss: 0.00706 action_loss: 19.88647\n",
      "update_step:   4 model loss: 3.00923, kl_loss: 3.00093, obs_loss: 0.00829, reward_loss: 0.00001, value_loss: 0.00657 action_loss: 19.88674\n",
      "update_step:   5 model loss: 3.01399, kl_loss: 3.00098, obs_loss: 0.01301, reward_loss: 0.00001, value_loss: 0.00636 action_loss: 19.92983\n",
      "update_step:   6 model loss: 3.01754, kl_loss: 3.00049, obs_loss: 0.01704, reward_loss: 0.00001, value_loss: 0.00629 action_loss: 19.94001\n",
      "update_step:   7 model loss: 3.01900, kl_loss: 3.00036, obs_loss: 0.01863, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.97719\n",
      "update_step:   8 model loss: 3.02163, kl_loss: 3.00007, obs_loss: 0.02156, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.95966\n",
      "update_step:   9 model loss: 3.02445, kl_loss: 3.00000, obs_loss: 0.02445, reward_loss: 0.00001, value_loss: 0.00617 action_loss: 19.96326\n",
      "update_step:  10 model loss: 3.02073, kl_loss: 3.00023, obs_loss: 0.02049, reward_loss: 0.00001, value_loss: 0.00623 action_loss: 19.92809\n",
      "update_step:  11 model loss: 3.02124, kl_loss: 3.00054, obs_loss: 0.02070, reward_loss: 0.00001, value_loss: 0.00624 action_loss: 19.93049\n",
      "update_step:  12 model loss: 3.02337, kl_loss: 3.00125, obs_loss: 0.02212, reward_loss: 0.00001, value_loss: 0.00621 action_loss: 19.91547\n",
      "update_step:  13 model loss: 3.01364, kl_loss: 3.00063, obs_loss: 0.01301, reward_loss: 0.00001, value_loss: 0.00624 action_loss: 19.93238\n",
      "update_step:  14 model loss: 3.00709, kl_loss: 3.00111, obs_loss: 0.00598, reward_loss: 0.00001, value_loss: 0.00628 action_loss: 19.94339\n",
      "update_step:  15 model loss: 3.00801, kl_loss: 3.00128, obs_loss: 0.00672, reward_loss: 0.00001, value_loss: 0.00652 action_loss: 19.96897\n",
      "update_step:  16 model loss: 3.00545, kl_loss: 3.00159, obs_loss: 0.00385, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.98663\n",
      "update_step:  17 model loss: 3.00479, kl_loss: 3.00085, obs_loss: 0.00393, reward_loss: 0.00001, value_loss: 0.00635 action_loss: 19.99196\n",
      "update_step:  18 model loss: 3.01205, kl_loss: 3.00113, obs_loss: 0.01091, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.99444\n",
      "update_step:  19 model loss: 3.00484, kl_loss: 3.00015, obs_loss: 0.00468, reward_loss: 0.00001, value_loss: 0.00646 action_loss: 19.97895\n",
      "update_step:  20 model loss: 3.02131, kl_loss: 3.00144, obs_loss: 0.01987, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.97791\n",
      "update_step:  21 model loss: 3.00813, kl_loss: 3.00023, obs_loss: 0.00790, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.96631\n",
      "update_step:  22 model loss: 3.00649, kl_loss: 3.00011, obs_loss: 0.00637, reward_loss: 0.00001, value_loss: 0.00634 action_loss: 19.98146\n",
      "update_step:  23 model loss: 3.00740, kl_loss: 3.00010, obs_loss: 0.00729, reward_loss: 0.00001, value_loss: 0.00637 action_loss: 19.97694\n",
      "update_step:  24 model loss: 3.01058, kl_loss: 3.00044, obs_loss: 0.01013, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.98945\n",
      "update_step:  25 model loss: 3.01891, kl_loss: 3.00074, obs_loss: 0.01817, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.97568\n",
      "update_step:  26 model loss: 3.01117, kl_loss: 3.00002, obs_loss: 0.01114, reward_loss: 0.00001, value_loss: 0.00652 action_loss: 19.99871\n",
      "update_step:  27 model loss: 3.01175, kl_loss: 3.00031, obs_loss: 0.01143, reward_loss: 0.00001, value_loss: 0.00644 action_loss: 19.98141\n",
      "update_step:  28 model loss: 3.01450, kl_loss: 3.00161, obs_loss: 0.01288, reward_loss: 0.00001, value_loss: 0.00638 action_loss: 19.98480\n",
      "update_step:  29 model loss: 3.01363, kl_loss: 3.00181, obs_loss: 0.01181, reward_loss: 0.00001, value_loss: 0.00652 action_loss: 19.96021\n",
      "update_step:  30 model loss: 3.01922, kl_loss: 3.00148, obs_loss: 0.01774, reward_loss: 0.00001, value_loss: 0.00653 action_loss: 19.97835\n",
      "update_step:  31 model loss: 3.01690, kl_loss: 3.00021, obs_loss: 0.01669, reward_loss: 0.00001, value_loss: 0.00637 action_loss: 19.95466\n",
      "update_step:  32 model loss: 3.02451, kl_loss: 3.00065, obs_loss: 0.02384, reward_loss: 0.00001, value_loss: 0.00645 action_loss: 19.94724\n",
      "update_step:  33 model loss: 3.01816, kl_loss: 3.00063, obs_loss: 0.01753, reward_loss: 0.00001, value_loss: 0.00659 action_loss: 19.92632\n",
      "update_step:  34 model loss: 3.01324, kl_loss: 3.00016, obs_loss: 0.01307, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.93498\n",
      "update_step:  35 model loss: 3.01977, kl_loss: 3.00066, obs_loss: 0.01910, reward_loss: 0.00001, value_loss: 0.00651 action_loss: 19.92189\n",
      "update_step:  36 model loss: 3.01481, kl_loss: 3.00043, obs_loss: 0.01437, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.93602\n",
      "update_step:  37 model loss: 3.00985, kl_loss: 3.00007, obs_loss: 0.00977, reward_loss: 0.00001, value_loss: 0.00649 action_loss: 19.94183\n",
      "update_step:  38 model loss: 3.01470, kl_loss: 3.00078, obs_loss: 0.01391, reward_loss: 0.00001, value_loss: 0.00658 action_loss: 19.94171\n",
      "update_step:  39 model loss: 3.00752, kl_loss: 3.00002, obs_loss: 0.00749, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.94706\n",
      "update_step:  40 model loss: 3.01092, kl_loss: 3.00071, obs_loss: 0.01020, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.96701\n",
      "update_step:  41 model loss: 3.00791, kl_loss: 3.00032, obs_loss: 0.00759, reward_loss: 0.00001, value_loss: 0.00650 action_loss: 19.97991\n",
      "update_step:  42 model loss: 3.01389, kl_loss: 3.00103, obs_loss: 0.01285, reward_loss: 0.00001, value_loss: 0.00659 action_loss: 19.97152\n",
      "update_step:  43 model loss: 3.00750, kl_loss: 3.00106, obs_loss: 0.00643, reward_loss: 0.00001, value_loss: 0.00660 action_loss: 19.98905\n",
      "update_step:  44 model loss: 3.00880, kl_loss: 3.00134, obs_loss: 0.00745, reward_loss: 0.00001, value_loss: 0.00648 action_loss: 19.98735\n",
      "update_step:  45 model loss: 3.00817, kl_loss: 3.00063, obs_loss: 0.00753, reward_loss: 0.00001, value_loss: 0.00634 action_loss: 19.98642\n",
      "update_step:  46 model loss: 3.00766, kl_loss: 3.00014, obs_loss: 0.00751, reward_loss: 0.00001, value_loss: 0.00636 action_loss: 19.97313\n",
      "update_step:  47 model loss: 3.01020, kl_loss: 3.00037, obs_loss: 0.00982, reward_loss: 0.00001, value_loss: 0.00627 action_loss: 19.98092\n",
      "update_step:  48 model loss: 3.00901, kl_loss: 3.00004, obs_loss: 0.00896, reward_loss: 0.00001, value_loss: 0.00631 action_loss: 19.97216\n",
      "update_step:  49 model loss: 3.01306, kl_loss: 3.00076, obs_loss: 0.01229, reward_loss: 0.00001, value_loss: 0.00630 action_loss: 19.97064\n",
      "update_step:  50 model loss: 3.00541, kl_loss: 3.00022, obs_loss: 0.00518, reward_loss: 0.00001, value_loss: 0.00620 action_loss: 19.97218\n",
      "update_step:  51 model loss: 3.00506, kl_loss: 3.00010, obs_loss: 0.00495, reward_loss: 0.00001, value_loss: 0.00618 action_loss: 19.97779\n",
      "update_step:  52 model loss: 3.00367, kl_loss: 3.00019, obs_loss: 0.00348, reward_loss: 0.00001, value_loss: 0.00595 action_loss: 19.97008\n",
      "update_step:  53 model loss: 3.00546, kl_loss: 3.00018, obs_loss: 0.00527, reward_loss: 0.00001, value_loss: 0.00604 action_loss: 19.96983\n",
      "update_step:  54 model loss: 3.01123, kl_loss: 3.00053, obs_loss: 0.01069, reward_loss: 0.00001, value_loss: 0.00600 action_loss: 19.96338\n",
      "update_step:  55 model loss: 3.00932, kl_loss: 3.00199, obs_loss: 0.00732, reward_loss: 0.00001, value_loss: 0.00611 action_loss: 19.96174\n",
      "update_step:  56 model loss: 3.01240, kl_loss: 3.00056, obs_loss: 0.01184, reward_loss: 0.00001, value_loss: 0.00597 action_loss: 19.94554\n",
      "update_step:  57 model loss: 3.00829, kl_loss: 3.00087, obs_loss: 0.00741, reward_loss: 0.00001, value_loss: 0.00590 action_loss: 19.93701\n",
      "update_step:  58 model loss: 3.00602, kl_loss: 3.00160, obs_loss: 0.00442, reward_loss: 0.00001, value_loss: 0.00600 action_loss: 19.93225\n",
      "update_step:  59 model loss: 3.00479, kl_loss: 3.00075, obs_loss: 0.00403, reward_loss: 0.00001, value_loss: 0.00595 action_loss: 19.93871\n",
      "update_step:  60 model loss: 3.01389, kl_loss: 3.00171, obs_loss: 0.01218, reward_loss: 0.00001, value_loss: 0.00597 action_loss: 19.95458\n",
      "update_step:  61 model loss: 3.00707, kl_loss: 3.00029, obs_loss: 0.00678, reward_loss: 0.00001, value_loss: 0.00602 action_loss: 19.95621\n",
      "update_step:  62 model loss: 3.00646, kl_loss: 3.00020, obs_loss: 0.00625, reward_loss: 0.00001, value_loss: 0.00589 action_loss: 19.97015\n",
      "update_step:  63 model loss: 3.01007, kl_loss: 3.00025, obs_loss: 0.00981, reward_loss: 0.00001, value_loss: 0.00592 action_loss: 19.96177\n",
      "update_step:  64 model loss: 3.00890, kl_loss: 3.00126, obs_loss: 0.00763, reward_loss: 0.00001, value_loss: 0.00601 action_loss: 19.96907\n",
      "update_step:  65 model loss: 3.01038, kl_loss: 3.00015, obs_loss: 0.01023, reward_loss: 0.00001, value_loss: 0.00596 action_loss: 19.95148\n",
      "update_step:  66 model loss: 3.01350, kl_loss: 3.00030, obs_loss: 0.01319, reward_loss: 0.00001, value_loss: 0.00593 action_loss: 19.96307\n",
      "update_step:  67 model loss: 3.01309, kl_loss: 3.00022, obs_loss: 0.01287, reward_loss: 0.00001, value_loss: 0.00590 action_loss: 19.94061\n",
      "update_step:  68 model loss: 3.02104, kl_loss: 3.00136, obs_loss: 0.01967, reward_loss: 0.00001, value_loss: 0.00608 action_loss: 19.95513\n",
      "update_step:  69 model loss: 3.02043, kl_loss: 3.00023, obs_loss: 0.02020, reward_loss: 0.00001, value_loss: 0.00610 action_loss: 19.93403\n",
      "update_step:  70 model loss: 3.02279, kl_loss: 3.00074, obs_loss: 0.02204, reward_loss: 0.00001, value_loss: 0.00603 action_loss: 19.96242\n",
      "update_step:  71 model loss: 3.02342, kl_loss: 3.00110, obs_loss: 0.02232, reward_loss: 0.00001, value_loss: 0.00619 action_loss: 19.96593\n",
      "update_step:  72 model loss: 3.02716, kl_loss: 3.00051, obs_loss: 0.02664, reward_loss: 0.00001, value_loss: 0.00623 action_loss: 20.01561\n",
      "update_step:  73 model loss: 3.02655, kl_loss: 3.00040, obs_loss: 0.02614, reward_loss: 0.00001, value_loss: 0.00608 action_loss: 19.98685\n",
      "update_step:  74 model loss: 3.03120, kl_loss: 3.00016, obs_loss: 0.03103, reward_loss: 0.00001, value_loss: 0.00617 action_loss: 19.99780\n",
      "update_step:  75 model loss: 3.04335, kl_loss: 3.00129, obs_loss: 0.04206, reward_loss: 0.00001, value_loss: 0.00602 action_loss: 19.96162\n",
      "update_step:  76 model loss: 3.04395, kl_loss: 3.00027, obs_loss: 0.04367, reward_loss: 0.00001, value_loss: 0.00617 action_loss: 19.98098\n",
      "update_step:  77 model loss: 3.04355, kl_loss: 3.00043, obs_loss: 0.04310, reward_loss: 0.00001, value_loss: 0.00601 action_loss: 19.93264\n",
      "update_step:  78 model loss: 3.04817, kl_loss: 3.00100, obs_loss: 0.04716, reward_loss: 0.00001, value_loss: 0.00622 action_loss: 19.96114\n",
      "update_step:  79 model loss: 3.05003, kl_loss: 3.00251, obs_loss: 0.04751, reward_loss: 0.00001, value_loss: 0.00646 action_loss: 19.93909\n",
      "update_step:  80 model loss: 3.04749, kl_loss: 3.00124, obs_loss: 0.04624, reward_loss: 0.00001, value_loss: 0.00623 action_loss: 19.97520\n",
      "update_step:  81 model loss: 3.05230, kl_loss: 3.00112, obs_loss: 0.05117, reward_loss: 0.00001, value_loss: 0.00624 action_loss: 19.92876\n",
      "update_step:  82 model loss: 3.05824, kl_loss: 3.00226, obs_loss: 0.05596, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.96282\n",
      "update_step:  83 model loss: 3.04548, kl_loss: 3.00106, obs_loss: 0.04441, reward_loss: 0.00001, value_loss: 0.00662 action_loss: 19.95143\n",
      "update_step:  84 model loss: 3.02806, kl_loss: 3.00093, obs_loss: 0.02713, reward_loss: 0.00001, value_loss: 0.00656 action_loss: 19.96127\n",
      "update_step:  85 model loss: 3.02422, kl_loss: 3.00090, obs_loss: 0.02331, reward_loss: 0.00001, value_loss: 0.00670 action_loss: 19.92148\n",
      "update_step:  86 model loss: 3.01092, kl_loss: 3.00030, obs_loss: 0.01061, reward_loss: 0.00001, value_loss: 0.00655 action_loss: 19.92471\n",
      "update_step:  87 model loss: 3.01242, kl_loss: 3.00072, obs_loss: 0.01170, reward_loss: 0.00001, value_loss: 0.00650 action_loss: 19.94356\n",
      "update_step:  88 model loss: 3.01107, kl_loss: 3.00017, obs_loss: 0.01088, reward_loss: 0.00001, value_loss: 0.00633 action_loss: 19.93416\n",
      "update_step:  89 model loss: 3.02538, kl_loss: 3.00050, obs_loss: 0.02486, reward_loss: 0.00001, value_loss: 0.00643 action_loss: 19.97496\n",
      "update_step:  90 model loss: 3.03827, kl_loss: 3.00089, obs_loss: 0.03737, reward_loss: 0.00001, value_loss: 0.00669 action_loss: 19.97777\n",
      "update_step:  91 model loss: 3.04982, kl_loss: 3.00067, obs_loss: 0.04914, reward_loss: 0.00001, value_loss: 0.00689 action_loss: 20.01969\n",
      "update_step:  92 model loss: 3.03748, kl_loss: 3.00097, obs_loss: 0.03649, reward_loss: 0.00001, value_loss: 0.00711 action_loss: 19.99276\n",
      "update_step:  93 model loss: 3.04078, kl_loss: 3.00106, obs_loss: 0.03971, reward_loss: 0.00001, value_loss: 0.00705 action_loss: 20.02884\n",
      "update_step:  94 model loss: 3.02131, kl_loss: 3.00037, obs_loss: 0.02092, reward_loss: 0.00001, value_loss: 0.00656 action_loss: 19.98833\n",
      "update_step:  95 model loss: 3.02257, kl_loss: 3.00071, obs_loss: 0.02186, reward_loss: 0.00001, value_loss: 0.00640 action_loss: 19.95242\n",
      "update_step:  96 model loss: 3.01232, kl_loss: 3.00011, obs_loss: 0.01220, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 19.97039\n",
      "update_step:  97 model loss: 3.02306, kl_loss: 3.00001, obs_loss: 0.02305, reward_loss: 0.00001, value_loss: 0.00635 action_loss: 19.94764\n",
      "update_step:  98 model loss: 3.04865, kl_loss: 3.00000, obs_loss: 0.04864, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 19.95946\n",
      "update_step:  99 model loss: 3.05501, kl_loss: 3.00027, obs_loss: 0.05473, reward_loss: 0.00001, value_loss: 0.00611 action_loss: 19.92908\n",
      "update_step: 100 model loss: 3.07017, kl_loss: 3.00020, obs_loss: 0.06996, reward_loss: 0.00001, value_loss: 0.00635 action_loss: 19.98815\n",
      "elasped time for update: 20.10s\n",
      "episode [  32/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.06026, kl_loss: 3.00019, obs_loss: 0.06005, reward_loss: 0.00001, value_loss: 0.00628 action_loss: 19.95062\n",
      "update_step:   2 model loss: 3.05294, kl_loss: 3.00012, obs_loss: 0.05281, reward_loss: 0.00001, value_loss: 0.00645 action_loss: 19.99323\n",
      "update_step:   3 model loss: 3.03327, kl_loss: 3.00049, obs_loss: 0.03278, reward_loss: 0.00001, value_loss: 0.00634 action_loss: 19.99910\n",
      "update_step:   4 model loss: 3.01506, kl_loss: 3.00017, obs_loss: 0.01488, reward_loss: 0.00001, value_loss: 0.00620 action_loss: 19.98264\n",
      "update_step:   5 model loss: 3.01827, kl_loss: 3.00079, obs_loss: 0.01748, reward_loss: 0.00001, value_loss: 0.00629 action_loss: 19.95856\n",
      "update_step:   6 model loss: 3.04231, kl_loss: 3.00027, obs_loss: 0.04204, reward_loss: 0.00001, value_loss: 0.00630 action_loss: 19.89040\n",
      "update_step:   7 model loss: 3.09593, kl_loss: 3.00025, obs_loss: 0.09568, reward_loss: 0.00001, value_loss: 0.00641 action_loss: 19.91523\n",
      "update_step:   8 model loss: 3.12020, kl_loss: 3.00019, obs_loss: 0.12000, reward_loss: 0.00002, value_loss: 0.00675 action_loss: 19.84883\n",
      "update_step:   9 model loss: 3.13875, kl_loss: 3.00028, obs_loss: 0.13846, reward_loss: 0.00001, value_loss: 0.00636 action_loss: 19.93738\n",
      "update_step:  10 model loss: 3.05944, kl_loss: 3.00012, obs_loss: 0.05931, reward_loss: 0.00001, value_loss: 0.00635 action_loss: 19.96865\n",
      "update_step:  11 model loss: 3.05952, kl_loss: 3.00016, obs_loss: 0.05935, reward_loss: 0.00001, value_loss: 0.00666 action_loss: 19.99698\n",
      "update_step:  12 model loss: 3.01335, kl_loss: 3.00023, obs_loss: 0.01311, reward_loss: 0.00001, value_loss: 0.00705 action_loss: 19.98481\n",
      "update_step:  13 model loss: 3.05025, kl_loss: 3.00041, obs_loss: 0.04983, reward_loss: 0.00001, value_loss: 0.00686 action_loss: 19.95339\n",
      "update_step:  14 model loss: 3.04535, kl_loss: 3.00000, obs_loss: 0.04534, reward_loss: 0.00001, value_loss: 0.00697 action_loss: 19.96421\n",
      "update_step:  15 model loss: 3.04478, kl_loss: 3.00000, obs_loss: 0.04477, reward_loss: 0.00001, value_loss: 0.00733 action_loss: 19.89420\n",
      "update_step:  16 model loss: 3.05489, kl_loss: 3.00023, obs_loss: 0.05465, reward_loss: 0.00001, value_loss: 0.00712 action_loss: 19.90665\n",
      "update_step:  17 model loss: 3.03071, kl_loss: 3.00019, obs_loss: 0.03052, reward_loss: 0.00001, value_loss: 0.00721 action_loss: 19.91766\n",
      "update_step:  18 model loss: 3.03295, kl_loss: 3.00001, obs_loss: 0.03293, reward_loss: 0.00001, value_loss: 0.00684 action_loss: 19.99417\n",
      "update_step:  19 model loss: 3.02197, kl_loss: 3.00010, obs_loss: 0.02186, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 20.02506\n",
      "update_step:  20 model loss: 3.04089, kl_loss: 3.00079, obs_loss: 0.04009, reward_loss: 0.00001, value_loss: 0.00850 action_loss: 20.08295\n",
      "update_step:  21 model loss: 3.02383, kl_loss: 3.00272, obs_loss: 0.02110, reward_loss: 0.00001, value_loss: 0.00890 action_loss: 20.09951\n",
      "update_step:  22 model loss: 3.02308, kl_loss: 3.00151, obs_loss: 0.02157, reward_loss: 0.00001, value_loss: 0.00819 action_loss: 20.07925\n",
      "update_step:  23 model loss: 3.01583, kl_loss: 3.00049, obs_loss: 0.01534, reward_loss: 0.00001, value_loss: 0.00673 action_loss: 20.00067\n",
      "update_step:  24 model loss: 3.00948, kl_loss: 3.00028, obs_loss: 0.00918, reward_loss: 0.00001, value_loss: 0.00769 action_loss: 19.94530\n",
      "update_step:  25 model loss: 3.02954, kl_loss: 3.00151, obs_loss: 0.02802, reward_loss: 0.00001, value_loss: 0.00859 action_loss: 19.91437\n",
      "update_step:  26 model loss: 3.01149, kl_loss: 3.00008, obs_loss: 0.01140, reward_loss: 0.00001, value_loss: 0.00747 action_loss: 19.89269\n",
      "update_step:  27 model loss: 3.00773, kl_loss: 3.00015, obs_loss: 0.00757, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.89772\n",
      "update_step:  28 model loss: 3.01783, kl_loss: 3.00043, obs_loss: 0.01739, reward_loss: 0.00001, value_loss: 0.00667 action_loss: 19.94797\n",
      "update_step:  29 model loss: 3.00819, kl_loss: 3.00038, obs_loss: 0.00780, reward_loss: 0.00001, value_loss: 0.00614 action_loss: 19.97879\n",
      "update_step:  30 model loss: 3.02092, kl_loss: 3.00010, obs_loss: 0.02081, reward_loss: 0.00001, value_loss: 0.00705 action_loss: 19.99773\n",
      "update_step:  31 model loss: 3.01639, kl_loss: 3.00048, obs_loss: 0.01589, reward_loss: 0.00001, value_loss: 0.00701 action_loss: 20.01228\n",
      "update_step:  32 model loss: 3.00990, kl_loss: 3.00033, obs_loss: 0.00956, reward_loss: 0.00001, value_loss: 0.00696 action_loss: 20.04833\n",
      "update_step:  33 model loss: 3.01210, kl_loss: 3.00069, obs_loss: 0.01139, reward_loss: 0.00001, value_loss: 0.00686 action_loss: 20.01712\n",
      "update_step:  34 model loss: 3.01218, kl_loss: 3.00130, obs_loss: 0.01088, reward_loss: 0.00001, value_loss: 0.00626 action_loss: 19.96720\n",
      "update_step:  35 model loss: 3.01442, kl_loss: 3.00091, obs_loss: 0.01350, reward_loss: 0.00001, value_loss: 0.00597 action_loss: 19.95331\n",
      "update_step:  36 model loss: 3.01165, kl_loss: 3.00078, obs_loss: 0.01086, reward_loss: 0.00001, value_loss: 0.00670 action_loss: 19.92175\n",
      "update_step:  37 model loss: 3.01252, kl_loss: 3.00171, obs_loss: 0.01080, reward_loss: 0.00001, value_loss: 0.00629 action_loss: 19.89001\n",
      "update_step:  38 model loss: 3.01040, kl_loss: 3.00043, obs_loss: 0.00995, reward_loss: 0.00001, value_loss: 0.00650 action_loss: 19.88462\n",
      "update_step:  39 model loss: 3.00643, kl_loss: 3.00056, obs_loss: 0.00586, reward_loss: 0.00001, value_loss: 0.00692 action_loss: 19.91858\n",
      "update_step:  40 model loss: 3.01127, kl_loss: 3.00039, obs_loss: 0.01087, reward_loss: 0.00001, value_loss: 0.00596 action_loss: 19.94741\n",
      "update_step:  41 model loss: 3.00630, kl_loss: 3.00042, obs_loss: 0.00588, reward_loss: 0.00001, value_loss: 0.00619 action_loss: 19.98009\n",
      "update_step:  42 model loss: 3.01022, kl_loss: 3.00063, obs_loss: 0.00958, reward_loss: 0.00001, value_loss: 0.00647 action_loss: 20.01090\n",
      "update_step:  43 model loss: 3.01283, kl_loss: 3.00041, obs_loss: 0.01241, reward_loss: 0.00001, value_loss: 0.00618 action_loss: 20.04481\n",
      "update_step:  44 model loss: 3.00972, kl_loss: 3.00034, obs_loss: 0.00937, reward_loss: 0.00001, value_loss: 0.00610 action_loss: 20.00551\n",
      "update_step:  45 model loss: 3.02111, kl_loss: 3.00210, obs_loss: 0.01900, reward_loss: 0.00001, value_loss: 0.00579 action_loss: 19.96332\n",
      "update_step:  46 model loss: 3.00951, kl_loss: 3.00101, obs_loss: 0.00849, reward_loss: 0.00001, value_loss: 0.00582 action_loss: 19.93670\n",
      "update_step:  47 model loss: 3.00580, kl_loss: 3.00061, obs_loss: 0.00518, reward_loss: 0.00001, value_loss: 0.00623 action_loss: 19.91720\n",
      "update_step:  48 model loss: 3.00712, kl_loss: 3.00048, obs_loss: 0.00663, reward_loss: 0.00001, value_loss: 0.00591 action_loss: 19.91483\n",
      "update_step:  49 model loss: 3.01229, kl_loss: 3.00023, obs_loss: 0.01206, reward_loss: 0.00001, value_loss: 0.00571 action_loss: 19.91366\n",
      "update_step:  50 model loss: 3.01756, kl_loss: 3.00023, obs_loss: 0.01732, reward_loss: 0.00001, value_loss: 0.00579 action_loss: 19.97950\n",
      "update_step:  51 model loss: 3.01462, kl_loss: 3.00042, obs_loss: 0.01419, reward_loss: 0.00001, value_loss: 0.00558 action_loss: 20.01022\n",
      "update_step:  52 model loss: 3.01137, kl_loss: 3.00006, obs_loss: 0.01130, reward_loss: 0.00001, value_loss: 0.00622 action_loss: 20.03747\n",
      "update_step:  53 model loss: 3.00563, kl_loss: 3.00001, obs_loss: 0.00561, reward_loss: 0.00001, value_loss: 0.00576 action_loss: 20.04129\n",
      "update_step:  54 model loss: 3.01035, kl_loss: 3.00072, obs_loss: 0.00963, reward_loss: 0.00001, value_loss: 0.00555 action_loss: 20.02748\n",
      "update_step:  55 model loss: 3.00791, kl_loss: 3.00049, obs_loss: 0.00741, reward_loss: 0.00001, value_loss: 0.00543 action_loss: 20.00234\n",
      "update_step:  56 model loss: 3.01438, kl_loss: 3.00057, obs_loss: 0.01380, reward_loss: 0.00001, value_loss: 0.00530 action_loss: 19.96107\n",
      "update_step:  57 model loss: 3.00909, kl_loss: 3.00024, obs_loss: 0.00884, reward_loss: 0.00001, value_loss: 0.00568 action_loss: 19.95457\n",
      "update_step:  58 model loss: 3.00901, kl_loss: 3.00052, obs_loss: 0.00848, reward_loss: 0.00001, value_loss: 0.00576 action_loss: 19.95234\n",
      "update_step:  59 model loss: 3.00822, kl_loss: 3.00144, obs_loss: 0.00677, reward_loss: 0.00001, value_loss: 0.00548 action_loss: 19.95894\n",
      "update_step:  60 model loss: 3.00472, kl_loss: 3.00040, obs_loss: 0.00431, reward_loss: 0.00001, value_loss: 0.00566 action_loss: 19.97250\n",
      "update_step:  61 model loss: 3.00613, kl_loss: 3.00081, obs_loss: 0.00531, reward_loss: 0.00001, value_loss: 0.00555 action_loss: 20.00460\n",
      "update_step:  62 model loss: 3.00433, kl_loss: 3.00041, obs_loss: 0.00391, reward_loss: 0.00001, value_loss: 0.00553 action_loss: 20.00966\n",
      "update_step:  63 model loss: 3.00380, kl_loss: 3.00022, obs_loss: 0.00357, reward_loss: 0.00001, value_loss: 0.00557 action_loss: 19.99380\n",
      "update_step:  64 model loss: 3.00459, kl_loss: 3.00010, obs_loss: 0.00448, reward_loss: 0.00001, value_loss: 0.00552 action_loss: 19.98786\n",
      "update_step:  65 model loss: 3.00566, kl_loss: 3.00043, obs_loss: 0.00522, reward_loss: 0.00001, value_loss: 0.00558 action_loss: 19.97462\n",
      "update_step:  66 model loss: 3.00465, kl_loss: 3.00043, obs_loss: 0.00421, reward_loss: 0.00001, value_loss: 0.00555 action_loss: 19.95620\n",
      "update_step:  67 model loss: 3.00398, kl_loss: 3.00021, obs_loss: 0.00377, reward_loss: 0.00001, value_loss: 0.00553 action_loss: 19.94592\n",
      "update_step:  68 model loss: 3.00347, kl_loss: 3.00040, obs_loss: 0.00306, reward_loss: 0.00001, value_loss: 0.00542 action_loss: 19.95250\n",
      "update_step:  69 model loss: 3.00471, kl_loss: 3.00014, obs_loss: 0.00456, reward_loss: 0.00001, value_loss: 0.00541 action_loss: 19.96102\n",
      "update_step:  70 model loss: 3.01145, kl_loss: 3.00028, obs_loss: 0.01116, reward_loss: 0.00001, value_loss: 0.00557 action_loss: 19.95690\n",
      "update_step:  71 model loss: 3.00557, kl_loss: 3.00003, obs_loss: 0.00554, reward_loss: 0.00001, value_loss: 0.00546 action_loss: 19.97058\n",
      "update_step:  72 model loss: 3.00806, kl_loss: 3.00004, obs_loss: 0.00801, reward_loss: 0.00001, value_loss: 0.00534 action_loss: 19.97087\n",
      "update_step:  73 model loss: 3.01187, kl_loss: 3.00036, obs_loss: 0.01150, reward_loss: 0.00001, value_loss: 0.00544 action_loss: 19.98344\n",
      "update_step:  74 model loss: 3.00897, kl_loss: 3.00017, obs_loss: 0.00879, reward_loss: 0.00001, value_loss: 0.00551 action_loss: 19.96650\n",
      "update_step:  75 model loss: 3.01242, kl_loss: 3.00058, obs_loss: 0.01183, reward_loss: 0.00001, value_loss: 0.00550 action_loss: 19.97702\n",
      "update_step:  76 model loss: 3.01317, kl_loss: 3.00061, obs_loss: 0.01255, reward_loss: 0.00001, value_loss: 0.00554 action_loss: 19.95598\n",
      "update_step:  77 model loss: 3.01172, kl_loss: 3.00077, obs_loss: 0.01095, reward_loss: 0.00001, value_loss: 0.00548 action_loss: 19.95257\n",
      "update_step:  78 model loss: 3.00982, kl_loss: 3.00069, obs_loss: 0.00912, reward_loss: 0.00001, value_loss: 0.00538 action_loss: 19.94983\n",
      "update_step:  79 model loss: 3.00629, kl_loss: 3.00016, obs_loss: 0.00613, reward_loss: 0.00001, value_loss: 0.00539 action_loss: 19.95656\n",
      "update_step:  80 model loss: 3.01118, kl_loss: 3.00131, obs_loss: 0.00986, reward_loss: 0.00001, value_loss: 0.00540 action_loss: 19.96765\n",
      "update_step:  81 model loss: 3.01232, kl_loss: 3.00099, obs_loss: 0.01133, reward_loss: 0.00001, value_loss: 0.00522 action_loss: 19.96358\n",
      "update_step:  82 model loss: 3.01625, kl_loss: 3.00082, obs_loss: 0.01542, reward_loss: 0.00001, value_loss: 0.00533 action_loss: 19.98409\n",
      "update_step:  83 model loss: 3.01708, kl_loss: 3.00118, obs_loss: 0.01590, reward_loss: 0.00001, value_loss: 0.00524 action_loss: 19.97144\n",
      "update_step:  84 model loss: 3.01719, kl_loss: 3.00022, obs_loss: 0.01696, reward_loss: 0.00001, value_loss: 0.00542 action_loss: 19.98077\n",
      "update_step:  85 model loss: 3.02439, kl_loss: 3.00063, obs_loss: 0.02376, reward_loss: 0.00001, value_loss: 0.00535 action_loss: 19.96129\n",
      "update_step:  86 model loss: 3.02430, kl_loss: 3.00057, obs_loss: 0.02372, reward_loss: 0.00001, value_loss: 0.00551 action_loss: 19.96181\n",
      "update_step:  87 model loss: 3.02734, kl_loss: 3.00019, obs_loss: 0.02715, reward_loss: 0.00001, value_loss: 0.00526 action_loss: 19.94423\n",
      "update_step:  88 model loss: 3.03220, kl_loss: 3.00016, obs_loss: 0.03203, reward_loss: 0.00001, value_loss: 0.00545 action_loss: 19.94722\n",
      "update_step:  89 model loss: 3.05314, kl_loss: 3.00101, obs_loss: 0.05212, reward_loss: 0.00001, value_loss: 0.00537 action_loss: 19.95312\n",
      "update_step:  90 model loss: 3.06240, kl_loss: 3.00098, obs_loss: 0.06141, reward_loss: 0.00001, value_loss: 0.00527 action_loss: 19.96584\n",
      "update_step:  91 model loss: 3.08324, kl_loss: 3.00055, obs_loss: 0.08269, reward_loss: 0.00001, value_loss: 0.00531 action_loss: 19.97101\n",
      "update_step:  92 model loss: 3.10484, kl_loss: 3.00022, obs_loss: 0.10462, reward_loss: 0.00001, value_loss: 0.00532 action_loss: 19.97941\n",
      "update_step:  93 model loss: 3.12548, kl_loss: 3.00044, obs_loss: 0.12504, reward_loss: 0.00001, value_loss: 0.00539 action_loss: 19.99021\n",
      "update_step:  94 model loss: 3.14426, kl_loss: 3.00042, obs_loss: 0.14384, reward_loss: 0.00001, value_loss: 0.00540 action_loss: 19.97744\n",
      "update_step:  95 model loss: 3.14507, kl_loss: 3.00008, obs_loss: 0.14498, reward_loss: 0.00001, value_loss: 0.00535 action_loss: 19.97979\n",
      "update_step:  96 model loss: 3.12499, kl_loss: 3.00060, obs_loss: 0.12438, reward_loss: 0.00001, value_loss: 0.00521 action_loss: 19.97301\n",
      "update_step:  97 model loss: 3.07953, kl_loss: 3.00042, obs_loss: 0.07911, reward_loss: 0.00001, value_loss: 0.00534 action_loss: 19.97859\n",
      "update_step:  98 model loss: 3.04194, kl_loss: 3.00010, obs_loss: 0.04183, reward_loss: 0.00001, value_loss: 0.00520 action_loss: 19.96895\n",
      "update_step:  99 model loss: 3.01476, kl_loss: 3.00021, obs_loss: 0.01454, reward_loss: 0.00001, value_loss: 0.00523 action_loss: 19.97108\n",
      "update_step: 100 model loss: 3.00674, kl_loss: 3.00054, obs_loss: 0.00620, reward_loss: 0.00001, value_loss: 0.00518 action_loss: 19.97265\n",
      "elasped time for update: 20.38s\n",
      "episode [  33/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.01904, kl_loss: 3.00112, obs_loss: 0.01791, reward_loss: 0.00001, value_loss: 0.00520 action_loss: 19.96045\n",
      "update_step:   2 model loss: 3.02863, kl_loss: 3.00021, obs_loss: 0.02841, reward_loss: 0.00001, value_loss: 0.00536 action_loss: 19.96966\n",
      "update_step:   3 model loss: 3.04521, kl_loss: 3.00067, obs_loss: 0.04453, reward_loss: 0.00001, value_loss: 0.00516 action_loss: 19.96858\n",
      "update_step:   4 model loss: 3.04084, kl_loss: 3.00017, obs_loss: 0.04067, reward_loss: 0.00001, value_loss: 0.00520 action_loss: 19.97840\n",
      "update_step:   5 model loss: 3.02848, kl_loss: 3.00026, obs_loss: 0.02820, reward_loss: 0.00001, value_loss: 0.00524 action_loss: 19.97365\n",
      "update_step:   6 model loss: 3.01123, kl_loss: 3.00037, obs_loss: 0.01086, reward_loss: 0.00001, value_loss: 0.00523 action_loss: 19.99281\n",
      "update_step:   7 model loss: 3.00680, kl_loss: 3.00055, obs_loss: 0.00624, reward_loss: 0.00001, value_loss: 0.00503 action_loss: 19.99109\n",
      "update_step:   8 model loss: 3.01056, kl_loss: 3.00016, obs_loss: 0.01039, reward_loss: 0.00001, value_loss: 0.00523 action_loss: 19.98574\n",
      "update_step:   9 model loss: 3.01952, kl_loss: 3.00040, obs_loss: 0.01912, reward_loss: 0.00001, value_loss: 0.00514 action_loss: 19.98880\n",
      "update_step:  10 model loss: 3.02913, kl_loss: 3.00095, obs_loss: 0.02817, reward_loss: 0.00001, value_loss: 0.00517 action_loss: 19.98412\n",
      "update_step:  11 model loss: 3.02151, kl_loss: 3.00079, obs_loss: 0.02071, reward_loss: 0.00001, value_loss: 0.00509 action_loss: 19.97850\n",
      "update_step:  12 model loss: 3.01302, kl_loss: 3.00043, obs_loss: 0.01258, reward_loss: 0.00001, value_loss: 0.00513 action_loss: 19.96952\n",
      "update_step:  13 model loss: 3.01186, kl_loss: 3.00121, obs_loss: 0.01065, reward_loss: 0.00001, value_loss: 0.00515 action_loss: 19.98185\n",
      "update_step:  14 model loss: 3.00961, kl_loss: 3.00097, obs_loss: 0.00863, reward_loss: 0.00001, value_loss: 0.00504 action_loss: 19.98575\n",
      "update_step:  15 model loss: 3.01060, kl_loss: 3.00086, obs_loss: 0.00973, reward_loss: 0.00001, value_loss: 0.00509 action_loss: 19.98502\n",
      "update_step:  16 model loss: 3.01523, kl_loss: 3.00054, obs_loss: 0.01469, reward_loss: 0.00001, value_loss: 0.00514 action_loss: 19.98238\n",
      "update_step:  17 model loss: 3.01506, kl_loss: 3.00017, obs_loss: 0.01489, reward_loss: 0.00001, value_loss: 0.00506 action_loss: 19.97360\n",
      "update_step:  18 model loss: 3.01107, kl_loss: 3.00038, obs_loss: 0.01068, reward_loss: 0.00001, value_loss: 0.00511 action_loss: 19.95458\n",
      "update_step:  19 model loss: 3.00721, kl_loss: 3.00066, obs_loss: 0.00654, reward_loss: 0.00001, value_loss: 0.00506 action_loss: 19.94300\n",
      "update_step:  20 model loss: 3.00471, kl_loss: 3.00003, obs_loss: 0.00467, reward_loss: 0.00001, value_loss: 0.00508 action_loss: 19.93863\n",
      "update_step:  21 model loss: 3.00869, kl_loss: 3.00003, obs_loss: 0.00866, reward_loss: 0.00001, value_loss: 0.00506 action_loss: 19.95034\n",
      "update_step:  22 model loss: 3.01411, kl_loss: 3.00130, obs_loss: 0.01280, reward_loss: 0.00001, value_loss: 0.00515 action_loss: 19.95457\n",
      "update_step:  23 model loss: 3.01958, kl_loss: 3.00096, obs_loss: 0.01862, reward_loss: 0.00001, value_loss: 0.00498 action_loss: 19.96413\n",
      "update_step:  24 model loss: 3.01673, kl_loss: 3.00076, obs_loss: 0.01596, reward_loss: 0.00000, value_loss: 0.00496 action_loss: 19.96595\n",
      "update_step:  25 model loss: 3.00925, kl_loss: 3.00031, obs_loss: 0.00894, reward_loss: 0.00001, value_loss: 0.00494 action_loss: 19.95913\n",
      "update_step:  26 model loss: 3.01110, kl_loss: 3.00169, obs_loss: 0.00940, reward_loss: 0.00001, value_loss: 0.00485 action_loss: 19.95350\n",
      "update_step:  27 model loss: 3.00476, kl_loss: 3.00112, obs_loss: 0.00363, reward_loss: 0.00001, value_loss: 0.00491 action_loss: 19.95025\n",
      "update_step:  28 model loss: 3.01498, kl_loss: 3.00294, obs_loss: 0.01204, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 19.94738\n",
      "update_step:  29 model loss: 3.00847, kl_loss: 3.00067, obs_loss: 0.00780, reward_loss: 0.00001, value_loss: 0.00489 action_loss: 19.94076\n",
      "update_step:  30 model loss: 3.01292, kl_loss: 3.00024, obs_loss: 0.01267, reward_loss: 0.00001, value_loss: 0.00496 action_loss: 19.95002\n",
      "update_step:  31 model loss: 3.00579, kl_loss: 3.00016, obs_loss: 0.00562, reward_loss: 0.00001, value_loss: 0.00486 action_loss: 19.96386\n",
      "update_step:  32 model loss: 3.00734, kl_loss: 3.00042, obs_loss: 0.00691, reward_loss: 0.00001, value_loss: 0.00478 action_loss: 19.97725\n",
      "update_step:  33 model loss: 3.00622, kl_loss: 3.00008, obs_loss: 0.00614, reward_loss: 0.00001, value_loss: 0.00477 action_loss: 19.98246\n",
      "update_step:  34 model loss: 3.00794, kl_loss: 3.00028, obs_loss: 0.00766, reward_loss: 0.00001, value_loss: 0.00477 action_loss: 19.99362\n",
      "update_step:  35 model loss: 3.01038, kl_loss: 3.00065, obs_loss: 0.00972, reward_loss: 0.00001, value_loss: 0.00479 action_loss: 19.98768\n",
      "update_step:  36 model loss: 3.00985, kl_loss: 3.00051, obs_loss: 0.00934, reward_loss: 0.00001, value_loss: 0.00482 action_loss: 19.97681\n",
      "update_step:  37 model loss: 3.00665, kl_loss: 3.00092, obs_loss: 0.00573, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 19.96826\n",
      "update_step:  38 model loss: 3.02183, kl_loss: 3.00192, obs_loss: 0.01990, reward_loss: 0.00001, value_loss: 0.00473 action_loss: 19.96613\n",
      "update_step:  39 model loss: 3.00603, kl_loss: 3.00159, obs_loss: 0.00444, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 19.96617\n",
      "update_step:  40 model loss: 3.01175, kl_loss: 3.00191, obs_loss: 0.00983, reward_loss: 0.00001, value_loss: 0.00461 action_loss: 19.97549\n",
      "update_step:  41 model loss: 3.00489, kl_loss: 3.00107, obs_loss: 0.00381, reward_loss: 0.00001, value_loss: 0.00461 action_loss: 19.98109\n",
      "update_step:  42 model loss: 3.00604, kl_loss: 3.00062, obs_loss: 0.00541, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 19.97802\n",
      "update_step:  43 model loss: 3.00559, kl_loss: 3.00047, obs_loss: 0.00512, reward_loss: 0.00001, value_loss: 0.00476 action_loss: 19.96725\n",
      "update_step:  44 model loss: 3.00991, kl_loss: 3.00036, obs_loss: 0.00954, reward_loss: 0.00001, value_loss: 0.00461 action_loss: 19.95226\n",
      "update_step:  45 model loss: 3.00612, kl_loss: 3.00010, obs_loss: 0.00601, reward_loss: 0.00001, value_loss: 0.00477 action_loss: 19.94579\n",
      "update_step:  46 model loss: 3.01339, kl_loss: 3.00084, obs_loss: 0.01254, reward_loss: 0.00001, value_loss: 0.00482 action_loss: 19.94408\n",
      "update_step:  47 model loss: 3.00325, kl_loss: 3.00011, obs_loss: 0.00314, reward_loss: 0.00001, value_loss: 0.00468 action_loss: 19.94689\n",
      "update_step:  48 model loss: 3.00613, kl_loss: 3.00024, obs_loss: 0.00588, reward_loss: 0.00001, value_loss: 0.00462 action_loss: 19.94576\n",
      "update_step:  49 model loss: 3.00708, kl_loss: 3.00074, obs_loss: 0.00633, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 19.95315\n",
      "update_step:  50 model loss: 3.00490, kl_loss: 3.00016, obs_loss: 0.00473, reward_loss: 0.00001, value_loss: 0.00468 action_loss: 19.94596\n",
      "update_step:  51 model loss: 3.00693, kl_loss: 3.00027, obs_loss: 0.00666, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 19.95789\n",
      "update_step:  52 model loss: 3.00512, kl_loss: 3.00009, obs_loss: 0.00503, reward_loss: 0.00000, value_loss: 0.00464 action_loss: 19.95231\n",
      "update_step:  53 model loss: 3.00624, kl_loss: 3.00015, obs_loss: 0.00609, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 19.96603\n",
      "update_step:  54 model loss: 3.01961, kl_loss: 3.00140, obs_loss: 0.01821, reward_loss: 0.00001, value_loss: 0.00464 action_loss: 19.95554\n",
      "update_step:  55 model loss: 3.01040, kl_loss: 3.00067, obs_loss: 0.00972, reward_loss: 0.00001, value_loss: 0.00468 action_loss: 19.96945\n",
      "update_step:  56 model loss: 3.01199, kl_loss: 3.00046, obs_loss: 0.01153, reward_loss: 0.00001, value_loss: 0.00468 action_loss: 19.95666\n",
      "update_step:  57 model loss: 3.01622, kl_loss: 3.00061, obs_loss: 0.01560, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 19.97233\n",
      "update_step:  58 model loss: 3.01550, kl_loss: 3.00024, obs_loss: 0.01525, reward_loss: 0.00001, value_loss: 0.00471 action_loss: 19.94550\n",
      "update_step:  59 model loss: 3.02391, kl_loss: 3.00110, obs_loss: 0.02281, reward_loss: 0.00001, value_loss: 0.00472 action_loss: 19.95661\n",
      "update_step:  60 model loss: 3.02971, kl_loss: 3.00081, obs_loss: 0.02890, reward_loss: 0.00001, value_loss: 0.00479 action_loss: 19.93869\n",
      "update_step:  61 model loss: 3.02648, kl_loss: 3.00033, obs_loss: 0.02614, reward_loss: 0.00001, value_loss: 0.00480 action_loss: 19.97435\n",
      "update_step:  62 model loss: 3.02938, kl_loss: 3.00019, obs_loss: 0.02918, reward_loss: 0.00001, value_loss: 0.00478 action_loss: 19.95919\n",
      "update_step:  63 model loss: 3.03096, kl_loss: 3.00119, obs_loss: 0.02977, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 20.01091\n",
      "update_step:  64 model loss: 3.04011, kl_loss: 3.00143, obs_loss: 0.03867, reward_loss: 0.00001, value_loss: 0.00489 action_loss: 20.01023\n",
      "update_step:  65 model loss: 3.02965, kl_loss: 3.00023, obs_loss: 0.02941, reward_loss: 0.00001, value_loss: 0.00538 action_loss: 20.04341\n",
      "update_step:  66 model loss: 3.03069, kl_loss: 3.00104, obs_loss: 0.02965, reward_loss: 0.00001, value_loss: 0.00514 action_loss: 20.01418\n",
      "update_step:  67 model loss: 3.02649, kl_loss: 3.00037, obs_loss: 0.02610, reward_loss: 0.00001, value_loss: 0.00536 action_loss: 20.01554\n",
      "update_step:  68 model loss: 3.02436, kl_loss: 3.00023, obs_loss: 0.02412, reward_loss: 0.00001, value_loss: 0.00512 action_loss: 19.95424\n",
      "update_step:  69 model loss: 3.02334, kl_loss: 3.00032, obs_loss: 0.02301, reward_loss: 0.00001, value_loss: 0.00526 action_loss: 19.94925\n",
      "update_step:  70 model loss: 3.02403, kl_loss: 3.00060, obs_loss: 0.02343, reward_loss: 0.00001, value_loss: 0.00539 action_loss: 19.92569\n",
      "update_step:  71 model loss: 3.01313, kl_loss: 3.00023, obs_loss: 0.01289, reward_loss: 0.00001, value_loss: 0.00503 action_loss: 19.93323\n",
      "update_step:  72 model loss: 3.00831, kl_loss: 3.00001, obs_loss: 0.00829, reward_loss: 0.00001, value_loss: 0.00513 action_loss: 19.93177\n",
      "update_step:  73 model loss: 3.00528, kl_loss: 3.00018, obs_loss: 0.00509, reward_loss: 0.00001, value_loss: 0.00506 action_loss: 19.95773\n",
      "update_step:  74 model loss: 3.00359, kl_loss: 3.00014, obs_loss: 0.00344, reward_loss: 0.00001, value_loss: 0.00506 action_loss: 19.97913\n",
      "update_step:  75 model loss: 3.01196, kl_loss: 3.00101, obs_loss: 0.01095, reward_loss: 0.00001, value_loss: 0.00525 action_loss: 20.00015\n",
      "update_step:  76 model loss: 3.01116, kl_loss: 3.00074, obs_loss: 0.01042, reward_loss: 0.00001, value_loss: 0.00524 action_loss: 20.01694\n",
      "update_step:  77 model loss: 3.01377, kl_loss: 3.00170, obs_loss: 0.01207, reward_loss: 0.00001, value_loss: 0.00521 action_loss: 20.00628\n",
      "update_step:  78 model loss: 3.01181, kl_loss: 3.00120, obs_loss: 0.01060, reward_loss: 0.00001, value_loss: 0.00494 action_loss: 19.99744\n",
      "update_step:  79 model loss: 3.00870, kl_loss: 3.00073, obs_loss: 0.00796, reward_loss: 0.00001, value_loss: 0.00498 action_loss: 19.96627\n",
      "update_step:  80 model loss: 3.01528, kl_loss: 3.00133, obs_loss: 0.01394, reward_loss: 0.00001, value_loss: 0.00516 action_loss: 19.96052\n",
      "update_step:  81 model loss: 3.00928, kl_loss: 3.00065, obs_loss: 0.00862, reward_loss: 0.00001, value_loss: 0.00515 action_loss: 19.94054\n",
      "update_step:  82 model loss: 3.01045, kl_loss: 3.00019, obs_loss: 0.01026, reward_loss: 0.00001, value_loss: 0.00507 action_loss: 19.95129\n",
      "update_step:  83 model loss: 3.00952, kl_loss: 3.00038, obs_loss: 0.00913, reward_loss: 0.00001, value_loss: 0.00496 action_loss: 19.94533\n",
      "update_step:  84 model loss: 3.01085, kl_loss: 3.00012, obs_loss: 0.01072, reward_loss: 0.00001, value_loss: 0.00500 action_loss: 19.97140\n",
      "update_step:  85 model loss: 3.01099, kl_loss: 3.00023, obs_loss: 0.01076, reward_loss: 0.00001, value_loss: 0.00490 action_loss: 19.97001\n",
      "update_step:  86 model loss: 3.01296, kl_loss: 3.00036, obs_loss: 0.01259, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 19.97988\n",
      "update_step:  87 model loss: 3.01294, kl_loss: 3.00028, obs_loss: 0.01266, reward_loss: 0.00001, value_loss: 0.00496 action_loss: 19.96874\n",
      "update_step:  88 model loss: 3.00614, kl_loss: 3.00010, obs_loss: 0.00603, reward_loss: 0.00001, value_loss: 0.00492 action_loss: 19.95311\n",
      "update_step:  89 model loss: 3.00956, kl_loss: 3.00044, obs_loss: 0.00911, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 19.93812\n",
      "update_step:  90 model loss: 3.00577, kl_loss: 3.00056, obs_loss: 0.00520, reward_loss: 0.00001, value_loss: 0.00490 action_loss: 19.93027\n",
      "update_step:  91 model loss: 3.00909, kl_loss: 3.00108, obs_loss: 0.00800, reward_loss: 0.00001, value_loss: 0.00491 action_loss: 19.93299\n",
      "update_step:  92 model loss: 3.00973, kl_loss: 3.00060, obs_loss: 0.00912, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 19.93206\n",
      "update_step:  93 model loss: 3.01128, kl_loss: 3.00073, obs_loss: 0.01055, reward_loss: 0.00001, value_loss: 0.00483 action_loss: 19.97239\n",
      "update_step:  94 model loss: 3.01561, kl_loss: 3.00048, obs_loss: 0.01513, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 19.97494\n",
      "update_step:  95 model loss: 3.02272, kl_loss: 3.00046, obs_loss: 0.02226, reward_loss: 0.00001, value_loss: 0.00503 action_loss: 19.99751\n",
      "update_step:  96 model loss: 3.02334, kl_loss: 3.00014, obs_loss: 0.02319, reward_loss: 0.00001, value_loss: 0.00472 action_loss: 19.97718\n",
      "update_step:  97 model loss: 3.02523, kl_loss: 3.00003, obs_loss: 0.02520, reward_loss: 0.00001, value_loss: 0.00497 action_loss: 19.99679\n",
      "update_step:  98 model loss: 3.03425, kl_loss: 3.00020, obs_loss: 0.03404, reward_loss: 0.00001, value_loss: 0.00497 action_loss: 19.92847\n",
      "update_step:  99 model loss: 3.04450, kl_loss: 3.00012, obs_loss: 0.04437, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 19.94718\n",
      "update_step: 100 model loss: 3.06064, kl_loss: 3.00019, obs_loss: 0.06044, reward_loss: 0.00001, value_loss: 0.00517 action_loss: 19.92121\n",
      "elasped time for update: 20.27s\n",
      "episode [  34/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.07348, kl_loss: 3.00023, obs_loss: 0.07324, reward_loss: 0.00001, value_loss: 0.00508 action_loss: 19.97462\n",
      "update_step:   2 model loss: 3.08358, kl_loss: 3.00085, obs_loss: 0.08272, reward_loss: 0.00001, value_loss: 0.00534 action_loss: 19.92423\n",
      "update_step:   3 model loss: 3.10375, kl_loss: 3.00049, obs_loss: 0.10324, reward_loss: 0.00002, value_loss: 0.00513 action_loss: 19.98586\n",
      "update_step:   4 model loss: 3.08564, kl_loss: 3.00020, obs_loss: 0.08542, reward_loss: 0.00001, value_loss: 0.00519 action_loss: 19.93760\n",
      "update_step:   5 model loss: 3.11215, kl_loss: 3.00037, obs_loss: 0.11178, reward_loss: 0.00001, value_loss: 0.00513 action_loss: 19.94672\n",
      "update_step:   6 model loss: 3.05785, kl_loss: 3.00094, obs_loss: 0.05690, reward_loss: 0.00001, value_loss: 0.00526 action_loss: 19.93419\n",
      "update_step:   7 model loss: 3.04565, kl_loss: 3.00154, obs_loss: 0.04411, reward_loss: 0.00001, value_loss: 0.00540 action_loss: 19.97012\n",
      "update_step:   8 model loss: 3.00962, kl_loss: 3.00038, obs_loss: 0.00923, reward_loss: 0.00001, value_loss: 0.00556 action_loss: 19.99759\n",
      "update_step:   9 model loss: 3.02479, kl_loss: 3.00076, obs_loss: 0.02402, reward_loss: 0.00001, value_loss: 0.00598 action_loss: 20.02534\n",
      "update_step:  10 model loss: 3.03412, kl_loss: 3.00043, obs_loss: 0.03368, reward_loss: 0.00001, value_loss: 0.00709 action_loss: 20.07372\n",
      "update_step:  11 model loss: 3.01460, kl_loss: 3.00213, obs_loss: 0.01246, reward_loss: 0.00001, value_loss: 0.00708 action_loss: 20.07603\n",
      "update_step:  12 model loss: 3.03062, kl_loss: 3.00135, obs_loss: 0.02927, reward_loss: 0.00001, value_loss: 0.00619 action_loss: 20.00591\n",
      "update_step:  13 model loss: 3.02172, kl_loss: 3.00017, obs_loss: 0.02154, reward_loss: 0.00001, value_loss: 0.00677 action_loss: 19.95417\n",
      "update_step:  14 model loss: 3.05992, kl_loss: 3.00026, obs_loss: 0.05965, reward_loss: 0.00001, value_loss: 0.00731 action_loss: 19.84620\n",
      "update_step:  15 model loss: 3.09195, kl_loss: 3.00081, obs_loss: 0.09113, reward_loss: 0.00001, value_loss: 0.00776 action_loss: 19.86438\n",
      "update_step:  16 model loss: 3.11803, kl_loss: 3.00066, obs_loss: 0.11736, reward_loss: 0.00001, value_loss: 0.00690 action_loss: 19.81265\n",
      "update_step:  17 model loss: 3.08957, kl_loss: 3.00041, obs_loss: 0.08915, reward_loss: 0.00001, value_loss: 0.00570 action_loss: 19.89638\n",
      "update_step:  18 model loss: 3.04857, kl_loss: 3.00034, obs_loss: 0.04823, reward_loss: 0.00001, value_loss: 0.00573 action_loss: 19.94625\n",
      "update_step:  19 model loss: 3.02271, kl_loss: 3.00037, obs_loss: 0.02233, reward_loss: 0.00001, value_loss: 0.00664 action_loss: 20.04271\n",
      "update_step:  20 model loss: 3.01683, kl_loss: 3.00052, obs_loss: 0.01630, reward_loss: 0.00001, value_loss: 0.00816 action_loss: 20.08008\n",
      "update_step:  21 model loss: 3.02847, kl_loss: 3.00086, obs_loss: 0.02761, reward_loss: 0.00001, value_loss: 0.00696 action_loss: 20.05803\n",
      "update_step:  22 model loss: 3.05311, kl_loss: 3.00034, obs_loss: 0.05276, reward_loss: 0.00001, value_loss: 0.00603 action_loss: 20.07992\n",
      "update_step:  23 model loss: 3.08603, kl_loss: 3.00050, obs_loss: 0.08550, reward_loss: 0.00002, value_loss: 0.00525 action_loss: 19.96875\n",
      "update_step:  24 model loss: 3.10673, kl_loss: 3.00048, obs_loss: 0.10624, reward_loss: 0.00001, value_loss: 0.00567 action_loss: 19.94640\n",
      "update_step:  25 model loss: 3.12287, kl_loss: 3.00063, obs_loss: 0.12223, reward_loss: 0.00001, value_loss: 0.00738 action_loss: 19.85827\n",
      "update_step:  26 model loss: 3.15141, kl_loss: 3.00172, obs_loss: 0.14967, reward_loss: 0.00001, value_loss: 0.00885 action_loss: 19.94427\n",
      "update_step:  27 model loss: 3.09859, kl_loss: 3.00049, obs_loss: 0.09807, reward_loss: 0.00003, value_loss: 0.00589 action_loss: 19.95023\n",
      "update_step:  28 model loss: 3.06829, kl_loss: 3.00013, obs_loss: 0.06815, reward_loss: 0.00001, value_loss: 0.00614 action_loss: 20.01337\n",
      "update_step:  29 model loss: 3.03358, kl_loss: 3.00084, obs_loss: 0.03272, reward_loss: 0.00001, value_loss: 0.00638 action_loss: 20.06448\n",
      "update_step:  30 model loss: 3.04557, kl_loss: 3.00007, obs_loss: 0.04549, reward_loss: 0.00001, value_loss: 0.00615 action_loss: 20.05653\n",
      "update_step:  31 model loss: 3.07339, kl_loss: 3.00118, obs_loss: 0.07220, reward_loss: 0.00001, value_loss: 0.00678 action_loss: 20.05650\n",
      "update_step:  32 model loss: 3.07544, kl_loss: 3.00061, obs_loss: 0.07483, reward_loss: 0.00001, value_loss: 0.00592 action_loss: 19.93743\n",
      "update_step:  33 model loss: 3.08407, kl_loss: 3.00109, obs_loss: 0.08295, reward_loss: 0.00003, value_loss: 0.00670 action_loss: 19.94356\n",
      "update_step:  34 model loss: 3.06225, kl_loss: 3.00052, obs_loss: 0.06171, reward_loss: 0.00002, value_loss: 0.00721 action_loss: 19.88886\n",
      "update_step:  35 model loss: 3.05224, kl_loss: 3.00057, obs_loss: 0.05166, reward_loss: 0.00001, value_loss: 0.00611 action_loss: 19.89843\n",
      "update_step:  36 model loss: 3.03653, kl_loss: 3.00091, obs_loss: 0.03560, reward_loss: 0.00002, value_loss: 0.00555 action_loss: 19.94277\n",
      "update_step:  37 model loss: 3.02329, kl_loss: 3.00050, obs_loss: 0.02277, reward_loss: 0.00001, value_loss: 0.00610 action_loss: 19.98482\n",
      "update_step:  38 model loss: 3.05917, kl_loss: 3.00046, obs_loss: 0.05869, reward_loss: 0.00002, value_loss: 0.00663 action_loss: 20.04909\n",
      "update_step:  39 model loss: 3.04947, kl_loss: 3.00035, obs_loss: 0.04911, reward_loss: 0.00001, value_loss: 0.00810 action_loss: 20.02082\n",
      "update_step:  40 model loss: 3.02659, kl_loss: 3.00045, obs_loss: 0.02611, reward_loss: 0.00003, value_loss: 0.00659 action_loss: 20.03702\n",
      "update_step:  41 model loss: 3.02121, kl_loss: 3.00027, obs_loss: 0.02094, reward_loss: 0.00001, value_loss: 0.00599 action_loss: 20.00994\n",
      "update_step:  42 model loss: 3.02743, kl_loss: 3.00088, obs_loss: 0.02653, reward_loss: 0.00002, value_loss: 0.00570 action_loss: 19.92906\n",
      "update_step:  43 model loss: 3.03701, kl_loss: 3.00136, obs_loss: 0.03564, reward_loss: 0.00001, value_loss: 0.00602 action_loss: 19.90784\n",
      "update_step:  44 model loss: 3.03864, kl_loss: 3.00115, obs_loss: 0.03748, reward_loss: 0.00001, value_loss: 0.00722 action_loss: 19.89571\n",
      "update_step:  45 model loss: 3.03406, kl_loss: 3.00210, obs_loss: 0.03195, reward_loss: 0.00001, value_loss: 0.00663 action_loss: 19.93834\n",
      "update_step:  46 model loss: 3.01131, kl_loss: 3.00051, obs_loss: 0.01079, reward_loss: 0.00001, value_loss: 0.00578 action_loss: 19.96296\n",
      "update_step:  47 model loss: 3.01331, kl_loss: 3.00028, obs_loss: 0.01302, reward_loss: 0.00001, value_loss: 0.00603 action_loss: 20.00723\n",
      "update_step:  48 model loss: 3.01697, kl_loss: 3.00021, obs_loss: 0.01674, reward_loss: 0.00001, value_loss: 0.00607 action_loss: 20.06105\n",
      "update_step:  49 model loss: 3.02248, kl_loss: 3.00052, obs_loss: 0.02194, reward_loss: 0.00002, value_loss: 0.00612 action_loss: 20.05112\n",
      "update_step:  50 model loss: 3.02436, kl_loss: 3.00003, obs_loss: 0.02432, reward_loss: 0.00001, value_loss: 0.00688 action_loss: 20.04852\n",
      "update_step:  51 model loss: 3.01676, kl_loss: 3.00057, obs_loss: 0.01618, reward_loss: 0.00001, value_loss: 0.00565 action_loss: 20.00841\n",
      "update_step:  52 model loss: 3.01445, kl_loss: 3.00076, obs_loss: 0.01368, reward_loss: 0.00001, value_loss: 0.00570 action_loss: 19.96188\n",
      "update_step:  53 model loss: 3.01033, kl_loss: 3.00095, obs_loss: 0.00937, reward_loss: 0.00001, value_loss: 0.00557 action_loss: 19.92849\n",
      "update_step:  54 model loss: 3.01110, kl_loss: 3.00043, obs_loss: 0.01066, reward_loss: 0.00001, value_loss: 0.00533 action_loss: 19.90616\n",
      "update_step:  55 model loss: 3.01990, kl_loss: 3.00109, obs_loss: 0.01881, reward_loss: 0.00001, value_loss: 0.00544 action_loss: 19.92426\n",
      "update_step:  56 model loss: 3.01926, kl_loss: 3.00112, obs_loss: 0.01813, reward_loss: 0.00001, value_loss: 0.00514 action_loss: 19.93085\n",
      "update_step:  57 model loss: 3.01021, kl_loss: 3.00037, obs_loss: 0.00984, reward_loss: 0.00001, value_loss: 0.00501 action_loss: 19.96039\n",
      "update_step:  58 model loss: 3.00643, kl_loss: 3.00077, obs_loss: 0.00565, reward_loss: 0.00001, value_loss: 0.00512 action_loss: 19.99555\n",
      "update_step:  59 model loss: 3.00788, kl_loss: 3.00105, obs_loss: 0.00682, reward_loss: 0.00001, value_loss: 0.00505 action_loss: 20.00596\n",
      "update_step:  60 model loss: 3.01402, kl_loss: 3.00059, obs_loss: 0.01343, reward_loss: 0.00001, value_loss: 0.00515 action_loss: 20.02468\n",
      "update_step:  61 model loss: 3.01309, kl_loss: 3.00044, obs_loss: 0.01265, reward_loss: 0.00001, value_loss: 0.00504 action_loss: 20.01023\n",
      "update_step:  62 model loss: 3.01478, kl_loss: 3.00044, obs_loss: 0.01433, reward_loss: 0.00001, value_loss: 0.00503 action_loss: 20.00567\n",
      "update_step:  63 model loss: 3.00891, kl_loss: 3.00035, obs_loss: 0.00856, reward_loss: 0.00001, value_loss: 0.00492 action_loss: 19.97150\n",
      "update_step:  64 model loss: 3.00360, kl_loss: 3.00023, obs_loss: 0.00336, reward_loss: 0.00001, value_loss: 0.00525 action_loss: 19.93887\n",
      "update_step:  65 model loss: 3.01373, kl_loss: 3.00080, obs_loss: 0.01292, reward_loss: 0.00001, value_loss: 0.00557 action_loss: 19.93308\n",
      "update_step:  66 model loss: 3.00899, kl_loss: 3.00065, obs_loss: 0.00833, reward_loss: 0.00001, value_loss: 0.00525 action_loss: 19.92001\n",
      "update_step:  67 model loss: 3.00783, kl_loss: 3.00012, obs_loss: 0.00770, reward_loss: 0.00001, value_loss: 0.00495 action_loss: 19.94406\n",
      "update_step:  68 model loss: 3.00866, kl_loss: 3.00041, obs_loss: 0.00824, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 19.95721\n",
      "update_step:  69 model loss: 3.01262, kl_loss: 3.00159, obs_loss: 0.01102, reward_loss: 0.00001, value_loss: 0.00475 action_loss: 19.98983\n",
      "update_step:  70 model loss: 3.00651, kl_loss: 3.00139, obs_loss: 0.00511, reward_loss: 0.00001, value_loss: 0.00495 action_loss: 20.00850\n",
      "update_step:  71 model loss: 3.00446, kl_loss: 3.00056, obs_loss: 0.00389, reward_loss: 0.00001, value_loss: 0.00498 action_loss: 20.01566\n",
      "update_step:  72 model loss: 3.00713, kl_loss: 3.00109, obs_loss: 0.00603, reward_loss: 0.00001, value_loss: 0.00489 action_loss: 20.01401\n",
      "update_step:  73 model loss: 3.00955, kl_loss: 3.00078, obs_loss: 0.00877, reward_loss: 0.00001, value_loss: 0.00466 action_loss: 19.99306\n",
      "update_step:  74 model loss: 3.01025, kl_loss: 3.00036, obs_loss: 0.00989, reward_loss: 0.00001, value_loss: 0.00472 action_loss: 19.98110\n",
      "update_step:  75 model loss: 3.02307, kl_loss: 3.00147, obs_loss: 0.02160, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 19.96115\n",
      "update_step:  76 model loss: 3.00531, kl_loss: 3.00012, obs_loss: 0.00518, reward_loss: 0.00001, value_loss: 0.00482 action_loss: 19.95965\n",
      "update_step:  77 model loss: 3.00460, kl_loss: 3.00081, obs_loss: 0.00378, reward_loss: 0.00001, value_loss: 0.00459 action_loss: 19.96281\n",
      "update_step:  78 model loss: 3.01123, kl_loss: 3.00190, obs_loss: 0.00933, reward_loss: 0.00001, value_loss: 0.00459 action_loss: 19.96690\n",
      "update_step:  79 model loss: 3.00672, kl_loss: 3.00122, obs_loss: 0.00549, reward_loss: 0.00001, value_loss: 0.00468 action_loss: 19.97936\n",
      "update_step:  80 model loss: 3.00676, kl_loss: 3.00085, obs_loss: 0.00591, reward_loss: 0.00001, value_loss: 0.00464 action_loss: 19.97490\n",
      "update_step:  81 model loss: 3.00848, kl_loss: 3.00105, obs_loss: 0.00742, reward_loss: 0.00001, value_loss: 0.00477 action_loss: 19.96572\n",
      "update_step:  82 model loss: 3.00601, kl_loss: 3.00135, obs_loss: 0.00465, reward_loss: 0.00001, value_loss: 0.00475 action_loss: 19.95374\n",
      "update_step:  83 model loss: 3.01168, kl_loss: 3.00084, obs_loss: 0.01084, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 19.93615\n",
      "update_step:  84 model loss: 3.01304, kl_loss: 3.00125, obs_loss: 0.01179, reward_loss: 0.00001, value_loss: 0.00475 action_loss: 19.93086\n",
      "update_step:  85 model loss: 3.01202, kl_loss: 3.00064, obs_loss: 0.01137, reward_loss: 0.00001, value_loss: 0.00463 action_loss: 19.91878\n",
      "update_step:  86 model loss: 3.00540, kl_loss: 3.00010, obs_loss: 0.00530, reward_loss: 0.00001, value_loss: 0.00475 action_loss: 19.92890\n",
      "update_step:  87 model loss: 3.00424, kl_loss: 3.00037, obs_loss: 0.00386, reward_loss: 0.00001, value_loss: 0.00455 action_loss: 19.92871\n",
      "update_step:  88 model loss: 3.00833, kl_loss: 3.00125, obs_loss: 0.00708, reward_loss: 0.00001, value_loss: 0.00457 action_loss: 19.94924\n",
      "update_step:  89 model loss: 3.01147, kl_loss: 3.00247, obs_loss: 0.00899, reward_loss: 0.00001, value_loss: 0.00443 action_loss: 19.95675\n",
      "update_step:  90 model loss: 3.00694, kl_loss: 3.00132, obs_loss: 0.00561, reward_loss: 0.00001, value_loss: 0.00455 action_loss: 19.97088\n",
      "update_step:  91 model loss: 3.00255, kl_loss: 3.00008, obs_loss: 0.00247, reward_loss: 0.00001, value_loss: 0.00462 action_loss: 19.98547\n",
      "update_step:  92 model loss: 3.00792, kl_loss: 3.00101, obs_loss: 0.00690, reward_loss: 0.00001, value_loss: 0.00456 action_loss: 19.98342\n",
      "update_step:  93 model loss: 3.00474, kl_loss: 3.00128, obs_loss: 0.00345, reward_loss: 0.00001, value_loss: 0.00438 action_loss: 19.97778\n",
      "update_step:  94 model loss: 3.00589, kl_loss: 3.00016, obs_loss: 0.00573, reward_loss: 0.00000, value_loss: 0.00448 action_loss: 19.96099\n",
      "update_step:  95 model loss: 3.00463, kl_loss: 3.00001, obs_loss: 0.00462, reward_loss: 0.00001, value_loss: 0.00458 action_loss: 19.95253\n",
      "update_step:  96 model loss: 3.00595, kl_loss: 3.00050, obs_loss: 0.00545, reward_loss: 0.00001, value_loss: 0.00453 action_loss: 19.94576\n",
      "update_step:  97 model loss: 3.00664, kl_loss: 3.00010, obs_loss: 0.00653, reward_loss: 0.00001, value_loss: 0.00458 action_loss: 19.94780\n",
      "update_step:  98 model loss: 3.00912, kl_loss: 3.00103, obs_loss: 0.00808, reward_loss: 0.00001, value_loss: 0.00451 action_loss: 19.95357\n",
      "update_step:  99 model loss: 3.00965, kl_loss: 3.00039, obs_loss: 0.00925, reward_loss: 0.00000, value_loss: 0.00444 action_loss: 19.96083\n",
      "update_step: 100 model loss: 3.00772, kl_loss: 3.00089, obs_loss: 0.00682, reward_loss: 0.00001, value_loss: 0.00453 action_loss: 19.97331\n",
      "elasped time for update: 20.02s\n",
      "episode [  35/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.36s\n",
      "update_step:   1 model loss: 3.00827, kl_loss: 3.00100, obs_loss: 0.00727, reward_loss: 0.00001, value_loss: 0.00450 action_loss: 19.97383\n",
      "update_step:   2 model loss: 3.00541, kl_loss: 3.00096, obs_loss: 0.00445, reward_loss: 0.00000, value_loss: 0.00436 action_loss: 19.97091\n",
      "update_step:   3 model loss: 3.00376, kl_loss: 3.00092, obs_loss: 0.00283, reward_loss: 0.00000, value_loss: 0.00447 action_loss: 19.96240\n",
      "update_step:   4 model loss: 3.00588, kl_loss: 3.00145, obs_loss: 0.00443, reward_loss: 0.00001, value_loss: 0.00456 action_loss: 19.94885\n",
      "update_step:   5 model loss: 3.00389, kl_loss: 3.00039, obs_loss: 0.00349, reward_loss: 0.00000, value_loss: 0.00458 action_loss: 19.93696\n",
      "update_step:   6 model loss: 3.00719, kl_loss: 3.00022, obs_loss: 0.00696, reward_loss: 0.00001, value_loss: 0.00460 action_loss: 19.93311\n",
      "update_step:   7 model loss: 3.00442, kl_loss: 3.00054, obs_loss: 0.00387, reward_loss: 0.00001, value_loss: 0.00458 action_loss: 19.93985\n",
      "update_step:   8 model loss: 3.00793, kl_loss: 3.00016, obs_loss: 0.00777, reward_loss: 0.00001, value_loss: 0.00447 action_loss: 19.94614\n",
      "update_step:   9 model loss: 3.00384, kl_loss: 3.00008, obs_loss: 0.00375, reward_loss: 0.00001, value_loss: 0.00451 action_loss: 19.96686\n",
      "update_step:  10 model loss: 3.01148, kl_loss: 3.00088, obs_loss: 0.01060, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 19.98028\n",
      "update_step:  11 model loss: 3.00646, kl_loss: 3.00042, obs_loss: 0.00604, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 19.99272\n",
      "update_step:  12 model loss: 3.00633, kl_loss: 3.00050, obs_loss: 0.00582, reward_loss: 0.00001, value_loss: 0.00444 action_loss: 19.99286\n",
      "update_step:  13 model loss: 3.00291, kl_loss: 3.00006, obs_loss: 0.00284, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 19.98934\n",
      "update_step:  14 model loss: 3.01313, kl_loss: 3.00206, obs_loss: 0.01106, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 19.98161\n",
      "update_step:  15 model loss: 3.01180, kl_loss: 3.00154, obs_loss: 0.01025, reward_loss: 0.00000, value_loss: 0.00436 action_loss: 19.96129\n",
      "update_step:  16 model loss: 3.00700, kl_loss: 3.00211, obs_loss: 0.00488, reward_loss: 0.00001, value_loss: 0.00451 action_loss: 19.95616\n",
      "update_step:  17 model loss: 3.00575, kl_loss: 3.00055, obs_loss: 0.00519, reward_loss: 0.00000, value_loss: 0.00446 action_loss: 19.95133\n",
      "update_step:  18 model loss: 3.00887, kl_loss: 3.00113, obs_loss: 0.00773, reward_loss: 0.00000, value_loss: 0.00451 action_loss: 19.95996\n",
      "update_step:  19 model loss: 3.00921, kl_loss: 3.00124, obs_loss: 0.00797, reward_loss: 0.00000, value_loss: 0.00438 action_loss: 19.96337\n",
      "update_step:  20 model loss: 3.01348, kl_loss: 3.00101, obs_loss: 0.01246, reward_loss: 0.00001, value_loss: 0.00443 action_loss: 19.97748\n",
      "update_step:  21 model loss: 3.00711, kl_loss: 3.00028, obs_loss: 0.00682, reward_loss: 0.00000, value_loss: 0.00453 action_loss: 19.97600\n",
      "update_step:  22 model loss: 3.01353, kl_loss: 3.00062, obs_loss: 0.01291, reward_loss: 0.00000, value_loss: 0.00449 action_loss: 19.97194\n",
      "update_step:  23 model loss: 3.00728, kl_loss: 3.00056, obs_loss: 0.00671, reward_loss: 0.00001, value_loss: 0.00444 action_loss: 19.96948\n",
      "update_step:  24 model loss: 3.00588, kl_loss: 3.00043, obs_loss: 0.00545, reward_loss: 0.00001, value_loss: 0.00438 action_loss: 19.95578\n",
      "update_step:  25 model loss: 3.00545, kl_loss: 3.00013, obs_loss: 0.00532, reward_loss: 0.00001, value_loss: 0.00448 action_loss: 19.94843\n",
      "update_step:  26 model loss: 3.00998, kl_loss: 3.00077, obs_loss: 0.00921, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 19.94032\n",
      "update_step:  27 model loss: 3.01394, kl_loss: 3.00112, obs_loss: 0.01281, reward_loss: 0.00000, value_loss: 0.00439 action_loss: 19.94174\n",
      "update_step:  28 model loss: 3.01307, kl_loss: 3.00064, obs_loss: 0.01243, reward_loss: 0.00001, value_loss: 0.00429 action_loss: 19.94968\n",
      "update_step:  29 model loss: 3.01042, kl_loss: 3.00091, obs_loss: 0.00950, reward_loss: 0.00001, value_loss: 0.00438 action_loss: 19.96293\n",
      "update_step:  30 model loss: 3.01151, kl_loss: 3.00047, obs_loss: 0.01103, reward_loss: 0.00001, value_loss: 0.00433 action_loss: 19.97478\n",
      "update_step:  31 model loss: 3.00912, kl_loss: 3.00096, obs_loss: 0.00815, reward_loss: 0.00000, value_loss: 0.00436 action_loss: 19.96969\n",
      "update_step:  32 model loss: 3.01176, kl_loss: 3.00055, obs_loss: 0.01120, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 19.97321\n",
      "update_step:  33 model loss: 3.01701, kl_loss: 3.00070, obs_loss: 0.01630, reward_loss: 0.00001, value_loss: 0.00431 action_loss: 19.96106\n",
      "update_step:  34 model loss: 3.01977, kl_loss: 3.00062, obs_loss: 0.01914, reward_loss: 0.00001, value_loss: 0.00428 action_loss: 19.97634\n",
      "update_step:  35 model loss: 3.01918, kl_loss: 3.00025, obs_loss: 0.01893, reward_loss: 0.00001, value_loss: 0.00434 action_loss: 19.96300\n",
      "update_step:  36 model loss: 3.02266, kl_loss: 3.00002, obs_loss: 0.02264, reward_loss: 0.00000, value_loss: 0.00438 action_loss: 19.97533\n",
      "update_step:  37 model loss: 3.02790, kl_loss: 3.00003, obs_loss: 0.02786, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 19.96682\n",
      "update_step:  38 model loss: 3.03475, kl_loss: 3.00022, obs_loss: 0.03452, reward_loss: 0.00001, value_loss: 0.00449 action_loss: 19.98787\n",
      "update_step:  39 model loss: 3.03670, kl_loss: 3.00012, obs_loss: 0.03658, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 19.97779\n",
      "update_step:  40 model loss: 3.04127, kl_loss: 3.00032, obs_loss: 0.04095, reward_loss: 0.00001, value_loss: 0.00434 action_loss: 19.99218\n",
      "update_step:  41 model loss: 3.04534, kl_loss: 3.00025, obs_loss: 0.04509, reward_loss: 0.00000, value_loss: 0.00435 action_loss: 19.98041\n",
      "update_step:  42 model loss: 3.05117, kl_loss: 3.00046, obs_loss: 0.05071, reward_loss: 0.00001, value_loss: 0.00431 action_loss: 19.99594\n",
      "update_step:  43 model loss: 3.05654, kl_loss: 3.00087, obs_loss: 0.05566, reward_loss: 0.00001, value_loss: 0.00436 action_loss: 19.97137\n",
      "update_step:  44 model loss: 3.05580, kl_loss: 3.00122, obs_loss: 0.05457, reward_loss: 0.00001, value_loss: 0.00433 action_loss: 19.96653\n",
      "update_step:  45 model loss: 3.03511, kl_loss: 3.00089, obs_loss: 0.03421, reward_loss: 0.00001, value_loss: 0.00430 action_loss: 19.95733\n",
      "update_step:  46 model loss: 3.01786, kl_loss: 3.00064, obs_loss: 0.01721, reward_loss: 0.00001, value_loss: 0.00439 action_loss: 19.99177\n",
      "update_step:  47 model loss: 3.00856, kl_loss: 3.00016, obs_loss: 0.00839, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 20.00740\n",
      "update_step:  48 model loss: 3.00525, kl_loss: 3.00069, obs_loss: 0.00456, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 20.00990\n",
      "update_step:  49 model loss: 3.00478, kl_loss: 3.00007, obs_loss: 0.00471, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 20.00864\n",
      "update_step:  50 model loss: 3.01464, kl_loss: 3.00082, obs_loss: 0.01382, reward_loss: 0.00001, value_loss: 0.00455 action_loss: 19.98337\n",
      "update_step:  51 model loss: 3.01908, kl_loss: 3.00031, obs_loss: 0.01876, reward_loss: 0.00001, value_loss: 0.00459 action_loss: 19.94991\n",
      "update_step:  52 model loss: 3.02394, kl_loss: 3.00081, obs_loss: 0.02312, reward_loss: 0.00001, value_loss: 0.00465 action_loss: 19.91101\n",
      "update_step:  53 model loss: 3.02875, kl_loss: 3.00014, obs_loss: 0.02860, reward_loss: 0.00001, value_loss: 0.00499 action_loss: 19.91929\n",
      "update_step:  54 model loss: 3.02898, kl_loss: 3.00058, obs_loss: 0.02840, reward_loss: 0.00001, value_loss: 0.00449 action_loss: 19.91628\n",
      "update_step:  55 model loss: 3.03037, kl_loss: 3.00085, obs_loss: 0.02951, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 19.93956\n",
      "update_step:  56 model loss: 3.02291, kl_loss: 3.00080, obs_loss: 0.02210, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 19.96768\n",
      "update_step:  57 model loss: 3.01797, kl_loss: 3.00060, obs_loss: 0.01736, reward_loss: 0.00000, value_loss: 0.00457 action_loss: 19.99997\n",
      "update_step:  58 model loss: 3.01214, kl_loss: 3.00026, obs_loss: 0.01187, reward_loss: 0.00001, value_loss: 0.00467 action_loss: 19.99553\n",
      "update_step:  59 model loss: 3.00765, kl_loss: 3.00036, obs_loss: 0.00728, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 20.00290\n",
      "update_step:  60 model loss: 3.00509, kl_loss: 3.00009, obs_loss: 0.00499, reward_loss: 0.00001, value_loss: 0.00453 action_loss: 20.00041\n",
      "update_step:  61 model loss: 3.00618, kl_loss: 3.00020, obs_loss: 0.00597, reward_loss: 0.00001, value_loss: 0.00453 action_loss: 19.99107\n",
      "update_step:  62 model loss: 3.00985, kl_loss: 3.00063, obs_loss: 0.00921, reward_loss: 0.00001, value_loss: 0.00443 action_loss: 19.98568\n",
      "update_step:  63 model loss: 3.02125, kl_loss: 3.00064, obs_loss: 0.02061, reward_loss: 0.00001, value_loss: 0.00453 action_loss: 19.98487\n",
      "update_step:  64 model loss: 3.01663, kl_loss: 3.00020, obs_loss: 0.01642, reward_loss: 0.00000, value_loss: 0.00447 action_loss: 19.99550\n",
      "update_step:  65 model loss: 3.01674, kl_loss: 3.00017, obs_loss: 0.01656, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 19.98725\n",
      "update_step:  66 model loss: 3.01571, kl_loss: 3.00043, obs_loss: 0.01527, reward_loss: 0.00001, value_loss: 0.00446 action_loss: 19.99583\n",
      "update_step:  67 model loss: 3.01744, kl_loss: 3.00167, obs_loss: 0.01577, reward_loss: 0.00001, value_loss: 0.00463 action_loss: 20.00132\n",
      "update_step:  68 model loss: 3.01074, kl_loss: 3.00062, obs_loss: 0.01011, reward_loss: 0.00001, value_loss: 0.00465 action_loss: 20.00270\n",
      "update_step:  69 model loss: 3.01063, kl_loss: 3.00019, obs_loss: 0.01043, reward_loss: 0.00001, value_loss: 0.00482 action_loss: 19.99538\n",
      "update_step:  70 model loss: 3.00651, kl_loss: 3.00011, obs_loss: 0.00639, reward_loss: 0.00001, value_loss: 0.00463 action_loss: 19.99828\n",
      "update_step:  71 model loss: 3.00727, kl_loss: 3.00039, obs_loss: 0.00688, reward_loss: 0.00000, value_loss: 0.00457 action_loss: 19.99880\n",
      "update_step:  72 model loss: 3.00618, kl_loss: 3.00003, obs_loss: 0.00614, reward_loss: 0.00001, value_loss: 0.00456 action_loss: 19.97459\n",
      "update_step:  73 model loss: 3.00609, kl_loss: 3.00006, obs_loss: 0.00603, reward_loss: 0.00001, value_loss: 0.00457 action_loss: 19.96600\n",
      "update_step:  74 model loss: 3.01074, kl_loss: 3.00048, obs_loss: 0.01026, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 19.95441\n",
      "update_step:  75 model loss: 3.00737, kl_loss: 3.00022, obs_loss: 0.00714, reward_loss: 0.00000, value_loss: 0.00462 action_loss: 19.95977\n",
      "update_step:  76 model loss: 3.01276, kl_loss: 3.00060, obs_loss: 0.01215, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 19.96151\n",
      "update_step:  77 model loss: 3.00635, kl_loss: 3.00027, obs_loss: 0.00607, reward_loss: 0.00001, value_loss: 0.00445 action_loss: 19.99122\n",
      "update_step:  78 model loss: 3.00807, kl_loss: 3.00055, obs_loss: 0.00752, reward_loss: 0.00001, value_loss: 0.00457 action_loss: 20.01609\n",
      "update_step:  79 model loss: 3.00724, kl_loss: 3.00035, obs_loss: 0.00689, reward_loss: 0.00001, value_loss: 0.00487 action_loss: 20.03873\n",
      "update_step:  80 model loss: 3.00886, kl_loss: 3.00107, obs_loss: 0.00779, reward_loss: 0.00001, value_loss: 0.00475 action_loss: 20.04643\n",
      "update_step:  81 model loss: 3.01138, kl_loss: 3.00099, obs_loss: 0.01038, reward_loss: 0.00001, value_loss: 0.00474 action_loss: 20.03772\n",
      "update_step:  82 model loss: 3.00718, kl_loss: 3.00017, obs_loss: 0.00701, reward_loss: 0.00001, value_loss: 0.00447 action_loss: 19.99681\n",
      "update_step:  83 model loss: 3.01479, kl_loss: 3.00208, obs_loss: 0.01271, reward_loss: 0.00000, value_loss: 0.00453 action_loss: 19.95970\n",
      "update_step:  84 model loss: 3.01133, kl_loss: 3.00112, obs_loss: 0.01021, reward_loss: 0.00001, value_loss: 0.00501 action_loss: 19.92860\n",
      "update_step:  85 model loss: 3.01535, kl_loss: 3.00094, obs_loss: 0.01441, reward_loss: 0.00001, value_loss: 0.00488 action_loss: 19.92107\n",
      "update_step:  86 model loss: 3.00288, kl_loss: 3.00008, obs_loss: 0.00279, reward_loss: 0.00001, value_loss: 0.00460 action_loss: 19.93726\n",
      "update_step:  87 model loss: 3.00515, kl_loss: 3.00046, obs_loss: 0.00469, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 19.96489\n",
      "update_step:  88 model loss: 3.00627, kl_loss: 3.00082, obs_loss: 0.00545, reward_loss: 0.00000, value_loss: 0.00438 action_loss: 19.99984\n",
      "update_step:  89 model loss: 3.00534, kl_loss: 3.00051, obs_loss: 0.00483, reward_loss: 0.00000, value_loss: 0.00455 action_loss: 20.01040\n",
      "update_step:  90 model loss: 3.00980, kl_loss: 3.00185, obs_loss: 0.00794, reward_loss: 0.00001, value_loss: 0.00466 action_loss: 20.00397\n",
      "update_step:  91 model loss: 3.01085, kl_loss: 3.00089, obs_loss: 0.00996, reward_loss: 0.00000, value_loss: 0.00444 action_loss: 19.98199\n",
      "update_step:  92 model loss: 3.00740, kl_loss: 3.00101, obs_loss: 0.00639, reward_loss: 0.00000, value_loss: 0.00431 action_loss: 19.95915\n",
      "update_step:  93 model loss: 3.00882, kl_loss: 3.00042, obs_loss: 0.00839, reward_loss: 0.00001, value_loss: 0.00463 action_loss: 19.93091\n",
      "update_step:  94 model loss: 3.00648, kl_loss: 3.00000, obs_loss: 0.00647, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 19.92987\n",
      "update_step:  95 model loss: 3.00877, kl_loss: 3.00020, obs_loss: 0.00856, reward_loss: 0.00000, value_loss: 0.00462 action_loss: 19.93919\n",
      "update_step:  96 model loss: 3.00960, kl_loss: 3.00074, obs_loss: 0.00886, reward_loss: 0.00000, value_loss: 0.00446 action_loss: 19.96975\n",
      "update_step:  97 model loss: 3.00604, kl_loss: 3.00025, obs_loss: 0.00579, reward_loss: 0.00000, value_loss: 0.00447 action_loss: 19.99281\n",
      "update_step:  98 model loss: 3.00642, kl_loss: 3.00055, obs_loss: 0.00586, reward_loss: 0.00000, value_loss: 0.00455 action_loss: 20.01134\n",
      "update_step:  99 model loss: 3.00517, kl_loss: 3.00016, obs_loss: 0.00500, reward_loss: 0.00000, value_loss: 0.00464 action_loss: 20.01103\n",
      "update_step: 100 model loss: 3.00586, kl_loss: 3.00002, obs_loss: 0.00583, reward_loss: 0.00000, value_loss: 0.00458 action_loss: 20.00436\n",
      "elasped time for update: 20.31s\n",
      "episode [  36/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.00633, kl_loss: 3.00017, obs_loss: 0.00616, reward_loss: 0.00001, value_loss: 0.00446 action_loss: 19.97772\n",
      "update_step:   2 model loss: 3.00354, kl_loss: 3.00000, obs_loss: 0.00353, reward_loss: 0.00001, value_loss: 0.00446 action_loss: 19.96962\n",
      "update_step:   3 model loss: 3.00560, kl_loss: 3.00000, obs_loss: 0.00559, reward_loss: 0.00001, value_loss: 0.00445 action_loss: 19.95174\n",
      "update_step:   4 model loss: 3.00635, kl_loss: 3.00019, obs_loss: 0.00616, reward_loss: 0.00001, value_loss: 0.00449 action_loss: 19.94728\n",
      "update_step:   5 model loss: 3.00279, kl_loss: 3.00000, obs_loss: 0.00278, reward_loss: 0.00001, value_loss: 0.00443 action_loss: 19.94455\n",
      "update_step:   6 model loss: 3.00199, kl_loss: 3.00000, obs_loss: 0.00198, reward_loss: 0.00000, value_loss: 0.00440 action_loss: 19.95547\n",
      "update_step:   7 model loss: 3.01146, kl_loss: 3.00095, obs_loss: 0.01050, reward_loss: 0.00000, value_loss: 0.00428 action_loss: 19.96094\n",
      "update_step:   8 model loss: 3.00616, kl_loss: 3.00095, obs_loss: 0.00520, reward_loss: 0.00000, value_loss: 0.00425 action_loss: 19.96652\n",
      "update_step:   9 model loss: 3.00845, kl_loss: 3.00160, obs_loss: 0.00684, reward_loss: 0.00001, value_loss: 0.00449 action_loss: 19.97613\n",
      "update_step:  10 model loss: 3.00515, kl_loss: 3.00137, obs_loss: 0.00378, reward_loss: 0.00001, value_loss: 0.00438 action_loss: 19.97843\n",
      "update_step:  11 model loss: 3.00518, kl_loss: 3.00087, obs_loss: 0.00430, reward_loss: 0.00000, value_loss: 0.00435 action_loss: 19.97903\n",
      "update_step:  12 model loss: 3.00491, kl_loss: 3.00008, obs_loss: 0.00483, reward_loss: 0.00000, value_loss: 0.00438 action_loss: 19.97005\n",
      "update_step:  13 model loss: 3.00690, kl_loss: 3.00002, obs_loss: 0.00688, reward_loss: 0.00001, value_loss: 0.00451 action_loss: 19.97829\n",
      "update_step:  14 model loss: 3.00996, kl_loss: 3.00049, obs_loss: 0.00946, reward_loss: 0.00001, value_loss: 0.00466 action_loss: 19.96893\n",
      "update_step:  15 model loss: 3.01081, kl_loss: 3.00037, obs_loss: 0.01044, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 19.97466\n",
      "update_step:  16 model loss: 3.01262, kl_loss: 3.00028, obs_loss: 0.01233, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 19.97827\n",
      "update_step:  17 model loss: 3.01099, kl_loss: 3.00016, obs_loss: 0.01083, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 19.99844\n",
      "update_step:  18 model loss: 3.01083, kl_loss: 3.00047, obs_loss: 0.01035, reward_loss: 0.00001, value_loss: 0.00433 action_loss: 19.99339\n",
      "update_step:  19 model loss: 3.01450, kl_loss: 3.00056, obs_loss: 0.01393, reward_loss: 0.00001, value_loss: 0.00445 action_loss: 20.01501\n",
      "update_step:  20 model loss: 3.01590, kl_loss: 3.00070, obs_loss: 0.01520, reward_loss: 0.00001, value_loss: 0.00444 action_loss: 20.00160\n",
      "update_step:  21 model loss: 3.01582, kl_loss: 3.00035, obs_loss: 0.01546, reward_loss: 0.00000, value_loss: 0.00441 action_loss: 20.00943\n",
      "update_step:  22 model loss: 3.01954, kl_loss: 3.00069, obs_loss: 0.01885, reward_loss: 0.00001, value_loss: 0.00433 action_loss: 19.97789\n",
      "update_step:  23 model loss: 3.02310, kl_loss: 3.00067, obs_loss: 0.02243, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 19.98620\n",
      "update_step:  24 model loss: 3.02630, kl_loss: 3.00010, obs_loss: 0.02619, reward_loss: 0.00001, value_loss: 0.00431 action_loss: 19.94862\n",
      "update_step:  25 model loss: 3.04474, kl_loss: 3.00078, obs_loss: 0.04395, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 19.96359\n",
      "update_step:  26 model loss: 3.03948, kl_loss: 3.00003, obs_loss: 0.03944, reward_loss: 0.00001, value_loss: 0.00439 action_loss: 19.93700\n",
      "update_step:  27 model loss: 3.05567, kl_loss: 3.00047, obs_loss: 0.05519, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 19.97184\n",
      "update_step:  28 model loss: 3.05560, kl_loss: 3.00054, obs_loss: 0.05506, reward_loss: 0.00001, value_loss: 0.00459 action_loss: 19.93806\n",
      "update_step:  29 model loss: 3.06294, kl_loss: 3.00032, obs_loss: 0.06262, reward_loss: 0.00001, value_loss: 0.00455 action_loss: 19.99069\n",
      "update_step:  30 model loss: 3.07680, kl_loss: 3.00126, obs_loss: 0.07553, reward_loss: 0.00001, value_loss: 0.00468 action_loss: 19.96887\n",
      "update_step:  31 model loss: 3.09552, kl_loss: 3.00052, obs_loss: 0.09499, reward_loss: 0.00001, value_loss: 0.00534 action_loss: 20.05229\n",
      "update_step:  32 model loss: 3.13521, kl_loss: 3.00033, obs_loss: 0.13487, reward_loss: 0.00001, value_loss: 0.00511 action_loss: 20.00782\n",
      "update_step:  33 model loss: 3.17778, kl_loss: 3.00000, obs_loss: 0.17776, reward_loss: 0.00001, value_loss: 0.00579 action_loss: 20.07865\n",
      "update_step:  34 model loss: 3.21179, kl_loss: 3.00056, obs_loss: 0.21122, reward_loss: 0.00001, value_loss: 0.00471 action_loss: 20.00867\n",
      "update_step:  35 model loss: 3.29747, kl_loss: 3.00000, obs_loss: 0.29745, reward_loss: 0.00002, value_loss: 0.00621 action_loss: 20.06413\n",
      "update_step:  36 model loss: 3.24431, kl_loss: 3.00022, obs_loss: 0.24407, reward_loss: 0.00002, value_loss: 0.00527 action_loss: 19.93875\n",
      "update_step:  37 model loss: 3.20047, kl_loss: 3.00062, obs_loss: 0.19984, reward_loss: 0.00002, value_loss: 0.00616 action_loss: 19.95402\n",
      "update_step:  38 model loss: 3.09845, kl_loss: 3.00014, obs_loss: 0.09830, reward_loss: 0.00001, value_loss: 0.00711 action_loss: 19.92675\n",
      "update_step:  39 model loss: 3.02618, kl_loss: 3.00000, obs_loss: 0.02617, reward_loss: 0.00001, value_loss: 0.00753 action_loss: 19.88402\n",
      "update_step:  40 model loss: 3.14944, kl_loss: 3.00091, obs_loss: 0.14852, reward_loss: 0.00001, value_loss: 0.00624 action_loss: 19.96174\n",
      "update_step:  41 model loss: 3.24329, kl_loss: 3.00007, obs_loss: 0.24320, reward_loss: 0.00001, value_loss: 0.00763 action_loss: 19.92171\n",
      "update_step:  42 model loss: 3.29371, kl_loss: 3.00006, obs_loss: 0.29362, reward_loss: 0.00002, value_loss: 0.00902 action_loss: 20.17240\n",
      "update_step:  43 model loss: 3.15234, kl_loss: 3.00000, obs_loss: 0.15231, reward_loss: 0.00003, value_loss: 0.01051 action_loss: 20.19811\n",
      "update_step:  44 model loss: 3.02668, kl_loss: 3.00004, obs_loss: 0.02663, reward_loss: 0.00001, value_loss: 0.01022 action_loss: 20.21801\n",
      "update_step:  45 model loss: 3.06324, kl_loss: 3.00000, obs_loss: 0.06322, reward_loss: 0.00002, value_loss: 0.00817 action_loss: 20.22328\n",
      "update_step:  46 model loss: 3.13211, kl_loss: 3.00015, obs_loss: 0.13193, reward_loss: 0.00003, value_loss: 0.00620 action_loss: 20.00864\n",
      "update_step:  47 model loss: 3.19229, kl_loss: 3.00054, obs_loss: 0.19173, reward_loss: 0.00002, value_loss: 0.00794 action_loss: 19.94832\n",
      "update_step:  48 model loss: 3.12394, kl_loss: 3.00107, obs_loss: 0.12287, reward_loss: 0.00001, value_loss: 0.00961 action_loss: 19.86061\n",
      "update_step:  49 model loss: 3.02419, kl_loss: 3.00171, obs_loss: 0.02248, reward_loss: 0.00001, value_loss: 0.00815 action_loss: 19.89586\n",
      "update_step:  50 model loss: 3.03162, kl_loss: 3.00154, obs_loss: 0.03006, reward_loss: 0.00001, value_loss: 0.00702 action_loss: 20.00253\n",
      "update_step:  51 model loss: 3.09452, kl_loss: 3.00240, obs_loss: 0.09211, reward_loss: 0.00001, value_loss: 0.00894 action_loss: 20.06729\n",
      "update_step:  52 model loss: 3.09253, kl_loss: 3.00035, obs_loss: 0.09216, reward_loss: 0.00002, value_loss: 0.01189 action_loss: 20.19236\n",
      "update_step:  53 model loss: 3.05819, kl_loss: 3.00046, obs_loss: 0.05771, reward_loss: 0.00002, value_loss: 0.01114 action_loss: 20.16166\n",
      "update_step:  54 model loss: 3.02524, kl_loss: 3.00067, obs_loss: 0.02456, reward_loss: 0.00001, value_loss: 0.00743 action_loss: 20.01932\n",
      "update_step:  55 model loss: 3.08094, kl_loss: 3.00134, obs_loss: 0.07957, reward_loss: 0.00002, value_loss: 0.00786 action_loss: 19.95054\n",
      "update_step:  56 model loss: 3.10293, kl_loss: 3.00097, obs_loss: 0.10194, reward_loss: 0.00002, value_loss: 0.01080 action_loss: 19.79844\n",
      "update_step:  57 model loss: 3.05991, kl_loss: 3.00142, obs_loss: 0.05848, reward_loss: 0.00001, value_loss: 0.01138 action_loss: 19.74066\n",
      "update_step:  58 model loss: 3.01624, kl_loss: 3.00178, obs_loss: 0.01445, reward_loss: 0.00001, value_loss: 0.01056 action_loss: 19.77370\n",
      "update_step:  59 model loss: 3.04306, kl_loss: 3.00047, obs_loss: 0.04258, reward_loss: 0.00001, value_loss: 0.00813 action_loss: 19.84678\n",
      "update_step:  60 model loss: 3.06715, kl_loss: 3.00063, obs_loss: 0.06652, reward_loss: 0.00001, value_loss: 0.00715 action_loss: 19.99748\n",
      "update_step:  61 model loss: 3.04289, kl_loss: 3.00032, obs_loss: 0.04256, reward_loss: 0.00001, value_loss: 0.00986 action_loss: 20.06910\n",
      "update_step:  62 model loss: 3.01567, kl_loss: 3.00014, obs_loss: 0.01552, reward_loss: 0.00001, value_loss: 0.01005 action_loss: 20.12928\n",
      "update_step:  63 model loss: 3.02456, kl_loss: 3.00001, obs_loss: 0.02453, reward_loss: 0.00001, value_loss: 0.00973 action_loss: 20.17002\n",
      "update_step:  64 model loss: 3.06634, kl_loss: 3.00009, obs_loss: 0.06623, reward_loss: 0.00002, value_loss: 0.00759 action_loss: 20.05172\n",
      "update_step:  65 model loss: 3.07017, kl_loss: 3.00074, obs_loss: 0.06941, reward_loss: 0.00002, value_loss: 0.00584 action_loss: 20.00702\n",
      "update_step:  66 model loss: 3.03215, kl_loss: 3.00099, obs_loss: 0.03115, reward_loss: 0.00001, value_loss: 0.00778 action_loss: 19.96320\n",
      "update_step:  67 model loss: 3.01310, kl_loss: 3.00068, obs_loss: 0.01240, reward_loss: 0.00002, value_loss: 0.00746 action_loss: 19.90993\n",
      "update_step:  68 model loss: 3.04573, kl_loss: 3.00069, obs_loss: 0.04503, reward_loss: 0.00001, value_loss: 0.00600 action_loss: 19.93792\n",
      "update_step:  69 model loss: 3.05255, kl_loss: 3.00096, obs_loss: 0.05159, reward_loss: 0.00001, value_loss: 0.00560 action_loss: 19.96235\n",
      "update_step:  70 model loss: 3.03440, kl_loss: 3.00051, obs_loss: 0.03388, reward_loss: 0.00001, value_loss: 0.00548 action_loss: 20.03831\n",
      "update_step:  71 model loss: 3.01764, kl_loss: 3.00042, obs_loss: 0.01721, reward_loss: 0.00002, value_loss: 0.00608 action_loss: 20.05319\n",
      "update_step:  72 model loss: 3.01917, kl_loss: 3.00000, obs_loss: 0.01917, reward_loss: 0.00001, value_loss: 0.00724 action_loss: 20.03129\n",
      "update_step:  73 model loss: 3.05115, kl_loss: 3.00189, obs_loss: 0.04923, reward_loss: 0.00002, value_loss: 0.00535 action_loss: 20.04993\n",
      "update_step:  74 model loss: 3.02574, kl_loss: 3.00043, obs_loss: 0.02529, reward_loss: 0.00002, value_loss: 0.00489 action_loss: 20.00482\n",
      "update_step:  75 model loss: 3.00816, kl_loss: 3.00040, obs_loss: 0.00775, reward_loss: 0.00001, value_loss: 0.00514 action_loss: 19.94885\n",
      "update_step:  76 model loss: 3.01423, kl_loss: 3.00187, obs_loss: 0.01234, reward_loss: 0.00002, value_loss: 0.00483 action_loss: 19.91985\n",
      "update_step:  77 model loss: 3.02539, kl_loss: 3.00161, obs_loss: 0.02378, reward_loss: 0.00001, value_loss: 0.00619 action_loss: 19.88310\n",
      "update_step:  78 model loss: 3.03094, kl_loss: 3.00151, obs_loss: 0.02941, reward_loss: 0.00001, value_loss: 0.00537 action_loss: 19.88692\n",
      "update_step:  79 model loss: 3.01208, kl_loss: 3.00029, obs_loss: 0.01178, reward_loss: 0.00001, value_loss: 0.00487 action_loss: 19.89858\n",
      "update_step:  80 model loss: 3.00702, kl_loss: 3.00003, obs_loss: 0.00698, reward_loss: 0.00001, value_loss: 0.00474 action_loss: 19.92862\n",
      "update_step:  81 model loss: 3.01028, kl_loss: 3.00000, obs_loss: 0.01027, reward_loss: 0.00001, value_loss: 0.00491 action_loss: 19.99100\n",
      "update_step:  82 model loss: 3.01358, kl_loss: 3.00013, obs_loss: 0.01343, reward_loss: 0.00002, value_loss: 0.00505 action_loss: 19.98800\n",
      "update_step:  83 model loss: 3.01178, kl_loss: 3.00024, obs_loss: 0.01154, reward_loss: 0.00001, value_loss: 0.00516 action_loss: 19.98886\n",
      "update_step:  84 model loss: 3.00874, kl_loss: 3.00066, obs_loss: 0.00807, reward_loss: 0.00001, value_loss: 0.00485 action_loss: 19.99199\n",
      "update_step:  85 model loss: 3.01392, kl_loss: 3.00033, obs_loss: 0.01357, reward_loss: 0.00001, value_loss: 0.00487 action_loss: 19.94694\n",
      "update_step:  86 model loss: 3.01290, kl_loss: 3.00030, obs_loss: 0.01259, reward_loss: 0.00001, value_loss: 0.00472 action_loss: 19.92634\n",
      "update_step:  87 model loss: 3.01396, kl_loss: 3.00063, obs_loss: 0.01332, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 19.91845\n",
      "update_step:  88 model loss: 3.01462, kl_loss: 3.00162, obs_loss: 0.01299, reward_loss: 0.00001, value_loss: 0.00480 action_loss: 19.94050\n",
      "update_step:  89 model loss: 3.01004, kl_loss: 3.00125, obs_loss: 0.00878, reward_loss: 0.00001, value_loss: 0.00465 action_loss: 19.97955\n",
      "update_step:  90 model loss: 3.01007, kl_loss: 3.00107, obs_loss: 0.00900, reward_loss: 0.00001, value_loss: 0.00498 action_loss: 19.99352\n",
      "update_step:  91 model loss: 3.01098, kl_loss: 3.00160, obs_loss: 0.00937, reward_loss: 0.00001, value_loss: 0.00490 action_loss: 20.02545\n",
      "update_step:  92 model loss: 3.00767, kl_loss: 3.00068, obs_loss: 0.00699, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 20.02764\n",
      "update_step:  93 model loss: 3.01020, kl_loss: 3.00057, obs_loss: 0.00961, reward_loss: 0.00001, value_loss: 0.00462 action_loss: 19.99161\n",
      "update_step:  94 model loss: 3.00993, kl_loss: 3.00026, obs_loss: 0.00966, reward_loss: 0.00001, value_loss: 0.00455 action_loss: 19.97602\n",
      "update_step:  95 model loss: 3.00908, kl_loss: 3.00001, obs_loss: 0.00906, reward_loss: 0.00001, value_loss: 0.00477 action_loss: 19.95022\n",
      "update_step:  96 model loss: 3.00945, kl_loss: 3.00030, obs_loss: 0.00915, reward_loss: 0.00001, value_loss: 0.00472 action_loss: 19.94061\n",
      "update_step:  97 model loss: 3.00548, kl_loss: 3.00022, obs_loss: 0.00525, reward_loss: 0.00001, value_loss: 0.00445 action_loss: 19.92201\n",
      "update_step:  98 model loss: 3.00749, kl_loss: 3.00056, obs_loss: 0.00692, reward_loss: 0.00001, value_loss: 0.00450 action_loss: 19.92969\n",
      "update_step:  99 model loss: 3.00870, kl_loss: 3.00025, obs_loss: 0.00844, reward_loss: 0.00000, value_loss: 0.00437 action_loss: 19.95625\n",
      "update_step: 100 model loss: 3.01651, kl_loss: 3.00082, obs_loss: 0.01568, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 19.96398\n",
      "elasped time for update: 20.61s\n",
      "episode [  37/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.36s\n",
      "update_step:   1 model loss: 3.00840, kl_loss: 3.00107, obs_loss: 0.00732, reward_loss: 0.00001, value_loss: 0.00445 action_loss: 19.97134\n",
      "update_step:   2 model loss: 3.00484, kl_loss: 3.00078, obs_loss: 0.00406, reward_loss: 0.00001, value_loss: 0.00429 action_loss: 19.98239\n",
      "update_step:   3 model loss: 3.00699, kl_loss: 3.00067, obs_loss: 0.00631, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 19.96336\n",
      "update_step:   4 model loss: 3.00864, kl_loss: 3.00082, obs_loss: 0.00781, reward_loss: 0.00001, value_loss: 0.00431 action_loss: 19.94312\n",
      "update_step:   5 model loss: 3.00450, kl_loss: 3.00083, obs_loss: 0.00366, reward_loss: 0.00001, value_loss: 0.00444 action_loss: 19.93680\n",
      "update_step:   6 model loss: 3.00359, kl_loss: 3.00006, obs_loss: 0.00353, reward_loss: 0.00001, value_loss: 0.00451 action_loss: 19.94040\n",
      "update_step:   7 model loss: 3.00807, kl_loss: 3.00037, obs_loss: 0.00769, reward_loss: 0.00001, value_loss: 0.00430 action_loss: 19.95469\n",
      "update_step:   8 model loss: 3.00751, kl_loss: 3.00011, obs_loss: 0.00739, reward_loss: 0.00000, value_loss: 0.00425 action_loss: 19.96580\n",
      "update_step:   9 model loss: 3.01039, kl_loss: 3.00060, obs_loss: 0.00979, reward_loss: 0.00001, value_loss: 0.00426 action_loss: 20.00705\n",
      "update_step:  10 model loss: 3.00629, kl_loss: 3.00042, obs_loss: 0.00586, reward_loss: 0.00001, value_loss: 0.00448 action_loss: 20.03124\n",
      "update_step:  11 model loss: 3.00582, kl_loss: 3.00027, obs_loss: 0.00555, reward_loss: 0.00001, value_loss: 0.00466 action_loss: 20.02983\n",
      "update_step:  12 model loss: 3.01141, kl_loss: 3.00047, obs_loss: 0.01093, reward_loss: 0.00001, value_loss: 0.00444 action_loss: 20.02854\n",
      "update_step:  13 model loss: 3.00580, kl_loss: 3.00049, obs_loss: 0.00531, reward_loss: 0.00001, value_loss: 0.00434 action_loss: 19.99217\n",
      "update_step:  14 model loss: 3.00777, kl_loss: 3.00163, obs_loss: 0.00613, reward_loss: 0.00001, value_loss: 0.00428 action_loss: 19.95687\n",
      "update_step:  15 model loss: 3.00437, kl_loss: 3.00037, obs_loss: 0.00399, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 19.92803\n",
      "update_step:  16 model loss: 3.00573, kl_loss: 3.00039, obs_loss: 0.00534, reward_loss: 0.00001, value_loss: 0.00466 action_loss: 19.92735\n",
      "update_step:  17 model loss: 3.00697, kl_loss: 3.00039, obs_loss: 0.00658, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 19.94156\n",
      "update_step:  18 model loss: 3.00438, kl_loss: 3.00014, obs_loss: 0.00423, reward_loss: 0.00001, value_loss: 0.00433 action_loss: 19.95495\n",
      "update_step:  19 model loss: 3.00251, kl_loss: 3.00002, obs_loss: 0.00248, reward_loss: 0.00001, value_loss: 0.00435 action_loss: 19.97626\n",
      "update_step:  20 model loss: 3.00958, kl_loss: 3.00053, obs_loss: 0.00905, reward_loss: 0.00000, value_loss: 0.00428 action_loss: 19.98947\n",
      "update_step:  21 model loss: 3.00417, kl_loss: 3.00012, obs_loss: 0.00405, reward_loss: 0.00001, value_loss: 0.00447 action_loss: 19.97589\n",
      "update_step:  22 model loss: 3.00786, kl_loss: 3.00042, obs_loss: 0.00743, reward_loss: 0.00000, value_loss: 0.00439 action_loss: 19.95714\n",
      "update_step:  23 model loss: 3.00512, kl_loss: 3.00033, obs_loss: 0.00479, reward_loss: 0.00001, value_loss: 0.00438 action_loss: 19.93981\n",
      "update_step:  24 model loss: 3.01497, kl_loss: 3.00100, obs_loss: 0.01396, reward_loss: 0.00001, value_loss: 0.00459 action_loss: 19.92738\n",
      "update_step:  25 model loss: 3.00495, kl_loss: 3.00032, obs_loss: 0.00463, reward_loss: 0.00001, value_loss: 0.00448 action_loss: 19.91639\n",
      "update_step:  26 model loss: 3.00405, kl_loss: 3.00093, obs_loss: 0.00311, reward_loss: 0.00001, value_loss: 0.00450 action_loss: 19.92789\n",
      "update_step:  27 model loss: 3.00573, kl_loss: 3.00032, obs_loss: 0.00540, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 19.97622\n",
      "update_step:  28 model loss: 3.00675, kl_loss: 3.00079, obs_loss: 0.00595, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 20.00735\n",
      "update_step:  29 model loss: 3.01010, kl_loss: 3.00197, obs_loss: 0.00813, reward_loss: 0.00000, value_loss: 0.00463 action_loss: 20.02612\n",
      "update_step:  30 model loss: 3.01469, kl_loss: 3.00146, obs_loss: 0.01323, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 20.03249\n",
      "update_step:  31 model loss: 3.00906, kl_loss: 3.00078, obs_loss: 0.00827, reward_loss: 0.00000, value_loss: 0.00435 action_loss: 20.02216\n",
      "update_step:  32 model loss: 3.00305, kl_loss: 3.00024, obs_loss: 0.00280, reward_loss: 0.00001, value_loss: 0.00425 action_loss: 19.99759\n",
      "update_step:  33 model loss: 3.00871, kl_loss: 3.00152, obs_loss: 0.00718, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 19.97652\n",
      "update_step:  34 model loss: 3.00556, kl_loss: 3.00051, obs_loss: 0.00505, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 19.97140\n",
      "update_step:  35 model loss: 3.00474, kl_loss: 3.00066, obs_loss: 0.00407, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 19.97029\n",
      "update_step:  36 model loss: 3.00886, kl_loss: 3.00067, obs_loss: 0.00819, reward_loss: 0.00000, value_loss: 0.00411 action_loss: 19.97345\n",
      "update_step:  37 model loss: 3.00279, kl_loss: 3.00038, obs_loss: 0.00241, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 19.99728\n",
      "update_step:  38 model loss: 3.00480, kl_loss: 3.00024, obs_loss: 0.00455, reward_loss: 0.00000, value_loss: 0.00429 action_loss: 20.01677\n",
      "update_step:  39 model loss: 3.01203, kl_loss: 3.00096, obs_loss: 0.01107, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 20.02457\n",
      "update_step:  40 model loss: 3.00551, kl_loss: 3.00076, obs_loss: 0.00475, reward_loss: 0.00000, value_loss: 0.00438 action_loss: 20.01267\n",
      "update_step:  41 model loss: 3.00290, kl_loss: 3.00047, obs_loss: 0.00242, reward_loss: 0.00001, value_loss: 0.00424 action_loss: 19.99416\n",
      "update_step:  42 model loss: 3.01030, kl_loss: 3.00078, obs_loss: 0.00951, reward_loss: 0.00000, value_loss: 0.00420 action_loss: 19.97090\n",
      "update_step:  43 model loss: 3.00807, kl_loss: 3.00107, obs_loss: 0.00700, reward_loss: 0.00001, value_loss: 0.00424 action_loss: 19.94577\n",
      "update_step:  44 model loss: 3.02044, kl_loss: 3.00181, obs_loss: 0.01862, reward_loss: 0.00001, value_loss: 0.00419 action_loss: 19.94561\n",
      "update_step:  45 model loss: 3.00487, kl_loss: 3.00057, obs_loss: 0.00430, reward_loss: 0.00000, value_loss: 0.00435 action_loss: 19.95336\n",
      "update_step:  46 model loss: 3.00468, kl_loss: 3.00066, obs_loss: 0.00401, reward_loss: 0.00001, value_loss: 0.00420 action_loss: 19.97092\n",
      "update_step:  47 model loss: 3.00355, kl_loss: 3.00040, obs_loss: 0.00314, reward_loss: 0.00000, value_loss: 0.00427 action_loss: 19.98846\n",
      "update_step:  48 model loss: 3.00993, kl_loss: 3.00080, obs_loss: 0.00912, reward_loss: 0.00001, value_loss: 0.00431 action_loss: 20.00043\n",
      "update_step:  49 model loss: 3.00846, kl_loss: 3.00068, obs_loss: 0.00778, reward_loss: 0.00000, value_loss: 0.00419 action_loss: 19.99389\n",
      "update_step:  50 model loss: 3.00494, kl_loss: 3.00029, obs_loss: 0.00464, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 19.97933\n",
      "update_step:  51 model loss: 3.00539, kl_loss: 3.00038, obs_loss: 0.00500, reward_loss: 0.00001, value_loss: 0.00422 action_loss: 19.96265\n",
      "update_step:  52 model loss: 3.00422, kl_loss: 3.00029, obs_loss: 0.00392, reward_loss: 0.00000, value_loss: 0.00436 action_loss: 19.95667\n",
      "update_step:  53 model loss: 3.00516, kl_loss: 3.00062, obs_loss: 0.00453, reward_loss: 0.00000, value_loss: 0.00435 action_loss: 19.95547\n",
      "update_step:  54 model loss: 3.00391, kl_loss: 3.00022, obs_loss: 0.00369, reward_loss: 0.00001, value_loss: 0.00416 action_loss: 19.96713\n",
      "update_step:  55 model loss: 3.00359, kl_loss: 3.00029, obs_loss: 0.00330, reward_loss: 0.00001, value_loss: 0.00421 action_loss: 19.98608\n",
      "update_step:  56 model loss: 3.00429, kl_loss: 3.00028, obs_loss: 0.00400, reward_loss: 0.00000, value_loss: 0.00419 action_loss: 20.00236\n",
      "update_step:  57 model loss: 3.00483, kl_loss: 3.00029, obs_loss: 0.00453, reward_loss: 0.00001, value_loss: 0.00438 action_loss: 20.01798\n",
      "update_step:  58 model loss: 3.00230, kl_loss: 3.00006, obs_loss: 0.00224, reward_loss: 0.00000, value_loss: 0.00429 action_loss: 20.01249\n",
      "update_step:  59 model loss: 3.01104, kl_loss: 3.00066, obs_loss: 0.01037, reward_loss: 0.00000, value_loss: 0.00415 action_loss: 19.99425\n",
      "update_step:  60 model loss: 3.00199, kl_loss: 3.00000, obs_loss: 0.00199, reward_loss: 0.00000, value_loss: 0.00420 action_loss: 19.97332\n",
      "update_step:  61 model loss: 3.00423, kl_loss: 3.00057, obs_loss: 0.00366, reward_loss: 0.00000, value_loss: 0.00425 action_loss: 19.95067\n",
      "update_step:  62 model loss: 3.00251, kl_loss: 3.00014, obs_loss: 0.00237, reward_loss: 0.00000, value_loss: 0.00425 action_loss: 19.93725\n",
      "update_step:  63 model loss: 3.00689, kl_loss: 3.00033, obs_loss: 0.00656, reward_loss: 0.00001, value_loss: 0.00435 action_loss: 19.94904\n",
      "update_step:  64 model loss: 3.00317, kl_loss: 3.00026, obs_loss: 0.00290, reward_loss: 0.00000, value_loss: 0.00414 action_loss: 19.96706\n",
      "update_step:  65 model loss: 3.00978, kl_loss: 3.00165, obs_loss: 0.00812, reward_loss: 0.00000, value_loss: 0.00410 action_loss: 19.98244\n",
      "update_step:  66 model loss: 3.00784, kl_loss: 3.00153, obs_loss: 0.00631, reward_loss: 0.00001, value_loss: 0.00427 action_loss: 20.00289\n",
      "update_step:  67 model loss: 3.00312, kl_loss: 3.00086, obs_loss: 0.00226, reward_loss: 0.00000, value_loss: 0.00425 action_loss: 20.01653\n",
      "update_step:  68 model loss: 3.01138, kl_loss: 3.00124, obs_loss: 0.01014, reward_loss: 0.00001, value_loss: 0.00418 action_loss: 20.01228\n",
      "update_step:  69 model loss: 3.00611, kl_loss: 3.00074, obs_loss: 0.00536, reward_loss: 0.00000, value_loss: 0.00402 action_loss: 19.99991\n",
      "update_step:  70 model loss: 3.00536, kl_loss: 3.00011, obs_loss: 0.00525, reward_loss: 0.00001, value_loss: 0.00417 action_loss: 19.98197\n",
      "update_step:  71 model loss: 3.00864, kl_loss: 3.00075, obs_loss: 0.00789, reward_loss: 0.00000, value_loss: 0.00422 action_loss: 19.97231\n",
      "update_step:  72 model loss: 3.00510, kl_loss: 3.00018, obs_loss: 0.00492, reward_loss: 0.00000, value_loss: 0.00411 action_loss: 19.95899\n",
      "update_step:  73 model loss: 3.01023, kl_loss: 3.00029, obs_loss: 0.00993, reward_loss: 0.00001, value_loss: 0.00400 action_loss: 19.96567\n",
      "update_step:  74 model loss: 3.01032, kl_loss: 3.00048, obs_loss: 0.00983, reward_loss: 0.00000, value_loss: 0.00400 action_loss: 19.97322\n",
      "update_step:  75 model loss: 3.00899, kl_loss: 3.00028, obs_loss: 0.00871, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.98603\n",
      "update_step:  76 model loss: 3.01770, kl_loss: 3.00210, obs_loss: 0.01559, reward_loss: 0.00000, value_loss: 0.00404 action_loss: 19.98464\n",
      "update_step:  77 model loss: 3.01479, kl_loss: 3.00082, obs_loss: 0.01397, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 19.99977\n",
      "update_step:  78 model loss: 3.00970, kl_loss: 3.00084, obs_loss: 0.00885, reward_loss: 0.00000, value_loss: 0.00395 action_loss: 19.99454\n",
      "update_step:  79 model loss: 3.00907, kl_loss: 3.00032, obs_loss: 0.00875, reward_loss: 0.00001, value_loss: 0.00400 action_loss: 19.98443\n",
      "update_step:  80 model loss: 3.01038, kl_loss: 3.00063, obs_loss: 0.00975, reward_loss: 0.00000, value_loss: 0.00398 action_loss: 19.97257\n",
      "update_step:  81 model loss: 3.01586, kl_loss: 3.00103, obs_loss: 0.01482, reward_loss: 0.00000, value_loss: 0.00400 action_loss: 19.97500\n",
      "update_step:  82 model loss: 3.00968, kl_loss: 3.00017, obs_loss: 0.00950, reward_loss: 0.00001, value_loss: 0.00405 action_loss: 19.95945\n",
      "update_step:  83 model loss: 3.01889, kl_loss: 3.00101, obs_loss: 0.01788, reward_loss: 0.00000, value_loss: 0.00400 action_loss: 19.95485\n",
      "update_step:  84 model loss: 3.01748, kl_loss: 3.00040, obs_loss: 0.01707, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.95469\n",
      "update_step:  85 model loss: 3.01103, kl_loss: 3.00029, obs_loss: 0.01074, reward_loss: 0.00001, value_loss: 0.00397 action_loss: 19.95307\n",
      "update_step:  86 model loss: 3.01018, kl_loss: 3.00058, obs_loss: 0.00960, reward_loss: 0.00000, value_loss: 0.00391 action_loss: 19.94710\n",
      "update_step:  87 model loss: 3.00971, kl_loss: 3.00049, obs_loss: 0.00921, reward_loss: 0.00001, value_loss: 0.00398 action_loss: 19.95696\n",
      "update_step:  88 model loss: 3.01162, kl_loss: 3.00049, obs_loss: 0.01113, reward_loss: 0.00001, value_loss: 0.00399 action_loss: 19.96145\n",
      "update_step:  89 model loss: 3.01578, kl_loss: 3.00048, obs_loss: 0.01530, reward_loss: 0.00001, value_loss: 0.00398 action_loss: 19.95751\n",
      "update_step:  90 model loss: 3.01090, kl_loss: 3.00024, obs_loss: 0.01065, reward_loss: 0.00001, value_loss: 0.00408 action_loss: 19.96338\n",
      "update_step:  91 model loss: 3.01004, kl_loss: 3.00067, obs_loss: 0.00937, reward_loss: 0.00000, value_loss: 0.00415 action_loss: 19.97215\n",
      "update_step:  92 model loss: 3.01178, kl_loss: 3.00119, obs_loss: 0.01059, reward_loss: 0.00001, value_loss: 0.00410 action_loss: 19.96598\n",
      "update_step:  93 model loss: 3.00599, kl_loss: 3.00014, obs_loss: 0.00585, reward_loss: 0.00001, value_loss: 0.00392 action_loss: 19.97298\n",
      "update_step:  94 model loss: 3.00518, kl_loss: 3.00032, obs_loss: 0.00485, reward_loss: 0.00001, value_loss: 0.00396 action_loss: 19.98225\n",
      "update_step:  95 model loss: 3.00750, kl_loss: 3.00118, obs_loss: 0.00631, reward_loss: 0.00001, value_loss: 0.00391 action_loss: 19.99096\n",
      "update_step:  96 model loss: 3.00645, kl_loss: 3.00037, obs_loss: 0.00608, reward_loss: 0.00000, value_loss: 0.00397 action_loss: 19.97974\n",
      "update_step:  97 model loss: 3.00529, kl_loss: 3.00026, obs_loss: 0.00502, reward_loss: 0.00001, value_loss: 0.00395 action_loss: 19.98243\n",
      "update_step:  98 model loss: 3.00543, kl_loss: 3.00002, obs_loss: 0.00541, reward_loss: 0.00000, value_loss: 0.00393 action_loss: 19.97855\n",
      "update_step:  99 model loss: 3.00773, kl_loss: 3.00039, obs_loss: 0.00733, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 19.97370\n",
      "update_step: 100 model loss: 3.00764, kl_loss: 3.00028, obs_loss: 0.00736, reward_loss: 0.00001, value_loss: 0.00383 action_loss: 19.97758\n",
      "elasped time for update: 20.59s\n",
      "episode [  38/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.00826, kl_loss: 3.00024, obs_loss: 0.00801, reward_loss: 0.00000, value_loss: 0.00391 action_loss: 19.99020\n",
      "update_step:   2 model loss: 3.01868, kl_loss: 3.00063, obs_loss: 0.01804, reward_loss: 0.00001, value_loss: 0.00387 action_loss: 19.98223\n",
      "update_step:   3 model loss: 3.01044, kl_loss: 3.00024, obs_loss: 0.01020, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.96901\n",
      "update_step:   4 model loss: 3.01247, kl_loss: 3.00077, obs_loss: 0.01169, reward_loss: 0.00001, value_loss: 0.00397 action_loss: 19.96888\n",
      "update_step:   5 model loss: 3.00905, kl_loss: 3.00071, obs_loss: 0.00833, reward_loss: 0.00000, value_loss: 0.00387 action_loss: 19.98171\n",
      "update_step:   6 model loss: 3.01027, kl_loss: 3.00058, obs_loss: 0.00969, reward_loss: 0.00001, value_loss: 0.00407 action_loss: 19.97619\n",
      "update_step:   7 model loss: 3.01263, kl_loss: 3.00051, obs_loss: 0.01211, reward_loss: 0.00001, value_loss: 0.00396 action_loss: 19.98732\n",
      "update_step:   8 model loss: 3.01085, kl_loss: 3.00023, obs_loss: 0.01062, reward_loss: 0.00000, value_loss: 0.00395 action_loss: 19.98686\n",
      "update_step:   9 model loss: 3.01747, kl_loss: 3.00077, obs_loss: 0.01670, reward_loss: 0.00000, value_loss: 0.00394 action_loss: 19.98978\n",
      "update_step:  10 model loss: 3.01632, kl_loss: 3.00024, obs_loss: 0.01607, reward_loss: 0.00000, value_loss: 0.00394 action_loss: 19.97160\n",
      "update_step:  11 model loss: 3.02278, kl_loss: 3.00044, obs_loss: 0.02233, reward_loss: 0.00001, value_loss: 0.00406 action_loss: 19.98762\n",
      "update_step:  12 model loss: 3.03019, kl_loss: 3.00106, obs_loss: 0.02912, reward_loss: 0.00000, value_loss: 0.00408 action_loss: 19.98995\n",
      "update_step:  13 model loss: 3.03350, kl_loss: 3.00025, obs_loss: 0.03325, reward_loss: 0.00001, value_loss: 0.00401 action_loss: 20.00138\n",
      "update_step:  14 model loss: 3.04157, kl_loss: 3.00020, obs_loss: 0.04137, reward_loss: 0.00000, value_loss: 0.00410 action_loss: 19.99535\n",
      "update_step:  15 model loss: 3.05246, kl_loss: 3.00006, obs_loss: 0.05239, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 20.00826\n",
      "update_step:  16 model loss: 3.06094, kl_loss: 3.00026, obs_loss: 0.06068, reward_loss: 0.00001, value_loss: 0.00398 action_loss: 19.97879\n",
      "update_step:  17 model loss: 3.06512, kl_loss: 3.00026, obs_loss: 0.06486, reward_loss: 0.00001, value_loss: 0.00402 action_loss: 19.97288\n",
      "update_step:  18 model loss: 3.06118, kl_loss: 3.00045, obs_loss: 0.06072, reward_loss: 0.00000, value_loss: 0.00407 action_loss: 19.95313\n",
      "update_step:  19 model loss: 3.05236, kl_loss: 3.00014, obs_loss: 0.05222, reward_loss: 0.00000, value_loss: 0.00420 action_loss: 19.96084\n",
      "update_step:  20 model loss: 3.04301, kl_loss: 3.00052, obs_loss: 0.04249, reward_loss: 0.00001, value_loss: 0.00391 action_loss: 19.94515\n",
      "update_step:  21 model loss: 3.03506, kl_loss: 3.00120, obs_loss: 0.03386, reward_loss: 0.00001, value_loss: 0.00399 action_loss: 19.94963\n",
      "update_step:  22 model loss: 3.01448, kl_loss: 3.00024, obs_loss: 0.01423, reward_loss: 0.00000, value_loss: 0.00409 action_loss: 19.95378\n",
      "update_step:  23 model loss: 3.00477, kl_loss: 3.00019, obs_loss: 0.00457, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.97019\n",
      "update_step:  24 model loss: 3.00487, kl_loss: 3.00088, obs_loss: 0.00398, reward_loss: 0.00000, value_loss: 0.00397 action_loss: 19.98844\n",
      "update_step:  25 model loss: 3.00733, kl_loss: 3.00037, obs_loss: 0.00696, reward_loss: 0.00000, value_loss: 0.00401 action_loss: 19.99216\n",
      "update_step:  26 model loss: 3.02030, kl_loss: 3.00089, obs_loss: 0.01941, reward_loss: 0.00001, value_loss: 0.00410 action_loss: 20.00469\n",
      "update_step:  27 model loss: 3.01977, kl_loss: 3.00010, obs_loss: 0.01967, reward_loss: 0.00000, value_loss: 0.00391 action_loss: 19.98754\n",
      "update_step:  28 model loss: 3.02695, kl_loss: 3.00030, obs_loss: 0.02664, reward_loss: 0.00001, value_loss: 0.00387 action_loss: 19.98891\n",
      "update_step:  29 model loss: 3.02934, kl_loss: 3.00032, obs_loss: 0.02902, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.96766\n",
      "update_step:  30 model loss: 3.02547, kl_loss: 3.00000, obs_loss: 0.02547, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.96470\n",
      "update_step:  31 model loss: 3.01892, kl_loss: 3.00005, obs_loss: 0.01887, reward_loss: 0.00000, value_loss: 0.00381 action_loss: 19.95669\n",
      "update_step:  32 model loss: 3.01443, kl_loss: 3.00081, obs_loss: 0.01361, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.96810\n",
      "update_step:  33 model loss: 3.00576, kl_loss: 3.00052, obs_loss: 0.00523, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 19.98841\n",
      "update_step:  34 model loss: 3.00591, kl_loss: 3.00122, obs_loss: 0.00468, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 20.00086\n",
      "update_step:  35 model loss: 3.00598, kl_loss: 3.00079, obs_loss: 0.00519, reward_loss: 0.00000, value_loss: 0.00393 action_loss: 20.01566\n",
      "update_step:  36 model loss: 3.00731, kl_loss: 3.00027, obs_loss: 0.00704, reward_loss: 0.00000, value_loss: 0.00393 action_loss: 20.00959\n",
      "update_step:  37 model loss: 3.01030, kl_loss: 3.00003, obs_loss: 0.01027, reward_loss: 0.00000, value_loss: 0.00393 action_loss: 20.00805\n",
      "update_step:  38 model loss: 3.01526, kl_loss: 3.00039, obs_loss: 0.01487, reward_loss: 0.00000, value_loss: 0.00388 action_loss: 19.98853\n",
      "update_step:  39 model loss: 3.01576, kl_loss: 3.00000, obs_loss: 0.01576, reward_loss: 0.00001, value_loss: 0.00403 action_loss: 19.98083\n",
      "update_step:  40 model loss: 3.01648, kl_loss: 3.00059, obs_loss: 0.01588, reward_loss: 0.00000, value_loss: 0.00394 action_loss: 19.97185\n",
      "update_step:  41 model loss: 3.01272, kl_loss: 3.00003, obs_loss: 0.01268, reward_loss: 0.00000, value_loss: 0.00400 action_loss: 19.96838\n",
      "update_step:  42 model loss: 3.00496, kl_loss: 3.00050, obs_loss: 0.00446, reward_loss: 0.00000, value_loss: 0.00401 action_loss: 19.96552\n",
      "update_step:  43 model loss: 3.00409, kl_loss: 3.00049, obs_loss: 0.00359, reward_loss: 0.00000, value_loss: 0.00399 action_loss: 19.97308\n",
      "update_step:  44 model loss: 3.00290, kl_loss: 3.00062, obs_loss: 0.00228, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.97910\n",
      "update_step:  45 model loss: 3.00902, kl_loss: 3.00102, obs_loss: 0.00799, reward_loss: 0.00000, value_loss: 0.00408 action_loss: 19.98526\n",
      "update_step:  46 model loss: 3.00764, kl_loss: 3.00094, obs_loss: 0.00669, reward_loss: 0.00000, value_loss: 0.00402 action_loss: 19.98625\n",
      "update_step:  47 model loss: 3.00524, kl_loss: 3.00052, obs_loss: 0.00471, reward_loss: 0.00000, value_loss: 0.00395 action_loss: 19.99280\n",
      "update_step:  48 model loss: 3.00552, kl_loss: 3.00003, obs_loss: 0.00549, reward_loss: 0.00000, value_loss: 0.00388 action_loss: 19.99001\n",
      "update_step:  49 model loss: 3.00865, kl_loss: 3.00031, obs_loss: 0.00834, reward_loss: 0.00000, value_loss: 0.00394 action_loss: 19.98695\n",
      "update_step:  50 model loss: 3.00834, kl_loss: 3.00044, obs_loss: 0.00789, reward_loss: 0.00000, value_loss: 0.00398 action_loss: 19.98998\n",
      "update_step:  51 model loss: 3.02038, kl_loss: 3.00187, obs_loss: 0.01850, reward_loss: 0.00000, value_loss: 0.00395 action_loss: 19.99348\n",
      "update_step:  52 model loss: 3.01089, kl_loss: 3.00089, obs_loss: 0.00999, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 19.99924\n",
      "update_step:  53 model loss: 3.00636, kl_loss: 3.00050, obs_loss: 0.00586, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.99405\n",
      "update_step:  54 model loss: 3.00462, kl_loss: 3.00052, obs_loss: 0.00409, reward_loss: 0.00001, value_loss: 0.00385 action_loss: 20.00808\n",
      "update_step:  55 model loss: 3.00861, kl_loss: 3.00149, obs_loss: 0.00711, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 20.00901\n",
      "update_step:  56 model loss: 3.00486, kl_loss: 3.00063, obs_loss: 0.00423, reward_loss: 0.00000, value_loss: 0.00380 action_loss: 20.01166\n",
      "update_step:  57 model loss: 3.00604, kl_loss: 3.00111, obs_loss: 0.00493, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 20.00765\n",
      "update_step:  58 model loss: 3.01216, kl_loss: 3.00091, obs_loss: 0.01125, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 19.99872\n",
      "update_step:  59 model loss: 3.00676, kl_loss: 3.00062, obs_loss: 0.00613, reward_loss: 0.00001, value_loss: 0.00382 action_loss: 19.97956\n",
      "update_step:  60 model loss: 3.00967, kl_loss: 3.00041, obs_loss: 0.00926, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 19.96235\n",
      "update_step:  61 model loss: 3.00334, kl_loss: 3.00006, obs_loss: 0.00327, reward_loss: 0.00001, value_loss: 0.00385 action_loss: 19.97241\n",
      "update_step:  62 model loss: 3.00688, kl_loss: 3.00023, obs_loss: 0.00664, reward_loss: 0.00001, value_loss: 0.00386 action_loss: 19.97705\n",
      "update_step:  63 model loss: 3.00510, kl_loss: 3.00031, obs_loss: 0.00479, reward_loss: 0.00000, value_loss: 0.00391 action_loss: 19.98879\n",
      "update_step:  64 model loss: 3.00683, kl_loss: 3.00073, obs_loss: 0.00610, reward_loss: 0.00000, value_loss: 0.00380 action_loss: 19.99411\n",
      "update_step:  65 model loss: 3.00528, kl_loss: 3.00069, obs_loss: 0.00459, reward_loss: 0.00000, value_loss: 0.00375 action_loss: 19.99537\n",
      "update_step:  66 model loss: 3.00284, kl_loss: 3.00045, obs_loss: 0.00238, reward_loss: 0.00000, value_loss: 0.00387 action_loss: 19.98837\n",
      "update_step:  67 model loss: 3.00313, kl_loss: 3.00008, obs_loss: 0.00305, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 19.98061\n",
      "update_step:  68 model loss: 3.00477, kl_loss: 3.00026, obs_loss: 0.00451, reward_loss: 0.00000, value_loss: 0.00381 action_loss: 19.97614\n",
      "update_step:  69 model loss: 3.00312, kl_loss: 3.00008, obs_loss: 0.00304, reward_loss: 0.00000, value_loss: 0.00385 action_loss: 19.96868\n",
      "update_step:  70 model loss: 3.01192, kl_loss: 3.00111, obs_loss: 0.01081, reward_loss: 0.00000, value_loss: 0.00379 action_loss: 19.96288\n",
      "update_step:  71 model loss: 3.00314, kl_loss: 3.00022, obs_loss: 0.00292, reward_loss: 0.00000, value_loss: 0.00379 action_loss: 19.96539\n",
      "update_step:  72 model loss: 3.00567, kl_loss: 3.00034, obs_loss: 0.00533, reward_loss: 0.00000, value_loss: 0.00375 action_loss: 19.97038\n",
      "update_step:  73 model loss: 3.01074, kl_loss: 3.00074, obs_loss: 0.01000, reward_loss: 0.00000, value_loss: 0.00370 action_loss: 19.97628\n",
      "update_step:  74 model loss: 3.00320, kl_loss: 3.00046, obs_loss: 0.00274, reward_loss: 0.00000, value_loss: 0.00366 action_loss: 19.98866\n",
      "update_step:  75 model loss: 3.00520, kl_loss: 3.00065, obs_loss: 0.00454, reward_loss: 0.00000, value_loss: 0.00373 action_loss: 19.99431\n",
      "update_step:  76 model loss: 3.00487, kl_loss: 3.00064, obs_loss: 0.00423, reward_loss: 0.00000, value_loss: 0.00373 action_loss: 19.98925\n",
      "update_step:  77 model loss: 3.00908, kl_loss: 3.00104, obs_loss: 0.00804, reward_loss: 0.00000, value_loss: 0.00373 action_loss: 19.98282\n",
      "update_step:  78 model loss: 3.00386, kl_loss: 3.00130, obs_loss: 0.00255, reward_loss: 0.00000, value_loss: 0.00381 action_loss: 19.97754\n",
      "update_step:  79 model loss: 3.01052, kl_loss: 3.00098, obs_loss: 0.00954, reward_loss: 0.00000, value_loss: 0.00388 action_loss: 19.97344\n",
      "update_step:  80 model loss: 3.00834, kl_loss: 3.00043, obs_loss: 0.00791, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.96545\n",
      "update_step:  81 model loss: 3.00312, kl_loss: 3.00000, obs_loss: 0.00312, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 19.97102\n",
      "update_step:  82 model loss: 3.00302, kl_loss: 3.00005, obs_loss: 0.00296, reward_loss: 0.00000, value_loss: 0.00385 action_loss: 19.97603\n",
      "update_step:  83 model loss: 3.01249, kl_loss: 3.00061, obs_loss: 0.01188, reward_loss: 0.00000, value_loss: 0.00380 action_loss: 19.98687\n",
      "update_step:  84 model loss: 3.00748, kl_loss: 3.00053, obs_loss: 0.00694, reward_loss: 0.00000, value_loss: 0.00385 action_loss: 19.99123\n",
      "update_step:  85 model loss: 3.00868, kl_loss: 3.00124, obs_loss: 0.00743, reward_loss: 0.00000, value_loss: 0.00392 action_loss: 20.00342\n",
      "update_step:  86 model loss: 3.00471, kl_loss: 3.00072, obs_loss: 0.00399, reward_loss: 0.00000, value_loss: 0.00399 action_loss: 20.00156\n",
      "update_step:  87 model loss: 3.01507, kl_loss: 3.00135, obs_loss: 0.01371, reward_loss: 0.00000, value_loss: 0.00386 action_loss: 19.99913\n",
      "update_step:  88 model loss: 3.01929, kl_loss: 3.00113, obs_loss: 0.01815, reward_loss: 0.00000, value_loss: 0.00385 action_loss: 19.97929\n",
      "update_step:  89 model loss: 3.01849, kl_loss: 3.00085, obs_loss: 0.01764, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 19.96570\n",
      "update_step:  90 model loss: 3.00935, kl_loss: 3.00071, obs_loss: 0.00864, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.95412\n",
      "update_step:  91 model loss: 3.00970, kl_loss: 3.00061, obs_loss: 0.00908, reward_loss: 0.00000, value_loss: 0.00386 action_loss: 19.96001\n",
      "update_step:  92 model loss: 3.01972, kl_loss: 3.00174, obs_loss: 0.01797, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.96876\n",
      "update_step:  93 model loss: 3.01737, kl_loss: 3.00076, obs_loss: 0.01661, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 19.98266\n",
      "update_step:  94 model loss: 3.01384, kl_loss: 3.00018, obs_loss: 0.01366, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 19.98565\n",
      "update_step:  95 model loss: 3.02568, kl_loss: 3.00020, obs_loss: 0.02547, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.99549\n",
      "update_step:  96 model loss: 3.02343, kl_loss: 3.00025, obs_loss: 0.02318, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.98942\n",
      "update_step:  97 model loss: 3.02810, kl_loss: 3.00045, obs_loss: 0.02765, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 19.99667\n",
      "update_step:  98 model loss: 3.02874, kl_loss: 3.00024, obs_loss: 0.02849, reward_loss: 0.00000, value_loss: 0.00389 action_loss: 19.96958\n",
      "update_step:  99 model loss: 3.02955, kl_loss: 3.00006, obs_loss: 0.02948, reward_loss: 0.00000, value_loss: 0.00385 action_loss: 19.97698\n",
      "update_step: 100 model loss: 3.03268, kl_loss: 3.00040, obs_loss: 0.03228, reward_loss: 0.00000, value_loss: 0.00376 action_loss: 19.96944\n",
      "elasped time for update: 20.33s\n",
      "episode [  39/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.02914, kl_loss: 3.00029, obs_loss: 0.02884, reward_loss: 0.00001, value_loss: 0.00382 action_loss: 19.99677\n",
      "update_step:   2 model loss: 3.02302, kl_loss: 3.00039, obs_loss: 0.02262, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 19.99893\n",
      "update_step:   3 model loss: 3.02501, kl_loss: 3.00138, obs_loss: 0.02363, reward_loss: 0.00000, value_loss: 0.00387 action_loss: 20.02861\n",
      "update_step:   4 model loss: 3.02295, kl_loss: 3.00058, obs_loss: 0.02236, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 20.01520\n",
      "update_step:   5 model loss: 3.01930, kl_loss: 3.00078, obs_loss: 0.01851, reward_loss: 0.00001, value_loss: 0.00381 action_loss: 20.01575\n",
      "update_step:   6 model loss: 3.01543, kl_loss: 3.00018, obs_loss: 0.01524, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 19.98040\n",
      "update_step:   7 model loss: 3.01706, kl_loss: 3.00028, obs_loss: 0.01678, reward_loss: 0.00000, value_loss: 0.00379 action_loss: 19.97132\n",
      "update_step:   8 model loss: 3.01355, kl_loss: 3.00038, obs_loss: 0.01317, reward_loss: 0.00000, value_loss: 0.00380 action_loss: 19.97044\n",
      "update_step:   9 model loss: 3.00628, kl_loss: 3.00005, obs_loss: 0.00623, reward_loss: 0.00000, value_loss: 0.00369 action_loss: 19.98367\n",
      "update_step:  10 model loss: 3.00463, kl_loss: 3.00004, obs_loss: 0.00458, reward_loss: 0.00001, value_loss: 0.00385 action_loss: 19.98730\n",
      "update_step:  11 model loss: 3.00730, kl_loss: 3.00045, obs_loss: 0.00685, reward_loss: 0.00001, value_loss: 0.00384 action_loss: 20.00546\n",
      "update_step:  12 model loss: 3.01149, kl_loss: 3.00073, obs_loss: 0.01076, reward_loss: 0.00000, value_loss: 0.00375 action_loss: 20.01210\n",
      "update_step:  13 model loss: 3.00441, kl_loss: 3.00040, obs_loss: 0.00400, reward_loss: 0.00000, value_loss: 0.00375 action_loss: 19.99565\n",
      "update_step:  14 model loss: 3.00646, kl_loss: 3.00050, obs_loss: 0.00595, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 19.97429\n",
      "update_step:  15 model loss: 3.01786, kl_loss: 3.00133, obs_loss: 0.01653, reward_loss: 0.00000, value_loss: 0.00398 action_loss: 19.96706\n",
      "update_step:  16 model loss: 3.01506, kl_loss: 3.00126, obs_loss: 0.01379, reward_loss: 0.00001, value_loss: 0.00391 action_loss: 19.95954\n",
      "update_step:  17 model loss: 3.00926, kl_loss: 3.00052, obs_loss: 0.00874, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 19.97504\n",
      "update_step:  18 model loss: 3.00936, kl_loss: 3.00034, obs_loss: 0.00901, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 20.00035\n",
      "update_step:  19 model loss: 3.00977, kl_loss: 3.00024, obs_loss: 0.00952, reward_loss: 0.00001, value_loss: 0.00386 action_loss: 20.02936\n",
      "update_step:  20 model loss: 3.00986, kl_loss: 3.00012, obs_loss: 0.00973, reward_loss: 0.00001, value_loss: 0.00397 action_loss: 20.04380\n",
      "update_step:  21 model loss: 3.00726, kl_loss: 3.00016, obs_loss: 0.00710, reward_loss: 0.00000, value_loss: 0.00380 action_loss: 20.03451\n",
      "update_step:  22 model loss: 3.00941, kl_loss: 3.00009, obs_loss: 0.00931, reward_loss: 0.00000, value_loss: 0.00380 action_loss: 20.02907\n",
      "update_step:  23 model loss: 3.01621, kl_loss: 3.00022, obs_loss: 0.01599, reward_loss: 0.00001, value_loss: 0.00383 action_loss: 19.98306\n",
      "update_step:  24 model loss: 3.01978, kl_loss: 3.00028, obs_loss: 0.01949, reward_loss: 0.00000, value_loss: 0.00387 action_loss: 19.97191\n",
      "update_step:  25 model loss: 3.02317, kl_loss: 3.00040, obs_loss: 0.02276, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 19.95862\n",
      "update_step:  26 model loss: 3.03400, kl_loss: 3.00035, obs_loss: 0.03365, reward_loss: 0.00001, value_loss: 0.00385 action_loss: 20.01252\n",
      "update_step:  27 model loss: 3.03906, kl_loss: 3.00037, obs_loss: 0.03869, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 19.99966\n",
      "update_step:  28 model loss: 3.05224, kl_loss: 3.00019, obs_loss: 0.05204, reward_loss: 0.00001, value_loss: 0.00415 action_loss: 20.06128\n",
      "update_step:  29 model loss: 3.06175, kl_loss: 3.00020, obs_loss: 0.06154, reward_loss: 0.00001, value_loss: 0.00401 action_loss: 20.04110\n",
      "update_step:  30 model loss: 3.07062, kl_loss: 3.00006, obs_loss: 0.07055, reward_loss: 0.00000, value_loss: 0.00433 action_loss: 20.05209\n",
      "update_step:  31 model loss: 3.05901, kl_loss: 3.00029, obs_loss: 0.05872, reward_loss: 0.00001, value_loss: 0.00401 action_loss: 19.97459\n",
      "update_step:  32 model loss: 3.05221, kl_loss: 3.00000, obs_loss: 0.05220, reward_loss: 0.00001, value_loss: 0.00427 action_loss: 20.01619\n",
      "update_step:  33 model loss: 3.03675, kl_loss: 3.00053, obs_loss: 0.03621, reward_loss: 0.00001, value_loss: 0.00401 action_loss: 20.00119\n",
      "update_step:  34 model loss: 3.01874, kl_loss: 3.00000, obs_loss: 0.01874, reward_loss: 0.00001, value_loss: 0.00410 action_loss: 19.98304\n",
      "update_step:  35 model loss: 3.01131, kl_loss: 3.00063, obs_loss: 0.01067, reward_loss: 0.00001, value_loss: 0.00449 action_loss: 19.97913\n",
      "update_step:  36 model loss: 3.01761, kl_loss: 3.00058, obs_loss: 0.01702, reward_loss: 0.00001, value_loss: 0.00427 action_loss: 19.95893\n",
      "update_step:  37 model loss: 3.02872, kl_loss: 3.00067, obs_loss: 0.02804, reward_loss: 0.00001, value_loss: 0.00433 action_loss: 19.99908\n",
      "update_step:  38 model loss: 3.03431, kl_loss: 3.00044, obs_loss: 0.03387, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 20.00078\n",
      "update_step:  39 model loss: 3.03109, kl_loss: 3.00070, obs_loss: 0.03038, reward_loss: 0.00001, value_loss: 0.00450 action_loss: 20.05758\n",
      "update_step:  40 model loss: 3.03240, kl_loss: 3.00068, obs_loss: 0.03171, reward_loss: 0.00001, value_loss: 0.00509 action_loss: 20.05952\n",
      "update_step:  41 model loss: 3.02008, kl_loss: 3.00053, obs_loss: 0.01955, reward_loss: 0.00001, value_loss: 0.00484 action_loss: 20.08430\n",
      "update_step:  42 model loss: 3.01183, kl_loss: 3.00013, obs_loss: 0.01169, reward_loss: 0.00001, value_loss: 0.00459 action_loss: 20.08520\n",
      "update_step:  43 model loss: 3.01502, kl_loss: 3.00044, obs_loss: 0.01457, reward_loss: 0.00001, value_loss: 0.00463 action_loss: 20.01953\n",
      "update_step:  44 model loss: 3.01714, kl_loss: 3.00029, obs_loss: 0.01684, reward_loss: 0.00001, value_loss: 0.00482 action_loss: 19.97895\n",
      "update_step:  45 model loss: 3.02228, kl_loss: 3.00009, obs_loss: 0.02218, reward_loss: 0.00001, value_loss: 0.00521 action_loss: 19.94246\n",
      "update_step:  46 model loss: 3.01518, kl_loss: 3.00031, obs_loss: 0.01487, reward_loss: 0.00001, value_loss: 0.00501 action_loss: 19.94625\n",
      "update_step:  47 model loss: 3.01466, kl_loss: 3.00032, obs_loss: 0.01434, reward_loss: 0.00001, value_loss: 0.00447 action_loss: 19.95281\n",
      "update_step:  48 model loss: 3.00951, kl_loss: 3.00027, obs_loss: 0.00923, reward_loss: 0.00001, value_loss: 0.00422 action_loss: 19.98556\n",
      "update_step:  49 model loss: 3.00895, kl_loss: 3.00035, obs_loss: 0.00859, reward_loss: 0.00001, value_loss: 0.00451 action_loss: 20.02154\n",
      "update_step:  50 model loss: 3.01821, kl_loss: 3.00116, obs_loss: 0.01704, reward_loss: 0.00001, value_loss: 0.00439 action_loss: 20.02215\n",
      "update_step:  51 model loss: 3.00959, kl_loss: 3.00001, obs_loss: 0.00957, reward_loss: 0.00001, value_loss: 0.00426 action_loss: 20.03635\n",
      "update_step:  52 model loss: 3.01309, kl_loss: 3.00005, obs_loss: 0.01304, reward_loss: 0.00001, value_loss: 0.00422 action_loss: 20.00714\n",
      "update_step:  53 model loss: 3.00877, kl_loss: 3.00027, obs_loss: 0.00850, reward_loss: 0.00001, value_loss: 0.00410 action_loss: 19.96814\n",
      "update_step:  54 model loss: 3.00902, kl_loss: 3.00067, obs_loss: 0.00835, reward_loss: 0.00001, value_loss: 0.00415 action_loss: 19.96626\n",
      "update_step:  55 model loss: 3.01190, kl_loss: 3.00050, obs_loss: 0.01140, reward_loss: 0.00000, value_loss: 0.00429 action_loss: 19.98570\n",
      "update_step:  56 model loss: 3.01074, kl_loss: 3.00044, obs_loss: 0.01030, reward_loss: 0.00001, value_loss: 0.00392 action_loss: 20.03147\n",
      "update_step:  57 model loss: 3.01469, kl_loss: 3.00014, obs_loss: 0.01454, reward_loss: 0.00000, value_loss: 0.00417 action_loss: 20.03766\n",
      "update_step:  58 model loss: 3.02502, kl_loss: 3.00061, obs_loss: 0.02440, reward_loss: 0.00001, value_loss: 0.00425 action_loss: 20.07769\n",
      "update_step:  59 model loss: 3.01398, kl_loss: 3.00002, obs_loss: 0.01395, reward_loss: 0.00001, value_loss: 0.00425 action_loss: 20.07950\n",
      "update_step:  60 model loss: 3.00706, kl_loss: 3.00011, obs_loss: 0.00694, reward_loss: 0.00001, value_loss: 0.00415 action_loss: 20.05482\n",
      "update_step:  61 model loss: 3.00714, kl_loss: 3.00075, obs_loss: 0.00638, reward_loss: 0.00001, value_loss: 0.00401 action_loss: 20.02592\n",
      "update_step:  62 model loss: 3.00639, kl_loss: 3.00075, obs_loss: 0.00563, reward_loss: 0.00000, value_loss: 0.00427 action_loss: 20.00327\n",
      "update_step:  63 model loss: 3.01697, kl_loss: 3.00155, obs_loss: 0.01541, reward_loss: 0.00001, value_loss: 0.00382 action_loss: 19.98709\n",
      "update_step:  64 model loss: 3.01652, kl_loss: 3.00185, obs_loss: 0.01467, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 19.98197\n",
      "update_step:  65 model loss: 3.00838, kl_loss: 3.00047, obs_loss: 0.00790, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 20.02217\n",
      "update_step:  66 model loss: 3.00826, kl_loss: 3.00031, obs_loss: 0.00794, reward_loss: 0.00001, value_loss: 0.00387 action_loss: 20.04100\n",
      "update_step:  67 model loss: 3.00687, kl_loss: 3.00028, obs_loss: 0.00658, reward_loss: 0.00000, value_loss: 0.00457 action_loss: 20.06245\n",
      "update_step:  68 model loss: 3.00584, kl_loss: 3.00017, obs_loss: 0.00566, reward_loss: 0.00001, value_loss: 0.00410 action_loss: 20.06420\n",
      "update_step:  69 model loss: 3.00942, kl_loss: 3.00027, obs_loss: 0.00914, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 20.06117\n",
      "update_step:  70 model loss: 3.00462, kl_loss: 3.00003, obs_loss: 0.00458, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 20.01839\n",
      "update_step:  71 model loss: 3.00461, kl_loss: 3.00015, obs_loss: 0.00445, reward_loss: 0.00001, value_loss: 0.00382 action_loss: 19.96559\n",
      "update_step:  72 model loss: 3.00325, kl_loss: 3.00017, obs_loss: 0.00307, reward_loss: 0.00001, value_loss: 0.00424 action_loss: 19.95111\n",
      "update_step:  73 model loss: 3.01042, kl_loss: 3.00037, obs_loss: 0.01004, reward_loss: 0.00001, value_loss: 0.00411 action_loss: 19.93446\n",
      "update_step:  74 model loss: 3.00806, kl_loss: 3.00055, obs_loss: 0.00751, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 19.95118\n",
      "update_step:  75 model loss: 3.02296, kl_loss: 3.00232, obs_loss: 0.02064, reward_loss: 0.00001, value_loss: 0.00383 action_loss: 19.97730\n",
      "update_step:  76 model loss: 3.00713, kl_loss: 3.00073, obs_loss: 0.00640, reward_loss: 0.00000, value_loss: 0.00382 action_loss: 20.02081\n",
      "update_step:  77 model loss: 3.00685, kl_loss: 3.00106, obs_loss: 0.00578, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 20.02120\n",
      "update_step:  78 model loss: 3.00531, kl_loss: 3.00070, obs_loss: 0.00461, reward_loss: 0.00001, value_loss: 0.00379 action_loss: 20.02595\n",
      "update_step:  79 model loss: 3.00443, kl_loss: 3.00029, obs_loss: 0.00414, reward_loss: 0.00000, value_loss: 0.00369 action_loss: 19.99494\n",
      "update_step:  80 model loss: 3.00248, kl_loss: 3.00000, obs_loss: 0.00247, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 19.96771\n",
      "update_step:  81 model loss: 3.00339, kl_loss: 3.00007, obs_loss: 0.00332, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 19.95807\n",
      "update_step:  82 model loss: 3.00510, kl_loss: 3.00009, obs_loss: 0.00500, reward_loss: 0.00000, value_loss: 0.00395 action_loss: 19.96285\n",
      "update_step:  83 model loss: 3.00394, kl_loss: 3.00000, obs_loss: 0.00394, reward_loss: 0.00000, value_loss: 0.00369 action_loss: 19.98932\n",
      "update_step:  84 model loss: 3.00482, kl_loss: 3.00000, obs_loss: 0.00482, reward_loss: 0.00000, value_loss: 0.00366 action_loss: 20.01477\n",
      "update_step:  85 model loss: 3.00702, kl_loss: 3.00026, obs_loss: 0.00675, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 20.05137\n",
      "update_step:  86 model loss: 3.01047, kl_loss: 3.00062, obs_loss: 0.00984, reward_loss: 0.00001, value_loss: 0.00396 action_loss: 20.04965\n",
      "update_step:  87 model loss: 3.00888, kl_loss: 3.00012, obs_loss: 0.00876, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 20.06050\n",
      "update_step:  88 model loss: 3.00905, kl_loss: 3.00050, obs_loss: 0.00854, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 20.03941\n",
      "update_step:  89 model loss: 3.01241, kl_loss: 3.00106, obs_loss: 0.01135, reward_loss: 0.00000, value_loss: 0.00354 action_loss: 20.02748\n",
      "update_step:  90 model loss: 3.01042, kl_loss: 3.00057, obs_loss: 0.00985, reward_loss: 0.00000, value_loss: 0.00364 action_loss: 20.00720\n",
      "update_step:  91 model loss: 3.00976, kl_loss: 3.00058, obs_loss: 0.00918, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 20.02380\n",
      "update_step:  92 model loss: 3.01189, kl_loss: 3.00038, obs_loss: 0.01150, reward_loss: 0.00001, value_loss: 0.00362 action_loss: 20.00993\n",
      "update_step:  93 model loss: 3.01089, kl_loss: 3.00000, obs_loss: 0.01089, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 20.02086\n",
      "update_step:  94 model loss: 3.01587, kl_loss: 3.00054, obs_loss: 0.01533, reward_loss: 0.00000, value_loss: 0.00361 action_loss: 20.01012\n",
      "update_step:  95 model loss: 3.01414, kl_loss: 3.00008, obs_loss: 0.01405, reward_loss: 0.00000, value_loss: 0.00352 action_loss: 20.01565\n",
      "update_step:  96 model loss: 3.01375, kl_loss: 3.00001, obs_loss: 0.01374, reward_loss: 0.00001, value_loss: 0.00363 action_loss: 19.98963\n",
      "update_step:  97 model loss: 3.01398, kl_loss: 3.00005, obs_loss: 0.01392, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 19.98372\n",
      "update_step:  98 model loss: 3.01634, kl_loss: 3.00100, obs_loss: 0.01533, reward_loss: 0.00000, value_loss: 0.00368 action_loss: 19.97211\n",
      "update_step:  99 model loss: 3.01999, kl_loss: 3.00056, obs_loss: 0.01943, reward_loss: 0.00000, value_loss: 0.00350 action_loss: 19.97805\n",
      "update_step: 100 model loss: 3.01584, kl_loss: 3.00018, obs_loss: 0.01566, reward_loss: 0.00000, value_loss: 0.00351 action_loss: 19.98903\n",
      "elasped time for update: 20.29s\n",
      "episode [  40/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.02198, kl_loss: 3.00067, obs_loss: 0.02131, reward_loss: 0.00000, value_loss: 0.00350 action_loss: 19.98896\n",
      "update_step:   2 model loss: 3.03216, kl_loss: 3.00061, obs_loss: 0.03154, reward_loss: 0.00000, value_loss: 0.00346 action_loss: 20.00794\n",
      "update_step:   3 model loss: 3.03089, kl_loss: 3.00057, obs_loss: 0.03032, reward_loss: 0.00001, value_loss: 0.00347 action_loss: 19.98498\n",
      "update_step:   4 model loss: 3.03684, kl_loss: 3.00109, obs_loss: 0.03575, reward_loss: 0.00000, value_loss: 0.00341 action_loss: 19.96806\n",
      "update_step:   5 model loss: 3.03422, kl_loss: 3.00147, obs_loss: 0.03274, reward_loss: 0.00000, value_loss: 0.00366 action_loss: 19.93258\n",
      "update_step:   6 model loss: 3.03279, kl_loss: 3.00140, obs_loss: 0.03138, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 19.93632\n",
      "update_step:   7 model loss: 3.02833, kl_loss: 3.00045, obs_loss: 0.02787, reward_loss: 0.00001, value_loss: 0.00350 action_loss: 19.93556\n",
      "update_step:   8 model loss: 3.02463, kl_loss: 3.00027, obs_loss: 0.02435, reward_loss: 0.00001, value_loss: 0.00335 action_loss: 19.96978\n",
      "update_step:   9 model loss: 3.03723, kl_loss: 3.00113, obs_loss: 0.03610, reward_loss: 0.00001, value_loss: 0.00350 action_loss: 20.01213\n",
      "update_step:  10 model loss: 3.01663, kl_loss: 3.00082, obs_loss: 0.01580, reward_loss: 0.00001, value_loss: 0.00386 action_loss: 20.03821\n",
      "update_step:  11 model loss: 3.00880, kl_loss: 3.00028, obs_loss: 0.00852, reward_loss: 0.00001, value_loss: 0.00377 action_loss: 20.05264\n",
      "update_step:  12 model loss: 3.00954, kl_loss: 3.00053, obs_loss: 0.00901, reward_loss: 0.00000, value_loss: 0.00360 action_loss: 20.03757\n",
      "update_step:  13 model loss: 3.01462, kl_loss: 3.00114, obs_loss: 0.01349, reward_loss: 0.00000, value_loss: 0.00371 action_loss: 20.02195\n",
      "update_step:  14 model loss: 3.02094, kl_loss: 3.00112, obs_loss: 0.01982, reward_loss: 0.00000, value_loss: 0.00344 action_loss: 19.98421\n",
      "update_step:  15 model loss: 3.02736, kl_loss: 3.00099, obs_loss: 0.02636, reward_loss: 0.00001, value_loss: 0.00349 action_loss: 19.99926\n",
      "update_step:  16 model loss: 3.03823, kl_loss: 3.00054, obs_loss: 0.03768, reward_loss: 0.00001, value_loss: 0.00340 action_loss: 19.98704\n",
      "update_step:  17 model loss: 3.04094, kl_loss: 3.00059, obs_loss: 0.04034, reward_loss: 0.00000, value_loss: 0.00357 action_loss: 20.02004\n",
      "update_step:  18 model loss: 3.06139, kl_loss: 3.00138, obs_loss: 0.06001, reward_loss: 0.00000, value_loss: 0.00342 action_loss: 20.00450\n",
      "update_step:  19 model loss: 3.06096, kl_loss: 3.00068, obs_loss: 0.06027, reward_loss: 0.00001, value_loss: 0.00352 action_loss: 20.02190\n",
      "update_step:  20 model loss: 3.06204, kl_loss: 3.00063, obs_loss: 0.06140, reward_loss: 0.00001, value_loss: 0.00351 action_loss: 20.00874\n",
      "update_step:  21 model loss: 3.05849, kl_loss: 3.00040, obs_loss: 0.05809, reward_loss: 0.00001, value_loss: 0.00347 action_loss: 19.99497\n",
      "update_step:  22 model loss: 3.04470, kl_loss: 3.00000, obs_loss: 0.04469, reward_loss: 0.00001, value_loss: 0.00351 action_loss: 19.96840\n",
      "update_step:  23 model loss: 3.03625, kl_loss: 3.00004, obs_loss: 0.03620, reward_loss: 0.00000, value_loss: 0.00372 action_loss: 19.95082\n",
      "update_step:  24 model loss: 3.02744, kl_loss: 3.00004, obs_loss: 0.02739, reward_loss: 0.00001, value_loss: 0.00340 action_loss: 19.95302\n",
      "update_step:  25 model loss: 3.02317, kl_loss: 3.00046, obs_loss: 0.02271, reward_loss: 0.00000, value_loss: 0.00341 action_loss: 19.95802\n",
      "update_step:  26 model loss: 3.01567, kl_loss: 3.00056, obs_loss: 0.01510, reward_loss: 0.00001, value_loss: 0.00346 action_loss: 20.02611\n",
      "update_step:  27 model loss: 3.01493, kl_loss: 3.00025, obs_loss: 0.01468, reward_loss: 0.00001, value_loss: 0.00369 action_loss: 20.02712\n",
      "update_step:  28 model loss: 3.01314, kl_loss: 3.00000, obs_loss: 0.01313, reward_loss: 0.00000, value_loss: 0.00392 action_loss: 20.03626\n",
      "update_step:  29 model loss: 3.01678, kl_loss: 3.00019, obs_loss: 0.01658, reward_loss: 0.00001, value_loss: 0.00346 action_loss: 20.00893\n",
      "update_step:  30 model loss: 3.01746, kl_loss: 3.00005, obs_loss: 0.01740, reward_loss: 0.00000, value_loss: 0.00357 action_loss: 19.99786\n",
      "update_step:  31 model loss: 3.01941, kl_loss: 3.00045, obs_loss: 0.01896, reward_loss: 0.00001, value_loss: 0.00344 action_loss: 19.96198\n",
      "update_step:  32 model loss: 3.01649, kl_loss: 3.00086, obs_loss: 0.01562, reward_loss: 0.00001, value_loss: 0.00374 action_loss: 19.95517\n",
      "update_step:  33 model loss: 3.01345, kl_loss: 3.00054, obs_loss: 0.01291, reward_loss: 0.00000, value_loss: 0.00363 action_loss: 19.97434\n",
      "update_step:  34 model loss: 3.01935, kl_loss: 3.00087, obs_loss: 0.01847, reward_loss: 0.00001, value_loss: 0.00353 action_loss: 19.96291\n",
      "update_step:  35 model loss: 3.02550, kl_loss: 3.00082, obs_loss: 0.02467, reward_loss: 0.00001, value_loss: 0.00358 action_loss: 20.00224\n",
      "update_step:  36 model loss: 3.04327, kl_loss: 3.00078, obs_loss: 0.04248, reward_loss: 0.00000, value_loss: 0.00355 action_loss: 19.98369\n",
      "update_step:  37 model loss: 3.05272, kl_loss: 3.00082, obs_loss: 0.05189, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 20.01599\n",
      "update_step:  38 model loss: 3.04624, kl_loss: 3.00016, obs_loss: 0.04608, reward_loss: 0.00001, value_loss: 0.00388 action_loss: 19.98457\n",
      "update_step:  39 model loss: 3.04385, kl_loss: 3.00004, obs_loss: 0.04380, reward_loss: 0.00001, value_loss: 0.00374 action_loss: 20.04833\n",
      "update_step:  40 model loss: 3.02964, kl_loss: 3.00023, obs_loss: 0.02940, reward_loss: 0.00001, value_loss: 0.00338 action_loss: 20.01901\n",
      "update_step:  41 model loss: 3.02268, kl_loss: 3.00045, obs_loss: 0.02222, reward_loss: 0.00001, value_loss: 0.00358 action_loss: 19.97978\n",
      "update_step:  42 model loss: 3.01024, kl_loss: 3.00069, obs_loss: 0.00954, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 19.96285\n",
      "update_step:  43 model loss: 3.02575, kl_loss: 3.00008, obs_loss: 0.02566, reward_loss: 0.00001, value_loss: 0.00448 action_loss: 19.91270\n",
      "update_step:  44 model loss: 3.05554, kl_loss: 3.00047, obs_loss: 0.05506, reward_loss: 0.00000, value_loss: 0.00396 action_loss: 19.95461\n",
      "update_step:  45 model loss: 3.08968, kl_loss: 3.00023, obs_loss: 0.08945, reward_loss: 0.00001, value_loss: 0.00388 action_loss: 19.91943\n",
      "update_step:  46 model loss: 3.11640, kl_loss: 3.00003, obs_loss: 0.11636, reward_loss: 0.00001, value_loss: 0.00370 action_loss: 20.01782\n",
      "update_step:  47 model loss: 3.10322, kl_loss: 3.00031, obs_loss: 0.10289, reward_loss: 0.00002, value_loss: 0.00430 action_loss: 19.99566\n",
      "update_step:  48 model loss: 3.08305, kl_loss: 3.00005, obs_loss: 0.08299, reward_loss: 0.00001, value_loss: 0.00575 action_loss: 20.10788\n",
      "update_step:  49 model loss: 3.04473, kl_loss: 3.00008, obs_loss: 0.04464, reward_loss: 0.00001, value_loss: 0.00518 action_loss: 20.08486\n",
      "update_step:  50 model loss: 3.02561, kl_loss: 3.00015, obs_loss: 0.02545, reward_loss: 0.00001, value_loss: 0.00442 action_loss: 20.05304\n",
      "update_step:  51 model loss: 3.01705, kl_loss: 3.00001, obs_loss: 0.01703, reward_loss: 0.00001, value_loss: 0.00409 action_loss: 19.99295\n",
      "update_step:  52 model loss: 3.02733, kl_loss: 3.00056, obs_loss: 0.02677, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 19.91864\n",
      "update_step:  53 model loss: 3.02969, kl_loss: 3.00079, obs_loss: 0.02890, reward_loss: 0.00001, value_loss: 0.00513 action_loss: 19.94624\n",
      "update_step:  54 model loss: 3.04333, kl_loss: 3.00109, obs_loss: 0.04222, reward_loss: 0.00001, value_loss: 0.00419 action_loss: 19.94130\n",
      "update_step:  55 model loss: 3.03164, kl_loss: 3.00007, obs_loss: 0.03156, reward_loss: 0.00001, value_loss: 0.00406 action_loss: 20.00258\n",
      "update_step:  56 model loss: 3.02593, kl_loss: 3.00053, obs_loss: 0.02539, reward_loss: 0.00001, value_loss: 0.00418 action_loss: 19.98377\n",
      "update_step:  57 model loss: 3.01256, kl_loss: 3.00050, obs_loss: 0.01205, reward_loss: 0.00001, value_loss: 0.00415 action_loss: 19.99200\n",
      "update_step:  58 model loss: 3.00862, kl_loss: 3.00007, obs_loss: 0.00854, reward_loss: 0.00001, value_loss: 0.00420 action_loss: 20.00902\n",
      "update_step:  59 model loss: 3.01587, kl_loss: 3.00002, obs_loss: 0.01584, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 20.01790\n",
      "update_step:  60 model loss: 3.03211, kl_loss: 3.00028, obs_loss: 0.03182, reward_loss: 0.00001, value_loss: 0.00441 action_loss: 20.06219\n",
      "update_step:  61 model loss: 3.02496, kl_loss: 3.00047, obs_loss: 0.02449, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 20.04437\n",
      "update_step:  62 model loss: 3.01515, kl_loss: 3.00036, obs_loss: 0.01479, reward_loss: 0.00001, value_loss: 0.00435 action_loss: 20.05624\n",
      "update_step:  63 model loss: 3.01446, kl_loss: 3.00158, obs_loss: 0.01288, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 20.02427\n",
      "update_step:  64 model loss: 3.00934, kl_loss: 3.00224, obs_loss: 0.00710, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 19.98805\n",
      "update_step:  65 model loss: 3.01494, kl_loss: 3.00252, obs_loss: 0.01241, reward_loss: 0.00001, value_loss: 0.00457 action_loss: 19.99469\n",
      "update_step:  66 model loss: 3.02327, kl_loss: 3.00201, obs_loss: 0.02125, reward_loss: 0.00001, value_loss: 0.00409 action_loss: 19.99670\n",
      "update_step:  67 model loss: 3.02167, kl_loss: 3.00084, obs_loss: 0.02082, reward_loss: 0.00001, value_loss: 0.00420 action_loss: 20.05211\n",
      "update_step:  68 model loss: 3.01605, kl_loss: 3.00009, obs_loss: 0.01595, reward_loss: 0.00001, value_loss: 0.00480 action_loss: 20.08984\n",
      "update_step:  69 model loss: 3.00934, kl_loss: 3.00000, obs_loss: 0.00933, reward_loss: 0.00001, value_loss: 0.00488 action_loss: 20.10778\n",
      "update_step:  70 model loss: 3.00978, kl_loss: 3.00009, obs_loss: 0.00968, reward_loss: 0.00001, value_loss: 0.00484 action_loss: 20.10191\n",
      "update_step:  71 model loss: 3.02569, kl_loss: 3.00017, obs_loss: 0.02551, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 20.02634\n",
      "update_step:  72 model loss: 3.03881, kl_loss: 3.00000, obs_loss: 0.03880, reward_loss: 0.00001, value_loss: 0.00411 action_loss: 19.99389\n",
      "update_step:  73 model loss: 3.04825, kl_loss: 3.00060, obs_loss: 0.04765, reward_loss: 0.00001, value_loss: 0.00527 action_loss: 19.91002\n",
      "update_step:  74 model loss: 3.02412, kl_loss: 3.00004, obs_loss: 0.02407, reward_loss: 0.00001, value_loss: 0.00511 action_loss: 19.89810\n",
      "update_step:  75 model loss: 3.01915, kl_loss: 3.00018, obs_loss: 0.01897, reward_loss: 0.00001, value_loss: 0.00471 action_loss: 19.91641\n",
      "update_step:  76 model loss: 3.01116, kl_loss: 3.00074, obs_loss: 0.01041, reward_loss: 0.00001, value_loss: 0.00386 action_loss: 19.94628\n",
      "update_step:  77 model loss: 3.02208, kl_loss: 3.00259, obs_loss: 0.01948, reward_loss: 0.00001, value_loss: 0.00411 action_loss: 20.03722\n",
      "update_step:  78 model loss: 3.02853, kl_loss: 3.00506, obs_loss: 0.02346, reward_loss: 0.00000, value_loss: 0.00563 action_loss: 20.06730\n",
      "update_step:  79 model loss: 3.02359, kl_loss: 3.00239, obs_loss: 0.02119, reward_loss: 0.00001, value_loss: 0.00482 action_loss: 20.08824\n",
      "update_step:  80 model loss: 3.01550, kl_loss: 3.00204, obs_loss: 0.01345, reward_loss: 0.00001, value_loss: 0.00388 action_loss: 20.03219\n",
      "update_step:  81 model loss: 3.01426, kl_loss: 3.00105, obs_loss: 0.01320, reward_loss: 0.00000, value_loss: 0.00363 action_loss: 19.96466\n",
      "update_step:  82 model loss: 3.00586, kl_loss: 3.00007, obs_loss: 0.00579, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 19.92681\n",
      "update_step:  83 model loss: 3.01170, kl_loss: 3.00000, obs_loss: 0.01169, reward_loss: 0.00001, value_loss: 0.00499 action_loss: 19.90918\n",
      "update_step:  84 model loss: 3.01509, kl_loss: 3.00000, obs_loss: 0.01508, reward_loss: 0.00001, value_loss: 0.00421 action_loss: 19.95933\n",
      "update_step:  85 model loss: 3.01525, kl_loss: 3.00000, obs_loss: 0.01524, reward_loss: 0.00001, value_loss: 0.00372 action_loss: 19.98429\n",
      "update_step:  86 model loss: 3.01350, kl_loss: 3.00000, obs_loss: 0.01349, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 20.04938\n",
      "update_step:  87 model loss: 3.01057, kl_loss: 3.00000, obs_loss: 0.01056, reward_loss: 0.00001, value_loss: 0.00412 action_loss: 20.08335\n",
      "update_step:  88 model loss: 3.00394, kl_loss: 3.00000, obs_loss: 0.00394, reward_loss: 0.00001, value_loss: 0.00443 action_loss: 20.07411\n",
      "update_step:  89 model loss: 3.00544, kl_loss: 3.00000, obs_loss: 0.00544, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 20.04678\n",
      "update_step:  90 model loss: 3.01334, kl_loss: 3.00026, obs_loss: 0.01307, reward_loss: 0.00001, value_loss: 0.00358 action_loss: 20.00268\n",
      "update_step:  91 model loss: 3.00900, kl_loss: 3.00041, obs_loss: 0.00858, reward_loss: 0.00001, value_loss: 0.00392 action_loss: 19.97223\n",
      "update_step:  92 model loss: 3.00897, kl_loss: 3.00061, obs_loss: 0.00836, reward_loss: 0.00001, value_loss: 0.00411 action_loss: 19.90979\n",
      "update_step:  93 model loss: 3.00522, kl_loss: 3.00115, obs_loss: 0.00407, reward_loss: 0.00001, value_loss: 0.00420 action_loss: 19.92551\n",
      "update_step:  94 model loss: 3.01447, kl_loss: 3.00214, obs_loss: 0.01232, reward_loss: 0.00001, value_loss: 0.00365 action_loss: 19.96332\n",
      "update_step:  95 model loss: 3.00483, kl_loss: 3.00122, obs_loss: 0.00361, reward_loss: 0.00001, value_loss: 0.00409 action_loss: 20.00518\n",
      "update_step:  96 model loss: 3.00412, kl_loss: 3.00034, obs_loss: 0.00378, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 20.03991\n",
      "update_step:  97 model loss: 3.00638, kl_loss: 3.00044, obs_loss: 0.00594, reward_loss: 0.00000, value_loss: 0.00398 action_loss: 20.03466\n",
      "update_step:  98 model loss: 3.00817, kl_loss: 3.00018, obs_loss: 0.00798, reward_loss: 0.00001, value_loss: 0.00368 action_loss: 19.99680\n",
      "update_step:  99 model loss: 3.00346, kl_loss: 3.00000, obs_loss: 0.00345, reward_loss: 0.00000, value_loss: 0.00364 action_loss: 19.94847\n",
      "update_step: 100 model loss: 3.00305, kl_loss: 3.00010, obs_loss: 0.00295, reward_loss: 0.00000, value_loss: 0.00419 action_loss: 19.91984\n",
      "elasped time for update: 21.18s\n",
      "Total test reward at episode [  40/ 100] is -2.000000\n",
      "elasped time for test: 0.05s\n",
      "episode [  41/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.36s\n",
      "update_step:   1 model loss: 3.00300, kl_loss: 3.00000, obs_loss: 0.00300, reward_loss: 0.00001, value_loss: 0.00428 action_loss: 19.93298\n",
      "update_step:   2 model loss: 3.00678, kl_loss: 3.00018, obs_loss: 0.00660, reward_loss: 0.00001, value_loss: 0.00356 action_loss: 19.96154\n",
      "update_step:   3 model loss: 3.00553, kl_loss: 3.00019, obs_loss: 0.00534, reward_loss: 0.00001, value_loss: 0.00359 action_loss: 20.01648\n",
      "update_step:   4 model loss: 3.00676, kl_loss: 3.00026, obs_loss: 0.00649, reward_loss: 0.00000, value_loss: 0.00355 action_loss: 20.04328\n",
      "update_step:   5 model loss: 3.00957, kl_loss: 3.00046, obs_loss: 0.00911, reward_loss: 0.00000, value_loss: 0.00383 action_loss: 20.05649\n",
      "update_step:   6 model loss: 3.00419, kl_loss: 3.00064, obs_loss: 0.00355, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 20.03613\n",
      "update_step:   7 model loss: 3.01462, kl_loss: 3.00154, obs_loss: 0.01308, reward_loss: 0.00000, value_loss: 0.00360 action_loss: 20.00997\n",
      "update_step:   8 model loss: 3.00556, kl_loss: 3.00087, obs_loss: 0.00469, reward_loss: 0.00000, value_loss: 0.00365 action_loss: 19.99289\n",
      "update_step:   9 model loss: 3.00407, kl_loss: 3.00047, obs_loss: 0.00359, reward_loss: 0.00000, value_loss: 0.00362 action_loss: 19.98693\n",
      "update_step:  10 model loss: 3.01378, kl_loss: 3.00086, obs_loss: 0.01292, reward_loss: 0.00000, value_loss: 0.00367 action_loss: 19.99566\n",
      "update_step:  11 model loss: 3.00516, kl_loss: 3.00050, obs_loss: 0.00466, reward_loss: 0.00000, value_loss: 0.00346 action_loss: 20.01366\n",
      "update_step:  12 model loss: 3.00350, kl_loss: 3.00026, obs_loss: 0.00324, reward_loss: 0.00000, value_loss: 0.00354 action_loss: 20.02633\n",
      "update_step:  13 model loss: 3.01277, kl_loss: 3.00076, obs_loss: 0.01201, reward_loss: 0.00000, value_loss: 0.00360 action_loss: 20.03489\n",
      "update_step:  14 model loss: 3.00421, kl_loss: 3.00067, obs_loss: 0.00354, reward_loss: 0.00000, value_loss: 0.00351 action_loss: 20.02816\n",
      "update_step:  15 model loss: 3.01734, kl_loss: 3.00160, obs_loss: 0.01574, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 20.02608\n",
      "update_step:  16 model loss: 3.00687, kl_loss: 3.00067, obs_loss: 0.00619, reward_loss: 0.00000, value_loss: 0.00351 action_loss: 20.00451\n",
      "update_step:  17 model loss: 3.00899, kl_loss: 3.00137, obs_loss: 0.00761, reward_loss: 0.00001, value_loss: 0.00347 action_loss: 20.00851\n",
      "update_step:  18 model loss: 3.00510, kl_loss: 3.00089, obs_loss: 0.00421, reward_loss: 0.00000, value_loss: 0.00345 action_loss: 19.99260\n",
      "update_step:  19 model loss: 3.00386, kl_loss: 3.00024, obs_loss: 0.00361, reward_loss: 0.00000, value_loss: 0.00337 action_loss: 19.98313\n",
      "update_step:  20 model loss: 3.00964, kl_loss: 3.00077, obs_loss: 0.00886, reward_loss: 0.00000, value_loss: 0.00348 action_loss: 19.97655\n",
      "update_step:  21 model loss: 3.00785, kl_loss: 3.00038, obs_loss: 0.00747, reward_loss: 0.00000, value_loss: 0.00339 action_loss: 19.98050\n",
      "update_step:  22 model loss: 3.01417, kl_loss: 3.00185, obs_loss: 0.01231, reward_loss: 0.00000, value_loss: 0.00332 action_loss: 19.99800\n",
      "update_step:  23 model loss: 3.01310, kl_loss: 3.00090, obs_loss: 0.01220, reward_loss: 0.00000, value_loss: 0.00343 action_loss: 20.00504\n",
      "update_step:  24 model loss: 3.00615, kl_loss: 3.00012, obs_loss: 0.00602, reward_loss: 0.00000, value_loss: 0.00336 action_loss: 20.01928\n",
      "update_step:  25 model loss: 3.00876, kl_loss: 3.00048, obs_loss: 0.00828, reward_loss: 0.00000, value_loss: 0.00336 action_loss: 20.02280\n",
      "update_step:  26 model loss: 3.00805, kl_loss: 3.00007, obs_loss: 0.00798, reward_loss: 0.00000, value_loss: 0.00338 action_loss: 20.01760\n",
      "update_step:  27 model loss: 3.00233, kl_loss: 3.00000, obs_loss: 0.00233, reward_loss: 0.00000, value_loss: 0.00330 action_loss: 19.99847\n",
      "update_step:  28 model loss: 3.00259, kl_loss: 3.00000, obs_loss: 0.00259, reward_loss: 0.00000, value_loss: 0.00344 action_loss: 19.98410\n",
      "update_step:  29 model loss: 3.00174, kl_loss: 3.00005, obs_loss: 0.00168, reward_loss: 0.00001, value_loss: 0.00337 action_loss: 19.96315\n",
      "update_step:  30 model loss: 3.00521, kl_loss: 3.00017, obs_loss: 0.00504, reward_loss: 0.00000, value_loss: 0.00338 action_loss: 19.95613\n",
      "update_step:  31 model loss: 3.00306, kl_loss: 3.00026, obs_loss: 0.00279, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 19.97460\n",
      "update_step:  32 model loss: 3.00331, kl_loss: 3.00044, obs_loss: 0.00287, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 19.99824\n",
      "update_step:  33 model loss: 3.00668, kl_loss: 3.00084, obs_loss: 0.00584, reward_loss: 0.00000, value_loss: 0.00344 action_loss: 20.01136\n",
      "update_step:  34 model loss: 3.00726, kl_loss: 3.00103, obs_loss: 0.00623, reward_loss: 0.00000, value_loss: 0.00340 action_loss: 20.02101\n",
      "update_step:  35 model loss: 3.01167, kl_loss: 3.00143, obs_loss: 0.01023, reward_loss: 0.00000, value_loss: 0.00331 action_loss: 20.01032\n",
      "update_step:  36 model loss: 3.00470, kl_loss: 3.00011, obs_loss: 0.00458, reward_loss: 0.00000, value_loss: 0.00317 action_loss: 19.99533\n",
      "update_step:  37 model loss: 3.01115, kl_loss: 3.00044, obs_loss: 0.01071, reward_loss: 0.00000, value_loss: 0.00333 action_loss: 19.97391\n",
      "update_step:  38 model loss: 3.00514, kl_loss: 3.00008, obs_loss: 0.00505, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 19.97395\n",
      "update_step:  39 model loss: 3.00577, kl_loss: 3.00040, obs_loss: 0.00536, reward_loss: 0.00000, value_loss: 0.00338 action_loss: 19.97912\n",
      "update_step:  40 model loss: 3.00551, kl_loss: 3.00004, obs_loss: 0.00546, reward_loss: 0.00000, value_loss: 0.00341 action_loss: 20.00306\n",
      "update_step:  41 model loss: 3.00787, kl_loss: 3.00015, obs_loss: 0.00772, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 20.00690\n",
      "update_step:  42 model loss: 3.01028, kl_loss: 3.00005, obs_loss: 0.01022, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 20.02884\n",
      "update_step:  43 model loss: 3.01820, kl_loss: 3.00079, obs_loss: 0.01741, reward_loss: 0.00000, value_loss: 0.00342 action_loss: 20.01362\n",
      "update_step:  44 model loss: 3.01634, kl_loss: 3.00081, obs_loss: 0.01553, reward_loss: 0.00001, value_loss: 0.00331 action_loss: 20.02311\n",
      "update_step:  45 model loss: 3.02080, kl_loss: 3.00106, obs_loss: 0.01974, reward_loss: 0.00001, value_loss: 0.00331 action_loss: 19.98554\n",
      "update_step:  46 model loss: 3.01870, kl_loss: 3.00071, obs_loss: 0.01798, reward_loss: 0.00000, value_loss: 0.00340 action_loss: 19.99183\n",
      "update_step:  47 model loss: 3.02341, kl_loss: 3.00049, obs_loss: 0.02291, reward_loss: 0.00000, value_loss: 0.00332 action_loss: 19.97828\n",
      "update_step:  48 model loss: 3.02888, kl_loss: 3.00019, obs_loss: 0.02868, reward_loss: 0.00000, value_loss: 0.00341 action_loss: 20.01047\n",
      "update_step:  49 model loss: 3.03208, kl_loss: 3.00026, obs_loss: 0.03181, reward_loss: 0.00001, value_loss: 0.00339 action_loss: 19.98711\n",
      "update_step:  50 model loss: 3.03946, kl_loss: 3.00005, obs_loss: 0.03940, reward_loss: 0.00001, value_loss: 0.00336 action_loss: 20.00110\n",
      "update_step:  51 model loss: 3.04933, kl_loss: 3.00011, obs_loss: 0.04922, reward_loss: 0.00000, value_loss: 0.00348 action_loss: 19.97167\n",
      "update_step:  52 model loss: 3.07096, kl_loss: 3.00026, obs_loss: 0.07069, reward_loss: 0.00000, value_loss: 0.00355 action_loss: 19.98230\n",
      "update_step:  53 model loss: 3.07171, kl_loss: 3.00021, obs_loss: 0.07149, reward_loss: 0.00001, value_loss: 0.00354 action_loss: 19.96074\n",
      "update_step:  54 model loss: 3.08185, kl_loss: 3.00120, obs_loss: 0.08064, reward_loss: 0.00001, value_loss: 0.00342 action_loss: 20.01045\n",
      "update_step:  55 model loss: 3.08372, kl_loss: 3.00069, obs_loss: 0.08303, reward_loss: 0.00000, value_loss: 0.00336 action_loss: 20.03346\n",
      "update_step:  56 model loss: 3.07907, kl_loss: 3.00115, obs_loss: 0.07792, reward_loss: 0.00000, value_loss: 0.00374 action_loss: 20.08143\n",
      "update_step:  57 model loss: 3.06190, kl_loss: 3.00068, obs_loss: 0.06122, reward_loss: 0.00000, value_loss: 0.00366 action_loss: 20.06995\n",
      "update_step:  58 model loss: 3.04898, kl_loss: 3.00035, obs_loss: 0.04862, reward_loss: 0.00001, value_loss: 0.00371 action_loss: 20.08597\n",
      "update_step:  59 model loss: 3.02737, kl_loss: 3.00000, obs_loss: 0.02736, reward_loss: 0.00001, value_loss: 0.00343 action_loss: 20.03504\n",
      "update_step:  60 model loss: 3.02002, kl_loss: 3.00021, obs_loss: 0.01980, reward_loss: 0.00001, value_loss: 0.00376 action_loss: 19.96320\n",
      "update_step:  61 model loss: 3.00709, kl_loss: 3.00011, obs_loss: 0.00697, reward_loss: 0.00001, value_loss: 0.00419 action_loss: 19.94496\n",
      "update_step:  62 model loss: 3.01311, kl_loss: 3.00000, obs_loss: 0.01311, reward_loss: 0.00001, value_loss: 0.00381 action_loss: 19.94592\n",
      "update_step:  63 model loss: 3.03096, kl_loss: 3.00031, obs_loss: 0.03065, reward_loss: 0.00000, value_loss: 0.00365 action_loss: 19.99476\n",
      "update_step:  64 model loss: 3.04933, kl_loss: 3.00033, obs_loss: 0.04900, reward_loss: 0.00000, value_loss: 0.00379 action_loss: 20.02938\n",
      "update_step:  65 model loss: 3.05242, kl_loss: 3.00046, obs_loss: 0.05196, reward_loss: 0.00000, value_loss: 0.00452 action_loss: 20.08207\n",
      "update_step:  66 model loss: 3.04949, kl_loss: 3.00143, obs_loss: 0.04805, reward_loss: 0.00001, value_loss: 0.00428 action_loss: 20.02038\n",
      "update_step:  67 model loss: 3.02804, kl_loss: 3.00080, obs_loss: 0.02722, reward_loss: 0.00001, value_loss: 0.00350 action_loss: 19.98812\n",
      "update_step:  68 model loss: 3.02555, kl_loss: 3.00184, obs_loss: 0.02370, reward_loss: 0.00001, value_loss: 0.00449 action_loss: 19.93458\n",
      "update_step:  69 model loss: 3.01037, kl_loss: 3.00154, obs_loss: 0.00883, reward_loss: 0.00001, value_loss: 0.00414 action_loss: 19.87383\n",
      "update_step:  70 model loss: 3.01218, kl_loss: 3.00076, obs_loss: 0.01140, reward_loss: 0.00001, value_loss: 0.00418 action_loss: 19.89359\n",
      "update_step:  71 model loss: 3.02535, kl_loss: 3.00062, obs_loss: 0.02472, reward_loss: 0.00001, value_loss: 0.00387 action_loss: 19.93330\n",
      "update_step:  72 model loss: 3.03860, kl_loss: 3.00041, obs_loss: 0.03818, reward_loss: 0.00001, value_loss: 0.00416 action_loss: 20.04806\n",
      "update_step:  73 model loss: 3.04856, kl_loss: 3.00019, obs_loss: 0.04836, reward_loss: 0.00000, value_loss: 0.00491 action_loss: 20.03110\n",
      "update_step:  74 model loss: 3.05258, kl_loss: 3.00025, obs_loss: 0.05232, reward_loss: 0.00001, value_loss: 0.00383 action_loss: 20.06414\n",
      "update_step:  75 model loss: 3.04214, kl_loss: 3.00013, obs_loss: 0.04200, reward_loss: 0.00002, value_loss: 0.00343 action_loss: 19.99315\n",
      "update_step:  76 model loss: 3.03043, kl_loss: 3.00093, obs_loss: 0.02950, reward_loss: 0.00001, value_loss: 0.00340 action_loss: 19.97142\n",
      "update_step:  77 model loss: 3.02114, kl_loss: 3.00049, obs_loss: 0.02065, reward_loss: 0.00001, value_loss: 0.00401 action_loss: 19.93186\n",
      "update_step:  78 model loss: 3.01272, kl_loss: 3.00052, obs_loss: 0.01219, reward_loss: 0.00000, value_loss: 0.00408 action_loss: 19.93775\n",
      "update_step:  79 model loss: 3.02688, kl_loss: 3.00124, obs_loss: 0.02564, reward_loss: 0.00001, value_loss: 0.00329 action_loss: 19.97736\n",
      "update_step:  80 model loss: 3.01891, kl_loss: 3.00093, obs_loss: 0.01798, reward_loss: 0.00001, value_loss: 0.00340 action_loss: 20.01721\n",
      "update_step:  81 model loss: 3.03500, kl_loss: 3.00098, obs_loss: 0.03401, reward_loss: 0.00001, value_loss: 0.00424 action_loss: 20.10640\n",
      "update_step:  82 model loss: 3.03101, kl_loss: 3.00018, obs_loss: 0.03082, reward_loss: 0.00002, value_loss: 0.00455 action_loss: 20.07712\n",
      "update_step:  83 model loss: 3.04347, kl_loss: 3.00015, obs_loss: 0.04331, reward_loss: 0.00001, value_loss: 0.00481 action_loss: 20.10249\n",
      "update_step:  84 model loss: 3.04440, kl_loss: 3.00056, obs_loss: 0.04383, reward_loss: 0.00001, value_loss: 0.00350 action_loss: 20.02332\n",
      "update_step:  85 model loss: 3.03345, kl_loss: 3.00040, obs_loss: 0.03305, reward_loss: 0.00001, value_loss: 0.00406 action_loss: 19.97304\n",
      "update_step:  86 model loss: 3.02853, kl_loss: 3.00015, obs_loss: 0.02838, reward_loss: 0.00001, value_loss: 0.00402 action_loss: 19.90168\n",
      "update_step:  87 model loss: 3.01420, kl_loss: 3.00000, obs_loss: 0.01419, reward_loss: 0.00001, value_loss: 0.00450 action_loss: 19.91095\n",
      "update_step:  88 model loss: 3.01152, kl_loss: 3.00002, obs_loss: 0.01149, reward_loss: 0.00001, value_loss: 0.00378 action_loss: 19.94331\n",
      "update_step:  89 model loss: 3.01213, kl_loss: 3.00022, obs_loss: 0.01190, reward_loss: 0.00001, value_loss: 0.00364 action_loss: 19.96195\n",
      "update_step:  90 model loss: 3.01145, kl_loss: 3.00020, obs_loss: 0.01124, reward_loss: 0.00001, value_loss: 0.00405 action_loss: 20.00731\n",
      "update_step:  91 model loss: 3.01428, kl_loss: 3.00049, obs_loss: 0.01379, reward_loss: 0.00001, value_loss: 0.00385 action_loss: 20.02226\n",
      "update_step:  92 model loss: 3.01250, kl_loss: 3.00057, obs_loss: 0.01192, reward_loss: 0.00001, value_loss: 0.00412 action_loss: 20.02200\n",
      "update_step:  93 model loss: 3.01293, kl_loss: 3.00048, obs_loss: 0.01244, reward_loss: 0.00001, value_loss: 0.00377 action_loss: 19.98023\n",
      "update_step:  94 model loss: 3.01342, kl_loss: 3.00065, obs_loss: 0.01277, reward_loss: 0.00001, value_loss: 0.00389 action_loss: 19.96043\n",
      "update_step:  95 model loss: 3.01814, kl_loss: 3.00116, obs_loss: 0.01697, reward_loss: 0.00001, value_loss: 0.00428 action_loss: 19.92026\n",
      "update_step:  96 model loss: 3.01388, kl_loss: 3.00047, obs_loss: 0.01341, reward_loss: 0.00001, value_loss: 0.00414 action_loss: 19.89208\n",
      "update_step:  97 model loss: 3.01753, kl_loss: 3.00011, obs_loss: 0.01742, reward_loss: 0.00001, value_loss: 0.00426 action_loss: 19.92786\n",
      "update_step:  98 model loss: 3.00842, kl_loss: 3.00012, obs_loss: 0.00829, reward_loss: 0.00001, value_loss: 0.00340 action_loss: 19.96475\n",
      "update_step:  99 model loss: 3.00818, kl_loss: 3.00022, obs_loss: 0.00796, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 20.05227\n",
      "update_step: 100 model loss: 3.00774, kl_loss: 3.00014, obs_loss: 0.00760, reward_loss: 0.00000, value_loss: 0.00522 action_loss: 20.09860\n",
      "elasped time for update: 20.57s\n",
      "episode [  42/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01104, kl_loss: 3.00034, obs_loss: 0.01069, reward_loss: 0.00001, value_loss: 0.00470 action_loss: 20.12273\n",
      "update_step:   2 model loss: 3.00813, kl_loss: 3.00007, obs_loss: 0.00805, reward_loss: 0.00001, value_loss: 0.00348 action_loss: 20.02115\n",
      "update_step:   3 model loss: 3.00958, kl_loss: 3.00042, obs_loss: 0.00915, reward_loss: 0.00001, value_loss: 0.00370 action_loss: 19.92081\n",
      "update_step:   4 model loss: 3.00897, kl_loss: 3.00027, obs_loss: 0.00870, reward_loss: 0.00000, value_loss: 0.00620 action_loss: 19.86278\n",
      "update_step:   5 model loss: 3.00570, kl_loss: 3.00015, obs_loss: 0.00554, reward_loss: 0.00001, value_loss: 0.00513 action_loss: 19.87893\n",
      "update_step:   6 model loss: 3.01281, kl_loss: 3.00052, obs_loss: 0.01228, reward_loss: 0.00000, value_loss: 0.00339 action_loss: 19.93593\n",
      "update_step:   7 model loss: 3.00275, kl_loss: 3.00029, obs_loss: 0.00245, reward_loss: 0.00001, value_loss: 0.00357 action_loss: 20.03610\n",
      "update_step:   8 model loss: 3.01421, kl_loss: 3.00155, obs_loss: 0.01265, reward_loss: 0.00000, value_loss: 0.00498 action_loss: 20.12306\n",
      "update_step:   9 model loss: 3.00456, kl_loss: 3.00015, obs_loss: 0.00440, reward_loss: 0.00001, value_loss: 0.00589 action_loss: 20.13557\n",
      "update_step:  10 model loss: 3.00566, kl_loss: 3.00117, obs_loss: 0.00448, reward_loss: 0.00001, value_loss: 0.00392 action_loss: 20.07230\n",
      "update_step:  11 model loss: 3.00596, kl_loss: 3.00000, obs_loss: 0.00596, reward_loss: 0.00000, value_loss: 0.00359 action_loss: 20.00402\n",
      "update_step:  12 model loss: 3.00523, kl_loss: 3.00010, obs_loss: 0.00513, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 19.91450\n",
      "update_step:  13 model loss: 3.00978, kl_loss: 3.00030, obs_loss: 0.00947, reward_loss: 0.00000, value_loss: 0.00494 action_loss: 19.88419\n",
      "update_step:  14 model loss: 3.00522, kl_loss: 3.00003, obs_loss: 0.00518, reward_loss: 0.00001, value_loss: 0.00452 action_loss: 19.91270\n",
      "update_step:  15 model loss: 3.00569, kl_loss: 3.00010, obs_loss: 0.00558, reward_loss: 0.00000, value_loss: 0.00317 action_loss: 19.98587\n",
      "update_step:  16 model loss: 3.00659, kl_loss: 3.00052, obs_loss: 0.00607, reward_loss: 0.00001, value_loss: 0.00443 action_loss: 20.04762\n",
      "update_step:  17 model loss: 3.00697, kl_loss: 3.00044, obs_loss: 0.00653, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 20.09160\n",
      "update_step:  18 model loss: 3.00668, kl_loss: 3.00090, obs_loss: 0.00578, reward_loss: 0.00000, value_loss: 0.00422 action_loss: 20.09067\n",
      "update_step:  19 model loss: 3.00669, kl_loss: 3.00050, obs_loss: 0.00619, reward_loss: 0.00001, value_loss: 0.00360 action_loss: 20.02383\n",
      "update_step:  20 model loss: 3.00443, kl_loss: 3.00000, obs_loss: 0.00442, reward_loss: 0.00001, value_loss: 0.00322 action_loss: 19.96663\n",
      "update_step:  21 model loss: 3.01652, kl_loss: 3.00055, obs_loss: 0.01597, reward_loss: 0.00000, value_loss: 0.00464 action_loss: 19.90767\n",
      "update_step:  22 model loss: 3.01139, kl_loss: 3.00069, obs_loss: 0.01069, reward_loss: 0.00000, value_loss: 0.00455 action_loss: 19.89727\n",
      "update_step:  23 model loss: 3.01103, kl_loss: 3.00087, obs_loss: 0.01016, reward_loss: 0.00000, value_loss: 0.00373 action_loss: 19.91033\n",
      "update_step:  24 model loss: 3.01267, kl_loss: 3.00097, obs_loss: 0.01169, reward_loss: 0.00001, value_loss: 0.00338 action_loss: 19.98328\n",
      "update_step:  25 model loss: 3.00708, kl_loss: 3.00011, obs_loss: 0.00696, reward_loss: 0.00001, value_loss: 0.00347 action_loss: 20.03894\n",
      "update_step:  26 model loss: 3.00484, kl_loss: 3.00024, obs_loss: 0.00459, reward_loss: 0.00000, value_loss: 0.00473 action_loss: 20.05747\n",
      "update_step:  27 model loss: 3.01006, kl_loss: 3.00068, obs_loss: 0.00937, reward_loss: 0.00001, value_loss: 0.00397 action_loss: 20.06223\n",
      "update_step:  28 model loss: 3.00889, kl_loss: 3.00042, obs_loss: 0.00847, reward_loss: 0.00000, value_loss: 0.00316 action_loss: 20.02253\n",
      "update_step:  29 model loss: 3.01310, kl_loss: 3.00089, obs_loss: 0.01220, reward_loss: 0.00000, value_loss: 0.00338 action_loss: 19.98707\n",
      "update_step:  30 model loss: 3.01142, kl_loss: 3.00095, obs_loss: 0.01047, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 19.93290\n",
      "update_step:  31 model loss: 3.01065, kl_loss: 3.00051, obs_loss: 0.01014, reward_loss: 0.00001, value_loss: 0.00448 action_loss: 19.95044\n",
      "update_step:  32 model loss: 3.00866, kl_loss: 3.00009, obs_loss: 0.00857, reward_loss: 0.00001, value_loss: 0.00379 action_loss: 19.95473\n",
      "update_step:  33 model loss: 3.01082, kl_loss: 3.00043, obs_loss: 0.01038, reward_loss: 0.00000, value_loss: 0.00342 action_loss: 20.00039\n",
      "update_step:  34 model loss: 3.01049, kl_loss: 3.00039, obs_loss: 0.01009, reward_loss: 0.00001, value_loss: 0.00333 action_loss: 20.04537\n",
      "update_step:  35 model loss: 3.01424, kl_loss: 3.00130, obs_loss: 0.01294, reward_loss: 0.00000, value_loss: 0.00351 action_loss: 20.08184\n",
      "update_step:  36 model loss: 3.00379, kl_loss: 3.00002, obs_loss: 0.00376, reward_loss: 0.00001, value_loss: 0.00398 action_loss: 20.07521\n",
      "update_step:  37 model loss: 3.00838, kl_loss: 3.00036, obs_loss: 0.00801, reward_loss: 0.00001, value_loss: 0.00333 action_loss: 20.04811\n",
      "update_step:  38 model loss: 3.00699, kl_loss: 3.00030, obs_loss: 0.00668, reward_loss: 0.00000, value_loss: 0.00328 action_loss: 20.02488\n",
      "update_step:  39 model loss: 3.00813, kl_loss: 3.00066, obs_loss: 0.00746, reward_loss: 0.00001, value_loss: 0.00335 action_loss: 19.97030\n",
      "update_step:  40 model loss: 3.00786, kl_loss: 3.00065, obs_loss: 0.00720, reward_loss: 0.00001, value_loss: 0.00359 action_loss: 19.96130\n",
      "update_step:  41 model loss: 3.01201, kl_loss: 3.00058, obs_loss: 0.01143, reward_loss: 0.00000, value_loss: 0.00354 action_loss: 19.95989\n",
      "update_step:  42 model loss: 3.00539, kl_loss: 3.00039, obs_loss: 0.00499, reward_loss: 0.00000, value_loss: 0.00318 action_loss: 19.98485\n",
      "update_step:  43 model loss: 3.00832, kl_loss: 3.00029, obs_loss: 0.00803, reward_loss: 0.00000, value_loss: 0.00334 action_loss: 20.01006\n",
      "update_step:  44 model loss: 3.01219, kl_loss: 3.00120, obs_loss: 0.01098, reward_loss: 0.00000, value_loss: 0.00332 action_loss: 20.03054\n",
      "update_step:  45 model loss: 3.00911, kl_loss: 3.00108, obs_loss: 0.00803, reward_loss: 0.00000, value_loss: 0.00350 action_loss: 20.04171\n",
      "update_step:  46 model loss: 3.00629, kl_loss: 3.00018, obs_loss: 0.00611, reward_loss: 0.00000, value_loss: 0.00352 action_loss: 20.01235\n",
      "update_step:  47 model loss: 3.00648, kl_loss: 3.00034, obs_loss: 0.00614, reward_loss: 0.00001, value_loss: 0.00335 action_loss: 20.02160\n",
      "update_step:  48 model loss: 3.01263, kl_loss: 3.00065, obs_loss: 0.01198, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 19.99192\n",
      "update_step:  49 model loss: 3.00939, kl_loss: 3.00039, obs_loss: 0.00900, reward_loss: 0.00000, value_loss: 0.00325 action_loss: 19.97132\n",
      "update_step:  50 model loss: 3.00530, kl_loss: 3.00055, obs_loss: 0.00475, reward_loss: 0.00000, value_loss: 0.00346 action_loss: 19.94477\n",
      "update_step:  51 model loss: 3.00362, kl_loss: 3.00000, obs_loss: 0.00362, reward_loss: 0.00000, value_loss: 0.00363 action_loss: 19.95517\n",
      "update_step:  52 model loss: 3.00401, kl_loss: 3.00012, obs_loss: 0.00388, reward_loss: 0.00001, value_loss: 0.00321 action_loss: 19.95787\n",
      "update_step:  53 model loss: 3.01041, kl_loss: 3.00117, obs_loss: 0.00924, reward_loss: 0.00000, value_loss: 0.00315 action_loss: 19.97785\n",
      "update_step:  54 model loss: 3.01187, kl_loss: 3.00173, obs_loss: 0.01013, reward_loss: 0.00001, value_loss: 0.00323 action_loss: 20.03684\n",
      "update_step:  55 model loss: 3.00503, kl_loss: 3.00112, obs_loss: 0.00390, reward_loss: 0.00001, value_loss: 0.00356 action_loss: 20.05743\n",
      "update_step:  56 model loss: 3.00849, kl_loss: 3.00159, obs_loss: 0.00689, reward_loss: 0.00000, value_loss: 0.00402 action_loss: 20.06592\n",
      "update_step:  57 model loss: 3.00641, kl_loss: 3.00102, obs_loss: 0.00538, reward_loss: 0.00001, value_loss: 0.00318 action_loss: 20.03377\n",
      "update_step:  58 model loss: 3.00690, kl_loss: 3.00045, obs_loss: 0.00644, reward_loss: 0.00000, value_loss: 0.00330 action_loss: 20.01032\n",
      "update_step:  59 model loss: 3.01566, kl_loss: 3.00067, obs_loss: 0.01498, reward_loss: 0.00001, value_loss: 0.00329 action_loss: 19.94585\n",
      "update_step:  60 model loss: 3.01060, kl_loss: 3.00010, obs_loss: 0.01049, reward_loss: 0.00001, value_loss: 0.00371 action_loss: 19.94830\n",
      "update_step:  61 model loss: 3.01069, kl_loss: 3.00000, obs_loss: 0.01068, reward_loss: 0.00000, value_loss: 0.00367 action_loss: 19.94798\n",
      "update_step:  62 model loss: 3.01508, kl_loss: 3.00009, obs_loss: 0.01498, reward_loss: 0.00000, value_loss: 0.00310 action_loss: 19.98985\n",
      "update_step:  63 model loss: 3.01711, kl_loss: 3.00001, obs_loss: 0.01709, reward_loss: 0.00000, value_loss: 0.00331 action_loss: 19.97430\n",
      "update_step:  64 model loss: 3.02684, kl_loss: 3.00043, obs_loss: 0.02640, reward_loss: 0.00001, value_loss: 0.00316 action_loss: 20.02442\n",
      "update_step:  65 model loss: 3.01862, kl_loss: 3.00017, obs_loss: 0.01844, reward_loss: 0.00001, value_loss: 0.00344 action_loss: 20.02580\n",
      "update_step:  66 model loss: 3.01741, kl_loss: 3.00010, obs_loss: 0.01731, reward_loss: 0.00001, value_loss: 0.00397 action_loss: 20.05418\n",
      "update_step:  67 model loss: 3.01759, kl_loss: 3.00028, obs_loss: 0.01731, reward_loss: 0.00000, value_loss: 0.00337 action_loss: 20.03649\n",
      "update_step:  68 model loss: 3.01757, kl_loss: 3.00181, obs_loss: 0.01576, reward_loss: 0.00000, value_loss: 0.00337 action_loss: 20.04067\n",
      "update_step:  69 model loss: 3.01265, kl_loss: 3.00083, obs_loss: 0.01181, reward_loss: 0.00001, value_loss: 0.00315 action_loss: 20.00010\n",
      "update_step:  70 model loss: 3.01013, kl_loss: 3.00059, obs_loss: 0.00954, reward_loss: 0.00001, value_loss: 0.00339 action_loss: 19.97798\n",
      "update_step:  71 model loss: 3.00802, kl_loss: 3.00035, obs_loss: 0.00767, reward_loss: 0.00000, value_loss: 0.00391 action_loss: 19.95706\n",
      "update_step:  72 model loss: 3.00852, kl_loss: 3.00007, obs_loss: 0.00845, reward_loss: 0.00001, value_loss: 0.00350 action_loss: 19.94810\n",
      "update_step:  73 model loss: 3.00796, kl_loss: 3.00008, obs_loss: 0.00787, reward_loss: 0.00001, value_loss: 0.00330 action_loss: 19.96983\n",
      "update_step:  74 model loss: 3.00830, kl_loss: 3.00000, obs_loss: 0.00830, reward_loss: 0.00001, value_loss: 0.00329 action_loss: 19.99120\n",
      "update_step:  75 model loss: 3.00913, kl_loss: 3.00007, obs_loss: 0.00905, reward_loss: 0.00000, value_loss: 0.00337 action_loss: 20.02823\n",
      "update_step:  76 model loss: 3.01130, kl_loss: 3.00008, obs_loss: 0.01121, reward_loss: 0.00001, value_loss: 0.00368 action_loss: 20.03738\n",
      "update_step:  77 model loss: 3.00684, kl_loss: 3.00000, obs_loss: 0.00684, reward_loss: 0.00001, value_loss: 0.00356 action_loss: 20.05479\n",
      "update_step:  78 model loss: 3.01073, kl_loss: 3.00060, obs_loss: 0.01012, reward_loss: 0.00000, value_loss: 0.00321 action_loss: 20.03963\n",
      "update_step:  79 model loss: 3.00462, kl_loss: 3.00014, obs_loss: 0.00447, reward_loss: 0.00000, value_loss: 0.00319 action_loss: 20.01985\n",
      "update_step:  80 model loss: 3.00823, kl_loss: 3.00118, obs_loss: 0.00705, reward_loss: 0.00000, value_loss: 0.00331 action_loss: 19.97978\n",
      "update_step:  81 model loss: 3.00338, kl_loss: 3.00019, obs_loss: 0.00319, reward_loss: 0.00001, value_loss: 0.00386 action_loss: 19.96675\n",
      "update_step:  82 model loss: 3.00325, kl_loss: 3.00015, obs_loss: 0.00310, reward_loss: 0.00001, value_loss: 0.00347 action_loss: 19.96151\n",
      "update_step:  83 model loss: 3.01036, kl_loss: 3.00130, obs_loss: 0.00905, reward_loss: 0.00000, value_loss: 0.00323 action_loss: 19.98410\n",
      "update_step:  84 model loss: 3.00499, kl_loss: 3.00030, obs_loss: 0.00469, reward_loss: 0.00001, value_loss: 0.00316 action_loss: 20.02353\n",
      "update_step:  85 model loss: 3.00731, kl_loss: 3.00021, obs_loss: 0.00710, reward_loss: 0.00000, value_loss: 0.00335 action_loss: 20.06216\n",
      "update_step:  86 model loss: 3.00625, kl_loss: 3.00000, obs_loss: 0.00624, reward_loss: 0.00001, value_loss: 0.00388 action_loss: 20.06412\n",
      "update_step:  87 model loss: 3.00783, kl_loss: 3.00010, obs_loss: 0.00772, reward_loss: 0.00001, value_loss: 0.00318 action_loss: 20.04935\n",
      "update_step:  88 model loss: 3.01634, kl_loss: 3.00017, obs_loss: 0.01617, reward_loss: 0.00000, value_loss: 0.00299 action_loss: 20.00650\n",
      "update_step:  89 model loss: 3.01438, kl_loss: 3.00013, obs_loss: 0.01424, reward_loss: 0.00000, value_loss: 0.00322 action_loss: 19.96223\n",
      "update_step:  90 model loss: 3.01803, kl_loss: 3.00051, obs_loss: 0.01751, reward_loss: 0.00000, value_loss: 0.00348 action_loss: 19.92007\n",
      "update_step:  91 model loss: 3.01739, kl_loss: 3.00008, obs_loss: 0.01730, reward_loss: 0.00001, value_loss: 0.00373 action_loss: 19.93112\n",
      "update_step:  92 model loss: 3.02044, kl_loss: 3.00025, obs_loss: 0.02019, reward_loss: 0.00001, value_loss: 0.00317 action_loss: 19.95060\n",
      "update_step:  93 model loss: 3.02399, kl_loss: 3.00057, obs_loss: 0.02342, reward_loss: 0.00000, value_loss: 0.00313 action_loss: 19.99814\n",
      "update_step:  94 model loss: 3.02823, kl_loss: 3.00063, obs_loss: 0.02760, reward_loss: 0.00000, value_loss: 0.00342 action_loss: 20.02626\n",
      "update_step:  95 model loss: 3.03121, kl_loss: 3.00023, obs_loss: 0.03097, reward_loss: 0.00000, value_loss: 0.00339 action_loss: 20.04977\n",
      "update_step:  96 model loss: 3.04187, kl_loss: 3.00027, obs_loss: 0.04159, reward_loss: 0.00001, value_loss: 0.00333 action_loss: 20.00519\n",
      "update_step:  97 model loss: 3.04535, kl_loss: 3.00029, obs_loss: 0.04506, reward_loss: 0.00000, value_loss: 0.00298 action_loss: 19.98877\n",
      "update_step:  98 model loss: 3.05414, kl_loss: 3.00016, obs_loss: 0.05398, reward_loss: 0.00000, value_loss: 0.00314 action_loss: 19.96310\n",
      "update_step:  99 model loss: 3.05764, kl_loss: 3.00008, obs_loss: 0.05756, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 19.98548\n",
      "update_step: 100 model loss: 3.06527, kl_loss: 3.00005, obs_loss: 0.06521, reward_loss: 0.00000, value_loss: 0.00304 action_loss: 19.97803\n",
      "elasped time for update: 20.33s\n",
      "episode [  43/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.06777, kl_loss: 3.00038, obs_loss: 0.06739, reward_loss: 0.00001, value_loss: 0.00327 action_loss: 20.02268\n",
      "update_step:   2 model loss: 3.05918, kl_loss: 3.00081, obs_loss: 0.05836, reward_loss: 0.00001, value_loss: 0.00306 action_loss: 19.98626\n",
      "update_step:   3 model loss: 3.04206, kl_loss: 3.00111, obs_loss: 0.04094, reward_loss: 0.00001, value_loss: 0.00311 action_loss: 19.99879\n",
      "update_step:   4 model loss: 3.02273, kl_loss: 3.00122, obs_loss: 0.02150, reward_loss: 0.00000, value_loss: 0.00306 action_loss: 19.97042\n",
      "update_step:   5 model loss: 3.02414, kl_loss: 3.00182, obs_loss: 0.02232, reward_loss: 0.00000, value_loss: 0.00309 action_loss: 19.99584\n",
      "update_step:   6 model loss: 3.01397, kl_loss: 3.00060, obs_loss: 0.01337, reward_loss: 0.00000, value_loss: 0.00313 action_loss: 19.98632\n",
      "update_step:   7 model loss: 3.02302, kl_loss: 3.00026, obs_loss: 0.02275, reward_loss: 0.00001, value_loss: 0.00308 action_loss: 19.99310\n",
      "update_step:   8 model loss: 3.03114, kl_loss: 3.00042, obs_loss: 0.03072, reward_loss: 0.00000, value_loss: 0.00304 action_loss: 19.96900\n",
      "update_step:   9 model loss: 3.03547, kl_loss: 3.00002, obs_loss: 0.03545, reward_loss: 0.00000, value_loss: 0.00312 action_loss: 19.95380\n",
      "update_step:  10 model loss: 3.03612, kl_loss: 3.00014, obs_loss: 0.03597, reward_loss: 0.00000, value_loss: 0.00322 action_loss: 19.92471\n",
      "update_step:  11 model loss: 3.03738, kl_loss: 3.00066, obs_loss: 0.03671, reward_loss: 0.00001, value_loss: 0.00329 action_loss: 19.96171\n",
      "update_step:  12 model loss: 3.03644, kl_loss: 3.00130, obs_loss: 0.03514, reward_loss: 0.00001, value_loss: 0.00320 action_loss: 19.97312\n",
      "update_step:  13 model loss: 3.02061, kl_loss: 3.00052, obs_loss: 0.02008, reward_loss: 0.00001, value_loss: 0.00347 action_loss: 20.03387\n",
      "update_step:  14 model loss: 3.01383, kl_loss: 3.00105, obs_loss: 0.01278, reward_loss: 0.00000, value_loss: 0.00339 action_loss: 20.06298\n",
      "update_step:  15 model loss: 3.01344, kl_loss: 3.00176, obs_loss: 0.01167, reward_loss: 0.00000, value_loss: 0.00374 action_loss: 20.09067\n",
      "update_step:  16 model loss: 3.01396, kl_loss: 3.00114, obs_loss: 0.01282, reward_loss: 0.00001, value_loss: 0.00338 action_loss: 20.05143\n",
      "update_step:  17 model loss: 3.02246, kl_loss: 3.00177, obs_loss: 0.02068, reward_loss: 0.00001, value_loss: 0.00344 action_loss: 20.03944\n",
      "update_step:  18 model loss: 3.01231, kl_loss: 3.00022, obs_loss: 0.01209, reward_loss: 0.00000, value_loss: 0.00376 action_loss: 20.01233\n",
      "update_step:  19 model loss: 3.01416, kl_loss: 3.00146, obs_loss: 0.01269, reward_loss: 0.00001, value_loss: 0.00338 action_loss: 19.98970\n",
      "update_step:  20 model loss: 3.00495, kl_loss: 3.00011, obs_loss: 0.00484, reward_loss: 0.00001, value_loss: 0.00323 action_loss: 20.00101\n",
      "update_step:  21 model loss: 3.00667, kl_loss: 3.00019, obs_loss: 0.00647, reward_loss: 0.00000, value_loss: 0.00348 action_loss: 20.00301\n",
      "update_step:  22 model loss: 3.01424, kl_loss: 3.00010, obs_loss: 0.01414, reward_loss: 0.00001, value_loss: 0.00319 action_loss: 20.02095\n",
      "update_step:  23 model loss: 3.02013, kl_loss: 3.00008, obs_loss: 0.02004, reward_loss: 0.00000, value_loss: 0.00367 action_loss: 20.00977\n",
      "update_step:  24 model loss: 3.02724, kl_loss: 3.00062, obs_loss: 0.02661, reward_loss: 0.00001, value_loss: 0.00344 action_loss: 20.04763\n",
      "update_step:  25 model loss: 3.03350, kl_loss: 3.00071, obs_loss: 0.03278, reward_loss: 0.00001, value_loss: 0.00380 action_loss: 20.02497\n",
      "update_step:  26 model loss: 3.02313, kl_loss: 3.00113, obs_loss: 0.02200, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 20.03884\n",
      "update_step:  27 model loss: 3.01527, kl_loss: 3.00054, obs_loss: 0.01472, reward_loss: 0.00001, value_loss: 0.00324 action_loss: 20.01128\n",
      "update_step:  28 model loss: 3.01303, kl_loss: 3.00082, obs_loss: 0.01221, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 20.00046\n",
      "update_step:  29 model loss: 3.01159, kl_loss: 3.00110, obs_loss: 0.01048, reward_loss: 0.00001, value_loss: 0.00371 action_loss: 19.92268\n",
      "update_step:  30 model loss: 3.01195, kl_loss: 3.00004, obs_loss: 0.01190, reward_loss: 0.00001, value_loss: 0.00416 action_loss: 19.91754\n",
      "update_step:  31 model loss: 3.01257, kl_loss: 3.00000, obs_loss: 0.01256, reward_loss: 0.00000, value_loss: 0.00450 action_loss: 19.92346\n",
      "update_step:  32 model loss: 3.02119, kl_loss: 3.00041, obs_loss: 0.02077, reward_loss: 0.00001, value_loss: 0.00328 action_loss: 19.97321\n",
      "update_step:  33 model loss: 3.01332, kl_loss: 3.00000, obs_loss: 0.01332, reward_loss: 0.00000, value_loss: 0.00386 action_loss: 20.00219\n",
      "update_step:  34 model loss: 3.02210, kl_loss: 3.00005, obs_loss: 0.02204, reward_loss: 0.00001, value_loss: 0.00366 action_loss: 20.08081\n",
      "update_step:  35 model loss: 3.01406, kl_loss: 3.00003, obs_loss: 0.01403, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 20.06102\n",
      "update_step:  36 model loss: 3.01622, kl_loss: 3.00006, obs_loss: 0.01615, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 20.04319\n",
      "update_step:  37 model loss: 3.01107, kl_loss: 3.00000, obs_loss: 0.01107, reward_loss: 0.00001, value_loss: 0.00323 action_loss: 19.99643\n",
      "update_step:  38 model loss: 3.01062, kl_loss: 3.00008, obs_loss: 0.01053, reward_loss: 0.00000, value_loss: 0.00399 action_loss: 19.96739\n",
      "update_step:  39 model loss: 3.00538, kl_loss: 3.00023, obs_loss: 0.00514, reward_loss: 0.00001, value_loss: 0.00364 action_loss: 19.91994\n",
      "update_step:  40 model loss: 3.00900, kl_loss: 3.00135, obs_loss: 0.00764, reward_loss: 0.00001, value_loss: 0.00402 action_loss: 19.93251\n",
      "update_step:  41 model loss: 3.00576, kl_loss: 3.00193, obs_loss: 0.00382, reward_loss: 0.00000, value_loss: 0.00381 action_loss: 19.94644\n",
      "update_step:  42 model loss: 3.00924, kl_loss: 3.00072, obs_loss: 0.00851, reward_loss: 0.00001, value_loss: 0.00332 action_loss: 19.97290\n",
      "update_step:  43 model loss: 3.00790, kl_loss: 3.00107, obs_loss: 0.00682, reward_loss: 0.00001, value_loss: 0.00372 action_loss: 20.05211\n",
      "update_step:  44 model loss: 3.00865, kl_loss: 3.00038, obs_loss: 0.00827, reward_loss: 0.00000, value_loss: 0.00390 action_loss: 20.09790\n",
      "update_step:  45 model loss: 3.00796, kl_loss: 3.00017, obs_loss: 0.00778, reward_loss: 0.00001, value_loss: 0.00463 action_loss: 20.09405\n",
      "update_step:  46 model loss: 3.00984, kl_loss: 3.00010, obs_loss: 0.00973, reward_loss: 0.00000, value_loss: 0.00368 action_loss: 20.03817\n",
      "update_step:  47 model loss: 3.01394, kl_loss: 3.00000, obs_loss: 0.01393, reward_loss: 0.00001, value_loss: 0.00373 action_loss: 20.02368\n",
      "update_step:  48 model loss: 3.01227, kl_loss: 3.00000, obs_loss: 0.01226, reward_loss: 0.00001, value_loss: 0.00376 action_loss: 19.96587\n",
      "update_step:  49 model loss: 3.01535, kl_loss: 3.00017, obs_loss: 0.01517, reward_loss: 0.00000, value_loss: 0.00359 action_loss: 19.96263\n",
      "update_step:  50 model loss: 3.00936, kl_loss: 3.00000, obs_loss: 0.00935, reward_loss: 0.00000, value_loss: 0.00373 action_loss: 19.96631\n",
      "update_step:  51 model loss: 3.00911, kl_loss: 3.00008, obs_loss: 0.00903, reward_loss: 0.00000, value_loss: 0.00317 action_loss: 19.99719\n",
      "update_step:  52 model loss: 3.01605, kl_loss: 3.00091, obs_loss: 0.01514, reward_loss: 0.00001, value_loss: 0.00345 action_loss: 20.01427\n",
      "update_step:  53 model loss: 3.00905, kl_loss: 3.00074, obs_loss: 0.00831, reward_loss: 0.00001, value_loss: 0.00365 action_loss: 20.05920\n",
      "update_step:  54 model loss: 3.00368, kl_loss: 3.00030, obs_loss: 0.00338, reward_loss: 0.00000, value_loss: 0.00347 action_loss: 20.06159\n",
      "update_step:  55 model loss: 3.00789, kl_loss: 3.00103, obs_loss: 0.00686, reward_loss: 0.00001, value_loss: 0.00358 action_loss: 20.02887\n",
      "update_step:  56 model loss: 3.01094, kl_loss: 3.00243, obs_loss: 0.00850, reward_loss: 0.00001, value_loss: 0.00318 action_loss: 19.98479\n",
      "update_step:  57 model loss: 3.00460, kl_loss: 3.00223, obs_loss: 0.00237, reward_loss: 0.00000, value_loss: 0.00386 action_loss: 19.96462\n",
      "update_step:  58 model loss: 3.01637, kl_loss: 3.00204, obs_loss: 0.01433, reward_loss: 0.00001, value_loss: 0.00330 action_loss: 19.94407\n",
      "update_step:  59 model loss: 3.01320, kl_loss: 3.00082, obs_loss: 0.01238, reward_loss: 0.00001, value_loss: 0.00316 action_loss: 19.96588\n",
      "update_step:  60 model loss: 3.00471, kl_loss: 3.00047, obs_loss: 0.00424, reward_loss: 0.00000, value_loss: 0.00312 action_loss: 20.00547\n",
      "update_step:  61 model loss: 3.01072, kl_loss: 3.00107, obs_loss: 0.00965, reward_loss: 0.00001, value_loss: 0.00334 action_loss: 20.03736\n",
      "update_step:  62 model loss: 3.00444, kl_loss: 3.00025, obs_loss: 0.00418, reward_loss: 0.00000, value_loss: 0.00356 action_loss: 20.04988\n",
      "update_step:  63 model loss: 3.00561, kl_loss: 3.00023, obs_loss: 0.00537, reward_loss: 0.00001, value_loss: 0.00327 action_loss: 20.05411\n",
      "update_step:  64 model loss: 3.00895, kl_loss: 3.00065, obs_loss: 0.00829, reward_loss: 0.00001, value_loss: 0.00314 action_loss: 20.01445\n",
      "update_step:  65 model loss: 3.00593, kl_loss: 3.00019, obs_loss: 0.00574, reward_loss: 0.00000, value_loss: 0.00311 action_loss: 19.99759\n",
      "update_step:  66 model loss: 3.00806, kl_loss: 3.00069, obs_loss: 0.00736, reward_loss: 0.00000, value_loss: 0.00360 action_loss: 19.95526\n",
      "update_step:  67 model loss: 3.00782, kl_loss: 3.00002, obs_loss: 0.00779, reward_loss: 0.00000, value_loss: 0.00369 action_loss: 19.94520\n",
      "update_step:  68 model loss: 3.00936, kl_loss: 3.00014, obs_loss: 0.00922, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 19.93780\n",
      "update_step:  69 model loss: 3.01197, kl_loss: 3.00011, obs_loss: 0.01185, reward_loss: 0.00001, value_loss: 0.00306 action_loss: 20.00249\n",
      "update_step:  70 model loss: 3.01725, kl_loss: 3.00077, obs_loss: 0.01647, reward_loss: 0.00001, value_loss: 0.00328 action_loss: 20.03226\n",
      "update_step:  71 model loss: 3.02240, kl_loss: 3.00011, obs_loss: 0.02228, reward_loss: 0.00000, value_loss: 0.00412 action_loss: 20.09134\n",
      "update_step:  72 model loss: 3.02672, kl_loss: 3.00022, obs_loss: 0.02649, reward_loss: 0.00000, value_loss: 0.00371 action_loss: 20.07779\n",
      "update_step:  73 model loss: 3.02809, kl_loss: 3.00013, obs_loss: 0.02796, reward_loss: 0.00001, value_loss: 0.00349 action_loss: 20.08316\n",
      "update_step:  74 model loss: 3.02683, kl_loss: 3.00023, obs_loss: 0.02659, reward_loss: 0.00001, value_loss: 0.00303 action_loss: 19.98098\n",
      "update_step:  75 model loss: 3.02787, kl_loss: 3.00040, obs_loss: 0.02745, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 19.96393\n",
      "update_step:  76 model loss: 3.02514, kl_loss: 3.00014, obs_loss: 0.02500, reward_loss: 0.00001, value_loss: 0.00421 action_loss: 19.91143\n",
      "update_step:  77 model loss: 3.02856, kl_loss: 3.00042, obs_loss: 0.02813, reward_loss: 0.00000, value_loss: 0.00350 action_loss: 19.96061\n",
      "update_step:  78 model loss: 3.03794, kl_loss: 3.00067, obs_loss: 0.03727, reward_loss: 0.00001, value_loss: 0.00314 action_loss: 19.96850\n",
      "update_step:  79 model loss: 3.03396, kl_loss: 3.00023, obs_loss: 0.03372, reward_loss: 0.00001, value_loss: 0.00339 action_loss: 20.05521\n",
      "update_step:  80 model loss: 3.03781, kl_loss: 3.00013, obs_loss: 0.03768, reward_loss: 0.00001, value_loss: 0.00400 action_loss: 20.02453\n",
      "update_step:  81 model loss: 3.03666, kl_loss: 3.00061, obs_loss: 0.03604, reward_loss: 0.00001, value_loss: 0.00427 action_loss: 20.07763\n",
      "update_step:  82 model loss: 3.03189, kl_loss: 3.00029, obs_loss: 0.03159, reward_loss: 0.00001, value_loss: 0.00349 action_loss: 20.03790\n",
      "update_step:  83 model loss: 3.02821, kl_loss: 3.00047, obs_loss: 0.02774, reward_loss: 0.00001, value_loss: 0.00366 action_loss: 20.03284\n",
      "update_step:  84 model loss: 3.02931, kl_loss: 3.00017, obs_loss: 0.02913, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 19.94493\n",
      "update_step:  85 model loss: 3.01701, kl_loss: 3.00024, obs_loss: 0.01676, reward_loss: 0.00001, value_loss: 0.00432 action_loss: 19.94482\n",
      "update_step:  86 model loss: 3.02929, kl_loss: 3.00051, obs_loss: 0.02878, reward_loss: 0.00001, value_loss: 0.00405 action_loss: 19.92781\n",
      "update_step:  87 model loss: 3.01514, kl_loss: 3.00042, obs_loss: 0.01472, reward_loss: 0.00001, value_loss: 0.00361 action_loss: 19.99138\n",
      "update_step:  88 model loss: 3.01354, kl_loss: 3.00007, obs_loss: 0.01346, reward_loss: 0.00001, value_loss: 0.00369 action_loss: 20.03865\n",
      "update_step:  89 model loss: 3.00645, kl_loss: 3.00012, obs_loss: 0.00633, reward_loss: 0.00000, value_loss: 0.00487 action_loss: 20.07638\n",
      "update_step:  90 model loss: 3.01985, kl_loss: 3.00095, obs_loss: 0.01889, reward_loss: 0.00000, value_loss: 0.00530 action_loss: 20.09705\n",
      "update_step:  91 model loss: 3.01618, kl_loss: 3.00052, obs_loss: 0.01565, reward_loss: 0.00000, value_loss: 0.00424 action_loss: 20.07430\n",
      "update_step:  92 model loss: 3.01842, kl_loss: 3.00072, obs_loss: 0.01770, reward_loss: 0.00000, value_loss: 0.00379 action_loss: 20.03708\n",
      "update_step:  93 model loss: 3.01661, kl_loss: 3.00038, obs_loss: 0.01622, reward_loss: 0.00001, value_loss: 0.00380 action_loss: 19.94839\n",
      "update_step:  94 model loss: 3.01063, kl_loss: 3.00006, obs_loss: 0.01057, reward_loss: 0.00001, value_loss: 0.00501 action_loss: 19.90184\n",
      "update_step:  95 model loss: 3.01120, kl_loss: 3.00000, obs_loss: 0.01119, reward_loss: 0.00000, value_loss: 0.00488 action_loss: 19.87329\n",
      "update_step:  96 model loss: 3.01008, kl_loss: 3.00008, obs_loss: 0.00999, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 19.93200\n",
      "update_step:  97 model loss: 3.02022, kl_loss: 3.00054, obs_loss: 0.01967, reward_loss: 0.00001, value_loss: 0.00316 action_loss: 19.96939\n",
      "update_step:  98 model loss: 3.01762, kl_loss: 3.00122, obs_loss: 0.01639, reward_loss: 0.00001, value_loss: 0.00367 action_loss: 20.04084\n",
      "update_step:  99 model loss: 3.02847, kl_loss: 3.00152, obs_loss: 0.02695, reward_loss: 0.00000, value_loss: 0.00406 action_loss: 20.06432\n",
      "update_step: 100 model loss: 3.02094, kl_loss: 3.00121, obs_loss: 0.01973, reward_loss: 0.00000, value_loss: 0.00438 action_loss: 20.10174\n",
      "elasped time for update: 20.23s\n",
      "episode [  44/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.33s\n",
      "update_step:   1 model loss: 3.01632, kl_loss: 3.00071, obs_loss: 0.01561, reward_loss: 0.00000, value_loss: 0.00322 action_loss: 20.02206\n",
      "update_step:   2 model loss: 3.01924, kl_loss: 3.00082, obs_loss: 0.01842, reward_loss: 0.00001, value_loss: 0.00362 action_loss: 19.98569\n",
      "update_step:   3 model loss: 3.01555, kl_loss: 3.00037, obs_loss: 0.01517, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 19.93448\n",
      "update_step:   4 model loss: 3.02555, kl_loss: 3.00123, obs_loss: 0.02432, reward_loss: 0.00000, value_loss: 0.00362 action_loss: 19.96748\n",
      "update_step:   5 model loss: 3.01908, kl_loss: 3.00053, obs_loss: 0.01855, reward_loss: 0.00000, value_loss: 0.00336 action_loss: 19.98690\n",
      "update_step:   6 model loss: 3.02640, kl_loss: 3.00027, obs_loss: 0.02613, reward_loss: 0.00000, value_loss: 0.00339 action_loss: 20.06775\n",
      "update_step:   7 model loss: 3.03501, kl_loss: 3.00020, obs_loss: 0.03480, reward_loss: 0.00001, value_loss: 0.00415 action_loss: 20.07390\n",
      "update_step:   8 model loss: 3.04331, kl_loss: 3.00005, obs_loss: 0.04326, reward_loss: 0.00001, value_loss: 0.00480 action_loss: 20.13394\n",
      "update_step:   9 model loss: 3.04366, kl_loss: 3.00000, obs_loss: 0.04366, reward_loss: 0.00001, value_loss: 0.00388 action_loss: 20.08717\n",
      "update_step:  10 model loss: 3.04378, kl_loss: 3.00000, obs_loss: 0.04378, reward_loss: 0.00000, value_loss: 0.00402 action_loss: 20.07847\n",
      "update_step:  11 model loss: 3.04555, kl_loss: 3.00015, obs_loss: 0.04540, reward_loss: 0.00001, value_loss: 0.00334 action_loss: 19.96924\n",
      "update_step:  12 model loss: 3.05603, kl_loss: 3.00009, obs_loss: 0.05593, reward_loss: 0.00001, value_loss: 0.00579 action_loss: 19.96012\n",
      "update_step:  13 model loss: 3.04112, kl_loss: 3.00003, obs_loss: 0.04108, reward_loss: 0.00001, value_loss: 0.00434 action_loss: 19.92589\n",
      "update_step:  14 model loss: 3.01795, kl_loss: 3.00041, obs_loss: 0.01754, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 19.89492\n",
      "update_step:  15 model loss: 3.03262, kl_loss: 3.00006, obs_loss: 0.03254, reward_loss: 0.00002, value_loss: 0.00412 action_loss: 19.96078\n",
      "update_step:  16 model loss: 3.05464, kl_loss: 3.00047, obs_loss: 0.05415, reward_loss: 0.00002, value_loss: 0.00353 action_loss: 19.99060\n",
      "update_step:  17 model loss: 3.08139, kl_loss: 3.00051, obs_loss: 0.08088, reward_loss: 0.00001, value_loss: 0.00545 action_loss: 20.06925\n",
      "update_step:  18 model loss: 3.14830, kl_loss: 3.00011, obs_loss: 0.14818, reward_loss: 0.00001, value_loss: 0.00491 action_loss: 19.95048\n",
      "update_step:  19 model loss: 3.20536, kl_loss: 3.00055, obs_loss: 0.20478, reward_loss: 0.00003, value_loss: 0.00457 action_loss: 20.02491\n",
      "update_step:  20 model loss: 3.18630, kl_loss: 3.00044, obs_loss: 0.18579, reward_loss: 0.00007, value_loss: 0.00409 action_loss: 19.98009\n",
      "update_step:  21 model loss: 3.16083, kl_loss: 3.00085, obs_loss: 0.15995, reward_loss: 0.00002, value_loss: 0.00509 action_loss: 20.08253\n",
      "update_step:  22 model loss: 3.08920, kl_loss: 3.00156, obs_loss: 0.08762, reward_loss: 0.00001, value_loss: 0.00440 action_loss: 20.09556\n",
      "update_step:  23 model loss: 3.03048, kl_loss: 3.00093, obs_loss: 0.02953, reward_loss: 0.00001, value_loss: 0.00457 action_loss: 20.10034\n",
      "update_step:  24 model loss: 3.03167, kl_loss: 3.00246, obs_loss: 0.02920, reward_loss: 0.00001, value_loss: 0.00467 action_loss: 20.07526\n",
      "update_step:  25 model loss: 3.05982, kl_loss: 3.00111, obs_loss: 0.05870, reward_loss: 0.00001, value_loss: 0.00504 action_loss: 19.96652\n",
      "update_step:  26 model loss: 3.08845, kl_loss: 3.00031, obs_loss: 0.08813, reward_loss: 0.00001, value_loss: 0.00835 action_loss: 19.97323\n",
      "update_step:  27 model loss: 3.08416, kl_loss: 3.00021, obs_loss: 0.08390, reward_loss: 0.00004, value_loss: 0.00537 action_loss: 19.89322\n",
      "update_step:  28 model loss: 3.04993, kl_loss: 3.00009, obs_loss: 0.04982, reward_loss: 0.00002, value_loss: 0.00495 action_loss: 19.95000\n",
      "update_step:  29 model loss: 3.02003, kl_loss: 3.00000, obs_loss: 0.02002, reward_loss: 0.00001, value_loss: 0.00473 action_loss: 20.03149\n",
      "update_step:  30 model loss: 3.01551, kl_loss: 3.00000, obs_loss: 0.01550, reward_loss: 0.00002, value_loss: 0.00557 action_loss: 20.07643\n",
      "update_step:  31 model loss: 3.05406, kl_loss: 3.00024, obs_loss: 0.05382, reward_loss: 0.00001, value_loss: 0.00760 action_loss: 20.13230\n",
      "update_step:  32 model loss: 3.06981, kl_loss: 3.00125, obs_loss: 0.06855, reward_loss: 0.00001, value_loss: 0.00450 action_loss: 20.06318\n",
      "update_step:  33 model loss: 3.04434, kl_loss: 3.00006, obs_loss: 0.04427, reward_loss: 0.00001, value_loss: 0.00497 action_loss: 20.01976\n",
      "update_step:  34 model loss: 3.02314, kl_loss: 3.00066, obs_loss: 0.02247, reward_loss: 0.00002, value_loss: 0.00512 action_loss: 19.92788\n",
      "update_step:  35 model loss: 3.01792, kl_loss: 3.00333, obs_loss: 0.01459, reward_loss: 0.00001, value_loss: 0.00603 action_loss: 19.89543\n",
      "update_step:  36 model loss: 3.01873, kl_loss: 3.00214, obs_loss: 0.01657, reward_loss: 0.00001, value_loss: 0.00599 action_loss: 19.95001\n",
      "update_step:  37 model loss: 3.02863, kl_loss: 3.00124, obs_loss: 0.02738, reward_loss: 0.00001, value_loss: 0.00410 action_loss: 19.93920\n",
      "update_step:  38 model loss: 3.03681, kl_loss: 3.00046, obs_loss: 0.03634, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 20.02642\n",
      "update_step:  39 model loss: 3.03049, kl_loss: 3.00010, obs_loss: 0.03038, reward_loss: 0.00001, value_loss: 0.00502 action_loss: 20.07061\n",
      "update_step:  40 model loss: 3.01116, kl_loss: 3.00001, obs_loss: 0.01114, reward_loss: 0.00001, value_loss: 0.00608 action_loss: 20.08668\n",
      "update_step:  41 model loss: 3.01699, kl_loss: 3.00044, obs_loss: 0.01655, reward_loss: 0.00001, value_loss: 0.00562 action_loss: 20.08981\n",
      "update_step:  42 model loss: 3.02440, kl_loss: 3.00024, obs_loss: 0.02415, reward_loss: 0.00001, value_loss: 0.00419 action_loss: 20.04452\n",
      "update_step:  43 model loss: 3.03575, kl_loss: 3.00159, obs_loss: 0.03416, reward_loss: 0.00001, value_loss: 0.00403 action_loss: 20.04162\n",
      "update_step:  44 model loss: 3.02167, kl_loss: 3.00078, obs_loss: 0.02089, reward_loss: 0.00001, value_loss: 0.00387 action_loss: 19.94173\n",
      "update_step:  45 model loss: 3.01164, kl_loss: 3.00048, obs_loss: 0.01115, reward_loss: 0.00001, value_loss: 0.00581 action_loss: 19.89939\n",
      "update_step:  46 model loss: 3.00534, kl_loss: 3.00025, obs_loss: 0.00508, reward_loss: 0.00001, value_loss: 0.00586 action_loss: 19.87827\n",
      "update_step:  47 model loss: 3.01362, kl_loss: 3.00125, obs_loss: 0.01236, reward_loss: 0.00001, value_loss: 0.00412 action_loss: 19.86810\n",
      "update_step:  48 model loss: 3.01708, kl_loss: 3.00151, obs_loss: 0.01555, reward_loss: 0.00001, value_loss: 0.00351 action_loss: 19.95004\n",
      "update_step:  49 model loss: 3.01860, kl_loss: 3.00073, obs_loss: 0.01786, reward_loss: 0.00001, value_loss: 0.00368 action_loss: 19.99373\n",
      "update_step:  50 model loss: 3.02141, kl_loss: 3.00077, obs_loss: 0.02063, reward_loss: 0.00001, value_loss: 0.00539 action_loss: 20.03136\n",
      "update_step:  51 model loss: 3.00916, kl_loss: 3.00126, obs_loss: 0.00789, reward_loss: 0.00001, value_loss: 0.00469 action_loss: 20.03616\n",
      "update_step:  52 model loss: 3.00801, kl_loss: 3.00043, obs_loss: 0.00758, reward_loss: 0.00000, value_loss: 0.00331 action_loss: 20.00396\n",
      "update_step:  53 model loss: 3.00760, kl_loss: 3.00026, obs_loss: 0.00734, reward_loss: 0.00001, value_loss: 0.00328 action_loss: 19.96038\n",
      "update_step:  54 model loss: 3.01006, kl_loss: 3.00005, obs_loss: 0.01001, reward_loss: 0.00000, value_loss: 0.00377 action_loss: 19.89114\n",
      "update_step:  55 model loss: 3.01283, kl_loss: 3.00065, obs_loss: 0.01217, reward_loss: 0.00001, value_loss: 0.00524 action_loss: 19.88775\n",
      "update_step:  56 model loss: 3.01419, kl_loss: 3.00164, obs_loss: 0.01254, reward_loss: 0.00001, value_loss: 0.00414 action_loss: 19.90701\n",
      "update_step:  57 model loss: 3.00684, kl_loss: 3.00044, obs_loss: 0.00640, reward_loss: 0.00000, value_loss: 0.00309 action_loss: 19.93938\n",
      "update_step:  58 model loss: 3.01340, kl_loss: 3.00112, obs_loss: 0.01227, reward_loss: 0.00001, value_loss: 0.00329 action_loss: 20.03916\n",
      "update_step:  59 model loss: 3.01672, kl_loss: 3.00106, obs_loss: 0.01566, reward_loss: 0.00001, value_loss: 0.00380 action_loss: 20.07944\n",
      "update_step:  60 model loss: 3.01296, kl_loss: 3.00052, obs_loss: 0.01244, reward_loss: 0.00000, value_loss: 0.00491 action_loss: 20.11734\n",
      "update_step:  61 model loss: 3.00686, kl_loss: 3.00023, obs_loss: 0.00663, reward_loss: 0.00000, value_loss: 0.00405 action_loss: 20.09984\n",
      "update_step:  62 model loss: 3.00853, kl_loss: 3.00100, obs_loss: 0.00753, reward_loss: 0.00000, value_loss: 0.00334 action_loss: 20.05901\n",
      "update_step:  63 model loss: 3.00598, kl_loss: 3.00005, obs_loss: 0.00593, reward_loss: 0.00000, value_loss: 0.00358 action_loss: 20.01737\n",
      "update_step:  64 model loss: 3.01656, kl_loss: 3.00097, obs_loss: 0.01558, reward_loss: 0.00000, value_loss: 0.00376 action_loss: 19.98185\n",
      "update_step:  65 model loss: 3.01826, kl_loss: 3.00190, obs_loss: 0.01634, reward_loss: 0.00001, value_loss: 0.00434 action_loss: 19.99845\n",
      "update_step:  66 model loss: 3.00864, kl_loss: 3.00026, obs_loss: 0.00837, reward_loss: 0.00001, value_loss: 0.00335 action_loss: 20.01475\n",
      "update_step:  67 model loss: 3.00311, kl_loss: 3.00004, obs_loss: 0.00306, reward_loss: 0.00000, value_loss: 0.00325 action_loss: 20.04153\n",
      "update_step:  68 model loss: 3.00483, kl_loss: 3.00023, obs_loss: 0.00460, reward_loss: 0.00001, value_loss: 0.00337 action_loss: 20.07861\n",
      "update_step:  69 model loss: 3.00561, kl_loss: 3.00021, obs_loss: 0.00540, reward_loss: 0.00000, value_loss: 0.00355 action_loss: 20.07599\n",
      "update_step:  70 model loss: 3.01031, kl_loss: 3.00032, obs_loss: 0.00998, reward_loss: 0.00000, value_loss: 0.00385 action_loss: 20.06694\n",
      "update_step:  71 model loss: 3.01550, kl_loss: 3.00063, obs_loss: 0.01487, reward_loss: 0.00000, value_loss: 0.00308 action_loss: 19.99891\n",
      "update_step:  72 model loss: 3.01184, kl_loss: 3.00047, obs_loss: 0.01136, reward_loss: 0.00001, value_loss: 0.00353 action_loss: 19.96239\n",
      "update_step:  73 model loss: 3.01039, kl_loss: 3.00012, obs_loss: 0.01026, reward_loss: 0.00001, value_loss: 0.00422 action_loss: 19.87470\n",
      "update_step:  74 model loss: 3.00885, kl_loss: 3.00065, obs_loss: 0.00819, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 19.86663\n",
      "update_step:  75 model loss: 3.00730, kl_loss: 3.00071, obs_loss: 0.00658, reward_loss: 0.00000, value_loss: 0.00337 action_loss: 19.91921\n",
      "update_step:  76 model loss: 3.00583, kl_loss: 3.00026, obs_loss: 0.00556, reward_loss: 0.00000, value_loss: 0.00319 action_loss: 19.98402\n",
      "update_step:  77 model loss: 3.00874, kl_loss: 3.00021, obs_loss: 0.00853, reward_loss: 0.00000, value_loss: 0.00365 action_loss: 20.06223\n",
      "update_step:  78 model loss: 3.01321, kl_loss: 3.00013, obs_loss: 0.01308, reward_loss: 0.00000, value_loss: 0.00393 action_loss: 20.05714\n",
      "update_step:  79 model loss: 3.02120, kl_loss: 3.00030, obs_loss: 0.02089, reward_loss: 0.00001, value_loss: 0.00319 action_loss: 20.04062\n",
      "update_step:  80 model loss: 3.02415, kl_loss: 3.00070, obs_loss: 0.02345, reward_loss: 0.00000, value_loss: 0.00310 action_loss: 19.97887\n",
      "update_step:  81 model loss: 3.00945, kl_loss: 3.00007, obs_loss: 0.00938, reward_loss: 0.00000, value_loss: 0.00381 action_loss: 19.95066\n",
      "update_step:  82 model loss: 3.01148, kl_loss: 3.00031, obs_loss: 0.01117, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 19.93542\n",
      "update_step:  83 model loss: 3.00469, kl_loss: 3.00022, obs_loss: 0.00446, reward_loss: 0.00000, value_loss: 0.00347 action_loss: 19.95008\n",
      "update_step:  84 model loss: 3.01194, kl_loss: 3.00090, obs_loss: 0.01104, reward_loss: 0.00000, value_loss: 0.00317 action_loss: 20.00213\n",
      "update_step:  85 model loss: 3.00926, kl_loss: 3.00062, obs_loss: 0.00863, reward_loss: 0.00000, value_loss: 0.00332 action_loss: 20.03600\n",
      "update_step:  86 model loss: 3.01469, kl_loss: 3.00148, obs_loss: 0.01320, reward_loss: 0.00000, value_loss: 0.00364 action_loss: 20.05660\n",
      "update_step:  87 model loss: 3.01375, kl_loss: 3.00145, obs_loss: 0.01230, reward_loss: 0.00000, value_loss: 0.00326 action_loss: 20.05622\n",
      "update_step:  88 model loss: 3.00753, kl_loss: 3.00122, obs_loss: 0.00631, reward_loss: 0.00000, value_loss: 0.00295 action_loss: 20.01991\n",
      "update_step:  89 model loss: 3.00611, kl_loss: 3.00056, obs_loss: 0.00555, reward_loss: 0.00000, value_loss: 0.00279 action_loss: 19.98449\n",
      "update_step:  90 model loss: 3.00625, kl_loss: 3.00032, obs_loss: 0.00592, reward_loss: 0.00000, value_loss: 0.00330 action_loss: 19.94258\n",
      "update_step:  91 model loss: 3.01012, kl_loss: 3.00041, obs_loss: 0.00971, reward_loss: 0.00000, value_loss: 0.00326 action_loss: 19.95420\n",
      "update_step:  92 model loss: 3.00408, kl_loss: 3.00002, obs_loss: 0.00406, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 19.97045\n",
      "update_step:  93 model loss: 3.00349, kl_loss: 3.00000, obs_loss: 0.00349, reward_loss: 0.00000, value_loss: 0.00272 action_loss: 20.00629\n",
      "update_step:  94 model loss: 3.00334, kl_loss: 3.00000, obs_loss: 0.00333, reward_loss: 0.00000, value_loss: 0.00283 action_loss: 20.03680\n",
      "update_step:  95 model loss: 3.01638, kl_loss: 3.00127, obs_loss: 0.01510, reward_loss: 0.00000, value_loss: 0.00298 action_loss: 20.03444\n",
      "update_step:  96 model loss: 3.01845, kl_loss: 3.00096, obs_loss: 0.01748, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 20.04871\n",
      "update_step:  97 model loss: 3.00756, kl_loss: 3.00170, obs_loss: 0.00585, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 20.03596\n",
      "update_step:  98 model loss: 3.00954, kl_loss: 3.00431, obs_loss: 0.00523, reward_loss: 0.00000, value_loss: 0.00286 action_loss: 20.01490\n",
      "update_step:  99 model loss: 3.01193, kl_loss: 3.00438, obs_loss: 0.00755, reward_loss: 0.00000, value_loss: 0.00287 action_loss: 19.98330\n",
      "update_step: 100 model loss: 3.00888, kl_loss: 3.00356, obs_loss: 0.00531, reward_loss: 0.00000, value_loss: 0.00325 action_loss: 19.95284\n",
      "elasped time for update: 20.35s\n",
      "episode [  45/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01054, kl_loss: 3.00196, obs_loss: 0.00858, reward_loss: 0.00000, value_loss: 0.00332 action_loss: 19.93561\n",
      "update_step:   2 model loss: 3.00712, kl_loss: 3.00025, obs_loss: 0.00687, reward_loss: 0.00000, value_loss: 0.00301 action_loss: 19.93160\n",
      "update_step:   3 model loss: 3.01864, kl_loss: 3.00117, obs_loss: 0.01747, reward_loss: 0.00001, value_loss: 0.00296 action_loss: 19.97908\n",
      "update_step:   4 model loss: 3.00775, kl_loss: 3.00051, obs_loss: 0.00724, reward_loss: 0.00000, value_loss: 0.00308 action_loss: 20.00941\n",
      "update_step:   5 model loss: 3.00448, kl_loss: 3.00030, obs_loss: 0.00418, reward_loss: 0.00000, value_loss: 0.00356 action_loss: 20.02498\n",
      "update_step:   6 model loss: 3.00302, kl_loss: 3.00006, obs_loss: 0.00296, reward_loss: 0.00000, value_loss: 0.00309 action_loss: 20.01314\n",
      "update_step:   7 model loss: 3.00204, kl_loss: 3.00002, obs_loss: 0.00201, reward_loss: 0.00000, value_loss: 0.00285 action_loss: 19.98204\n",
      "update_step:   8 model loss: 3.00203, kl_loss: 3.00000, obs_loss: 0.00202, reward_loss: 0.00000, value_loss: 0.00316 action_loss: 19.94916\n",
      "update_step:   9 model loss: 3.00351, kl_loss: 3.00003, obs_loss: 0.00347, reward_loss: 0.00000, value_loss: 0.00363 action_loss: 19.92931\n",
      "update_step:  10 model loss: 3.00889, kl_loss: 3.00040, obs_loss: 0.00849, reward_loss: 0.00000, value_loss: 0.00335 action_loss: 19.94156\n",
      "update_step:  11 model loss: 3.00235, kl_loss: 3.00006, obs_loss: 0.00228, reward_loss: 0.00000, value_loss: 0.00301 action_loss: 19.97363\n",
      "update_step:  12 model loss: 3.00383, kl_loss: 3.00067, obs_loss: 0.00315, reward_loss: 0.00000, value_loss: 0.00298 action_loss: 20.02207\n",
      "update_step:  13 model loss: 3.00851, kl_loss: 3.00094, obs_loss: 0.00757, reward_loss: 0.00000, value_loss: 0.00334 action_loss: 20.05500\n",
      "update_step:  14 model loss: 3.00575, kl_loss: 3.00071, obs_loss: 0.00504, reward_loss: 0.00000, value_loss: 0.00349 action_loss: 20.07111\n",
      "update_step:  15 model loss: 3.00269, kl_loss: 3.00045, obs_loss: 0.00224, reward_loss: 0.00000, value_loss: 0.00335 action_loss: 20.06326\n",
      "update_step:  16 model loss: 3.00329, kl_loss: 3.00116, obs_loss: 0.00212, reward_loss: 0.00000, value_loss: 0.00306 action_loss: 20.03479\n",
      "update_step:  17 model loss: 3.00398, kl_loss: 3.00044, obs_loss: 0.00353, reward_loss: 0.00000, value_loss: 0.00309 action_loss: 20.00373\n",
      "update_step:  18 model loss: 3.00249, kl_loss: 3.00004, obs_loss: 0.00245, reward_loss: 0.00000, value_loss: 0.00322 action_loss: 19.98926\n",
      "update_step:  19 model loss: 3.01001, kl_loss: 3.00043, obs_loss: 0.00958, reward_loss: 0.00000, value_loss: 0.00312 action_loss: 19.98751\n",
      "update_step:  20 model loss: 3.00507, kl_loss: 3.00032, obs_loss: 0.00475, reward_loss: 0.00000, value_loss: 0.00298 action_loss: 20.01794\n",
      "update_step:  21 model loss: 3.00301, kl_loss: 3.00007, obs_loss: 0.00294, reward_loss: 0.00000, value_loss: 0.00286 action_loss: 20.04218\n",
      "update_step:  22 model loss: 3.00875, kl_loss: 3.00042, obs_loss: 0.00832, reward_loss: 0.00000, value_loss: 0.00305 action_loss: 20.06046\n",
      "update_step:  23 model loss: 3.00810, kl_loss: 3.00081, obs_loss: 0.00729, reward_loss: 0.00000, value_loss: 0.00309 action_loss: 20.05314\n",
      "update_step:  24 model loss: 3.00580, kl_loss: 3.00014, obs_loss: 0.00565, reward_loss: 0.00000, value_loss: 0.00293 action_loss: 20.03994\n",
      "update_step:  25 model loss: 3.00872, kl_loss: 3.00023, obs_loss: 0.00849, reward_loss: 0.00000, value_loss: 0.00296 action_loss: 20.01303\n",
      "update_step:  26 model loss: 3.01784, kl_loss: 3.00109, obs_loss: 0.01675, reward_loss: 0.00000, value_loss: 0.00292 action_loss: 20.00108\n",
      "update_step:  27 model loss: 3.01258, kl_loss: 3.00160, obs_loss: 0.01097, reward_loss: 0.00000, value_loss: 0.00301 action_loss: 19.98608\n",
      "update_step:  28 model loss: 3.02241, kl_loss: 3.00094, obs_loss: 0.02146, reward_loss: 0.00000, value_loss: 0.00303 action_loss: 19.99610\n",
      "update_step:  29 model loss: 3.02827, kl_loss: 3.00085, obs_loss: 0.02741, reward_loss: 0.00000, value_loss: 0.00300 action_loss: 19.98675\n",
      "update_step:  30 model loss: 3.03358, kl_loss: 3.00151, obs_loss: 0.03207, reward_loss: 0.00000, value_loss: 0.00300 action_loss: 19.98961\n",
      "update_step:  31 model loss: 3.04098, kl_loss: 3.00091, obs_loss: 0.04006, reward_loss: 0.00000, value_loss: 0.00290 action_loss: 19.98716\n",
      "update_step:  32 model loss: 3.05246, kl_loss: 3.00030, obs_loss: 0.05216, reward_loss: 0.00000, value_loss: 0.00288 action_loss: 20.00221\n",
      "update_step:  33 model loss: 3.06643, kl_loss: 3.00041, obs_loss: 0.06601, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 19.99745\n",
      "update_step:  34 model loss: 3.08017, kl_loss: 3.00036, obs_loss: 0.07981, reward_loss: 0.00000, value_loss: 0.00283 action_loss: 20.01391\n",
      "update_step:  35 model loss: 3.08045, kl_loss: 3.00000, obs_loss: 0.08045, reward_loss: 0.00000, value_loss: 0.00288 action_loss: 20.00273\n",
      "update_step:  36 model loss: 3.07654, kl_loss: 3.00010, obs_loss: 0.07644, reward_loss: 0.00000, value_loss: 0.00288 action_loss: 20.01394\n",
      "update_step:  37 model loss: 3.07406, kl_loss: 3.00102, obs_loss: 0.07304, reward_loss: 0.00000, value_loss: 0.00318 action_loss: 19.96392\n",
      "update_step:  38 model loss: 3.05290, kl_loss: 3.00025, obs_loss: 0.05265, reward_loss: 0.00000, value_loss: 0.00321 action_loss: 19.97583\n",
      "update_step:  39 model loss: 3.03773, kl_loss: 3.00027, obs_loss: 0.03745, reward_loss: 0.00001, value_loss: 0.00297 action_loss: 19.98194\n",
      "update_step:  40 model loss: 3.00947, kl_loss: 3.00012, obs_loss: 0.00935, reward_loss: 0.00000, value_loss: 0.00292 action_loss: 20.01329\n",
      "update_step:  41 model loss: 3.01719, kl_loss: 3.00041, obs_loss: 0.01678, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 20.04055\n",
      "update_step:  42 model loss: 3.03147, kl_loss: 3.00031, obs_loss: 0.03115, reward_loss: 0.00000, value_loss: 0.00326 action_loss: 20.04625\n",
      "update_step:  43 model loss: 3.06329, kl_loss: 3.00036, obs_loss: 0.06293, reward_loss: 0.00000, value_loss: 0.00304 action_loss: 20.05229\n",
      "update_step:  44 model loss: 3.07709, kl_loss: 3.00037, obs_loss: 0.07672, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 20.00351\n",
      "update_step:  45 model loss: 3.08162, kl_loss: 3.00007, obs_loss: 0.08155, reward_loss: 0.00000, value_loss: 0.00320 action_loss: 20.01311\n",
      "update_step:  46 model loss: 3.07182, kl_loss: 3.00061, obs_loss: 0.07120, reward_loss: 0.00001, value_loss: 0.00319 action_loss: 19.95508\n",
      "update_step:  47 model loss: 3.04187, kl_loss: 3.00005, obs_loss: 0.04181, reward_loss: 0.00001, value_loss: 0.00317 action_loss: 20.01516\n",
      "update_step:  48 model loss: 3.02528, kl_loss: 3.00008, obs_loss: 0.02520, reward_loss: 0.00001, value_loss: 0.00303 action_loss: 20.02342\n",
      "update_step:  49 model loss: 3.03661, kl_loss: 3.00104, obs_loss: 0.03557, reward_loss: 0.00000, value_loss: 0.00339 action_loss: 20.06383\n",
      "update_step:  50 model loss: 3.03881, kl_loss: 3.00063, obs_loss: 0.03818, reward_loss: 0.00000, value_loss: 0.00324 action_loss: 20.03226\n",
      "update_step:  51 model loss: 3.03654, kl_loss: 3.00042, obs_loss: 0.03612, reward_loss: 0.00001, value_loss: 0.00312 action_loss: 20.01709\n",
      "update_step:  52 model loss: 3.03788, kl_loss: 3.00038, obs_loss: 0.03749, reward_loss: 0.00001, value_loss: 0.00335 action_loss: 19.98558\n",
      "update_step:  53 model loss: 3.02270, kl_loss: 3.00023, obs_loss: 0.02246, reward_loss: 0.00000, value_loss: 0.00342 action_loss: 19.96778\n",
      "update_step:  54 model loss: 3.01096, kl_loss: 3.00020, obs_loss: 0.01075, reward_loss: 0.00000, value_loss: 0.00345 action_loss: 19.97350\n",
      "update_step:  55 model loss: 3.01415, kl_loss: 3.00099, obs_loss: 0.01316, reward_loss: 0.00000, value_loss: 0.00313 action_loss: 19.99876\n",
      "update_step:  56 model loss: 3.01214, kl_loss: 3.00024, obs_loss: 0.01189, reward_loss: 0.00000, value_loss: 0.00333 action_loss: 20.03886\n",
      "update_step:  57 model loss: 3.02050, kl_loss: 3.00070, obs_loss: 0.01980, reward_loss: 0.00000, value_loss: 0.00378 action_loss: 20.07634\n",
      "update_step:  58 model loss: 3.02334, kl_loss: 3.00136, obs_loss: 0.02197, reward_loss: 0.00000, value_loss: 0.00356 action_loss: 20.08802\n",
      "update_step:  59 model loss: 3.02257, kl_loss: 3.00068, obs_loss: 0.02189, reward_loss: 0.00000, value_loss: 0.00347 action_loss: 20.07742\n",
      "update_step:  60 model loss: 3.01996, kl_loss: 3.00088, obs_loss: 0.01907, reward_loss: 0.00000, value_loss: 0.00335 action_loss: 20.02484\n",
      "update_step:  61 model loss: 3.01278, kl_loss: 3.00011, obs_loss: 0.01267, reward_loss: 0.00001, value_loss: 0.00343 action_loss: 20.02215\n",
      "update_step:  62 model loss: 3.01558, kl_loss: 3.00056, obs_loss: 0.01502, reward_loss: 0.00000, value_loss: 0.00369 action_loss: 20.00919\n",
      "update_step:  63 model loss: 3.01034, kl_loss: 3.00077, obs_loss: 0.00956, reward_loss: 0.00000, value_loss: 0.00342 action_loss: 19.99525\n",
      "update_step:  64 model loss: 3.01681, kl_loss: 3.00046, obs_loss: 0.01634, reward_loss: 0.00000, value_loss: 0.00330 action_loss: 19.99830\n",
      "update_step:  65 model loss: 3.02397, kl_loss: 3.00102, obs_loss: 0.02294, reward_loss: 0.00000, value_loss: 0.00328 action_loss: 19.99678\n",
      "update_step:  66 model loss: 3.02625, kl_loss: 3.00151, obs_loss: 0.02473, reward_loss: 0.00000, value_loss: 0.00327 action_loss: 20.03759\n",
      "update_step:  67 model loss: 3.02039, kl_loss: 3.00082, obs_loss: 0.01957, reward_loss: 0.00000, value_loss: 0.00355 action_loss: 20.04774\n",
      "update_step:  68 model loss: 3.01122, kl_loss: 3.00032, obs_loss: 0.01089, reward_loss: 0.00001, value_loss: 0.00331 action_loss: 20.07468\n",
      "update_step:  69 model loss: 3.00613, kl_loss: 3.00030, obs_loss: 0.00583, reward_loss: 0.00001, value_loss: 0.00314 action_loss: 20.02131\n",
      "update_step:  70 model loss: 3.00539, kl_loss: 3.00022, obs_loss: 0.00516, reward_loss: 0.00000, value_loss: 0.00323 action_loss: 19.95545\n",
      "update_step:  71 model loss: 3.01515, kl_loss: 3.00021, obs_loss: 0.01493, reward_loss: 0.00001, value_loss: 0.00335 action_loss: 19.96118\n",
      "update_step:  72 model loss: 3.01833, kl_loss: 3.00017, obs_loss: 0.01815, reward_loss: 0.00001, value_loss: 0.00317 action_loss: 19.97876\n",
      "update_step:  73 model loss: 3.01029, kl_loss: 3.00000, obs_loss: 0.01028, reward_loss: 0.00000, value_loss: 0.00311 action_loss: 20.00979\n",
      "update_step:  74 model loss: 3.01475, kl_loss: 3.00073, obs_loss: 0.01402, reward_loss: 0.00000, value_loss: 0.00303 action_loss: 20.01067\n",
      "update_step:  75 model loss: 3.00589, kl_loss: 3.00015, obs_loss: 0.00573, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 20.00070\n",
      "update_step:  76 model loss: 3.00557, kl_loss: 3.00011, obs_loss: 0.00546, reward_loss: 0.00001, value_loss: 0.00293 action_loss: 19.96671\n",
      "update_step:  77 model loss: 3.01157, kl_loss: 3.00041, obs_loss: 0.01115, reward_loss: 0.00000, value_loss: 0.00311 action_loss: 19.92619\n",
      "update_step:  78 model loss: 3.00957, kl_loss: 3.00088, obs_loss: 0.00869, reward_loss: 0.00001, value_loss: 0.00352 action_loss: 19.93302\n",
      "update_step:  79 model loss: 3.01131, kl_loss: 3.00137, obs_loss: 0.00994, reward_loss: 0.00001, value_loss: 0.00307 action_loss: 19.93747\n",
      "update_step:  80 model loss: 3.01468, kl_loss: 3.00081, obs_loss: 0.01387, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 19.99599\n",
      "update_step:  81 model loss: 3.01142, kl_loss: 3.00114, obs_loss: 0.01027, reward_loss: 0.00000, value_loss: 0.00301 action_loss: 20.04390\n",
      "update_step:  82 model loss: 3.00422, kl_loss: 3.00033, obs_loss: 0.00389, reward_loss: 0.00000, value_loss: 0.00315 action_loss: 20.07928\n",
      "update_step:  83 model loss: 3.00909, kl_loss: 3.00061, obs_loss: 0.00848, reward_loss: 0.00000, value_loss: 0.00304 action_loss: 20.05335\n",
      "update_step:  84 model loss: 3.00919, kl_loss: 3.00058, obs_loss: 0.00860, reward_loss: 0.00000, value_loss: 0.00284 action_loss: 20.01558\n",
      "update_step:  85 model loss: 3.00943, kl_loss: 3.00029, obs_loss: 0.00914, reward_loss: 0.00000, value_loss: 0.00300 action_loss: 20.00228\n",
      "update_step:  86 model loss: 3.01031, kl_loss: 3.00055, obs_loss: 0.00975, reward_loss: 0.00000, value_loss: 0.00279 action_loss: 19.99718\n",
      "update_step:  87 model loss: 3.00520, kl_loss: 3.00046, obs_loss: 0.00474, reward_loss: 0.00000, value_loss: 0.00279 action_loss: 20.03512\n",
      "update_step:  88 model loss: 3.00771, kl_loss: 3.00165, obs_loss: 0.00606, reward_loss: 0.00000, value_loss: 0.00294 action_loss: 20.06355\n",
      "update_step:  89 model loss: 3.00362, kl_loss: 3.00131, obs_loss: 0.00231, reward_loss: 0.00000, value_loss: 0.00322 action_loss: 20.07468\n",
      "update_step:  90 model loss: 3.00380, kl_loss: 3.00088, obs_loss: 0.00292, reward_loss: 0.00000, value_loss: 0.00306 action_loss: 20.05663\n",
      "update_step:  91 model loss: 3.00658, kl_loss: 3.00051, obs_loss: 0.00606, reward_loss: 0.00000, value_loss: 0.00266 action_loss: 19.99443\n",
      "update_step:  92 model loss: 3.00825, kl_loss: 3.00047, obs_loss: 0.00778, reward_loss: 0.00000, value_loss: 0.00280 action_loss: 19.93241\n",
      "update_step:  93 model loss: 3.00876, kl_loss: 3.00024, obs_loss: 0.00852, reward_loss: 0.00000, value_loss: 0.00311 action_loss: 19.88920\n",
      "update_step:  94 model loss: 3.00384, kl_loss: 3.00003, obs_loss: 0.00380, reward_loss: 0.00000, value_loss: 0.00306 action_loss: 19.90656\n",
      "update_step:  95 model loss: 3.00892, kl_loss: 3.00045, obs_loss: 0.00846, reward_loss: 0.00000, value_loss: 0.00269 action_loss: 19.92482\n",
      "update_step:  96 model loss: 3.00815, kl_loss: 3.00045, obs_loss: 0.00770, reward_loss: 0.00000, value_loss: 0.00259 action_loss: 19.98526\n",
      "update_step:  97 model loss: 3.00461, kl_loss: 3.00021, obs_loss: 0.00440, reward_loss: 0.00000, value_loss: 0.00276 action_loss: 20.01634\n",
      "update_step:  98 model loss: 3.00452, kl_loss: 3.00080, obs_loss: 0.00372, reward_loss: 0.00000, value_loss: 0.00281 action_loss: 20.03253\n",
      "update_step:  99 model loss: 3.00411, kl_loss: 3.00029, obs_loss: 0.00382, reward_loss: 0.00000, value_loss: 0.00246 action_loss: 20.01390\n",
      "update_step: 100 model loss: 3.00536, kl_loss: 3.00073, obs_loss: 0.00463, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 19.96635\n",
      "elasped time for update: 20.17s\n",
      "episode [  46/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.38s\n",
      "update_step:   1 model loss: 3.00972, kl_loss: 3.00068, obs_loss: 0.00904, reward_loss: 0.00000, value_loss: 0.00287 action_loss: 19.93602\n",
      "update_step:   2 model loss: 3.00565, kl_loss: 3.00029, obs_loss: 0.00535, reward_loss: 0.00000, value_loss: 0.00280 action_loss: 19.92189\n",
      "update_step:   3 model loss: 3.00996, kl_loss: 3.00027, obs_loss: 0.00968, reward_loss: 0.00000, value_loss: 0.00247 action_loss: 19.96582\n",
      "update_step:   4 model loss: 3.00974, kl_loss: 3.00012, obs_loss: 0.00962, reward_loss: 0.00000, value_loss: 0.00245 action_loss: 19.99376\n",
      "update_step:   5 model loss: 3.01440, kl_loss: 3.00061, obs_loss: 0.01378, reward_loss: 0.00000, value_loss: 0.00340 action_loss: 20.07263\n",
      "update_step:   6 model loss: 3.01110, kl_loss: 3.00015, obs_loss: 0.01095, reward_loss: 0.00000, value_loss: 0.00345 action_loss: 20.06896\n",
      "update_step:   7 model loss: 3.01268, kl_loss: 3.00056, obs_loss: 0.01212, reward_loss: 0.00000, value_loss: 0.00267 action_loss: 20.04578\n",
      "update_step:   8 model loss: 3.00695, kl_loss: 3.00057, obs_loss: 0.00638, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 19.95088\n",
      "update_step:   9 model loss: 3.00772, kl_loss: 3.00049, obs_loss: 0.00723, reward_loss: 0.00000, value_loss: 0.00329 action_loss: 19.89631\n",
      "update_step:  10 model loss: 3.00368, kl_loss: 3.00014, obs_loss: 0.00353, reward_loss: 0.00000, value_loss: 0.00316 action_loss: 19.92697\n",
      "update_step:  11 model loss: 3.00393, kl_loss: 3.00026, obs_loss: 0.00366, reward_loss: 0.00000, value_loss: 0.00245 action_loss: 19.96116\n",
      "update_step:  12 model loss: 3.00723, kl_loss: 3.00012, obs_loss: 0.00711, reward_loss: 0.00000, value_loss: 0.00251 action_loss: 20.01394\n",
      "update_step:  13 model loss: 3.01536, kl_loss: 3.00090, obs_loss: 0.01446, reward_loss: 0.00000, value_loss: 0.00240 action_loss: 20.00600\n",
      "update_step:  14 model loss: 3.01157, kl_loss: 3.00075, obs_loss: 0.01081, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 20.02270\n",
      "update_step:  15 model loss: 3.01085, kl_loss: 3.00057, obs_loss: 0.01027, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 20.00959\n",
      "update_step:  16 model loss: 3.01924, kl_loss: 3.00090, obs_loss: 0.01833, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 20.04233\n",
      "update_step:  17 model loss: 3.00898, kl_loss: 3.00010, obs_loss: 0.00887, reward_loss: 0.00001, value_loss: 0.00254 action_loss: 20.00811\n",
      "update_step:  18 model loss: 3.00698, kl_loss: 3.00009, obs_loss: 0.00689, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 20.00362\n",
      "update_step:  19 model loss: 3.00708, kl_loss: 3.00072, obs_loss: 0.00635, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 19.99045\n",
      "update_step:  20 model loss: 3.00599, kl_loss: 3.00041, obs_loss: 0.00558, reward_loss: 0.00000, value_loss: 0.00258 action_loss: 19.99181\n",
      "update_step:  21 model loss: 3.00347, kl_loss: 3.00041, obs_loss: 0.00305, reward_loss: 0.00000, value_loss: 0.00250 action_loss: 19.98458\n",
      "update_step:  22 model loss: 3.00449, kl_loss: 3.00075, obs_loss: 0.00374, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 19.97993\n",
      "update_step:  23 model loss: 3.00357, kl_loss: 3.00008, obs_loss: 0.00349, reward_loss: 0.00000, value_loss: 0.00262 action_loss: 19.98138\n",
      "update_step:  24 model loss: 3.00460, kl_loss: 3.00025, obs_loss: 0.00434, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 20.01072\n",
      "update_step:  25 model loss: 3.00218, kl_loss: 3.00001, obs_loss: 0.00217, reward_loss: 0.00000, value_loss: 0.00268 action_loss: 20.04679\n",
      "update_step:  26 model loss: 3.00492, kl_loss: 3.00000, obs_loss: 0.00492, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 20.00726\n",
      "update_step:  27 model loss: 3.00569, kl_loss: 3.00031, obs_loss: 0.00538, reward_loss: 0.00000, value_loss: 0.00254 action_loss: 19.98647\n",
      "update_step:  28 model loss: 3.00700, kl_loss: 3.00048, obs_loss: 0.00652, reward_loss: 0.00000, value_loss: 0.00262 action_loss: 19.95770\n",
      "update_step:  29 model loss: 3.01087, kl_loss: 3.00075, obs_loss: 0.01012, reward_loss: 0.00000, value_loss: 0.00264 action_loss: 19.97359\n",
      "update_step:  30 model loss: 3.01097, kl_loss: 3.00063, obs_loss: 0.01033, reward_loss: 0.00000, value_loss: 0.00265 action_loss: 19.96725\n",
      "update_step:  31 model loss: 3.01296, kl_loss: 3.00016, obs_loss: 0.01280, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 20.01170\n",
      "update_step:  32 model loss: 3.01207, kl_loss: 3.00031, obs_loss: 0.01176, reward_loss: 0.00000, value_loss: 0.00262 action_loss: 20.00797\n",
      "update_step:  33 model loss: 3.01625, kl_loss: 3.00023, obs_loss: 0.01601, reward_loss: 0.00001, value_loss: 0.00261 action_loss: 20.02820\n",
      "update_step:  34 model loss: 3.00850, kl_loss: 3.00037, obs_loss: 0.00813, reward_loss: 0.00000, value_loss: 0.00259 action_loss: 20.00768\n",
      "update_step:  35 model loss: 3.00764, kl_loss: 3.00037, obs_loss: 0.00726, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 20.00820\n",
      "update_step:  36 model loss: 3.00344, kl_loss: 3.00005, obs_loss: 0.00339, reward_loss: 0.00000, value_loss: 0.00256 action_loss: 19.99330\n",
      "update_step:  37 model loss: 3.00862, kl_loss: 3.00050, obs_loss: 0.00811, reward_loss: 0.00000, value_loss: 0.00268 action_loss: 19.98276\n",
      "update_step:  38 model loss: 3.00288, kl_loss: 3.00013, obs_loss: 0.00275, reward_loss: 0.00000, value_loss: 0.00262 action_loss: 19.98353\n",
      "update_step:  39 model loss: 3.00510, kl_loss: 3.00045, obs_loss: 0.00465, reward_loss: 0.00000, value_loss: 0.00264 action_loss: 19.96927\n",
      "update_step:  40 model loss: 3.00700, kl_loss: 3.00065, obs_loss: 0.00635, reward_loss: 0.00000, value_loss: 0.00267 action_loss: 19.97942\n",
      "update_step:  41 model loss: 3.00843, kl_loss: 3.00019, obs_loss: 0.00823, reward_loss: 0.00001, value_loss: 0.00259 action_loss: 19.97681\n",
      "update_step:  42 model loss: 3.00788, kl_loss: 3.00099, obs_loss: 0.00689, reward_loss: 0.00000, value_loss: 0.00267 action_loss: 20.00629\n",
      "update_step:  43 model loss: 3.00548, kl_loss: 3.00020, obs_loss: 0.00528, reward_loss: 0.00000, value_loss: 0.00267 action_loss: 20.02426\n",
      "update_step:  44 model loss: 3.00646, kl_loss: 3.00022, obs_loss: 0.00624, reward_loss: 0.00000, value_loss: 0.00277 action_loss: 20.03770\n",
      "update_step:  45 model loss: 3.00671, kl_loss: 3.00011, obs_loss: 0.00660, reward_loss: 0.00000, value_loss: 0.00275 action_loss: 20.04542\n",
      "update_step:  46 model loss: 3.00351, kl_loss: 3.00043, obs_loss: 0.00308, reward_loss: 0.00000, value_loss: 0.00260 action_loss: 19.98899\n",
      "update_step:  47 model loss: 3.00824, kl_loss: 3.00009, obs_loss: 0.00815, reward_loss: 0.00000, value_loss: 0.00296 action_loss: 19.96836\n",
      "update_step:  48 model loss: 3.02363, kl_loss: 3.00091, obs_loss: 0.02271, reward_loss: 0.00001, value_loss: 0.00289 action_loss: 19.92498\n",
      "update_step:  49 model loss: 3.02352, kl_loss: 3.00017, obs_loss: 0.02335, reward_loss: 0.00001, value_loss: 0.00268 action_loss: 19.99862\n",
      "update_step:  50 model loss: 3.02945, kl_loss: 3.00037, obs_loss: 0.02908, reward_loss: 0.00000, value_loss: 0.00273 action_loss: 20.00808\n",
      "update_step:  51 model loss: 3.04297, kl_loss: 3.00015, obs_loss: 0.04281, reward_loss: 0.00000, value_loss: 0.00315 action_loss: 20.07219\n",
      "update_step:  52 model loss: 3.03562, kl_loss: 3.00000, obs_loss: 0.03561, reward_loss: 0.00001, value_loss: 0.00350 action_loss: 20.03703\n",
      "update_step:  53 model loss: 3.03455, kl_loss: 3.00001, obs_loss: 0.03453, reward_loss: 0.00001, value_loss: 0.00287 action_loss: 20.04731\n",
      "update_step:  54 model loss: 3.02471, kl_loss: 3.00003, obs_loss: 0.02467, reward_loss: 0.00001, value_loss: 0.00294 action_loss: 19.95849\n",
      "update_step:  55 model loss: 3.01822, kl_loss: 3.00005, obs_loss: 0.01816, reward_loss: 0.00001, value_loss: 0.00310 action_loss: 19.92721\n",
      "update_step:  56 model loss: 3.01513, kl_loss: 3.00011, obs_loss: 0.01501, reward_loss: 0.00000, value_loss: 0.00293 action_loss: 19.93278\n",
      "update_step:  57 model loss: 3.01195, kl_loss: 3.00025, obs_loss: 0.01170, reward_loss: 0.00000, value_loss: 0.00262 action_loss: 19.96519\n",
      "update_step:  58 model loss: 3.01723, kl_loss: 3.00141, obs_loss: 0.01582, reward_loss: 0.00000, value_loss: 0.00282 action_loss: 20.03974\n",
      "update_step:  59 model loss: 3.02472, kl_loss: 3.00249, obs_loss: 0.02223, reward_loss: 0.00000, value_loss: 0.00319 action_loss: 20.04782\n",
      "update_step:  60 model loss: 3.03035, kl_loss: 3.00127, obs_loss: 0.02908, reward_loss: 0.00001, value_loss: 0.00342 action_loss: 20.06479\n",
      "update_step:  61 model loss: 3.02599, kl_loss: 3.00012, obs_loss: 0.02586, reward_loss: 0.00001, value_loss: 0.00325 action_loss: 19.98009\n",
      "update_step:  62 model loss: 3.02656, kl_loss: 3.00011, obs_loss: 0.02644, reward_loss: 0.00001, value_loss: 0.00333 action_loss: 19.98489\n",
      "update_step:  63 model loss: 3.02206, kl_loss: 3.00000, obs_loss: 0.02205, reward_loss: 0.00001, value_loss: 0.00309 action_loss: 19.94742\n",
      "update_step:  64 model loss: 3.02254, kl_loss: 3.00014, obs_loss: 0.02240, reward_loss: 0.00001, value_loss: 0.00314 action_loss: 19.97156\n",
      "update_step:  65 model loss: 3.01258, kl_loss: 3.00005, obs_loss: 0.01253, reward_loss: 0.00000, value_loss: 0.00294 action_loss: 19.96643\n",
      "update_step:  66 model loss: 3.00851, kl_loss: 3.00012, obs_loss: 0.00839, reward_loss: 0.00000, value_loss: 0.00278 action_loss: 19.98555\n",
      "update_step:  67 model loss: 3.00914, kl_loss: 3.00027, obs_loss: 0.00887, reward_loss: 0.00000, value_loss: 0.00272 action_loss: 19.97388\n",
      "update_step:  68 model loss: 3.01213, kl_loss: 3.00117, obs_loss: 0.01095, reward_loss: 0.00000, value_loss: 0.00273 action_loss: 19.97810\n",
      "update_step:  69 model loss: 3.00700, kl_loss: 3.00015, obs_loss: 0.00685, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 19.99994\n",
      "update_step:  70 model loss: 3.00910, kl_loss: 3.00033, obs_loss: 0.00876, reward_loss: 0.00000, value_loss: 0.00291 action_loss: 19.99712\n",
      "update_step:  71 model loss: 3.01178, kl_loss: 3.00043, obs_loss: 0.01134, reward_loss: 0.00001, value_loss: 0.00264 action_loss: 20.03831\n",
      "update_step:  72 model loss: 3.01201, kl_loss: 3.00049, obs_loss: 0.01152, reward_loss: 0.00001, value_loss: 0.00275 action_loss: 20.01596\n",
      "update_step:  73 model loss: 3.01005, kl_loss: 3.00006, obs_loss: 0.00998, reward_loss: 0.00000, value_loss: 0.00275 action_loss: 20.01911\n",
      "update_step:  74 model loss: 3.00953, kl_loss: 3.00025, obs_loss: 0.00927, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 19.99079\n",
      "update_step:  75 model loss: 3.01741, kl_loss: 3.00078, obs_loss: 0.01662, reward_loss: 0.00000, value_loss: 0.00294 action_loss: 19.97164\n",
      "update_step:  76 model loss: 3.00929, kl_loss: 3.00026, obs_loss: 0.00902, reward_loss: 0.00000, value_loss: 0.00276 action_loss: 19.95944\n",
      "update_step:  77 model loss: 3.00613, kl_loss: 3.00009, obs_loss: 0.00604, reward_loss: 0.00000, value_loss: 0.00271 action_loss: 19.97343\n",
      "update_step:  78 model loss: 3.01424, kl_loss: 3.00087, obs_loss: 0.01337, reward_loss: 0.00000, value_loss: 0.00250 action_loss: 20.00651\n",
      "update_step:  79 model loss: 3.01064, kl_loss: 3.00083, obs_loss: 0.00981, reward_loss: 0.00000, value_loss: 0.00278 action_loss: 20.02526\n",
      "update_step:  80 model loss: 3.00769, kl_loss: 3.00024, obs_loss: 0.00745, reward_loss: 0.00000, value_loss: 0.00283 action_loss: 20.05898\n",
      "update_step:  81 model loss: 3.00825, kl_loss: 3.00021, obs_loss: 0.00804, reward_loss: 0.00000, value_loss: 0.00278 action_loss: 20.04840\n",
      "update_step:  82 model loss: 3.00635, kl_loss: 3.00018, obs_loss: 0.00616, reward_loss: 0.00000, value_loss: 0.00272 action_loss: 20.03216\n",
      "update_step:  83 model loss: 3.01677, kl_loss: 3.00126, obs_loss: 0.01550, reward_loss: 0.00000, value_loss: 0.00273 action_loss: 19.98092\n",
      "update_step:  84 model loss: 3.00996, kl_loss: 3.00043, obs_loss: 0.00953, reward_loss: 0.00000, value_loss: 0.00295 action_loss: 19.95843\n",
      "update_step:  85 model loss: 3.00392, kl_loss: 3.00056, obs_loss: 0.00335, reward_loss: 0.00000, value_loss: 0.00287 action_loss: 19.95201\n",
      "update_step:  86 model loss: 3.00545, kl_loss: 3.00087, obs_loss: 0.00458, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 19.97611\n",
      "update_step:  87 model loss: 3.00795, kl_loss: 3.00068, obs_loss: 0.00727, reward_loss: 0.00000, value_loss: 0.00266 action_loss: 20.00345\n",
      "update_step:  88 model loss: 3.00536, kl_loss: 3.00071, obs_loss: 0.00464, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 20.03316\n",
      "update_step:  89 model loss: 3.00339, kl_loss: 3.00043, obs_loss: 0.00295, reward_loss: 0.00000, value_loss: 0.00335 action_loss: 20.04990\n",
      "update_step:  90 model loss: 3.00639, kl_loss: 3.00008, obs_loss: 0.00631, reward_loss: 0.00000, value_loss: 0.00277 action_loss: 20.02217\n",
      "update_step:  91 model loss: 3.00723, kl_loss: 3.00034, obs_loss: 0.00688, reward_loss: 0.00000, value_loss: 0.00277 action_loss: 19.98669\n",
      "update_step:  92 model loss: 3.00758, kl_loss: 3.00029, obs_loss: 0.00728, reward_loss: 0.00000, value_loss: 0.00300 action_loss: 19.93035\n",
      "update_step:  93 model loss: 3.01058, kl_loss: 3.00015, obs_loss: 0.01043, reward_loss: 0.00000, value_loss: 0.00320 action_loss: 19.92410\n",
      "update_step:  94 model loss: 3.01028, kl_loss: 3.00019, obs_loss: 0.01009, reward_loss: 0.00000, value_loss: 0.00299 action_loss: 19.92808\n",
      "update_step:  95 model loss: 3.01525, kl_loss: 3.00050, obs_loss: 0.01475, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 19.99153\n",
      "update_step:  96 model loss: 3.01410, kl_loss: 3.00012, obs_loss: 0.01397, reward_loss: 0.00000, value_loss: 0.00305 action_loss: 20.02987\n",
      "update_step:  97 model loss: 3.02161, kl_loss: 3.00137, obs_loss: 0.02024, reward_loss: 0.00000, value_loss: 0.00309 action_loss: 20.06588\n",
      "update_step:  98 model loss: 3.01203, kl_loss: 3.00028, obs_loss: 0.01175, reward_loss: 0.00000, value_loss: 0.00280 action_loss: 20.02298\n",
      "update_step:  99 model loss: 3.01192, kl_loss: 3.00049, obs_loss: 0.01143, reward_loss: 0.00000, value_loss: 0.00265 action_loss: 19.99677\n",
      "update_step: 100 model loss: 3.01237, kl_loss: 3.00013, obs_loss: 0.01224, reward_loss: 0.00000, value_loss: 0.00278 action_loss: 19.96854\n",
      "elasped time for update: 20.26s\n",
      "episode [  47/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.35s\n",
      "update_step:   1 model loss: 3.01838, kl_loss: 3.00041, obs_loss: 0.01797, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 19.97864\n",
      "update_step:   2 model loss: 3.01515, kl_loss: 3.00029, obs_loss: 0.01485, reward_loss: 0.00000, value_loss: 0.00269 action_loss: 19.98678\n",
      "update_step:   3 model loss: 3.01139, kl_loss: 3.00031, obs_loss: 0.01108, reward_loss: 0.00000, value_loss: 0.00267 action_loss: 20.00722\n",
      "update_step:   4 model loss: 3.01139, kl_loss: 3.00020, obs_loss: 0.01118, reward_loss: 0.00000, value_loss: 0.00270 action_loss: 20.02418\n",
      "update_step:   5 model loss: 3.01929, kl_loss: 3.00078, obs_loss: 0.01851, reward_loss: 0.00000, value_loss: 0.00282 action_loss: 20.02949\n",
      "update_step:   6 model loss: 3.00698, kl_loss: 3.00007, obs_loss: 0.00691, reward_loss: 0.00000, value_loss: 0.00284 action_loss: 20.03073\n",
      "update_step:   7 model loss: 3.00559, kl_loss: 3.00021, obs_loss: 0.00537, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 20.02056\n",
      "update_step:   8 model loss: 3.00903, kl_loss: 3.00070, obs_loss: 0.00832, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 20.01438\n",
      "update_step:   9 model loss: 3.00681, kl_loss: 3.00039, obs_loss: 0.00641, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 19.99097\n",
      "update_step:  10 model loss: 3.01209, kl_loss: 3.00091, obs_loss: 0.01118, reward_loss: 0.00001, value_loss: 0.00260 action_loss: 20.00473\n",
      "update_step:  11 model loss: 3.01274, kl_loss: 3.00115, obs_loss: 0.01159, reward_loss: 0.00000, value_loss: 0.00275 action_loss: 19.98755\n",
      "update_step:  12 model loss: 3.00581, kl_loss: 3.00140, obs_loss: 0.00441, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 19.98658\n",
      "update_step:  13 model loss: 3.00512, kl_loss: 3.00127, obs_loss: 0.00385, reward_loss: 0.00000, value_loss: 0.00257 action_loss: 19.99256\n",
      "update_step:  14 model loss: 3.00500, kl_loss: 3.00023, obs_loss: 0.00478, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 20.01413\n",
      "update_step:  15 model loss: 3.00621, kl_loss: 3.00005, obs_loss: 0.00616, reward_loss: 0.00001, value_loss: 0.00275 action_loss: 20.01851\n",
      "update_step:  16 model loss: 3.00644, kl_loss: 3.00010, obs_loss: 0.00633, reward_loss: 0.00000, value_loss: 0.00276 action_loss: 20.02455\n",
      "update_step:  17 model loss: 3.00693, kl_loss: 3.00017, obs_loss: 0.00676, reward_loss: 0.00000, value_loss: 0.00257 action_loss: 20.02800\n",
      "update_step:  18 model loss: 3.01098, kl_loss: 3.00005, obs_loss: 0.01093, reward_loss: 0.00001, value_loss: 0.00260 action_loss: 19.99288\n",
      "update_step:  19 model loss: 3.01256, kl_loss: 3.00028, obs_loss: 0.01228, reward_loss: 0.00000, value_loss: 0.00254 action_loss: 19.96106\n",
      "update_step:  20 model loss: 3.01127, kl_loss: 3.00021, obs_loss: 0.01106, reward_loss: 0.00001, value_loss: 0.00305 action_loss: 19.94085\n",
      "update_step:  21 model loss: 3.01336, kl_loss: 3.00008, obs_loss: 0.01328, reward_loss: 0.00001, value_loss: 0.00278 action_loss: 19.93190\n",
      "update_step:  22 model loss: 3.01646, kl_loss: 3.00035, obs_loss: 0.01611, reward_loss: 0.00000, value_loss: 0.00275 action_loss: 19.92844\n",
      "update_step:  23 model loss: 3.01894, kl_loss: 3.00003, obs_loss: 0.01891, reward_loss: 0.00001, value_loss: 0.00250 action_loss: 19.97644\n",
      "update_step:  24 model loss: 3.02430, kl_loss: 3.00047, obs_loss: 0.02383, reward_loss: 0.00001, value_loss: 0.00249 action_loss: 20.00323\n",
      "update_step:  25 model loss: 3.02736, kl_loss: 3.00042, obs_loss: 0.02694, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 20.03040\n",
      "update_step:  26 model loss: 3.03025, kl_loss: 3.00031, obs_loss: 0.02994, reward_loss: 0.00000, value_loss: 0.00251 action_loss: 20.02605\n",
      "update_step:  27 model loss: 3.03506, kl_loss: 3.00035, obs_loss: 0.03470, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 20.03913\n",
      "update_step:  28 model loss: 3.03613, kl_loss: 3.00021, obs_loss: 0.03592, reward_loss: 0.00001, value_loss: 0.00239 action_loss: 19.99614\n",
      "update_step:  29 model loss: 3.04430, kl_loss: 3.00068, obs_loss: 0.04361, reward_loss: 0.00001, value_loss: 0.00283 action_loss: 19.98474\n",
      "update_step:  30 model loss: 3.02792, kl_loss: 3.00005, obs_loss: 0.02786, reward_loss: 0.00000, value_loss: 0.00322 action_loss: 19.95015\n",
      "update_step:  31 model loss: 3.01925, kl_loss: 3.00030, obs_loss: 0.01895, reward_loss: 0.00000, value_loss: 0.00257 action_loss: 19.96595\n",
      "update_step:  32 model loss: 3.01446, kl_loss: 3.00037, obs_loss: 0.01408, reward_loss: 0.00000, value_loss: 0.00248 action_loss: 19.99405\n",
      "update_step:  33 model loss: 3.00888, kl_loss: 3.00013, obs_loss: 0.00874, reward_loss: 0.00001, value_loss: 0.00247 action_loss: 20.04632\n",
      "update_step:  34 model loss: 3.00923, kl_loss: 3.00007, obs_loss: 0.00916, reward_loss: 0.00001, value_loss: 0.00301 action_loss: 20.06696\n",
      "update_step:  35 model loss: 3.00762, kl_loss: 3.00004, obs_loss: 0.00758, reward_loss: 0.00000, value_loss: 0.00349 action_loss: 20.07082\n",
      "update_step:  36 model loss: 3.00540, kl_loss: 3.00000, obs_loss: 0.00540, reward_loss: 0.00001, value_loss: 0.00258 action_loss: 20.03973\n",
      "update_step:  37 model loss: 3.00808, kl_loss: 3.00000, obs_loss: 0.00807, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 19.99330\n",
      "update_step:  38 model loss: 3.00687, kl_loss: 3.00036, obs_loss: 0.00651, reward_loss: 0.00000, value_loss: 0.00271 action_loss: 19.95169\n",
      "update_step:  39 model loss: 3.00278, kl_loss: 3.00009, obs_loss: 0.00268, reward_loss: 0.00000, value_loss: 0.00311 action_loss: 19.93908\n",
      "update_step:  40 model loss: 3.00265, kl_loss: 3.00025, obs_loss: 0.00240, reward_loss: 0.00000, value_loss: 0.00272 action_loss: 19.95490\n",
      "update_step:  41 model loss: 3.00332, kl_loss: 3.00027, obs_loss: 0.00306, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 19.99676\n",
      "update_step:  42 model loss: 3.00482, kl_loss: 3.00013, obs_loss: 0.00469, reward_loss: 0.00000, value_loss: 0.00274 action_loss: 20.03163\n",
      "update_step:  43 model loss: 3.00593, kl_loss: 3.00031, obs_loss: 0.00562, reward_loss: 0.00000, value_loss: 0.00254 action_loss: 20.04537\n",
      "update_step:  44 model loss: 3.00615, kl_loss: 3.00029, obs_loss: 0.00585, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 19.99824\n",
      "update_step:  45 model loss: 3.00781, kl_loss: 3.00064, obs_loss: 0.00716, reward_loss: 0.00000, value_loss: 0.00236 action_loss: 19.96797\n",
      "update_step:  46 model loss: 3.00932, kl_loss: 3.00118, obs_loss: 0.00814, reward_loss: 0.00000, value_loss: 0.00290 action_loss: 19.91828\n",
      "update_step:  47 model loss: 3.00515, kl_loss: 3.00018, obs_loss: 0.00496, reward_loss: 0.00000, value_loss: 0.00283 action_loss: 19.91431\n",
      "update_step:  48 model loss: 3.00831, kl_loss: 3.00076, obs_loss: 0.00755, reward_loss: 0.00000, value_loss: 0.00245 action_loss: 19.94355\n",
      "update_step:  49 model loss: 3.01086, kl_loss: 3.00025, obs_loss: 0.01060, reward_loss: 0.00000, value_loss: 0.00235 action_loss: 20.01261\n",
      "update_step:  50 model loss: 3.01103, kl_loss: 3.00004, obs_loss: 0.01099, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 20.03300\n",
      "update_step:  51 model loss: 3.00979, kl_loss: 3.00016, obs_loss: 0.00962, reward_loss: 0.00000, value_loss: 0.00289 action_loss: 20.04090\n",
      "update_step:  52 model loss: 3.01033, kl_loss: 3.00023, obs_loss: 0.01009, reward_loss: 0.00000, value_loss: 0.00242 action_loss: 20.02631\n",
      "update_step:  53 model loss: 3.00894, kl_loss: 3.00007, obs_loss: 0.00886, reward_loss: 0.00000, value_loss: 0.00234 action_loss: 20.00560\n",
      "update_step:  54 model loss: 3.00855, kl_loss: 3.00007, obs_loss: 0.00847, reward_loss: 0.00000, value_loss: 0.00247 action_loss: 19.97536\n",
      "update_step:  55 model loss: 3.01015, kl_loss: 3.00025, obs_loss: 0.00990, reward_loss: 0.00000, value_loss: 0.00277 action_loss: 19.96277\n",
      "update_step:  56 model loss: 3.01059, kl_loss: 3.00030, obs_loss: 0.01029, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 19.95804\n",
      "update_step:  57 model loss: 3.00673, kl_loss: 3.00012, obs_loss: 0.00660, reward_loss: 0.00000, value_loss: 0.00242 action_loss: 19.97041\n",
      "update_step:  58 model loss: 3.00621, kl_loss: 3.00043, obs_loss: 0.00578, reward_loss: 0.00000, value_loss: 0.00231 action_loss: 19.99296\n",
      "update_step:  59 model loss: 3.00963, kl_loss: 3.00100, obs_loss: 0.00863, reward_loss: 0.00000, value_loss: 0.00239 action_loss: 19.99333\n",
      "update_step:  60 model loss: 3.00638, kl_loss: 3.00111, obs_loss: 0.00526, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 20.01395\n",
      "update_step:  61 model loss: 3.00622, kl_loss: 3.00091, obs_loss: 0.00531, reward_loss: 0.00000, value_loss: 0.00242 action_loss: 20.01145\n",
      "update_step:  62 model loss: 3.00556, kl_loss: 3.00003, obs_loss: 0.00553, reward_loss: 0.00000, value_loss: 0.00246 action_loss: 20.02011\n",
      "update_step:  63 model loss: 3.00774, kl_loss: 3.00000, obs_loss: 0.00773, reward_loss: 0.00000, value_loss: 0.00244 action_loss: 19.99286\n",
      "update_step:  64 model loss: 3.01676, kl_loss: 3.00019, obs_loss: 0.01656, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 20.00082\n",
      "update_step:  65 model loss: 3.01352, kl_loss: 3.00012, obs_loss: 0.01339, reward_loss: 0.00000, value_loss: 0.00260 action_loss: 19.97145\n",
      "update_step:  66 model loss: 3.01764, kl_loss: 3.00020, obs_loss: 0.01743, reward_loss: 0.00000, value_loss: 0.00265 action_loss: 20.01009\n",
      "update_step:  67 model loss: 3.01960, kl_loss: 3.00007, obs_loss: 0.01953, reward_loss: 0.00001, value_loss: 0.00252 action_loss: 19.98391\n",
      "update_step:  68 model loss: 3.02822, kl_loss: 3.00030, obs_loss: 0.02792, reward_loss: 0.00001, value_loss: 0.00257 action_loss: 20.03560\n",
      "update_step:  69 model loss: 3.03209, kl_loss: 3.00006, obs_loss: 0.03202, reward_loss: 0.00001, value_loss: 0.00283 action_loss: 20.01250\n",
      "update_step:  70 model loss: 3.04488, kl_loss: 3.00016, obs_loss: 0.04471, reward_loss: 0.00001, value_loss: 0.00288 action_loss: 20.05585\n",
      "update_step:  71 model loss: 3.05324, kl_loss: 3.00026, obs_loss: 0.05297, reward_loss: 0.00001, value_loss: 0.00269 action_loss: 19.97807\n",
      "update_step:  72 model loss: 3.07926, kl_loss: 3.00007, obs_loss: 0.07918, reward_loss: 0.00001, value_loss: 0.00278 action_loss: 19.98921\n",
      "update_step:  73 model loss: 3.09185, kl_loss: 3.00021, obs_loss: 0.09163, reward_loss: 0.00001, value_loss: 0.00288 action_loss: 19.91859\n",
      "update_step:  74 model loss: 3.12412, kl_loss: 3.00050, obs_loss: 0.12360, reward_loss: 0.00002, value_loss: 0.00283 action_loss: 19.99941\n",
      "update_step:  75 model loss: 3.12584, kl_loss: 3.00016, obs_loss: 0.12567, reward_loss: 0.00001, value_loss: 0.00291 action_loss: 19.95198\n",
      "update_step:  76 model loss: 3.13415, kl_loss: 3.00004, obs_loss: 0.13409, reward_loss: 0.00001, value_loss: 0.00325 action_loss: 20.03222\n",
      "update_step:  77 model loss: 3.09191, kl_loss: 3.00040, obs_loss: 0.09150, reward_loss: 0.00001, value_loss: 0.00331 action_loss: 19.98726\n",
      "update_step:  78 model loss: 3.05267, kl_loss: 3.00000, obs_loss: 0.05266, reward_loss: 0.00001, value_loss: 0.00353 action_loss: 20.03844\n",
      "update_step:  79 model loss: 3.02172, kl_loss: 3.00030, obs_loss: 0.02141, reward_loss: 0.00001, value_loss: 0.00325 action_loss: 20.00704\n",
      "update_step:  80 model loss: 3.00533, kl_loss: 3.00021, obs_loss: 0.00511, reward_loss: 0.00000, value_loss: 0.00311 action_loss: 19.96634\n",
      "update_step:  81 model loss: 3.01647, kl_loss: 3.00041, obs_loss: 0.01606, reward_loss: 0.00001, value_loss: 0.00362 action_loss: 20.02173\n",
      "update_step:  82 model loss: 3.02870, kl_loss: 3.00016, obs_loss: 0.02853, reward_loss: 0.00001, value_loss: 0.00313 action_loss: 19.98690\n",
      "update_step:  83 model loss: 3.04343, kl_loss: 3.00049, obs_loss: 0.04293, reward_loss: 0.00001, value_loss: 0.00380 action_loss: 20.00703\n",
      "update_step:  84 model loss: 3.03833, kl_loss: 3.00060, obs_loss: 0.03772, reward_loss: 0.00001, value_loss: 0.00348 action_loss: 19.95376\n",
      "update_step:  85 model loss: 3.03188, kl_loss: 3.00028, obs_loss: 0.03160, reward_loss: 0.00001, value_loss: 0.00418 action_loss: 19.96763\n",
      "update_step:  86 model loss: 3.01813, kl_loss: 3.00027, obs_loss: 0.01786, reward_loss: 0.00001, value_loss: 0.00365 action_loss: 19.93130\n",
      "update_step:  87 model loss: 3.01956, kl_loss: 3.00073, obs_loss: 0.01881, reward_loss: 0.00001, value_loss: 0.00340 action_loss: 19.97347\n",
      "update_step:  88 model loss: 3.00441, kl_loss: 3.00034, obs_loss: 0.00407, reward_loss: 0.00001, value_loss: 0.00331 action_loss: 20.01317\n",
      "update_step:  89 model loss: 3.00706, kl_loss: 3.00050, obs_loss: 0.00656, reward_loss: 0.00000, value_loss: 0.00350 action_loss: 20.04513\n",
      "update_step:  90 model loss: 3.00984, kl_loss: 3.00031, obs_loss: 0.00953, reward_loss: 0.00001, value_loss: 0.00394 action_loss: 20.09633\n",
      "update_step:  91 model loss: 3.02032, kl_loss: 3.00142, obs_loss: 0.01890, reward_loss: 0.00001, value_loss: 0.00404 action_loss: 20.06659\n",
      "update_step:  92 model loss: 3.01275, kl_loss: 3.00124, obs_loss: 0.01150, reward_loss: 0.00001, value_loss: 0.00369 action_loss: 20.05493\n",
      "update_step:  93 model loss: 3.01511, kl_loss: 3.00190, obs_loss: 0.01320, reward_loss: 0.00001, value_loss: 0.00353 action_loss: 19.98432\n",
      "update_step:  94 model loss: 3.01963, kl_loss: 3.00087, obs_loss: 0.01876, reward_loss: 0.00000, value_loss: 0.00353 action_loss: 19.96447\n",
      "update_step:  95 model loss: 3.01157, kl_loss: 3.00068, obs_loss: 0.01088, reward_loss: 0.00000, value_loss: 0.00328 action_loss: 19.95602\n",
      "update_step:  96 model loss: 3.01049, kl_loss: 3.00014, obs_loss: 0.01034, reward_loss: 0.00000, value_loss: 0.00292 action_loss: 19.99741\n",
      "update_step:  97 model loss: 3.00787, kl_loss: 3.00036, obs_loss: 0.00750, reward_loss: 0.00001, value_loss: 0.00333 action_loss: 20.03550\n",
      "update_step:  98 model loss: 3.00722, kl_loss: 3.00019, obs_loss: 0.00702, reward_loss: 0.00000, value_loss: 0.00384 action_loss: 20.06036\n",
      "update_step:  99 model loss: 3.00651, kl_loss: 3.00005, obs_loss: 0.00645, reward_loss: 0.00001, value_loss: 0.00384 action_loss: 20.09038\n",
      "update_step: 100 model loss: 3.00776, kl_loss: 3.00016, obs_loss: 0.00759, reward_loss: 0.00001, value_loss: 0.00339 action_loss: 20.04037\n",
      "elasped time for update: 20.43s\n",
      "episode [  48/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.01868, kl_loss: 3.00066, obs_loss: 0.01801, reward_loss: 0.00000, value_loss: 0.00310 action_loss: 19.97448\n",
      "update_step:   2 model loss: 3.00578, kl_loss: 3.00075, obs_loss: 0.00502, reward_loss: 0.00000, value_loss: 0.00457 action_loss: 19.89098\n",
      "update_step:   3 model loss: 3.00479, kl_loss: 3.00126, obs_loss: 0.00353, reward_loss: 0.00000, value_loss: 0.00556 action_loss: 19.84703\n",
      "update_step:   4 model loss: 3.01455, kl_loss: 3.00168, obs_loss: 0.01286, reward_loss: 0.00000, value_loss: 0.00439 action_loss: 19.84426\n",
      "update_step:   5 model loss: 3.00788, kl_loss: 3.00087, obs_loss: 0.00700, reward_loss: 0.00000, value_loss: 0.00308 action_loss: 19.89779\n",
      "update_step:   6 model loss: 3.00528, kl_loss: 3.00033, obs_loss: 0.00495, reward_loss: 0.00000, value_loss: 0.00293 action_loss: 20.00352\n",
      "update_step:   7 model loss: 3.00431, kl_loss: 3.00013, obs_loss: 0.00418, reward_loss: 0.00000, value_loss: 0.00487 action_loss: 20.08767\n",
      "update_step:   8 model loss: 3.00857, kl_loss: 3.00023, obs_loss: 0.00833, reward_loss: 0.00000, value_loss: 0.00492 action_loss: 20.11139\n",
      "update_step:   9 model loss: 3.00182, kl_loss: 3.00005, obs_loss: 0.00177, reward_loss: 0.00000, value_loss: 0.00281 action_loss: 20.08274\n",
      "update_step:  10 model loss: 3.00317, kl_loss: 3.00007, obs_loss: 0.00310, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 20.01415\n",
      "update_step:  11 model loss: 3.00421, kl_loss: 3.00001, obs_loss: 0.00420, reward_loss: 0.00000, value_loss: 0.00368 action_loss: 19.96663\n",
      "update_step:  12 model loss: 3.00619, kl_loss: 3.00009, obs_loss: 0.00609, reward_loss: 0.00000, value_loss: 0.00447 action_loss: 19.94690\n",
      "update_step:  13 model loss: 3.00793, kl_loss: 3.00032, obs_loss: 0.00761, reward_loss: 0.00000, value_loss: 0.00314 action_loss: 19.98701\n",
      "update_step:  14 model loss: 3.00905, kl_loss: 3.00038, obs_loss: 0.00866, reward_loss: 0.00000, value_loss: 0.00264 action_loss: 20.03876\n",
      "update_step:  15 model loss: 3.01564, kl_loss: 3.00231, obs_loss: 0.01332, reward_loss: 0.00000, value_loss: 0.00301 action_loss: 20.08713\n",
      "update_step:  16 model loss: 3.00479, kl_loss: 3.00199, obs_loss: 0.00279, reward_loss: 0.00000, value_loss: 0.00369 action_loss: 20.08679\n",
      "update_step:  17 model loss: 3.00391, kl_loss: 3.00063, obs_loss: 0.00328, reward_loss: 0.00000, value_loss: 0.00338 action_loss: 20.06510\n",
      "update_step:  18 model loss: 3.00395, kl_loss: 3.00042, obs_loss: 0.00352, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 20.01318\n",
      "update_step:  19 model loss: 3.00273, kl_loss: 3.00006, obs_loss: 0.00267, reward_loss: 0.00000, value_loss: 0.00262 action_loss: 19.95371\n",
      "update_step:  20 model loss: 3.00199, kl_loss: 3.00023, obs_loss: 0.00176, reward_loss: 0.00000, value_loss: 0.00308 action_loss: 19.91770\n",
      "update_step:  21 model loss: 3.01111, kl_loss: 3.00036, obs_loss: 0.01075, reward_loss: 0.00000, value_loss: 0.00336 action_loss: 19.90164\n",
      "update_step:  22 model loss: 3.00361, kl_loss: 3.00049, obs_loss: 0.00311, reward_loss: 0.00000, value_loss: 0.00283 action_loss: 19.92335\n",
      "update_step:  23 model loss: 3.00481, kl_loss: 3.00004, obs_loss: 0.00477, reward_loss: 0.00000, value_loss: 0.00235 action_loss: 19.96445\n",
      "update_step:  24 model loss: 3.00733, kl_loss: 3.00042, obs_loss: 0.00690, reward_loss: 0.00000, value_loss: 0.00256 action_loss: 20.01239\n",
      "update_step:  25 model loss: 3.00312, kl_loss: 3.00001, obs_loss: 0.00311, reward_loss: 0.00000, value_loss: 0.00295 action_loss: 20.03032\n",
      "update_step:  26 model loss: 3.00392, kl_loss: 3.00017, obs_loss: 0.00375, reward_loss: 0.00000, value_loss: 0.00284 action_loss: 20.03682\n",
      "update_step:  27 model loss: 3.00887, kl_loss: 3.00028, obs_loss: 0.00859, reward_loss: 0.00000, value_loss: 0.00238 action_loss: 19.99859\n",
      "update_step:  28 model loss: 3.00725, kl_loss: 3.00083, obs_loss: 0.00641, reward_loss: 0.00000, value_loss: 0.00244 action_loss: 19.96134\n",
      "update_step:  29 model loss: 3.00757, kl_loss: 3.00090, obs_loss: 0.00666, reward_loss: 0.00000, value_loss: 0.00261 action_loss: 19.93114\n",
      "update_step:  30 model loss: 3.00605, kl_loss: 3.00066, obs_loss: 0.00539, reward_loss: 0.00000, value_loss: 0.00273 action_loss: 19.93067\n",
      "update_step:  31 model loss: 3.01620, kl_loss: 3.00075, obs_loss: 0.01545, reward_loss: 0.00000, value_loss: 0.00250 action_loss: 19.96228\n",
      "update_step:  32 model loss: 3.01231, kl_loss: 3.00021, obs_loss: 0.01209, reward_loss: 0.00000, value_loss: 0.00229 action_loss: 19.99273\n",
      "update_step:  33 model loss: 3.02350, kl_loss: 3.00071, obs_loss: 0.02278, reward_loss: 0.00000, value_loss: 0.00264 action_loss: 20.03478\n",
      "update_step:  34 model loss: 3.02364, kl_loss: 3.00021, obs_loss: 0.02342, reward_loss: 0.00000, value_loss: 0.00268 action_loss: 20.04117\n",
      "update_step:  35 model loss: 3.03690, kl_loss: 3.00176, obs_loss: 0.03514, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 20.03325\n",
      "update_step:  36 model loss: 3.03639, kl_loss: 3.00062, obs_loss: 0.03577, reward_loss: 0.00000, value_loss: 0.00235 action_loss: 19.99041\n",
      "update_step:  37 model loss: 3.05043, kl_loss: 3.00053, obs_loss: 0.04989, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 19.96841\n",
      "update_step:  38 model loss: 3.06035, kl_loss: 3.00079, obs_loss: 0.05956, reward_loss: 0.00000, value_loss: 0.00263 action_loss: 19.96465\n",
      "update_step:  39 model loss: 3.06091, kl_loss: 3.00038, obs_loss: 0.06052, reward_loss: 0.00000, value_loss: 0.00240 action_loss: 19.97894\n",
      "update_step:  40 model loss: 3.06061, kl_loss: 3.00035, obs_loss: 0.06026, reward_loss: 0.00000, value_loss: 0.00236 action_loss: 19.98326\n",
      "update_step:  41 model loss: 3.05247, kl_loss: 3.00021, obs_loss: 0.05226, reward_loss: 0.00000, value_loss: 0.00238 action_loss: 19.98432\n",
      "update_step:  42 model loss: 3.04787, kl_loss: 3.00053, obs_loss: 0.04734, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 20.00665\n",
      "update_step:  43 model loss: 3.03924, kl_loss: 3.00026, obs_loss: 0.03898, reward_loss: 0.00000, value_loss: 0.00259 action_loss: 20.00152\n",
      "update_step:  44 model loss: 3.03177, kl_loss: 3.00016, obs_loss: 0.03160, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 20.02664\n",
      "update_step:  45 model loss: 3.02454, kl_loss: 3.00013, obs_loss: 0.02440, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 20.00330\n",
      "update_step:  46 model loss: 3.02546, kl_loss: 3.00055, obs_loss: 0.02490, reward_loss: 0.00000, value_loss: 0.00245 action_loss: 19.99875\n",
      "update_step:  47 model loss: 3.01276, kl_loss: 3.00032, obs_loss: 0.01244, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 19.96516\n",
      "update_step:  48 model loss: 3.00692, kl_loss: 3.00044, obs_loss: 0.00648, reward_loss: 0.00000, value_loss: 0.00290 action_loss: 19.95611\n",
      "update_step:  49 model loss: 3.00918, kl_loss: 3.00026, obs_loss: 0.00892, reward_loss: 0.00000, value_loss: 0.00260 action_loss: 19.94863\n",
      "update_step:  50 model loss: 3.01746, kl_loss: 3.00081, obs_loss: 0.01664, reward_loss: 0.00000, value_loss: 0.00232 action_loss: 19.96557\n",
      "update_step:  51 model loss: 3.01611, kl_loss: 3.00066, obs_loss: 0.01544, reward_loss: 0.00000, value_loss: 0.00240 action_loss: 20.00978\n",
      "update_step:  52 model loss: 3.01844, kl_loss: 3.00054, obs_loss: 0.01790, reward_loss: 0.00001, value_loss: 0.00264 action_loss: 20.01924\n",
      "update_step:  53 model loss: 3.02071, kl_loss: 3.00007, obs_loss: 0.02064, reward_loss: 0.00000, value_loss: 0.00297 action_loss: 20.04506\n",
      "update_step:  54 model loss: 3.02623, kl_loss: 3.00000, obs_loss: 0.02623, reward_loss: 0.00000, value_loss: 0.00246 action_loss: 20.01314\n",
      "update_step:  55 model loss: 3.02420, kl_loss: 3.00024, obs_loss: 0.02396, reward_loss: 0.00000, value_loss: 0.00237 action_loss: 19.99244\n",
      "update_step:  56 model loss: 3.02405, kl_loss: 3.00022, obs_loss: 0.02382, reward_loss: 0.00000, value_loss: 0.00276 action_loss: 19.91440\n",
      "update_step:  57 model loss: 3.01799, kl_loss: 3.00010, obs_loss: 0.01789, reward_loss: 0.00001, value_loss: 0.00290 action_loss: 19.93330\n",
      "update_step:  58 model loss: 3.02625, kl_loss: 3.00077, obs_loss: 0.02548, reward_loss: 0.00000, value_loss: 0.00247 action_loss: 19.95362\n",
      "update_step:  59 model loss: 3.00740, kl_loss: 3.00016, obs_loss: 0.00724, reward_loss: 0.00000, value_loss: 0.00258 action_loss: 20.02841\n",
      "update_step:  60 model loss: 3.00921, kl_loss: 3.00100, obs_loss: 0.00821, reward_loss: 0.00000, value_loss: 0.00303 action_loss: 20.06527\n",
      "update_step:  61 model loss: 3.01050, kl_loss: 3.00211, obs_loss: 0.00838, reward_loss: 0.00000, value_loss: 0.00290 action_loss: 20.07187\n",
      "update_step:  62 model loss: 3.00893, kl_loss: 3.00083, obs_loss: 0.00809, reward_loss: 0.00000, value_loss: 0.00260 action_loss: 20.04324\n",
      "update_step:  63 model loss: 3.00995, kl_loss: 3.00065, obs_loss: 0.00930, reward_loss: 0.00000, value_loss: 0.00245 action_loss: 19.98531\n",
      "update_step:  64 model loss: 3.01566, kl_loss: 3.00047, obs_loss: 0.01518, reward_loss: 0.00000, value_loss: 0.00294 action_loss: 19.95817\n",
      "update_step:  65 model loss: 3.01996, kl_loss: 3.00058, obs_loss: 0.01937, reward_loss: 0.00000, value_loss: 0.00267 action_loss: 19.93451\n",
      "update_step:  66 model loss: 3.01492, kl_loss: 3.00037, obs_loss: 0.01454, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 19.98087\n",
      "update_step:  67 model loss: 3.01269, kl_loss: 3.00009, obs_loss: 0.01259, reward_loss: 0.00000, value_loss: 0.00227 action_loss: 19.99648\n",
      "update_step:  68 model loss: 3.01742, kl_loss: 3.00026, obs_loss: 0.01716, reward_loss: 0.00000, value_loss: 0.00271 action_loss: 20.04645\n",
      "update_step:  69 model loss: 3.01173, kl_loss: 3.00022, obs_loss: 0.01150, reward_loss: 0.00000, value_loss: 0.00279 action_loss: 20.03637\n",
      "update_step:  70 model loss: 3.01223, kl_loss: 3.00032, obs_loss: 0.01191, reward_loss: 0.00000, value_loss: 0.00247 action_loss: 20.03188\n",
      "update_step:  71 model loss: 3.00966, kl_loss: 3.00048, obs_loss: 0.00918, reward_loss: 0.00000, value_loss: 0.00230 action_loss: 19.98024\n",
      "update_step:  72 model loss: 3.00987, kl_loss: 3.00060, obs_loss: 0.00927, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 19.95709\n",
      "update_step:  73 model loss: 3.01067, kl_loss: 3.00145, obs_loss: 0.00922, reward_loss: 0.00000, value_loss: 0.00270 action_loss: 19.93760\n",
      "update_step:  74 model loss: 3.00967, kl_loss: 3.00017, obs_loss: 0.00950, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 19.98997\n",
      "update_step:  75 model loss: 3.00858, kl_loss: 3.00026, obs_loss: 0.00832, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 20.02946\n",
      "update_step:  76 model loss: 3.00655, kl_loss: 3.00003, obs_loss: 0.00652, reward_loss: 0.00000, value_loss: 0.00260 action_loss: 20.02810\n",
      "update_step:  77 model loss: 3.00757, kl_loss: 3.00035, obs_loss: 0.00722, reward_loss: 0.00000, value_loss: 0.00238 action_loss: 20.00803\n",
      "update_step:  78 model loss: 3.00767, kl_loss: 3.00067, obs_loss: 0.00700, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 19.96231\n",
      "update_step:  79 model loss: 3.00652, kl_loss: 3.00049, obs_loss: 0.00602, reward_loss: 0.00000, value_loss: 0.00253 action_loss: 19.94063\n",
      "update_step:  80 model loss: 3.00370, kl_loss: 3.00051, obs_loss: 0.00319, reward_loss: 0.00000, value_loss: 0.00246 action_loss: 19.94138\n",
      "update_step:  81 model loss: 3.00458, kl_loss: 3.00030, obs_loss: 0.00428, reward_loss: 0.00000, value_loss: 0.00241 action_loss: 19.97889\n",
      "update_step:  82 model loss: 3.00607, kl_loss: 3.00027, obs_loss: 0.00580, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 20.00649\n",
      "update_step:  83 model loss: 3.00676, kl_loss: 3.00027, obs_loss: 0.00648, reward_loss: 0.00000, value_loss: 0.00273 action_loss: 20.02210\n",
      "update_step:  84 model loss: 3.00818, kl_loss: 3.00051, obs_loss: 0.00767, reward_loss: 0.00000, value_loss: 0.00244 action_loss: 20.02544\n",
      "update_step:  85 model loss: 3.00586, kl_loss: 3.00045, obs_loss: 0.00541, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 20.00077\n",
      "update_step:  86 model loss: 3.00510, kl_loss: 3.00021, obs_loss: 0.00489, reward_loss: 0.00000, value_loss: 0.00241 action_loss: 19.97978\n",
      "update_step:  87 model loss: 3.01369, kl_loss: 3.00043, obs_loss: 0.01326, reward_loss: 0.00000, value_loss: 0.00243 action_loss: 19.96056\n",
      "update_step:  88 model loss: 3.01438, kl_loss: 3.00092, obs_loss: 0.01346, reward_loss: 0.00000, value_loss: 0.00234 action_loss: 19.97466\n",
      "update_step:  89 model loss: 3.01078, kl_loss: 3.00095, obs_loss: 0.00982, reward_loss: 0.00000, value_loss: 0.00225 action_loss: 19.97003\n",
      "update_step:  90 model loss: 3.01635, kl_loss: 3.00076, obs_loss: 0.01559, reward_loss: 0.00001, value_loss: 0.00244 action_loss: 20.02079\n",
      "update_step:  91 model loss: 3.01663, kl_loss: 3.00066, obs_loss: 0.01596, reward_loss: 0.00001, value_loss: 0.00249 action_loss: 20.01523\n",
      "update_step:  92 model loss: 3.00735, kl_loss: 3.00011, obs_loss: 0.00723, reward_loss: 0.00000, value_loss: 0.00249 action_loss: 20.00795\n",
      "update_step:  93 model loss: 3.01535, kl_loss: 3.00104, obs_loss: 0.01430, reward_loss: 0.00000, value_loss: 0.00225 action_loss: 19.99735\n",
      "update_step:  94 model loss: 3.00533, kl_loss: 3.00034, obs_loss: 0.00498, reward_loss: 0.00000, value_loss: 0.00236 action_loss: 19.99285\n",
      "update_step:  95 model loss: 3.00637, kl_loss: 3.00043, obs_loss: 0.00594, reward_loss: 0.00000, value_loss: 0.00233 action_loss: 19.97827\n",
      "update_step:  96 model loss: 3.00577, kl_loss: 3.00008, obs_loss: 0.00568, reward_loss: 0.00001, value_loss: 0.00249 action_loss: 19.97469\n",
      "update_step:  97 model loss: 3.01165, kl_loss: 3.00055, obs_loss: 0.01110, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 19.97509\n",
      "update_step:  98 model loss: 3.00784, kl_loss: 3.00100, obs_loss: 0.00684, reward_loss: 0.00000, value_loss: 0.00233 action_loss: 19.96875\n",
      "update_step:  99 model loss: 3.01147, kl_loss: 3.00333, obs_loss: 0.00814, reward_loss: 0.00001, value_loss: 0.00228 action_loss: 19.99713\n",
      "update_step: 100 model loss: 3.00644, kl_loss: 3.00309, obs_loss: 0.00335, reward_loss: 0.00000, value_loss: 0.00227 action_loss: 20.02317\n",
      "elasped time for update: 20.14s\n",
      "episode [  49/ 100] is collected. Total reward is -2.000000\n",
      "elasped time for interaction: 0.34s\n",
      "update_step:   1 model loss: 3.00732, kl_loss: 3.00228, obs_loss: 0.00503, reward_loss: 0.00001, value_loss: 0.00263 action_loss: 20.02549\n",
      "update_step:   2 model loss: 3.00510, kl_loss: 3.00131, obs_loss: 0.00378, reward_loss: 0.00001, value_loss: 0.00235 action_loss: 20.02081\n",
      "update_step:   3 model loss: 3.00416, kl_loss: 3.00034, obs_loss: 0.00381, reward_loss: 0.00000, value_loss: 0.00252 action_loss: 20.01269\n",
      "update_step:   4 model loss: 3.00177, kl_loss: 3.00000, obs_loss: 0.00176, reward_loss: 0.00001, value_loss: 0.00242 action_loss: 19.98975\n",
      "update_step:   5 model loss: 3.00908, kl_loss: 3.00011, obs_loss: 0.00896, reward_loss: 0.00001, value_loss: 0.00247 action_loss: 19.97593\n",
      "update_step:   6 model loss: 3.00285, kl_loss: 3.00000, obs_loss: 0.00285, reward_loss: 0.00000, value_loss: 0.00255 action_loss: 19.98463\n",
      "update_step:   7 model loss: 3.00199, kl_loss: 3.00000, obs_loss: 0.00198, reward_loss: 0.00001, value_loss: 0.00246 action_loss: 19.99604\n",
      "update_step:   8 model loss: 3.00217, kl_loss: 3.00001, obs_loss: 0.00216, reward_loss: 0.00000, value_loss: 0.00254 action_loss: 20.00575\n",
      "update_step:   9 model loss: 3.00174, kl_loss: 3.00000, obs_loss: 0.00173, reward_loss: 0.00000, value_loss: 0.00241 action_loss: 20.01990\n",
      "update_step:  10 model loss: 3.00734, kl_loss: 3.00040, obs_loss: 0.00694, reward_loss: 0.00001, value_loss: 0.00254 action_loss: 20.01477\n",
      "update_step:  11 model loss: 3.01591, kl_loss: 3.00079, obs_loss: 0.01511, reward_loss: 0.00000, value_loss: 0.00241 action_loss: 19.99432\n",
      "update_step:  12 model loss: 3.00765, kl_loss: 3.00034, obs_loss: 0.00730, reward_loss: 0.00000, value_loss: 0.00265 action_loss: 19.98404\n",
      "update_step:  13 model loss: 3.00613, kl_loss: 3.00087, obs_loss: 0.00525, reward_loss: 0.00001, value_loss: 0.00247 action_loss: 19.97039\n",
      "update_step:  14 model loss: 3.00454, kl_loss: 3.00164, obs_loss: 0.00290, reward_loss: 0.00000, value_loss: 0.00235 action_loss: 19.97173\n",
      "update_step:  15 model loss: 3.00541, kl_loss: 3.00125, obs_loss: 0.00415, reward_loss: 0.00000, value_loss: 0.00241 action_loss: 19.98694\n",
      "update_step:  16 model loss: 3.00969, kl_loss: 3.00150, obs_loss: 0.00819, reward_loss: 0.00000, value_loss: 0.00235 action_loss: 19.99804\n",
      "update_step:  17 model loss: 3.00474, kl_loss: 3.00129, obs_loss: 0.00345, reward_loss: 0.00000, value_loss: 0.00246 action_loss: 20.00105\n",
      "update_step:  18 model loss: 3.01194, kl_loss: 3.00277, obs_loss: 0.00916, reward_loss: 0.00000, value_loss: 0.00227 action_loss: 20.00921\n",
      "update_step:  19 model loss: 3.01071, kl_loss: 3.00095, obs_loss: 0.00976, reward_loss: 0.00000, value_loss: 0.00229 action_loss: 19.99560\n",
      "update_step:  20 model loss: 3.00384, kl_loss: 3.00031, obs_loss: 0.00353, reward_loss: 0.00000, value_loss: 0.00224 action_loss: 19.99184\n",
      "update_step:  21 model loss: 3.01177, kl_loss: 3.00070, obs_loss: 0.01107, reward_loss: 0.00000, value_loss: 0.00233 action_loss: 19.99077\n",
      "update_step:  22 model loss: 3.00779, kl_loss: 3.00051, obs_loss: 0.00728, reward_loss: 0.00000, value_loss: 0.00236 action_loss: 20.00460\n",
      "update_step:  23 model loss: 3.00725, kl_loss: 3.00035, obs_loss: 0.00689, reward_loss: 0.00000, value_loss: 0.00224 action_loss: 20.00281\n",
      "update_step:  24 model loss: 3.01015, kl_loss: 3.00017, obs_loss: 0.00998, reward_loss: 0.00001, value_loss: 0.00231 action_loss: 20.01469\n",
      "update_step:  25 model loss: 3.00540, kl_loss: 3.00000, obs_loss: 0.00539, reward_loss: 0.00001, value_loss: 0.00223 action_loss: 19.99585\n",
      "update_step:  26 model loss: 3.01305, kl_loss: 3.00109, obs_loss: 0.01195, reward_loss: 0.00000, value_loss: 0.00222 action_loss: 20.01074\n",
      "update_step:  27 model loss: 3.00991, kl_loss: 3.00147, obs_loss: 0.00844, reward_loss: 0.00000, value_loss: 0.00223 action_loss: 19.99395\n",
      "update_step:  28 model loss: 3.01071, kl_loss: 3.00156, obs_loss: 0.00915, reward_loss: 0.00000, value_loss: 0.00224 action_loss: 19.99510\n",
      "update_step:  29 model loss: 3.00956, kl_loss: 3.00163, obs_loss: 0.00793, reward_loss: 0.00000, value_loss: 0.00231 action_loss: 19.98193\n",
      "update_step:  30 model loss: 3.00747, kl_loss: 3.00043, obs_loss: 0.00704, reward_loss: 0.00001, value_loss: 0.00248 action_loss: 20.04494\n",
      "update_step:  31 model loss: 3.01262, kl_loss: 3.00028, obs_loss: 0.01234, reward_loss: 0.00001, value_loss: 0.00271 action_loss: 20.04521\n",
      "update_step:  32 model loss: 3.01334, kl_loss: 3.00031, obs_loss: 0.01302, reward_loss: 0.00000, value_loss: 0.00251 action_loss: 20.03996\n",
      "update_step:  33 model loss: 3.01544, kl_loss: 3.00063, obs_loss: 0.01480, reward_loss: 0.00000, value_loss: 0.00225 action_loss: 19.96298\n",
      "update_step:  34 model loss: 3.02217, kl_loss: 3.00035, obs_loss: 0.02182, reward_loss: 0.00000, value_loss: 0.00296 action_loss: 19.94219\n",
      "update_step:  35 model loss: 3.02783, kl_loss: 3.00036, obs_loss: 0.02747, reward_loss: 0.00001, value_loss: 0.00316 action_loss: 19.88066\n",
      "update_step:  36 model loss: 3.03320, kl_loss: 3.00001, obs_loss: 0.03318, reward_loss: 0.00001, value_loss: 0.00288 action_loss: 19.92518\n",
      "update_step:  37 model loss: 3.04203, kl_loss: 3.00009, obs_loss: 0.04193, reward_loss: 0.00001, value_loss: 0.00291 action_loss: 19.90135\n",
      "update_step:  38 model loss: 3.05791, kl_loss: 3.00072, obs_loss: 0.05719, reward_loss: 0.00001, value_loss: 0.00256 action_loss: 20.00538\n",
      "update_step:  39 model loss: 3.06469, kl_loss: 3.00000, obs_loss: 0.06469, reward_loss: 0.00001, value_loss: 0.00329 action_loss: 19.95264\n",
      "update_step:  40 model loss: 3.07723, kl_loss: 3.00024, obs_loss: 0.07698, reward_loss: 0.00001, value_loss: 0.00327 action_loss: 20.02359\n",
      "update_step:  41 model loss: 3.09594, kl_loss: 3.00053, obs_loss: 0.09540, reward_loss: 0.00001, value_loss: 0.00386 action_loss: 20.02994\n",
      "update_step:  42 model loss: 3.10204, kl_loss: 3.00039, obs_loss: 0.10164, reward_loss: 0.00001, value_loss: 0.00417 action_loss: 20.14385\n",
      "update_step:  43 model loss: 3.10372, kl_loss: 3.00093, obs_loss: 0.10277, reward_loss: 0.00001, value_loss: 0.00334 action_loss: 20.01878\n",
      "update_step:  44 model loss: 3.12878, kl_loss: 3.00038, obs_loss: 0.12839, reward_loss: 0.00002, value_loss: 0.00377 action_loss: 20.04941\n",
      "update_step:  45 model loss: 3.08936, kl_loss: 3.00024, obs_loss: 0.08910, reward_loss: 0.00002, value_loss: 0.00352 action_loss: 19.96750\n",
      "update_step:  46 model loss: 3.07652, kl_loss: 3.00053, obs_loss: 0.07598, reward_loss: 0.00001, value_loss: 0.00414 action_loss: 19.96186\n",
      "update_step:  47 model loss: 3.02850, kl_loss: 3.00000, obs_loss: 0.02849, reward_loss: 0.00001, value_loss: 0.00493 action_loss: 19.90637\n",
      "update_step:  48 model loss: 3.02597, kl_loss: 3.00025, obs_loss: 0.02571, reward_loss: 0.00001, value_loss: 0.00331 action_loss: 19.96018\n",
      "update_step:  49 model loss: 3.02451, kl_loss: 3.00000, obs_loss: 0.02451, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 20.01132\n",
      "update_step:  50 model loss: 3.01844, kl_loss: 3.00000, obs_loss: 0.01843, reward_loss: 0.00001, value_loss: 0.00358 action_loss: 20.02526\n",
      "update_step:  51 model loss: 3.03097, kl_loss: 3.00000, obs_loss: 0.03096, reward_loss: 0.00001, value_loss: 0.00423 action_loss: 19.99513\n",
      "update_step:  52 model loss: 3.01646, kl_loss: 3.00000, obs_loss: 0.01645, reward_loss: 0.00001, value_loss: 0.00393 action_loss: 19.98939\n",
      "update_step:  53 model loss: 3.06210, kl_loss: 3.00033, obs_loss: 0.06176, reward_loss: 0.00001, value_loss: 0.00307 action_loss: 19.92230\n",
      "update_step:  54 model loss: 3.08241, kl_loss: 3.00040, obs_loss: 0.08200, reward_loss: 0.00001, value_loss: 0.00383 action_loss: 19.96570\n",
      "update_step:  55 model loss: 3.11433, kl_loss: 3.00005, obs_loss: 0.11427, reward_loss: 0.00001, value_loss: 0.00336 action_loss: 19.89556\n",
      "update_step:  56 model loss: 3.13943, kl_loss: 3.00121, obs_loss: 0.13819, reward_loss: 0.00002, value_loss: 0.00412 action_loss: 19.99374\n",
      "update_step:  57 model loss: 3.10657, kl_loss: 3.00099, obs_loss: 0.10556, reward_loss: 0.00002, value_loss: 0.00432 action_loss: 19.91746\n",
      "update_step:  58 model loss: 3.09551, kl_loss: 3.00341, obs_loss: 0.09210, reward_loss: 0.00001, value_loss: 0.00384 action_loss: 19.98766\n",
      "update_step:  59 model loss: 3.06255, kl_loss: 3.00226, obs_loss: 0.06028, reward_loss: 0.00001, value_loss: 0.00413 action_loss: 20.05444\n",
      "update_step:  60 model loss: 3.04486, kl_loss: 3.00076, obs_loss: 0.04409, reward_loss: 0.00001, value_loss: 0.00539 action_loss: 20.12123\n",
      "update_step:  61 model loss: 3.03952, kl_loss: 3.00001, obs_loss: 0.03950, reward_loss: 0.00001, value_loss: 0.00620 action_loss: 20.20534\n",
      "update_step:  62 model loss: 3.04655, kl_loss: 3.00046, obs_loss: 0.04608, reward_loss: 0.00001, value_loss: 0.00427 action_loss: 20.11931\n",
      "update_step:  63 model loss: 3.05488, kl_loss: 3.00021, obs_loss: 0.05466, reward_loss: 0.00001, value_loss: 0.00525 action_loss: 19.97469\n",
      "update_step:  64 model loss: 3.03679, kl_loss: 3.00068, obs_loss: 0.03609, reward_loss: 0.00001, value_loss: 0.00791 action_loss: 19.83624\n",
      "update_step:  65 model loss: 3.01850, kl_loss: 3.00073, obs_loss: 0.01777, reward_loss: 0.00001, value_loss: 0.00582 action_loss: 19.84844\n",
      "update_step:  66 model loss: 3.02996, kl_loss: 3.00207, obs_loss: 0.02789, reward_loss: 0.00001, value_loss: 0.00381 action_loss: 20.05017\n",
      "update_step:  67 model loss: 3.02537, kl_loss: 3.00129, obs_loss: 0.02408, reward_loss: 0.00001, value_loss: 0.00701 action_loss: 20.21448\n",
      "update_step:  68 model loss: 3.03792, kl_loss: 3.00139, obs_loss: 0.03652, reward_loss: 0.00001, value_loss: 0.00910 action_loss: 20.20950\n",
      "update_step:  69 model loss: 3.03508, kl_loss: 3.00247, obs_loss: 0.03260, reward_loss: 0.00001, value_loss: 0.00471 action_loss: 20.08234\n",
      "update_step:  70 model loss: 3.02089, kl_loss: 3.00136, obs_loss: 0.01952, reward_loss: 0.00000, value_loss: 0.00522 action_loss: 19.89731\n",
      "update_step:  71 model loss: 3.01707, kl_loss: 3.00116, obs_loss: 0.01590, reward_loss: 0.00001, value_loss: 0.00867 action_loss: 19.82081\n",
      "update_step:  72 model loss: 3.01484, kl_loss: 3.00059, obs_loss: 0.01424, reward_loss: 0.00001, value_loss: 0.00778 action_loss: 19.79966\n",
      "update_step:  73 model loss: 3.02358, kl_loss: 3.00067, obs_loss: 0.02290, reward_loss: 0.00001, value_loss: 0.00521 action_loss: 19.92550\n",
      "update_step:  74 model loss: 3.02382, kl_loss: 3.00148, obs_loss: 0.02232, reward_loss: 0.00001, value_loss: 0.00390 action_loss: 20.05989\n",
      "update_step:  75 model loss: 3.03250, kl_loss: 3.00085, obs_loss: 0.03164, reward_loss: 0.00000, value_loss: 0.00750 action_loss: 20.14581\n",
      "update_step:  76 model loss: 3.02167, kl_loss: 3.00046, obs_loss: 0.02120, reward_loss: 0.00001, value_loss: 0.00558 action_loss: 20.17803\n",
      "update_step:  77 model loss: 3.01821, kl_loss: 3.00175, obs_loss: 0.01646, reward_loss: 0.00001, value_loss: 0.00376 action_loss: 20.10476\n",
      "update_step:  78 model loss: 3.02209, kl_loss: 3.00155, obs_loss: 0.02054, reward_loss: 0.00000, value_loss: 0.00354 action_loss: 20.05760\n",
      "update_step:  79 model loss: 3.02402, kl_loss: 3.00236, obs_loss: 0.02166, reward_loss: 0.00001, value_loss: 0.00429 action_loss: 19.94427\n",
      "update_step:  80 model loss: 3.01634, kl_loss: 3.00208, obs_loss: 0.01425, reward_loss: 0.00001, value_loss: 0.00604 action_loss: 19.93308\n",
      "update_step:  81 model loss: 3.01783, kl_loss: 3.00074, obs_loss: 0.01708, reward_loss: 0.00001, value_loss: 0.00373 action_loss: 19.93848\n",
      "update_step:  82 model loss: 3.00676, kl_loss: 3.00000, obs_loss: 0.00676, reward_loss: 0.00000, value_loss: 0.00312 action_loss: 19.99229\n"
     ]
    }
   ],
   "source": [
    "for episode in range(seed_episodes, all_episodes):\n",
    "    # -----------------------------\n",
    "    #      経験を集める\n",
    "    # -----------------------------\n",
    "    start = time.time()\n",
    "    # 行動を決定するためのエージェントを宣言\n",
    "    policy = Agent(encoder, rssm.transition, action_model)\n",
    "\n",
    "    env = make_env()\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    # while not done:\n",
    "    action = policy(obs)\n",
    "    # 探索のためにガウス分布に従うノイズを加える(explaration noise)\n",
    "    action += np.random.normal(0, np.sqrt(action_noise_var),\n",
    "                                 env.action_space.shape[0])\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    #リプレイバッファに観測，行動，報酬，doneを格納\n",
    "    replay_buffer.push(obs, action, reward, terminated)\n",
    "\n",
    "    obs = next_obs\n",
    "    total_reward += reward\n",
    "\n",
    "    # 訓練時の報酬と経過時間をログとして表示\n",
    "    writer.add_scalar('total reward at train', total_reward, episode)\n",
    "    print('episode [%4d/%4d] is collected. Total reward is %f' %\n",
    "            (episode+1, all_episodes, total_reward))\n",
    "    print('elasped time for interaction: %.2fs' % (time.time() - start))\n",
    "\n",
    "    # NNのパラメータを更新する\n",
    "    start = time.time()\n",
    "    for update_step in range(collect_interval):\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        #  RSSM(trainsition_model, obs_model, reward_model)の更新 - Dynamics learning\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        observations, actions, rewards, _ = \\\n",
    "            replay_buffer.sample(batch_size, chunk_length)\n",
    "\n",
    "        # 観測を前処理し，RNNを用いたPyTorchでの学習のためにTensorの次元を調整\n",
    "        observations = preprocess_obs(observations)\n",
    "        observations = torch.as_tensor(observations, device=device)  # (B, T, H, W, C)\n",
    "        actions = torch.as_tensor(actions, device=device)  # (B, T, action dim)\n",
    "        rewards = torch.as_tensor(rewards, device=device)  # (B, T, 1)\n",
    "\n",
    "        observations = rearrange(observations, \"b t h w c -> t b c h w\")  # (T, B, C, H< W)\n",
    "        actions = rearrange(actions, \"b t d -> t b d\")  # (T, B, action dim)\n",
    "        rewards = rearrange(rewards, \"b t d -> t b d\")  # (T, B, 1)\n",
    "\n",
    "        # 観測をエンコーダで低次元のベクトルに変換\n",
    "        embedded_observations = encoder(\n",
    "            observations.reshape(-1, 3, 64, 64)).view(chunk_length, batch_size, -1)  # (T, B, 1024)\n",
    "\n",
    "        # 低次元の状態表現を保持しておくためのTensorを定義\n",
    "        states = torch.zeros(chunk_length, batch_size, state_dim, device=device)  # (T, B, state dim)\n",
    "        rnn_hiddens = torch.zeros(chunk_length, batch_size, rnn_hidden_dim, device=device)  # (T, B, rnn hidden dim)\n",
    "\n",
    "        # 低次元の状態表現は最初はゼロ初期化（timestep１つ分）\n",
    "        state = torch.zeros(batch_size, state_dim, device=device)\n",
    "        rnn_hidden = torch.zeros(batch_size, rnn_hidden_dim, device=device)\n",
    "\n",
    "        # 状態s_tの予測を行ってそのロスを計算する（priorとposteriorの間のKLダイバージェンス）\n",
    "        kl_loss = 0\n",
    "        for l in range(chunk_length-1):\n",
    "            next_state_prior, next_state_posterior, rnn_hidden = \\\n",
    "                rssm.transition(state, actions[l], rnn_hidden, embedded_observations[l+1])\n",
    "            state = next_state_posterior.rsample()\n",
    "            states[l+1] = state\n",
    "            rnn_hiddens[l+1] = rnn_hidden\n",
    "            kl = kl_divergence(next_state_prior, next_state_posterior).sum(dim=1) # WRITE ME （ヒント: kl_divergence()を使用）\n",
    "            kl_loss += kl.clamp(min=free_nats).mean()  # 原論文通り，KL誤差がfree_nats以下の時は無視\n",
    "        kl_loss /= (chunk_length - 1)\n",
    "\n",
    "        # states[0] and rnn_hiddens[0]はゼロ初期化なので以降では使わない\n",
    "        # states，rnn_hiddensは低次元の状態表現\n",
    "        states = states[1:]  # (T-1, B, state dim)\n",
    "        rnn_hiddens = rnn_hiddens[1:]  # (T-1, B, rnn hidden dim)\n",
    "\n",
    "        # 観測を再構成，また，報酬を予測\n",
    "        flatten_states = states.view(-1, state_dim)  # ((T-1) x B, state dim)\n",
    "        flatten_rnn_hiddens = rnn_hiddens.view(-1, rnn_hidden_dim)  # ((T-1) x B, rnn hidden dim)\n",
    "        recon_observations = rssm.observation(flatten_states, flatten_rnn_hiddens).view(chunk_length-1, batch_size, 3, 64, 64)  # (T-1, B, C, H, W)\n",
    "        predicted_rewards = rssm.reward(flatten_states, flatten_rnn_hiddens).view(chunk_length-1, batch_size, 1)  # (T-1, B, 1)\n",
    "\n",
    "        # 観測と報酬の予測誤差を計算\n",
    "        obs_loss = 0.5 * F.mse_loss(recon_observations, observations[1:], reduction='none').mean([0, 1]).sum()\n",
    "        reward_loss = 0.5 * F.mse_loss(predicted_rewards, rewards[:-1])\n",
    "\n",
    "        # 以上のロスを合わせて勾配降下で更新する\n",
    "        model_loss = kl_loss + obs_loss + reward_loss\n",
    "        model_optimizer.zero_grad()\n",
    "        model_loss.backward()\n",
    "        clip_grad_norm_(model_params, clip_grad_norm)\n",
    "        model_optimizer.step()\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        #  Action Model, Value　Modelの更新　- Behavior learning\n",
    "        # --------------------------------------------------\n",
    "        # Actor-Criticのロスで他のモデルを更新することはないので勾配の流れを一度遮断\n",
    "        # flatten_states, flatten_rnn_hiddensは RSSMから得られた低次元の状態表現を平坦化した値\n",
    "        flatten_states = flatten_states.detach()\n",
    "        flatten_rnn_hiddens = flatten_rnn_hiddens.detach()\n",
    "\n",
    "        # DreamerにおけるActor-Criticの更新のために，現在のモデルを用いた\n",
    "        # 数ステップ先の未来の状態予測を保持するためのTensorを用意\n",
    "        imagined_states = torch.zeros(imagination_horizon + 1,\n",
    "                                         *flatten_states.shape,\n",
    "                                          device=flatten_states.device)  # (horizon + 1, (T-1) x B, state dim)\n",
    "        imagined_rnn_hiddens = torch.zeros(imagination_horizon + 1,\n",
    "                                                *flatten_rnn_hiddens.shape,\n",
    "                                                device=flatten_rnn_hiddens.device)  # (horizon + 1, (T-1) x B, rnn hidden dim)\n",
    "\n",
    "        #　未来予測をして想像上の軌道を作る前に，最初の状態としては先ほどモデルの更新で使っていた\n",
    "        # リプレイバッファからサンプルされた観測データを取り込んだ上で推論した状態表現を使う\n",
    "        imagined_states[0] = flatten_states\n",
    "        imagined_rnn_hiddens[0] = flatten_rnn_hiddens\n",
    "\n",
    "        # open-loopで未来の状態予測を使い，想像上の軌道を作る\n",
    "        for h in range(1, imagination_horizon + 1):\n",
    "            # 行動はActionModelで決定．この行動はモデルのパラメータに対して微分可能で,\n",
    "            #　これを介してActionModelは更新される\n",
    "            actions = action_model(flatten_states, flatten_rnn_hiddens)  # ((T-1) x B, action dim)\n",
    "            flatten_states_prior, flatten_rnn_hiddens = rssm.transition.prior(rssm.transition.recurrent(flatten_states,\n",
    "                                                                   actions,\n",
    "                                                                   flatten_rnn_hiddens))\n",
    "            flatten_states = flatten_states_prior.rsample()\n",
    "            imagined_states[h] = flatten_states  # ((T-1) x B, state dim)\n",
    "            imagined_rnn_hiddens[h] = flatten_rnn_hiddens  # ((T-1) x B, rnn hidden dim)\n",
    "\n",
    "        # RSSMのreward_modelにより予測された架空の軌道に対する報酬を計算\n",
    "        flatten_imagined_states = imagined_states.view(-1, state_dim)  # ((hotizon+1)x(T-1)xB, state dim)\n",
    "        flatten_imagined_rnn_hiddens = imagined_rnn_hiddens.view(-1, rnn_hidden_dim)  # ((horizon+1)x(T-1)xB, rnn hidden dim)\n",
    "        imagined_rewards = \\\n",
    "            rssm.reward(flatten_imagined_states,\n",
    "                        flatten_imagined_rnn_hiddens).view(imagination_horizon + 1, -1)  # ((horizon+1), (T-1)xB, state dim)\n",
    "        imagined_values = \\\n",
    "            value_model(flatten_imagined_states,\n",
    "                        flatten_imagined_rnn_hiddens).view(imagination_horizon + 1, -1)  # ((horizon+1), (T-1)xB, rnn hidden dim)\n",
    "\n",
    "        # λ-returnのターゲットを計算(V_{\\lambda}(s_{\\tau})\n",
    "        # lambda_target_values  # WRITE ME （ヒント: lambda_target()を利用）  # ((horizon+1), (T-1)xB, 1)\n",
    "        lambda_target_values = lambda_target(imagined_rewards, imagined_values, gamma, lambda_)\n",
    "\n",
    "        # 価値関数の予測した価値が大きくなるようにActionModelを更新\n",
    "        # PyTorchの基本は勾配降下だが，今回は大きくしたいので-1をかける\n",
    "        action_loss = -lambda_target_values.mean()\n",
    "        action_optimizer.zero_grad()\n",
    "        action_loss.backward()\n",
    "        clip_grad_norm_(action_model.parameters(), clip_grad_norm)\n",
    "        action_optimizer.step()\n",
    "\n",
    "        # TD(λ)ベースの目的関数で価値関数を更新（価値関数のみを学習するため，学習しない変数のグラフは切っている．)\n",
    "        imagined_values = value_model(flatten_imagined_states.detach(), flatten_imagined_rnn_hiddens.detach()).view(imagination_horizon + 1, -1)# ((horizon+1), (T-1)xB, 1)\n",
    "        # value_loss = # WRITE ME （ヒント: 0.5 * F.mse_loss()を使用）\n",
    "        value_loss = 0.5 * F.mse_loss(imagined_values, lambda_target_values.detach())\n",
    "        value_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        clip_grad_norm_(value_model.parameters(), clip_grad_norm)\n",
    "        value_optimizer.step()\n",
    "\n",
    "        # ログをTensorBoardに出力\n",
    "        print('update_step: %3d model loss: %.5f, kl_loss: %.5f, '\n",
    "             'obs_loss: %.5f, reward_loss: %.5f, '\n",
    "             'value_loss: %.5f action_loss: %.5f'\n",
    "                % (update_step + 1, model_loss.item(), kl_loss.item(),\n",
    "                    obs_loss.item(), reward_loss.item(),\n",
    "                    value_loss.item(), action_loss.item()))\n",
    "        total_update_step = episode * collect_interval + update_step\n",
    "        writer.add_scalar('model loss', model_loss.item(), total_update_step)\n",
    "        writer.add_scalar('kl loss', kl_loss.item(), total_update_step)\n",
    "        writer.add_scalar('obs loss', obs_loss.item(), total_update_step)\n",
    "        writer.add_scalar('reward loss', reward_loss.item(), total_update_step)\n",
    "        writer.add_scalar('value loss', value_loss.item(), total_update_step)\n",
    "        writer.add_scalar('action loss', action_loss.item(), total_update_step)\n",
    "\n",
    "    print('elasped time for update: %.2fs' % (time.time() - start))\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    #    テストフェーズ．探索ノイズなしでの性能を評価する\n",
    "    # --------------------------------------------------------------\n",
    "    if (episode + 1) % test_interval == 0:\n",
    "        policy = Agent(encoder, rssm.transition, action_model)\n",
    "        start = time.time()\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        # while not done:\n",
    "        action = policy(obs, training=False)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        writer.add_scalar('total reward at test', total_reward, episode)\n",
    "        print('Total test reward at episode [%4d/%4d] is %f' %\n",
    "                (episode+1, all_episodes, total_reward))\n",
    "        print('elasped time for test: %.2fs' % (time.time() - start))\n",
    "\n",
    "    if (episode + 1) % model_save_interval == 0:\n",
    "        # 定期的に学習済みモデルのパラメータを保存する\n",
    "        model_log_dir = os.path.join(log_dir, 'episode_%04d' % (episode + 1))\n",
    "        os.makedirs(model_log_dir, exist_ok=True)\n",
    "        torch.save(encoder.state_dict(), os.path.join(model_log_dir, 'encoder.pth'))\n",
    "        torch.save(rssm.transition.state_dict(), os.path.join(model_log_dir, 'rssm.pth'))\n",
    "        torch.save(rssm.observation.state_dict(), os.path.join(model_log_dir, 'obs_model.pth'))\n",
    "        torch.save(rssm.reward.state_dict(), os.path.join(model_log_dir, 'reward_model.pth'))\n",
    "        torch.save(value_model.state_dict(), os.path.join(model_log_dir, 'value_model.pth'))\n",
    "        torch.save(action_model.state_dict(), os.path.join(model_log_dir, 'action_model.pth'))\n",
    "    del env\n",
    "    gc.collect()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7e85c-8067-4e4c-a23b-c569dfbd267f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
